/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py:401: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  num_classes = len(np.unique(np.array(dataset.train[:][1])))
/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py:401: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  num_classes = len(np.unique(np.array(dataset.train[:][1])))
/afs/crc.nd.edu/user/p/psoga/.conda/envs/gnn/lib/python3.10/site-packages/dgl/heterograph.py:3719: DGLWarning: DGLGraph.adjacency_matrix_scipy is deprecated. Please replace it with:

	DGLGraph.adjacency_matrix(transpose, scipy_fmt="csr").

  dgl_warning('DGLGraph.adjacency_matrix_scipy is deprecated. '
cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
[I] Loading dataset CYCLES...
train, test, val sizes : 9000 10000 1000
[I] Finished loading.
[I] Data load time: 14.1699s
learned_pos_enc
Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
Using matrix: E
MODEL DETAILS:

MODEL/Total parameters: GatedGCN 105823
Training Graphs:  200
Validation Graphs:  1000
Test Graphs:  10000
Number of Classes:  2
learned_pos_enc
Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
Using matrix: E
Epoch 1/1000
	Time: 1457.36s, LR: 0.00010, Train Loss: 3.0595, Train Acc: 0.5000,
                        Val Loss: 0.8491, Val Acc: 0.5000, Test Acc: 0.5000
Epoch 2/1000
	Time: 1461.63s, LR: 0.00010, Train Loss: 1.6562, Train Acc: 0.5000,
                        Val Loss: 0.7169, Val Acc: 0.5020, Test Acc: 0.4991
Epoch 3/1000
	Time: 1470.85s, LR: 0.00010, Train Loss: 0.8944, Train Acc: 0.4550,
                        Val Loss: 0.7642, Val Acc: 0.4890, Test Acc: 0.4959
Epoch 4/1000
	Time: 1471.52s, LR: 0.00010, Train Loss: 0.8217, Train Acc: 0.5400,
                        Val Loss: 0.7622, Val Acc: 0.4820, Test Acc: 0.4939
Epoch 5/1000
	Time: 1470.61s, LR: 0.00010, Train Loss: 0.7808, Train Acc: 0.5250,
                        Val Loss: 0.7642, Val Acc: 0.5080, Test Acc: 0.4988
Epoch 6/1000
	Time: 1468.83s, LR: 0.00010, Train Loss: 0.7845, Train Acc: 0.4400,
                        Val Loss: 0.8261, Val Acc: 0.5080, Test Acc: 0.5030
Epoch 7/1000
	Time: 1460.68s, LR: 0.00010, Train Loss: 0.7364, Train Acc: 0.5200,
                        Val Loss: 0.8071, Val Acc: 0.5110, Test Acc: 0.5080
Epoch 8/1000
	Time: 1471.99s, LR: 0.00010, Train Loss: 0.7056, Train Acc: 0.5450,
                        Val Loss: 0.7911, Val Acc: 0.5100, Test Acc: 0.5093
Epoch 9/1000
	Time: 1469.14s, LR: 0.00010, Train Loss: 0.7202, Train Acc: 0.5100,
                        Val Loss: 0.7458, Val Acc: 0.5230, Test Acc: 0.5116
Epoch 10/1000
	Time: 1470.99s, LR: 0.00010, Train Loss: 0.6790, Train Acc: 0.6050,
                        Val Loss: 0.7329, Val Acc: 0.5260, Test Acc: 0.5198
Epoch 11/1000
	Time: 1470.19s, LR: 0.00010, Train Loss: 0.6850, Train Acc: 0.6050,
                        Val Loss: 0.7367, Val Acc: 0.5350, Test Acc: 0.5144
Epoch 12/1000
	Time: 1469.68s, LR: 0.00010, Train Loss: 0.7144, Train Acc: 0.5100,
                        Val Loss: 0.7816, Val Acc: 0.5130, Test Acc: 0.5127
Epoch 13/1000
	Time: 1462.04s, LR: 0.00010, Train Loss: 0.7018, Train Acc: 0.5300,
                        Val Loss: 0.7930, Val Acc: 0.5330, Test Acc: 0.5171
Epoch 00013: reducing learning rate of group 0 to 5.0000e-05.
Epoch 14/1000
	Time: 1463.78s, LR: 0.00005, Train Loss: 0.6875, Train Acc: 0.5750,
                        Val Loss: 0.7913, Val Acc: 0.5260, Test Acc: 0.5153
Epoch 15/1000
	Time: 1470.18s, LR: 0.00005, Train Loss: 0.6840, Train Acc: 0.5750,
                        Val Loss: 0.7915, Val Acc: 0.5160, Test Acc: 0.5225
Epoch 16/1000
	Time: 1468.65s, LR: 0.00005, Train Loss: 0.6995, Train Acc: 0.5700,
                        Val Loss: 0.7731, Val Acc: 0.5280, Test Acc: 0.5176
Epoch 17/1000
	Time: 1463.77s, LR: 0.00005, Train Loss: 0.6928, Train Acc: 0.5600,
                        Val Loss: 0.7649, Val Acc: 0.5150, Test Acc: 0.5192
Epoch 18/1000
	Time: 1469.47s, LR: 0.00005, Train Loss: 0.6821, Train Acc: 0.5950,
                        Val Loss: 0.7819, Val Acc: 0.5110, Test Acc: 0.5143
Epoch 19/1000
	Time: 1469.57s, LR: 0.00005, Train Loss: 0.6926, Train Acc: 0.5400,
                        Val Loss: 0.7997, Val Acc: 0.5190, Test Acc: 0.5184
Epoch 20/1000
	Time: 1469.79s, LR: 0.00005, Train Loss: 0.6936, Train Acc: 0.5550,
                        Val Loss: 0.9232, Val Acc: 0.5050, Test Acc: 0.5097
Epoch 21/1000
	Time: 1466.62s, LR: 0.00005, Train Loss: 0.6786, Train Acc: 0.5950,
                        Val Loss: 1.0985, Val Acc: 0.5030, Test Acc: 0.5039
Epoch 22/1000
	Time: 1469.17s, LR: 0.00005, Train Loss: 0.6426, Train Acc: 0.6550,
                        Val Loss: 1.2522, Val Acc: 0.5060, Test Acc: 0.5066
Epoch 23/1000
	Time: 1469.91s, LR: 0.00005, Train Loss: 0.7101, Train Acc: 0.5200,
                        Val Loss: 1.5835, Val Acc: 0.5130, Test Acc: 0.5117
Epoch 24/1000
	Time: 1470.89s, LR: 0.00005, Train Loss: 0.6953, Train Acc: 0.5250,
                        Val Loss: 1.4881, Val Acc: 0.5430, Test Acc: 0.5163
Epoch 00024: reducing learning rate of group 0 to 2.5000e-05.
Epoch 25/1000
	Time: 1470.39s, LR: 0.00003, Train Loss: 0.6910, Train Acc: 0.5900,
                        Val Loss: 1.2364, Val Acc: 0.5430, Test Acc: 0.5183
Epoch 26/1000
	Time: 1470.12s, LR: 0.00003, Train Loss: 0.6907, Train Acc: 0.5350,
                        Val Loss: 1.1586, Val Acc: 0.5240, Test Acc: 0.5142
Epoch 27/1000
	Time: 1469.60s, LR: 0.00003, Train Loss: 0.6950, Train Acc: 0.5450,
                        Val Loss: 1.1817, Val Acc: 0.5240, Test Acc: 0.5146
Epoch 28/1000
	Time: 1470.87s, LR: 0.00003, Train Loss: 0.6867, Train Acc: 0.5450,
                        Val Loss: 1.0422, Val Acc: 0.5260, Test Acc: 0.5145
Epoch 29/1000
	Time: 1469.37s, LR: 0.00003, Train Loss: 0.6839, Train Acc: 0.5550,
                        Val Loss: 0.9552, Val Acc: 0.5390, Test Acc: 0.5176
Epoch 30/1000
	Time: 1470.45s, LR: 0.00003, Train Loss: 0.6959, Train Acc: 0.5350,
                        Val Loss: 0.8043, Val Acc: 0.5010, Test Acc: 0.5017
Epoch 31/1000
	Time: 1469.74s, LR: 0.00003, Train Loss: 0.7123, Train Acc: 0.5200,
                        Val Loss: 0.8516, Val Acc: 0.5080, Test Acc: 0.5020
Epoch 32/1000
	Time: 1470.88s, LR: 0.00003, Train Loss: 0.6910, Train Acc: 0.5250,
                        Val Loss: 0.9433, Val Acc: 0.5150, Test Acc: 0.5071
Epoch 33/1000
	Time: 1457.31s, LR: 0.00003, Train Loss: 0.7149, Train Acc: 0.5300,
                        Val Loss: 1.0856, Val Acc: 0.5000, Test Acc: 0.5071
Epoch 34/1000
	Time: 1455.73s, LR: 0.00003, Train Loss: 0.6828, Train Acc: 0.5800,
                        Val Loss: 1.0636, Val Acc: 0.5090, Test Acc: 0.5122
Epoch 35/1000
	Time: 1453.83s, LR: 0.00003, Train Loss: 0.6835, Train Acc: 0.5750,
                        Val Loss: 0.9955, Val Acc: 0.5190, Test Acc: 0.5138
Epoch 00035: reducing learning rate of group 0 to 1.2500e-05.
Epoch 36/1000
	Time: 1453.52s, LR: 0.00001, Train Loss: 0.6844, Train Acc: 0.5800,
                        Val Loss: 0.9645, Val Acc: 0.5350, Test Acc: 0.5155
Epoch 37/1000
	Time: 1462.10s, LR: 0.00001, Train Loss: 0.6927, Train Acc: 0.5300,
                        Val Loss: 0.9082, Val Acc: 0.5300, Test Acc: 0.5140
Epoch 38/1000
	Time: 1468.73s, LR: 0.00001, Train Loss: 0.7182, Train Acc: 0.5100,
                        Val Loss: 0.8954, Val Acc: 0.5130, Test Acc: 0.5113
Epoch 39/1000
	Time: 1469.17s, LR: 0.00001, Train Loss: 0.6919, Train Acc: 0.5850,
                        Val Loss: 0.8596, Val Acc: 0.5240, Test Acc: 0.5121
Epoch 40/1000
	Time: 1469.40s, LR: 0.00001, Train Loss: 0.6856, Train Acc: 0.5450,
                        Val Loss: 0.8486, Val Acc: 0.5160, Test Acc: 0.5137
Epoch 41/1000
	Time: 1469.91s, LR: 0.00001, Train Loss: 0.6979, Train Acc: 0.4850,
                        Val Loss: 0.8363, Val Acc: 0.5300, Test Acc: 0.5150
Epoch 42/1000
	Time: 1466.85s, LR: 0.00001, Train Loss: 0.7033, Train Acc: 0.5150,
                        Val Loss: 0.8465, Val Acc: 0.5120, Test Acc: 0.5131
Epoch 43/1000
	Time: 1464.07s, LR: 0.00001, Train Loss: 0.6932, Train Acc: 0.5550,
                        Val Loss: 0.8410, Val Acc: 0.5160, Test Acc: 0.5122
Epoch 44/1000
	Time: 1470.37s, LR: 0.00001, Train Loss: 0.6796, Train Acc: 0.5400,
                        Val Loss: 0.8604, Val Acc: 0.5200, Test Acc: 0.5149
Epoch 45/1000
	Time: 1470.80s, LR: 0.00001, Train Loss: 0.6964, Train Acc: 0.5450,
                        Val Loss: 0.8062, Val Acc: 0.5170, Test Acc: 0.5138
Epoch 46/1000
	Time: 1469.71s, LR: 0.00001, Train Loss: 0.6998, Train Acc: 0.4900,
                        Val Loss: 0.7988, Val Acc: 0.5390, Test Acc: 0.5212
Epoch 00046: reducing learning rate of group 0 to 6.2500e-06.
Epoch 47/1000
	Time: 1470.02s, LR: 0.00001, Train Loss: 0.6918, Train Acc: 0.5100,
                        Val Loss: 0.7971, Val Acc: 0.5270, Test Acc: 0.5217
Epoch 48/1000
	Time: 1468.87s, LR: 0.00001, Train Loss: 0.6940, Train Acc: 0.5700,
                        Val Loss: 0.7702, Val Acc: 0.5220, Test Acc: 0.5156
Epoch 49/1000
	Time: 1469.74s, LR: 0.00001, Train Loss: 0.6970, Train Acc: 0.5200,
                        Val Loss: 0.7753, Val Acc: 0.5210, Test Acc: 0.5106
Epoch 50/1000
	Time: 1470.51s, LR: 0.00001, Train Loss: 0.7018, Train Acc: 0.5200,
                        Val Loss: 0.7704, Val Acc: 0.5330, Test Acc: 0.5150
Epoch 51/1000
	Time: 1469.15s, LR: 0.00001, Train Loss: 0.6969, Train Acc: 0.4750,
                        Val Loss: 0.7795, Val Acc: 0.5350, Test Acc: 0.5177
Epoch 52/1000
	Time: 1468.73s, LR: 0.00001, Train Loss: 0.6927, Train Acc: 0.5550,
                        Val Loss: 0.8437, Val Acc: 0.5030, Test Acc: 0.5104
Epoch 53/1000
	Time: 1460.73s, LR: 0.00001, Train Loss: 0.6909, Train Acc: 0.5350,
                        Val Loss: 0.8217, Val Acc: 0.5120, Test Acc: 0.5139
Epoch 54/1000
	Time: 1460.13s, LR: 0.00001, Train Loss: 0.6528, Train Acc: 0.6100,
                        Val Loss: 0.8601, Val Acc: 0.5050, Test Acc: 0.5102
Epoch 55/1000
	Time: 1466.17s, LR: 0.00001, Train Loss: 0.6969, Train Acc: 0.5800,
                        Val Loss: 0.7914, Val Acc: 0.5100, Test Acc: 0.5151
Epoch 56/1000
	Time: 1468.25s, LR: 0.00001, Train Loss: 0.6725, Train Acc: 0.6000,
                        Val Loss: 0.7773, Val Acc: 0.5240, Test Acc: 0.5121
Epoch 57/1000
	Time: 1467.40s, LR: 0.00001, Train Loss: 0.6708, Train Acc: 0.5450,
                        Val Loss: 0.7799, Val Acc: 0.5160, Test Acc: 0.5137
Epoch 00057: reducing learning rate of group 0 to 3.1250e-06.
Epoch 58/1000
	Time: 1467.27s, LR: 0.00000, Train Loss: 0.6891, Train Acc: 0.5150,
                        Val Loss: 0.7722, Val Acc: 0.5340, Test Acc: 0.5168
Epoch 59/1000
	Time: 1468.90s, LR: 0.00000, Train Loss: 0.6982, Train Acc: 0.5350,
                        Val Loss: 0.7607, Val Acc: 0.5240, Test Acc: 0.5142
Epoch 60/1000
	Time: 1469.60s, LR: 0.00000, Train Loss: 0.6848, Train Acc: 0.5850,
                        Val Loss: 0.7646, Val Acc: 0.5240, Test Acc: 0.5159
Epoch 61/1000
	Time: 1469.54s, LR: 0.00000, Train Loss: 0.6906, Train Acc: 0.5200,
                        Val Loss: 0.7704, Val Acc: 0.5410, Test Acc: 0.5173
Epoch 62/1000
	Time: 1469.51s, LR: 0.00000, Train Loss: 0.7023, Train Acc: 0.5500,
                        Val Loss: 0.8056, Val Acc: 0.5190, Test Acc: 0.5154
Epoch 63/1000
	Time: 1471.16s, LR: 0.00000, Train Loss: 0.6782, Train Acc: 0.5550,
                        Val Loss: 0.8580, Val Acc: 0.5000, Test Acc: 0.5060
Epoch 64/1000
	Time: 1471.61s, LR: 0.00000, Train Loss: 0.6891, Train Acc: 0.5600,
                        Val Loss: 0.8711, Val Acc: 0.5010, Test Acc: 0.5033
Epoch 65/1000
	Time: 1471.38s, LR: 0.00000, Train Loss: 0.6714, Train Acc: 0.6000,
                        Val Loss: 0.8043, Val Acc: 0.5120, Test Acc: 0.5107
Epoch 66/1000
	Time: 1471.13s, LR: 0.00000, Train Loss: 0.6886, Train Acc: 0.5350,
                        Val Loss: 0.7848, Val Acc: 0.5180, Test Acc: 0.5125
Epoch 67/1000
	Time: 1472.19s, LR: 0.00000, Train Loss: 0.6850, Train Acc: 0.5300,
                        Val Loss: 0.7977, Val Acc: 0.5330, Test Acc: 0.5161
Epoch 68/1000
	Time: 1470.10s, LR: 0.00000, Train Loss: 0.7058, Train Acc: 0.5100,
                        Val Loss: 0.8003, Val Acc: 0.5400, Test Acc: 0.5163
Epoch 00068: reducing learning rate of group 0 to 1.5625e-06.
Epoch 69/1000
	Time: 1468.51s, LR: 0.00000, Train Loss: 0.7011, Train Acc: 0.5550,
                        Val Loss: 0.8010, Val Acc: 0.5330, Test Acc: 0.5186
Epoch 70/1000
	Time: 1471.09s, LR: 0.00000, Train Loss: 0.6909, Train Acc: 0.5500,
                        Val Loss: 0.8156, Val Acc: 0.5120, Test Acc: 0.5133
Epoch 71/1000
	Time: 1459.72s, LR: 0.00000, Train Loss: 0.7065, Train Acc: 0.4950,
                        Val Loss: 0.8055, Val Acc: 0.5120, Test Acc: 0.5172
Epoch 72/1000
	Time: 1457.10s, LR: 0.00000, Train Loss: 0.6751, Train Acc: 0.5600,
                        Val Loss: 0.8217, Val Acc: 0.5150, Test Acc: 0.5141
Epoch 73/1000
	Time: 1462.90s, LR: 0.00000, Train Loss: 0.6764, Train Acc: 0.5800,
                        Val Loss: 0.8039, Val Acc: 0.5460, Test Acc: 0.5172
Epoch 74/1000
	Time: 1470.43s, LR: 0.00000, Train Loss: 0.6918, Train Acc: 0.5550,
                        Val Loss: 0.7835, Val Acc: 0.5300, Test Acc: 0.5170
Epoch 75/1000
	Time: 1470.62s, LR: 0.00000, Train Loss: 0.6772, Train Acc: 0.5800,
                        Val Loss: 0.7913, Val Acc: 0.5420, Test Acc: 0.5148
Epoch 76/1000
	Time: 1470.68s, LR: 0.00000, Train Loss: 0.7189, Train Acc: 0.4550,
                        Val Loss: 0.7883, Val Acc: 0.5380, Test Acc: 0.5168
Epoch 77/1000
	Time: 1471.25s, LR: 0.00000, Train Loss: 0.6910, Train Acc: 0.5600,
                        Val Loss: 0.7883, Val Acc: 0.5370, Test Acc: 0.5150
Epoch 78/1000
	Time: 1470.38s, LR: 0.00000, Train Loss: 0.6622, Train Acc: 0.5650,
                        Val Loss: 0.7800, Val Acc: 0.5230, Test Acc: 0.5117
Epoch 79/1000
	Time: 1470.38s, LR: 0.00000, Train Loss: 0.6948, Train Acc: 0.5450,
                        Val Loss: 0.7835, Val Acc: 0.5330, Test Acc: 0.5145
Epoch 00079: reducing learning rate of group 0 to 7.8125e-07.

!! LR EQUAL TO MIN LR SET.
Test Accuracy: 0.5145
Train Accuracy: 0.5400
Convergence Time (Epochs): 78.0000
TOTAL TIME TAKEN: 117258.9364s
AVG TIME PER EPOCH: 1467.6633s
