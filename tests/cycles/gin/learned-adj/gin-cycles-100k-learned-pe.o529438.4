/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py:391: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  num_classes = len(np.unique(np.array(dataset.train[:][1])))
/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py:391: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  num_classes = len(np.unique(np.array(dataset.train[:][1])))
cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
[I] Loading dataset CYCLES...
train, test, val sizes : 9000 10000 1000
[I] Finished loading.
[I] Data load time: 15.3345s
Using learned automata position encoding
MODEL DETAILS:

MODEL/Total parameters: GIN 103504
Training Graphs:  200
Validation Graphs:  1000
Test Graphs:  10000
Number of Classes:  2
Using learned automata position encoding
Epoch 1/1000
	Time: 1125.86s, LR: 0.00010, Train Loss: 16.2412, Train Acc: 0.5550,
                        Val Loss: 1.0742, Val Acc: 0.5030, Test Acc: 0.5004
Epoch 2/1000
	Time: 1131.92s, LR: 0.00010, Train Loss: 6.4692, Train Acc: 0.5550,
                        Val Loss: 7.5667, Val Acc: 0.5000, Test Acc: 0.5000
Epoch 3/1000
	Time: 1168.33s, LR: 0.00010, Train Loss: 3.3097, Train Acc: 0.5500,
                        Val Loss: 11.0346, Val Acc: 0.5000, Test Acc: 0.5000
Epoch 4/1000
	Time: 1165.07s, LR: 0.00010, Train Loss: 1.5800, Train Acc: 0.6150,
                        Val Loss: 12.8739, Val Acc: 0.5000, Test Acc: 0.5000
Epoch 5/1000
	Time: 1163.67s, LR: 0.00010, Train Loss: 1.4976, Train Acc: 0.6850,
                        Val Loss: 8.3045, Val Acc: 0.5000, Test Acc: 0.5001
Epoch 6/1000
	Time: 1166.75s, LR: 0.00010, Train Loss: 1.4430, Train Acc: 0.6200,
                        Val Loss: 4.6231, Val Acc: 0.5210, Test Acc: 0.5205
Epoch 7/1000
	Time: 1167.05s, LR: 0.00010, Train Loss: 1.3266, Train Acc: 0.6800,
                        Val Loss: 2.8546, Val Acc: 0.5890, Test Acc: 0.5844
Epoch 8/1000
	Time: 1165.70s, LR: 0.00010, Train Loss: 2.0107, Train Acc: 0.6700,
                        Val Loss: 1.5743, Val Acc: 0.6780, Test Acc: 0.6788
Epoch 9/1000
	Time: 1167.56s, LR: 0.00010, Train Loss: 1.6672, Train Acc: 0.6050,
                        Val Loss: 1.6083, Val Acc: 0.6670, Test Acc: 0.6781
Epoch 10/1000
	Time: 1167.07s, LR: 0.00010, Train Loss: 1.5982, Train Acc: 0.6650,
                        Val Loss: 8.1209, Val Acc: 0.5000, Test Acc: 0.5016
Epoch 11/1000
	Time: 1167.49s, LR: 0.00010, Train Loss: 1.6042, Train Acc: 0.6500,
                        Val Loss: 3.4405, Val Acc: 0.5610, Test Acc: 0.5738
Epoch 12/1000
	Time: 1169.46s, LR: 0.00010, Train Loss: 1.7164, Train Acc: 0.6050,
                        Val Loss: 3.8182, Val Acc: 0.5690, Test Acc: 0.5842
Epoch 00012: reducing learning rate of group 0 to 5.0000e-05.
Epoch 13/1000
	Time: 1165.26s, LR: 0.00005, Train Loss: 1.3421, Train Acc: 0.6700,
                        Val Loss: 1.8926, Val Acc: 0.6240, Test Acc: 0.6473
Epoch 14/1000
	Time: 1165.20s, LR: 0.00005, Train Loss: 1.0322, Train Acc: 0.6950,
                        Val Loss: 2.6485, Val Acc: 0.4970, Test Acc: 0.5127
Epoch 15/1000
	Time: 1165.22s, LR: 0.00005, Train Loss: 1.1999, Train Acc: 0.5900,
                        Val Loss: 8.0952, Val Acc: 0.5020, Test Acc: 0.5035
Epoch 16/1000
	Time: 1162.24s, LR: 0.00005, Train Loss: 1.1956, Train Acc: 0.6600,
                        Val Loss: 2.1383, Val Acc: 0.5720, Test Acc: 0.6023
Epoch 17/1000
	Time: 1165.25s, LR: 0.00005, Train Loss: 0.9920, Train Acc: 0.6050,
                        Val Loss: 10.6885, Val Acc: 0.4940, Test Acc: 0.4993
Epoch 18/1000
	Time: 1154.64s, LR: 0.00005, Train Loss: 1.1618, Train Acc: 0.6200,
                        Val Loss: 5.8647, Val Acc: 0.5030, Test Acc: 0.5077
Epoch 19/1000
	Time: 1111.45s, LR: 0.00005, Train Loss: 1.1441, Train Acc: 0.6550,
                        Val Loss: 4.8250, Val Acc: 0.5050, Test Acc: 0.5081
Epoch 20/1000
	Time: 1108.03s, LR: 0.00005, Train Loss: 0.9413, Train Acc: 0.6500,
                        Val Loss: 2.1385, Val Acc: 0.6340, Test Acc: 0.6246
Epoch 21/1000
	Time: 1108.85s, LR: 0.00005, Train Loss: 1.1061, Train Acc: 0.6100,
                        Val Loss: 1.6173, Val Acc: 0.6100, Test Acc: 0.6168
Epoch 22/1000
	Time: 1109.24s, LR: 0.00005, Train Loss: 1.0655, Train Acc: 0.6700,
                        Val Loss: 1.5230, Val Acc: 0.5940, Test Acc: 0.5989
Epoch 23/1000
	Time: 1108.97s, LR: 0.00005, Train Loss: 1.0009, Train Acc: 0.6700,
                        Val Loss: 4.4630, Val Acc: 0.4970, Test Acc: 0.5003
Epoch 00023: reducing learning rate of group 0 to 2.5000e-05.
Epoch 24/1000
	Time: 1109.43s, LR: 0.00003, Train Loss: 0.9066, Train Acc: 0.6900,
                        Val Loss: 2.0121, Val Acc: 0.5920, Test Acc: 0.5689
Epoch 25/1000
	Time: 1108.90s, LR: 0.00003, Train Loss: 1.0208, Train Acc: 0.6350,
                        Val Loss: 1.3497, Val Acc: 0.6560, Test Acc: 0.6407
Epoch 26/1000
	Time: 1109.01s, LR: 0.00003, Train Loss: 0.7596, Train Acc: 0.6950,
                        Val Loss: 2.0414, Val Acc: 0.6010, Test Acc: 0.6226
Epoch 27/1000
	Time: 1108.73s, LR: 0.00003, Train Loss: 0.7972, Train Acc: 0.6850,
                        Val Loss: 1.5159, Val Acc: 0.6260, Test Acc: 0.6422
Epoch 28/1000
	Time: 1109.12s, LR: 0.00003, Train Loss: 0.8115, Train Acc: 0.6450,
                        Val Loss: 1.3922, Val Acc: 0.6300, Test Acc: 0.6245
Epoch 29/1000
	Time: 1109.06s, LR: 0.00003, Train Loss: 0.8396, Train Acc: 0.6600,
                        Val Loss: 2.1213, Val Acc: 0.5060, Test Acc: 0.5206
Epoch 30/1000
	Time: 1108.87s, LR: 0.00003, Train Loss: 0.6993, Train Acc: 0.7150,
                        Val Loss: 4.5915, Val Acc: 0.4970, Test Acc: 0.5004
Epoch 31/1000
	Time: 1109.41s, LR: 0.00003, Train Loss: 0.7287, Train Acc: 0.7050,
                        Val Loss: 4.1594, Val Acc: 0.4970, Test Acc: 0.5018
Epoch 32/1000
	Time: 1109.70s, LR: 0.00003, Train Loss: 0.7015, Train Acc: 0.7200,
                        Val Loss: 4.5344, Val Acc: 0.4960, Test Acc: 0.5001
Epoch 33/1000
	Time: 1109.22s, LR: 0.00003, Train Loss: 0.8630, Train Acc: 0.6500,
                        Val Loss: 1.5077, Val Acc: 0.5440, Test Acc: 0.5384
Epoch 34/1000
	Time: 1109.44s, LR: 0.00003, Train Loss: 0.8644, Train Acc: 0.7000,
                        Val Loss: 6.3675, Val Acc: 0.5070, Test Acc: 0.5072
Epoch 00034: reducing learning rate of group 0 to 1.2500e-05.
Epoch 35/1000
	Time: 1108.88s, LR: 0.00001, Train Loss: 0.8377, Train Acc: 0.7250,
                        Val Loss: 2.5220, Val Acc: 0.5260, Test Acc: 0.5348
Epoch 36/1000
	Time: 1109.46s, LR: 0.00001, Train Loss: 0.6336, Train Acc: 0.7200,
                        Val Loss: 1.2308, Val Acc: 0.5790, Test Acc: 0.5970
Epoch 37/1000
	Time: 1109.05s, LR: 0.00001, Train Loss: 0.7828, Train Acc: 0.6750,
                        Val Loss: 1.2853, Val Acc: 0.5410, Test Acc: 0.5541
Epoch 38/1000
	Time: 1114.70s, LR: 0.00001, Train Loss: 0.7710, Train Acc: 0.6850,
                        Val Loss: 1.6881, Val Acc: 0.5380, Test Acc: 0.5456
Epoch 39/1000
	Time: 1115.86s, LR: 0.00001, Train Loss: 0.7434, Train Acc: 0.7050,
                        Val Loss: 1.2515, Val Acc: 0.6040, Test Acc: 0.6012
-----------------------------------------------------------------------------------------
Max_time for training elapsed 12.00 hours, so stopping
Test Accuracy: 0.6012
Train Accuracy: 0.6250
Convergence Time (Epochs): 38.0000
TOTAL TIME TAKEN: 45203.9315s
AVG TIME PER EPOCH: 1133.5675s
