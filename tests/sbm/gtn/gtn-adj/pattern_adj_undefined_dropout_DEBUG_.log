2022-07-26 00:22:35,921:main_utils.py:38 -            gpu_setup(): cuda available with GPU: NVIDIA TITAN X (Pascal)
2022-07-26 00:22:59,191:pe_layer.py:45 -             __init__(): pos_enc
2022-07-26 00:22:59,191:pe_layer.py:76 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-07-26 00:22:59,191:pe_layer.py:78 -             __init__(): Using matrix: A
2022-07-26 00:22:59,192:pe_layer.py:79 -             __init__(): Matrix power: 1
2022-07-26 00:22:59,213:main_utils.py:52 -     view_model_param(): MODEL DETAILS:

2022-07-26 00:22:59,216:main_utils.py:57 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 733542
2022-07-26 00:22:59,216:main_SBMs_node_classification.py:52 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
