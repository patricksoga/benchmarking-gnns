2022-08-22 10:42:20,507:main_utils.py:39 -            gpu_setup(): cuda available with GPU: Quadro RTX 6000
2022-08-22 10:42:30,978:main_CYCLES_graph_classification.py:305 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 10, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/CYCLES_CYCLES/GraphTransformer/pos_enc/b25-bnorm-alt/10_DEBUG.log', 'device': device(type='cuda'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-22 10:42:30,978:main_CYCLES_graph_classification.py:306 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 10}
2022-08-22 10:42:30,979:pe_layer.py:54 -             __init__(): rand_pos_enc
2022-08-22 10:42:32,426:pe_layer.py:93 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-22 10:42:32,426:pe_layer.py:98 -             __init__(): Using matrix: A
2022-08-22 10:42:32,426:pe_layer.py:99 -             __init__(): Matrix power: 1
2022-08-22 10:42:32,436:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-22 10:42:32,438:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523653
2022-08-22 10:42:32,438:pe_layer.py:54 -             __init__(): rand_pos_enc
2022-08-22 10:42:32,438:pe_layer.py:93 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-22 10:42:32,439:pe_layer.py:98 -             __init__(): Using matrix: A
2022-08-22 10:42:32,439:pe_layer.py:99 -             __init__(): Matrix power: 1
2022-08-22 10:42:32,451:main_CYCLES_graph_classification.py:60 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (10).
2022-08-22 10:42:51,768:main_CYCLES_graph_classification.py:62 -   train_val_pipeline(): Time PE:19.33008575439453
2022-08-22 10:42:51,825:main_CYCLES_graph_classification.py:93 -   train_val_pipeline(): Training Graphs: 200
2022-08-22 10:42:51,825:main_CYCLES_graph_classification.py:94 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-22 10:42:51,825:main_CYCLES_graph_classification.py:95 -   train_val_pipeline(): Test Graphs: 10000
2022-08-22 10:42:51,826:main_CYCLES_graph_classification.py:96 -   train_val_pipeline(): Number of Classes: 2
2022-08-22 10:42:51,830:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 1/1000
2022-08-22 10:43:12,578:main_CYCLES_graph_classification.py:137 -   train_val_pipeline(): Saving best model with test accuracy: 0.5288 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_10_10_10h42m30s_on_Aug_22_2022/MODELS_
2022-08-22 10:43:12,579:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.75s, LR: 0.00050, Train Loss: 0.8736, Train Acc: 0.5450,
                        Val Loss: 1.6534, Val Acc: 0.5330, Test Acc: 0.5288
2022-08-22 10:43:12,579:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 2/1000
2022-08-22 10:43:33,027:main_CYCLES_graph_classification.py:137 -   train_val_pipeline(): Saving best model with test accuracy: 0.6499 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_10_10_10h42m30s_on_Aug_22_2022/MODELS_
2022-08-22 10:43:33,028:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.45s, LR: 0.00050, Train Loss: 0.6369, Train Acc: 0.6750,
                        Val Loss: 0.6279, Val Acc: 0.6730, Test Acc: 0.6499
2022-08-22 10:43:33,028:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 3/1000
2022-08-22 10:43:53,273:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.24s, LR: 0.00050, Train Loss: 0.5803, Train Acc: 0.6600,
                        Val Loss: 0.7269, Val Acc: 0.5460, Test Acc: 0.5414
2022-08-22 10:43:53,273:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 4/1000
2022-08-22 10:44:13,643:main_CYCLES_graph_classification.py:137 -   train_val_pipeline(): Saving best model with test accuracy: 0.7304 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_10_10_10h42m30s_on_Aug_22_2022/MODELS_
2022-08-22 10:44:13,644:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.37s, LR: 0.00050, Train Loss: 0.5249, Train Acc: 0.7050,
                        Val Loss: 0.5791, Val Acc: 0.7410, Test Acc: 0.7304
2022-08-22 10:44:13,644:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 5/1000
2022-08-22 10:44:33,843:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.20s, LR: 0.00050, Train Loss: 0.5307, Train Acc: 0.7250,
                        Val Loss: 0.7341, Val Acc: 0.6420, Test Acc: 0.6324
2022-08-22 10:44:33,844:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 6/1000
2022-08-22 10:44:54,027:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.18s, LR: 0.00050, Train Loss: 0.4869, Train Acc: 0.7450,
                        Val Loss: 0.7517, Val Acc: 0.6440, Test Acc: 0.6457
2022-08-22 10:44:54,028:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 7/1000
2022-08-22 10:45:14,159:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.13s, LR: 0.00050, Train Loss: 0.4854, Train Acc: 0.7400,
                        Val Loss: 1.0809, Val Acc: 0.5200, Test Acc: 0.5187
2022-08-22 10:45:14,160:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 8/1000
2022-08-22 10:45:34,254:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.09s, LR: 0.00050, Train Loss: 0.4727, Train Acc: 0.7650,
                        Val Loss: 0.6277, Val Acc: 0.7290, Test Acc: 0.7212
2022-08-22 10:45:34,255:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 9/1000
2022-08-22 10:45:54,344:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 20.09s, LR: 0.00050, Train Loss: 0.4459, Train Acc: 0.8050,
                        Val Loss: 0.6486, Val Acc: 0.7070, Test Acc: 0.7081
2022-08-22 10:45:54,344:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 10/1000
2022-08-22 10:46:14,193:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 19.85s, LR: 0.00050, Train Loss: 0.4528, Train Acc: 0.7700,
                        Val Loss: 0.7690, Val Acc: 0.6770, Test Acc: 0.6775
2022-08-22 10:46:14,198:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 11/1000
2022-08-22 10:46:34,146:main_CYCLES_graph_classification.py:137 -   train_val_pipeline(): Saving best model with test accuracy: 0.7633 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_10_10_10h42m30s_on_Aug_22_2022/MODELS_
2022-08-22 10:46:34,146:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 19.95s, LR: 0.00050, Train Loss: 0.4182, Train Acc: 0.7950,
                        Val Loss: 0.5629, Val Acc: 0.7600, Test Acc: 0.7633
2022-08-22 10:46:34,147:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 12/1000
2022-08-22 10:46:53,875:main_CYCLES_graph_classification.py:159 -   train_val_pipeline(): 	Time: 19.73s, LR: 0.00050, Train Loss: 0.3586, Train Acc: 0.8150,
                        Val Loss: 0.7059, Val Acc: 0.7140, Test Acc: 0.7296
2022-08-22 10:46:53,875:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Epoch 13/1000
