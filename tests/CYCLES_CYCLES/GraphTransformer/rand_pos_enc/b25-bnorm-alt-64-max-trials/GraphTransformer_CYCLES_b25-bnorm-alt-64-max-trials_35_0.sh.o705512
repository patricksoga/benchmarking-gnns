/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py:350: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.
  num_classes = len(np.unique(np.array(dataset.train[:][1])))
/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py:350: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.
  num_classes = len(np.unique(np.array(dataset.train[:][1])))
[I] Loading dataset CYCLES...
train, test, val sizes : 9000 10000 1000
[I] Finished loading.
[I] Data load time: 13.3148s
using 1 automata/automaton
using 1 automata/automaton
Traceback (most recent call last):
  File "/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py", line 375, in <module>
    main(args) 
  File "/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py", line 367, in main
    train_val_pipeline(MODEL_NAME, dataset, params, net_params, dirs, args.config, config)
  File "/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/main_CYCLES_graph_classification.py", line 161, in train_val_pipeline
    epoch_train_loss, epoch_train_acc, optimizer = train_epoch(model, optimizer, device, train_loader, epoch, MODEL_NAME, net_params)
  File "/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/train/train_CYCLES_graph_classification.py", line 66, in train_epoch_sparse
    loss.backward()
  File "/afs/crc.nd.edu/user/p/psoga/.conda/envs/gnn/lib/python3.10/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/afs/crc.nd.edu/user/p/psoga/.conda/envs/gnn/lib/python3.10/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [1214, 80]], which is output 0 of DivBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
