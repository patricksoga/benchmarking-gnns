2022-09-20 16:05:08,416:main_utils.py:62 -            gpu_setup(): cuda available with GPU: Quadro RTX 6000
2022-09-20 16:05:18,966:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/CYCLES_CYCLES/GraphTransformer/rand_pos_enc/b25-bnorm-alt-fg-trials-32/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-20 16:05:18,967:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'job_num': 32}
2022-09-20 16:05:18,968:pe_layer.py:67 -             __init__(): rand_pos_enc
2022-09-20 16:05:20,473:pe_layer.py:137 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-20 16:05:20,474:pe_layer.py:142 -             __init__(): Using matrix: A
2022-09-20 16:05:20,474:pe_layer.py:143 -             __init__(): Matrix power: 1
2022-09-20 16:05:20,483:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2022-09-20 16:05:20,485:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527414
2022-09-20 16:05:20,485:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2022-09-20 16:05:20,485:pe_layer.py:67 -             __init__(): rand_pos_enc
2022-09-20 16:05:20,486:pe_layer.py:137 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-20 16:05:20,486:pe_layer.py:142 -             __init__(): Using matrix: A
2022-09-20 16:05:20,486:pe_layer.py:143 -             __init__(): Matrix power: 1
2022-09-20 16:05:20,499:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-20 16:09:28,214:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA TITAN X (Pascal)
2022-09-20 16:09:42,289:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/CYCLES_CYCLES/GraphTransformer/rand_pos_enc/b25-bnorm-alt-fg-trials-32/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-20 16:09:42,289:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'job_num': 32}
2022-09-20 16:09:42,290:pe_layer.py:67 -             __init__(): rand_pos_enc
2022-09-20 16:09:43,577:pe_layer.py:137 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-20 16:09:43,577:pe_layer.py:142 -             __init__(): Using matrix: A
2022-09-20 16:09:43,577:pe_layer.py:143 -             __init__(): Matrix power: 1
2022-09-20 16:09:43,591:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2022-09-20 16:09:43,593:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527414
2022-09-20 16:09:43,593:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2022-09-20 16:09:43,594:pe_layer.py:67 -             __init__(): rand_pos_enc
2022-09-20 16:09:43,594:pe_layer.py:137 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-20 16:09:43,594:pe_layer.py:142 -             __init__(): Using matrix: A
2022-09-20 16:09:43,594:pe_layer.py:143 -             __init__(): Matrix power: 1
2022-09-20 16:09:43,613:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-20 16:10:16,340:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:32.74702715873718
2022-09-20 16:10:16,341:main_CYCLES_graph_classification.py:105 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-20 16:14:19,727:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-20 16:14:19,727:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-20 16:14:19,727:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-20 16:14:19,728:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-20 16:14:19,732:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-20 16:15:02,311:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5054 to out/CYCLES_graph_classification_b25-bnorm-alt-fg-trials-32checkpoints/GraphTransformer_CYCLES_GPU0_32_32_16h09m42s_on_Sep_20_2022/MODELS_
2022-09-20 16:15:02,313:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 42.58s, LR: 0.00050, Train Loss: 1.1014, Train Acc: 0.5500,
                            Val Loss: 2.7743, Val Acc: 0.5050, Test Acc: 0.5054
2022-09-20 16:15:02,313:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-20 16:15:43,714:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5234 to out/CYCLES_graph_classification_b25-bnorm-alt-fg-trials-32checkpoints/GraphTransformer_CYCLES_GPU0_32_32_16h09m42s_on_Sep_20_2022/MODELS_
2022-09-20 16:15:43,715:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.40s, LR: 0.00050, Train Loss: 0.8575, Train Acc: 0.5700,
                            Val Loss: 1.7383, Val Acc: 0.5150, Test Acc: 0.5234
2022-09-20 16:15:43,715:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-20 16:16:25,280:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5582 to out/CYCLES_graph_classification_b25-bnorm-alt-fg-trials-32checkpoints/GraphTransformer_CYCLES_GPU0_32_32_16h09m42s_on_Sep_20_2022/MODELS_
2022-09-20 16:16:25,281:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.57s, LR: 0.00050, Train Loss: 0.8833, Train Acc: 0.5700,
                            Val Loss: 1.2322, Val Acc: 0.5610, Test Acc: 0.5582
2022-09-20 16:16:25,282:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-20 16:17:06,910:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.63s, LR: 0.00050, Train Loss: 0.7254, Train Acc: 0.6400,
                            Val Loss: 1.3035, Val Acc: 0.5340, Test Acc: 0.5244
2022-09-20 16:17:06,911:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-20 16:17:48,663:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.75s, LR: 0.00050, Train Loss: 0.7829, Train Acc: 0.6400,
                            Val Loss: 1.1752, Val Acc: 0.5210, Test Acc: 0.5163
2022-09-20 16:17:48,664:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-20 16:18:30,490:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5621 to out/CYCLES_graph_classification_b25-bnorm-alt-fg-trials-32checkpoints/GraphTransformer_CYCLES_GPU0_32_32_16h09m42s_on_Sep_20_2022/MODELS_
2022-09-20 16:18:30,491:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.83s, LR: 0.00050, Train Loss: 0.7470, Train Acc: 0.6300,
                            Val Loss: 1.1896, Val Acc: 0.5630, Test Acc: 0.5621
2022-09-20 16:18:30,491:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-20 16:19:11,725:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.23s, LR: 0.00050, Train Loss: 0.6797, Train Acc: 0.6600,
                            Val Loss: 0.8118, Val Acc: 0.5430, Test Acc: 0.5345
2022-09-20 16:19:11,726:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-20 16:19:52,847:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5762 to out/CYCLES_graph_classification_b25-bnorm-alt-fg-trials-32checkpoints/GraphTransformer_CYCLES_GPU0_32_32_16h09m42s_on_Sep_20_2022/MODELS_
2022-09-20 16:19:52,848:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.12s, LR: 0.00050, Train Loss: 0.6435, Train Acc: 0.6400,
                            Val Loss: 0.8030, Val Acc: 0.5810, Test Acc: 0.5762
2022-09-20 16:19:52,848:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-20 16:20:34,569:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.72s, LR: 0.00050, Train Loss: 0.6378, Train Acc: 0.6300,
                            Val Loss: 0.8043, Val Acc: 0.5360, Test Acc: 0.5341
2022-09-20 16:20:34,569:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-20 16:21:16,427:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.86s, LR: 0.00050, Train Loss: 0.6770, Train Acc: 0.6050,
                            Val Loss: 0.7774, Val Acc: 0.5370, Test Acc: 0.5278
2022-09-20 16:21:16,428:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-20 16:21:58,219:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.79s, LR: 0.00050, Train Loss: 0.5805, Train Acc: 0.7050,
                            Val Loss: 0.8477, Val Acc: 0.5860, Test Acc: 0.5663
2022-09-20 16:21:58,220:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-20 16:22:40,052:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.83s, LR: 0.00050, Train Loss: 0.6169, Train Acc: 0.6100,
                            Val Loss: 0.7785, Val Acc: 0.5620, Test Acc: 0.5485
2022-09-20 16:22:40,053:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-20 16:23:21,682:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.63s, LR: 0.00050, Train Loss: 0.6191, Train Acc: 0.6800,
                            Val Loss: 0.7828, Val Acc: 0.5730, Test Acc: 0.5684
2022-09-20 16:23:21,683:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-20 16:24:02,650:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 40.97s, LR: 0.00050, Train Loss: 0.5905, Train Acc: 0.6900,
                            Val Loss: 0.7623, Val Acc: 0.5710, Test Acc: 0.5741
2022-09-20 16:24:03,800:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-20 16:24:45,327:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.53s, LR: 0.00050, Train Loss: 0.5578, Train Acc: 0.7100,
                            Val Loss: 0.9185, Val Acc: 0.5690, Test Acc: 0.5635
2022-09-20 16:24:45,328:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-20 16:25:27,003:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.68s, LR: 0.00050, Train Loss: 0.5913, Train Acc: 0.6950,
                            Val Loss: 0.7977, Val Acc: 0.5830, Test Acc: 0.5690
2022-09-20 16:25:27,004:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-20 16:26:09,213:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 42.21s, LR: 0.00050, Train Loss: 0.5791, Train Acc: 0.7300,
                            Val Loss: 0.7965, Val Acc: 0.5770, Test Acc: 0.5723
2022-09-20 16:26:09,214:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-20 16:26:51,260:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 42.05s, LR: 0.00050, Train Loss: 0.5806, Train Acc: 0.7050,
                            Val Loss: 0.8106, Val Acc: 0.5690, Test Acc: 0.5636
2022-09-20 16:26:51,260:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-20 16:27:33,242:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.98s, LR: 0.00050, Train Loss: 0.5758, Train Acc: 0.6900,
                            Val Loss: 0.7858, Val Acc: 0.5770, Test Acc: 0.5653
2022-09-20 16:27:33,243:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-20 16:28:14,809:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.57s, LR: 0.00050, Train Loss: 0.5764, Train Acc: 0.6900,
                            Val Loss: 0.8762, Val Acc: 0.5750, Test Acc: 0.5685
2022-09-20 16:28:14,810:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-20 16:28:56,100:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.29s, LR: 0.00050, Train Loss: 0.5410, Train Acc: 0.7100,
                            Val Loss: 0.8867, Val Acc: 0.5830, Test Acc: 0.5677
2022-09-20 16:28:56,101:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-20 16:29:37,925:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5808 to out/CYCLES_graph_classification_b25-bnorm-alt-fg-trials-32checkpoints/GraphTransformer_CYCLES_GPU0_32_32_16h09m42s_on_Sep_20_2022/MODELS_
2022-09-20 16:29:37,926:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 41.82s, LR: 0.00050, Train Loss: 0.5513, Train Acc: 0.7500,
                            Val Loss: 0.8926, Val Acc: 0.5850, Test Acc: 0.5808
2022-09-20 16:29:37,926:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 23/1000
2022-09-20 16:30:20,269:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 42.34s, LR: 0.00050, Train Loss: 0.5300, Train Acc: 0.7100,
                            Val Loss: 0.8930, Val Acc: 0.5930, Test Acc: 0.5766
2022-09-20 16:30:20,270:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 24/1000
2022-09-20 16:31:02,525:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 42.25s, LR: 0.00050, Train Loss: 0.5842, Train Acc: 0.7050,
                            Val Loss: 0.8294, Val Acc: 0.5540, Test Acc: 0.5396
2022-09-20 16:31:02,526:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 25/1000
2022-09-20 16:31:44,630:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 42.10s, LR: 0.00050, Train Loss: 0.6380, Train Acc: 0.6600,
                            Val Loss: 0.8970, Val Acc: 0.5890, Test Acc: 0.5731
2022-09-20 16:31:44,631:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 26/1000
