2022-09-05 02:45:01,839:main_utils.py:39 -            gpu_setup(): cuda available with GPU: Quadro RTX 6000
2022-09-05 02:45:12,314:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/CYCLES_CYCLES/GraphTransformer/rand_pos_enc/b25-alt-noedge-ngape2-lincomb-softmax-ind/64_DEBUG.log', 'device': device(type='cuda'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:45:12,314:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 02:45:12,317:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:45:13,884:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:45:13,884:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 02:45:13,884:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 02:45:13,894:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:45:13,896:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 583561
2022-09-05 02:45:13,898:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:45:13,899:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:45:13,899:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 02:45:13,899:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 02:45:13,914:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 02:45:13,914:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:46:45,579:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:91.68321299552917
2022-09-05 02:46:45,585:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 02:46:45,585:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 02:46:45,585:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 02:46:45,585:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 02:46:45,588:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 02:47:08,817:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-alt-noedge-ngape2-lincomb-softmax-indcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_02h45m12s_on_Sep_05_2022/MODELS_
2022-09-05 02:47:08,818:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 23.23s, LR: 0.00050, Train Loss: 0.8756, Train Acc: 0.5950,
                        Val Loss: 1.2651, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:47:08,819:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 02:47:31,418:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.60s, LR: 0.00050, Train Loss: 0.8018, Train Acc: 0.5850,
                        Val Loss: 0.9152, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:47:31,419:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 02:47:53,907:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.49s, LR: 0.00050, Train Loss: 0.6636, Train Acc: 0.6350,
                        Val Loss: 0.7215, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:47:53,907:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 02:48:16,498:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.59s, LR: 0.00050, Train Loss: 0.5668, Train Acc: 0.7300,
                        Val Loss: 0.7388, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:48:16,498:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 02:48:39,005:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.51s, LR: 0.00050, Train Loss: 0.5307, Train Acc: 0.7400,
                        Val Loss: 0.8184, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:48:39,005:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 02:49:01,476:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.47s, LR: 0.00050, Train Loss: 0.4463, Train Acc: 0.8100,
                        Val Loss: 0.7468, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:49:01,476:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 02:49:24,050:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5001 to out/CYCLES_graph_classification_b25-alt-noedge-ngape2-lincomb-softmax-indcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_02h45m12s_on_Sep_05_2022/MODELS_
2022-09-05 02:49:24,051:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.57s, LR: 0.00050, Train Loss: 0.4878, Train Acc: 0.7500,
                        Val Loss: 0.7981, Val Acc: 0.5000, Test Acc: 0.5001
2022-09-05 02:49:24,052:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 02:49:46,539:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.49s, LR: 0.00050, Train Loss: 0.4426, Train Acc: 0.8000,
                        Val Loss: 0.7879, Val Acc: 0.5080, Test Acc: 0.4982
2022-09-05 02:49:46,539:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 02:50:09,147:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.61s, LR: 0.00050, Train Loss: 0.4260, Train Acc: 0.8050,
                        Val Loss: 0.8046, Val Acc: 0.5090, Test Acc: 0.4952
2022-09-05 02:50:09,147:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 02:50:31,632:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5014 to out/CYCLES_graph_classification_b25-alt-noedge-ngape2-lincomb-softmax-indcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_02h45m12s_on_Sep_05_2022/MODELS_
2022-09-05 02:50:31,632:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.48s, LR: 0.00050, Train Loss: 0.4425, Train Acc: 0.8200,
                        Val Loss: 1.0229, Val Acc: 0.5000, Test Acc: 0.5014
2022-09-05 02:50:31,632:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 02:50:54,178:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.55s, LR: 0.00050, Train Loss: 0.4003, Train Acc: 0.8100,
                        Val Loss: 1.3333, Val Acc: 0.5000, Test Acc: 0.4999
2022-09-05 02:50:54,179:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 02:51:16,709:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5299 to out/CYCLES_graph_classification_b25-alt-noedge-ngape2-lincomb-softmax-indcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_02h45m12s_on_Sep_05_2022/MODELS_
2022-09-05 02:51:16,710:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00050, Train Loss: 0.4025, Train Acc: 0.8100,
                        Val Loss: 1.0166, Val Acc: 0.5330, Test Acc: 0.5299
2022-09-05 02:51:16,710:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 02:51:39,213:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.50s, LR: 0.00050, Train Loss: 0.4099, Train Acc: 0.7950,
                        Val Loss: 2.3054, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:51:39,214:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 02:52:01,760:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5411 to out/CYCLES_graph_classification_b25-alt-noedge-ngape2-lincomb-softmax-indcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_02h45m12s_on_Sep_05_2022/MODELS_
2022-09-05 02:52:01,761:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.55s, LR: 0.00050, Train Loss: 0.4141, Train Acc: 0.7800,
                        Val Loss: 2.2383, Val Acc: 0.5510, Test Acc: 0.5411
2022-09-05 02:52:01,761:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 02:52:24,407:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.65s, LR: 0.00025, Train Loss: 0.3425, Train Acc: 0.8550,
                        Val Loss: 0.9822, Val Acc: 0.5320, Test Acc: 0.5355
2022-09-05 02:52:24,408:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 02:52:46,972:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.6604 to out/CYCLES_graph_classification_b25-alt-noedge-ngape2-lincomb-softmax-indcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_02h45m12s_on_Sep_05_2022/MODELS_
2022-09-05 02:52:46,973:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.56s, LR: 0.00025, Train Loss: 0.3137, Train Acc: 0.8600,
                        Val Loss: 0.7037, Val Acc: 0.6540, Test Acc: 0.6604
2022-09-05 02:52:46,973:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 02:53:09,499:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00025, Train Loss: 0.2889, Train Acc: 0.8800,
                        Val Loss: 1.5957, Val Acc: 0.5110, Test Acc: 0.5131
2022-09-05 02:53:09,500:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 02:53:32,046:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.55s, LR: 0.00025, Train Loss: 0.2778, Train Acc: 0.8700,
                        Val Loss: 2.0345, Val Acc: 0.5010, Test Acc: 0.5009
2022-09-05 02:53:32,046:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 02:53:54,598:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.55s, LR: 0.00025, Train Loss: 0.2847, Train Acc: 0.8800,
                        Val Loss: 3.0628, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:53:54,599:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 02:54:17,123:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.52s, LR: 0.00025, Train Loss: 0.3285, Train Acc: 0.8400,
                        Val Loss: 1.8019, Val Acc: 0.5320, Test Acc: 0.5395
2022-09-05 02:54:17,124:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 02:54:39,640:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.52s, LR: 0.00025, Train Loss: 0.2701, Train Acc: 0.8550,
                        Val Loss: 6.0970, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 02:54:39,640:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 02:55:02,146:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.50s, LR: 0.00025, Train Loss: 0.2599, Train Acc: 0.8850,
                        Val Loss: 2.3133, Val Acc: 0.5480, Test Acc: 0.5391
2022-09-05 02:55:02,146:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 02:55:24,613:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.47s, LR: 0.00025, Train Loss: 0.2367, Train Acc: 0.9300,
                        Val Loss: 1.4520, Val Acc: 0.5560, Test Acc: 0.5538
2022-09-05 02:55:24,614:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 02:55:47,143:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00025, Train Loss: 0.2509, Train Acc: 0.8900,
                        Val Loss: 3.0764, Val Acc: 0.5000, Test Acc: 0.5010
2022-09-05 02:55:47,144:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 02:56:09,680:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.54s, LR: 0.00025, Train Loss: 0.2475, Train Acc: 0.8850,
                        Val Loss: 1.8738, Val Acc: 0.5110, Test Acc: 0.5199
2022-09-05 02:56:09,680:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 02:56:32,273:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.59s, LR: 0.00025, Train Loss: 0.2692, Train Acc: 0.8950,
                        Val Loss: 1.1459, Val Acc: 0.5910, Test Acc: 0.6010
2022-09-05 02:56:32,274:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 27/1000
