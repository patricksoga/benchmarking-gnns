2022-09-11 16:47:13,709:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2022-09-11 16:47:28,121:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'L', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_CLUSTER/GraphTransformer/rand_pos_enc/b32-bnorm-alt-clamped-L/64_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 64, 'in_dim': 7, 'n_classes': 6}
2022-09-11 16:47:28,121:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-11 16:47:28,122:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-11 16:47:29,659:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-11 16:47:29,659:pe_layer.py:134 -             __init__(): Using matrix: L
2022-09-11 16:47:29,659:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-11 16:47:29,674:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-11 16:47:29,676:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532507
2022-09-11 16:47:29,677:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-11 16:47:29,677:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-11 16:47:29,679:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-11 16:47:29,679:pe_layer.py:134 -             __init__(): Using matrix: L
2022-09-11 16:47:29,679:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-11 16:47:29,700:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-11 16:51:36,970:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:247.26970195770264
2022-09-11 16:51:36,972:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10000
2022-09-11 16:51:36,972:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-11 16:51:36,972:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 1000
2022-09-11 16:51:36,973:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 6
2022-09-11 16:51:36,977:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-11 16:53:05,187:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 57.7564 to out/SBMs_node_classification_b32-bnorm-alt-clamped-Lcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_16h47m28s_on_Sep_11_2022/MODELS_
2022-09-11 16:53:05,187:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 88.21s, LR: 0.00050, Train Loss: 1.2227, Train Acc: 53.8559,
                            Val Loss: 1.1423, Val Acc: 57.0918, Test Acc: 57.7564
2022-09-11 16:53:05,187:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 2/1000
2022-09-11 16:54:33,723:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 58.2656 to out/SBMs_node_classification_b32-bnorm-alt-clamped-Lcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_16h47m28s_on_Sep_11_2022/MODELS_
2022-09-11 16:54:33,723:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 88.54s, LR: 0.00050, Train Loss: 0.9252, Train Acc: 65.9545,
                            Val Loss: 1.1230, Val Acc: 57.1842, Test Acc: 58.2656
2022-09-11 16:54:33,724:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 3/1000
2022-09-11 16:56:02,384:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 69.9026 to out/SBMs_node_classification_b32-bnorm-alt-clamped-Lcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_16h47m28s_on_Sep_11_2022/MODELS_
2022-09-11 16:56:02,384:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 88.66s, LR: 0.00050, Train Loss: 0.8401, Train Acc: 69.1722,
                            Val Loss: 0.8330, Val Acc: 69.5115, Test Acc: 69.9026
2022-09-11 16:56:02,384:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 4/1000
2022-09-11 16:57:31,112:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 88.73s, LR: 0.00050, Train Loss: 0.7991, Train Acc: 70.7030,
                            Val Loss: 0.9055, Val Acc: 66.5086, Test Acc: 67.2934
2022-09-11 16:57:31,112:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 5/1000
2022-09-11 16:59:02,291:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 91.18s, LR: 0.00050, Train Loss: 0.7729, Train Acc: 71.6217,
                            Val Loss: 1.3560, Val Acc: 52.9453, Test Acc: 54.0683
2022-09-11 16:59:02,291:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 6/1000
2022-09-11 17:00:32,708:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 90.42s, LR: 0.00050, Train Loss: 0.7519, Train Acc: 72.4551,
                            Val Loss: 0.8551, Val Acc: 68.6904, Test Acc: 68.8787
2022-09-11 17:00:32,709:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 7/1000
2022-09-11 17:02:03,408:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 90.70s, LR: 0.00050, Train Loss: 0.7345, Train Acc: 73.1210,
                            Val Loss: 0.9230, Val Acc: 65.7183, Test Acc: 65.9903
2022-09-11 17:02:03,409:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 8/1000
2022-09-11 17:03:33,924:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 90.51s, LR: 0.00050, Train Loss: 0.7222, Train Acc: 73.5175,
                            Val Loss: 0.8916, Val Acc: 67.4848, Test Acc: 67.7660
2022-09-11 17:03:33,924:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 9/1000
2022-09-11 17:05:04,691:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 72.6547 to out/SBMs_node_classification_b32-bnorm-alt-clamped-Lcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_16h47m28s_on_Sep_11_2022/MODELS_
2022-09-11 17:05:04,691:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 90.77s, LR: 0.00050, Train Loss: 0.7120, Train Acc: 73.9153,
                            Val Loss: 0.7609, Val Acc: 72.3946, Test Acc: 72.6547
2022-09-11 17:05:04,691:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 10/1000
2022-09-11 17:06:35,615:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 90.92s, LR: 0.00050, Train Loss: 0.7009, Train Acc: 74.3929,
                            Val Loss: 0.8072, Val Acc: 71.1875, Test Acc: 71.3535
2022-09-11 17:06:35,616:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 11/1000
2022-09-11 17:08:05,288:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 89.67s, LR: 0.00050, Train Loss: 0.6952, Train Acc: 74.4711,
                            Val Loss: 0.9210, Val Acc: 65.5215, Test Acc: 65.7972
2022-09-11 17:08:05,289:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 12/1000
2022-09-11 17:09:36,033:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 73.1893 to out/SBMs_node_classification_b32-bnorm-alt-clamped-Lcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_16h47m28s_on_Sep_11_2022/MODELS_
2022-09-11 17:09:36,033:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 90.74s, LR: 0.00050, Train Loss: 0.6880, Train Acc: 74.7537,
                            Val Loss: 0.7410, Val Acc: 73.0988, Test Acc: 73.1893
2022-09-11 17:09:36,034:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 13/1000
