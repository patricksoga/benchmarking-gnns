2022-10-02 02:42:31,536:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2022-10-02 02:42:45,018:main_SBMs_node_classification.py:387 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': True, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_CLUSTER/GraphTransformer/rand_pos_enc/b32-bnorm-alt-64-norm-trials/64_DEBUG_0_41.log', 'device': device(type='cuda'), 'pos_enc_dim': 64, 'in_dim': 7, 'n_classes': 6, 'seed_array': [41]}
2022-10-02 02:42:45,018:main_SBMs_node_classification.py:388 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-10-02 02:42:45,019:pe_layer.py:76 -             __init__(): rand_pos_enc
2022-10-02 02:42:46,135:pe_layer.py:207 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-10-02 02:42:46,136:pe_layer.py:212 -             __init__(): Using matrix: A
2022-10-02 02:42:46,136:pe_layer.py:213 -             __init__(): Matrix power: 1
2022-10-02 02:42:46,151:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2022-10-02 02:42:46,153:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536666
2022-10-02 02:42:46,153:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-10-02 02:42:46,154:pe_layer.py:76 -             __init__(): rand_pos_enc
2022-10-02 02:42:46,154:pe_layer.py:207 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-10-02 02:42:46,154:pe_layer.py:212 -             __init__(): Using matrix: A
2022-10-02 02:42:46,154:pe_layer.py:213 -             __init__(): Matrix power: 1
2022-10-02 02:42:46,175:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-10-02 02:44:20,069:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:93.89389514923096
2022-10-02 02:44:20,073:main_SBMs_node_classification.py:167 -   train_val_pipeline(): Training Graphs: 10000
2022-10-02 02:44:20,073:main_SBMs_node_classification.py:168 -   train_val_pipeline(): Validation Graphs: 1000
2022-10-02 02:44:20,073:main_SBMs_node_classification.py:169 -   train_val_pipeline(): Test Graphs: 1000
2022-10-02 02:44:20,073:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Number of Classes: 6
2022-10-02 02:44:20,076:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 1/1000
2022-10-02 02:46:13,175:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 27.0575 to out/SBMs_node_classification_b32-bnorm-alt-64-norm-trialscheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_02h42m45s_on_Oct_02_2022/MODELS_
2022-10-02 02:46:13,176:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.10s, LR: 0.00050, Train Loss: 1.5451, Train Acc: 36.5642,
                            Val Loss: 2.1145, Val Acc: 26.8908, Test Acc: 27.0575
2022-10-02 02:46:13,176:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 2/1000
2022-10-02 02:48:06,486:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 40.6132 to out/SBMs_node_classification_b32-bnorm-alt-64-norm-trialscheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_02h42m45s_on_Oct_02_2022/MODELS_
2022-10-02 02:48:06,487:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.31s, LR: 0.00050, Train Loss: 1.2052, Train Acc: 54.4621,
                            Val Loss: 1.6619, Val Acc: 41.1368, Test Acc: 40.6132
2022-10-02 02:48:06,487:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 3/1000
2022-10-02 02:49:59,837:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 48.2330 to out/SBMs_node_classification_b32-bnorm-alt-64-norm-trialscheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_02h42m45s_on_Oct_02_2022/MODELS_
2022-10-02 02:49:59,837:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.35s, LR: 0.00050, Train Loss: 1.0776, Train Acc: 59.7278,
                            Val Loss: 1.4684, Val Acc: 48.0470, Test Acc: 48.2330
2022-10-02 02:49:59,837:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 4/1000
2022-10-02 02:51:53,823:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.99s, LR: 0.00050, Train Loss: 0.9906, Train Acc: 63.1726,
                            Val Loss: 1.8026, Val Acc: 32.5580, Test Acc: 32.3947
2022-10-02 02:51:53,824:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 5/1000
2022-10-02 02:53:46,973:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.15s, LR: 0.00050, Train Loss: 0.9497, Train Acc: 64.7359,
                            Val Loss: 1.9416, Val Acc: 36.7198, Test Acc: 36.6008
2022-10-02 02:53:46,974:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 6/1000
2022-10-02 02:55:40,393:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 65.3924 to out/SBMs_node_classification_b32-bnorm-alt-64-norm-trialscheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_02h42m45s_on_Oct_02_2022/MODELS_
2022-10-02 02:55:40,393:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.42s, LR: 0.00050, Train Loss: 0.9124, Train Acc: 66.1419,
                            Val Loss: 0.9185, Val Acc: 65.5938, Test Acc: 65.3924
2022-10-02 02:55:40,393:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 7/1000
2022-10-02 02:57:33,448:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.05s, LR: 0.00050, Train Loss: 0.8772, Train Acc: 67.5017,
                            Val Loss: 1.0477, Val Acc: 61.0487, Test Acc: 60.9489
2022-10-02 02:57:33,448:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 8/1000
2022-10-02 02:59:27,207:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.76s, LR: 0.00050, Train Loss: 0.8766, Train Acc: 67.5259,
                            Val Loss: 1.2900, Val Acc: 50.4079, Test Acc: 50.4286
2022-10-02 02:59:27,207:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 9/1000
2022-10-02 03:01:20,342:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.13s, LR: 0.00050, Train Loss: 0.8478, Train Acc: 68.5970,
                            Val Loss: 1.0733, Val Acc: 60.2544, Test Acc: 59.4378
2022-10-02 03:01:20,342:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 10/1000
2022-10-02 03:03:13,616:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 66.4241 to out/SBMs_node_classification_b32-bnorm-alt-64-norm-trialscheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_02h42m45s_on_Oct_02_2022/MODELS_
2022-10-02 03:03:13,617:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.27s, LR: 0.00050, Train Loss: 0.8360, Train Acc: 69.0881,
                            Val Loss: 0.8928, Val Acc: 66.8301, Test Acc: 66.4241
2022-10-02 03:03:13,617:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 11/1000
2022-10-02 03:05:06,916:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.30s, LR: 0.00050, Train Loss: 0.7987, Train Acc: 70.5205,
                            Val Loss: 0.9334, Val Acc: 65.1732, Test Acc: 65.1778
2022-10-02 03:05:06,917:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 12/1000
2022-10-02 03:07:00,614:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.70s, LR: 0.00050, Train Loss: 0.7796, Train Acc: 71.2360,
                            Val Loss: 0.9719, Val Acc: 64.1719, Test Acc: 64.0608
2022-10-02 03:07:00,615:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 13/1000
2022-10-02 03:08:53,643:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 69.6595 to out/SBMs_node_classification_b32-bnorm-alt-64-norm-trialscheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_02h42m45s_on_Oct_02_2022/MODELS_
2022-10-02 03:08:53,643:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.03s, LR: 0.00050, Train Loss: 0.7756, Train Acc: 71.4019,
                            Val Loss: 0.8197, Val Acc: 69.8084, Test Acc: 69.6595
2022-10-02 03:08:53,643:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 14/1000
2022-10-02 03:10:46,797:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 113.15s, LR: 0.00050, Train Loss: 0.7664, Train Acc: 71.7713,
                            Val Loss: 1.0392, Val Acc: 64.1073, Test Acc: 63.7010
2022-10-02 03:10:46,797:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 15/1000
