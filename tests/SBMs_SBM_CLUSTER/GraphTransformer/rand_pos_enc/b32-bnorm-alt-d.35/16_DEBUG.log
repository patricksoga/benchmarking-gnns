2022-08-20 10:05:44,337:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2022-08-20 10:05:57,852:main_SBMs_node_classification.py:306 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.35, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_CLUSTER/GraphTransformer/rand_pos_enc/b32-bnorm-alt-d.35/16_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 16, 'matrix_type': 'A', 'in_dim': 7, 'n_classes': 6}
2022-08-20 10:05:57,852:main_SBMs_node_classification.py:307 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-08-20 10:05:57,853:pe_layer.py:54 -             __init__(): rand_pos_enc
2022-08-20 10:05:58,946:pe_layer.py:93 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-20 10:05:58,946:pe_layer.py:98 -             __init__(): Using matrix: A
2022-08-20 10:05:58,946:pe_layer.py:99 -             __init__(): Matrix power: 1
2022-08-20 10:05:58,961:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-20 10:05:58,964:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-08-20 10:05:58,964:pe_layer.py:54 -             __init__(): rand_pos_enc
2022-08-20 10:05:58,965:pe_layer.py:93 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-20 10:05:58,965:pe_layer.py:98 -             __init__(): Using matrix: A
2022-08-20 10:05:58,965:pe_layer.py:99 -             __init__(): Matrix power: 1
2022-08-20 10:05:58,984:main_SBMs_node_classification.py:75 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-08-20 10:07:00,206:main_SBMs_node_classification.py:79 -   train_val_pipeline(): Time PE:61.22147583961487
2022-08-20 10:07:00,208:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Training Graphs: 10000
2022-08-20 10:07:00,208:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-20 10:07:00,208:main_SBMs_node_classification.py:101 -   train_val_pipeline(): Test Graphs: 1000
2022-08-20 10:07:00,208:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Number of Classes: 6
2022-08-20 10:07:00,213:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 1/1000
2022-08-20 10:08:39,877:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 58.5716 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:08:39,878:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 99.66s, LR: 0.00050, Train Loss: 1.3599, Train Acc: 47.7674,
                        Val Loss: 1.1342, Val Acc: 58.5165, Test Acc: 58.5716
2022-08-20 10:08:39,920:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 2/1000
2022-08-20 10:10:19,574:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 64.3798 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:10:19,574:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 99.65s, LR: 0.00050, Train Loss: 1.0869, Train Acc: 60.4679,
                        Val Loss: 0.9824, Val Acc: 64.3648, Test Acc: 64.3798
2022-08-20 10:10:19,618:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 3/1000
2022-08-20 10:11:59,976:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 67.7465 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:11:59,976:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 100.36s, LR: 0.00050, Train Loss: 0.9852, Train Acc: 64.3942,
                        Val Loss: 0.9029, Val Acc: 67.4832, Test Acc: 67.7465
2022-08-20 10:12:00,018:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 4/1000
2022-08-20 10:13:38,792:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 69.0345 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:13:38,792:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 98.77s, LR: 0.00050, Train Loss: 0.9324, Train Acc: 66.2767,
                        Val Loss: 0.8581, Val Acc: 68.8219, Test Acc: 69.0345
2022-08-20 10:13:38,835:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 5/1000
2022-08-20 10:15:13,517:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 69.7037 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:15:13,517:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 94.68s, LR: 0.00050, Train Loss: 0.8974, Train Acc: 67.5300,
                        Val Loss: 0.8396, Val Acc: 69.5874, Test Acc: 69.7037
2022-08-20 10:15:13,558:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 6/1000
2022-08-20 10:16:46,997:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 70.2014 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:16:46,997:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 93.44s, LR: 0.00050, Train Loss: 0.8796, Train Acc: 68.0858,
                        Val Loss: 0.8243, Val Acc: 70.1976, Test Acc: 70.2014
2022-08-20 10:16:47,039:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 7/1000
2022-08-20 10:18:20,299:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 70.5064 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:18:20,299:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 93.26s, LR: 0.00050, Train Loss: 0.8567, Train Acc: 68.9201,
                        Val Loss: 0.8242, Val Acc: 70.3982, Test Acc: 70.5064
2022-08-20 10:18:20,340:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 8/1000
2022-08-20 10:19:52,923:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 71.3226 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:19:52,923:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 92.58s, LR: 0.00050, Train Loss: 0.8445, Train Acc: 69.2807,
                        Val Loss: 0.8134, Val Acc: 70.8394, Test Acc: 71.3226
2022-08-20 10:19:52,967:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 9/1000
2022-08-20 10:21:25,978:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 71.3773 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:21:25,979:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 93.01s, LR: 0.00050, Train Loss: 0.8328, Train Acc: 69.7009,
                        Val Loss: 0.7910, Val Acc: 71.1241, Test Acc: 71.3773
2022-08-20 10:21:26,020:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 10/1000
2022-08-20 10:22:58,822:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 72.0580 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:22:58,823:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 92.80s, LR: 0.00050, Train Loss: 0.8212, Train Acc: 70.1052,
                        Val Loss: 0.7721, Val Acc: 71.9267, Test Acc: 72.0580
2022-08-20 10:22:58,864:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 11/1000
2022-08-20 10:24:31,367:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 72.2876 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:24:31,368:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 92.50s, LR: 0.00050, Train Loss: 0.8135, Train Acc: 70.4041,
                        Val Loss: 0.7695, Val Acc: 72.2363, Test Acc: 72.2876
2022-08-20 10:24:31,409:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 12/1000
2022-08-20 10:26:04,611:main_SBMs_node_classification.py:156 -   train_val_pipeline(): Saving best model with test accuracy: 72.4906 to out/SBMs_node_classification_b32-bnorm-alt-d.35checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_10h05m57s_on_Aug_20_2022/MODELS_
2022-08-20 10:26:04,611:main_SBMs_node_classification.py:178 -   train_val_pipeline(): 	Time: 93.20s, LR: 0.00050, Train Loss: 0.8094, Train Acc: 70.5149,
                        Val Loss: 0.7632, Val Acc: 72.2521, Test Acc: 72.4906
2022-08-20 10:26:04,680:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Epoch 13/1000
