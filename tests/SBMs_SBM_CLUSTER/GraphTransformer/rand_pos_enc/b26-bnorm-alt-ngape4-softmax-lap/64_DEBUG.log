2022-09-05 12:07:43,902:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2022-09-05 12:07:59,365:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'L', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_CLUSTER/GraphTransformer/rand_pos_enc/b26-bnorm-alt-ngape4-softmax-lap/64_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 64, 'in_dim': 7, 'n_classes': 6}
2022-09-05 12:07:59,365:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 12:07:59,369:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 12:08:00,883:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 12:08:00,883:pe_layer.py:137 -             __init__(): Using matrix: L
2022-09-05 12:08:00,883:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 12:08:00,900:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 12:08:00,903:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 587167
2022-09-05 12:08:00,906:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 12:08:00,908:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 12:08:00,909:pe_layer.py:137 -             __init__(): Using matrix: L
2022-09-05 12:08:00,909:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 12:08:00,931:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 12:08:00,931:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 12:17:23,638:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:562.7068560123444
2022-09-05 12:17:23,639:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 12:17:23,640:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 12:17:23,640:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 1000
2022-09-05 12:17:23,640:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 12:17:23,644:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 12:18:41,693:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 61.3394 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:18:41,694:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 78.05s, LR: 0.00050, Train Loss: 1.2389, Train Acc: 53.6622,
                        Val Loss: 1.0681, Val Acc: 61.2025, Test Acc: 61.3394
2022-09-05 12:18:41,694:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 12:19:58,410:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 66.3809 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:19:58,411:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 76.72s, LR: 0.00050, Train Loss: 0.9558, Train Acc: 65.0340,
                        Val Loss: 0.9201, Val Acc: 66.4025, Test Acc: 66.3809
2022-09-05 12:19:58,411:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 12:21:12,771:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 68.7342 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:21:12,771:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 74.36s, LR: 0.00050, Train Loss: 0.8791, Train Acc: 67.8788,
                        Val Loss: 0.8546, Val Acc: 68.6489, Test Acc: 68.7342
2022-09-05 12:21:12,771:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 12:22:27,926:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 70.0627 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:22:27,926:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.15s, LR: 0.00050, Train Loss: 0.8342, Train Acc: 69.4924,
                        Val Loss: 0.8269, Val Acc: 70.0343, Test Acc: 70.0627
2022-09-05 12:22:27,926:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 12:23:43,362:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 70.7139 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:23:43,362:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.44s, LR: 0.00050, Train Loss: 0.8026, Train Acc: 70.6566,
                        Val Loss: 0.7958, Val Acc: 71.0043, Test Acc: 70.7139
2022-09-05 12:23:43,362:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 12:24:58,843:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 71.2286 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:24:58,844:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.48s, LR: 0.00050, Train Loss: 0.7848, Train Acc: 71.3116,
                        Val Loss: 0.7895, Val Acc: 71.0576, Test Acc: 71.2286
2022-09-05 12:24:58,844:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 12:26:14,389:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 71.4325 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:26:14,389:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.55s, LR: 0.00050, Train Loss: 0.7643, Train Acc: 72.0465,
                        Val Loss: 0.7813, Val Acc: 71.2952, Test Acc: 71.4325
2022-09-05 12:26:14,390:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 12:27:29,562:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 71.5489 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:27:29,563:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.17s, LR: 0.00050, Train Loss: 0.7557, Train Acc: 72.3815,
                        Val Loss: 0.7893, Val Acc: 71.4989, Test Acc: 71.5489
2022-09-05 12:27:29,563:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 12:28:45,238:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 72.3729 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:28:45,238:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.68s, LR: 0.00050, Train Loss: 0.7473, Train Acc: 72.6390,
                        Val Loss: 0.7536, Val Acc: 72.6082, Test Acc: 72.3729
2022-09-05 12:28:45,238:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 12:30:00,814:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.58s, LR: 0.00050, Train Loss: 0.7381, Train Acc: 73.0569,
                        Val Loss: 0.7579, Val Acc: 72.4929, Test Acc: 72.3247
2022-09-05 12:30:00,814:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 12:31:16,325:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.51s, LR: 0.00050, Train Loss: 0.7313, Train Acc: 73.2376,
                        Val Loss: 0.7722, Val Acc: 71.9948, Test Acc: 72.0483
2022-09-05 12:31:16,325:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 12:32:32,116:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.79s, LR: 0.00050, Train Loss: 0.7254, Train Acc: 73.4745,
                        Val Loss: 0.7610, Val Acc: 72.1790, Test Acc: 72.3235
2022-09-05 12:32:32,117:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 12:33:47,852:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.74s, LR: 0.00050, Train Loss: 0.7214, Train Acc: 73.6308,
                        Val Loss: 0.7584, Val Acc: 72.4312, Test Acc: 72.2936
2022-09-05 12:33:47,853:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 12:35:03,378:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 72.4344 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:35:03,379:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.53s, LR: 0.00050, Train Loss: 0.7137, Train Acc: 73.9491,
                        Val Loss: 0.7595, Val Acc: 72.5070, Test Acc: 72.4344
2022-09-05 12:35:03,379:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 12:36:19,348:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.97s, LR: 0.00050, Train Loss: 0.7060, Train Acc: 74.1621,
                        Val Loss: 0.7740, Val Acc: 71.9850, Test Acc: 71.7757
2022-09-05 12:36:19,348:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 12:37:35,228:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 72.6289 to out/SBMs_node_classification_b26-bnorm-alt-ngape6-softmax-lapcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_64_64_12h07m59s_on_Sep_05_2022/MODELS_
2022-09-05 12:37:35,228:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 75.88s, LR: 0.00050, Train Loss: 0.7030, Train Acc: 74.3267,
                        Val Loss: 0.7505, Val Acc: 72.7198, Test Acc: 72.6289
2022-09-05 12:37:35,228:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
