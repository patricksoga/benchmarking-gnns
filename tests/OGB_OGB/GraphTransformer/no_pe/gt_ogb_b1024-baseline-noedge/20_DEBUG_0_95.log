2023-01-20 19:13:17,678:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-20 19:13:17,679:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-20 19:28:08,733:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-20 19:28:41,199:ogbdata.py:332 -             __init__(): Time taken: 923.5205s
2023-01-20 19:28:41,199:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-20 19:28:41,199:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-20 19:28:41,199:ogbdata.py:348 -             __init__(): [I] Data load time: 923.5209s
2023-01-20 19:28:41,200:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/no_pe/gt_ogb_b1024-baseline-noedge/20_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-20 19:28:41,200:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-20 19:28:41,207:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:28:41,207:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:28:41,207:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:28:41,306:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-20 19:28:41,309:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536741
2023-01-20 19:28:41,309:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-20 19:28:41,310:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:28:41,310:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:28:41,310:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:28:51,158:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-20 19:28:51,158:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-20 19:28:51,163:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-20 19:42:55,249:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2661679685115814
2023-01-20 19:42:55,251:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 844.09s, LR: 0.00070, Train Loss: 0.3086, Train MAE: 0.3086,
                            Val Loss: 0.2666, Val MAE: 0.2662
2023-01-20 19:42:55,252:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-20 19:53:45,412:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.19283095002174377
2023-01-20 19:53:45,417:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.16s, LR: 0.00070, Train Loss: 0.1764, Train MAE: 0.1764,
                            Val Loss: 0.1933, Val MAE: 0.1928
2023-01-20 19:53:45,417:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-20 20:04:35,775:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.36s, LR: 0.00070, Train Loss: 0.1613, Train MAE: 0.1613,
                            Val Loss: 0.1952, Val MAE: 0.1948
2023-01-20 20:04:35,776:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-20 20:15:26,501:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.17504295706748962
2023-01-20 20:15:26,503:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.73s, LR: 0.00070, Train Loss: 0.1545, Train MAE: 0.1545,
                            Val Loss: 0.1755, Val MAE: 0.1750
2023-01-20 20:15:26,503:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-20 20:26:17,146:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16640236973762512
2023-01-20 20:26:17,147:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.64s, LR: 0.00070, Train Loss: 0.1486, Train MAE: 0.1486,
                            Val Loss: 0.1669, Val MAE: 0.1664
2023-01-20 20:26:17,147:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-20 20:37:07,524:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.38s, LR: 0.00070, Train Loss: 0.1458, Train MAE: 0.1458,
                            Val Loss: 0.1687, Val MAE: 0.1683
2023-01-20 20:37:07,525:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-20 20:47:58,110:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.59s, LR: 0.00070, Train Loss: 0.1420, Train MAE: 0.1420,
                            Val Loss: 0.2249, Val MAE: 0.2245
2023-01-20 20:47:58,111:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-20 20:58:48,073:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.160552516579628
2023-01-20 20:58:48,074:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.96s, LR: 0.00070, Train Loss: 0.1397, Train MAE: 0.1397,
                            Val Loss: 0.1610, Val MAE: 0.1606
2023-01-20 20:58:48,074:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-20 21:09:48,084:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15702976286411285
2023-01-20 21:09:48,086:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.01s, LR: 0.00070, Train Loss: 0.1369, Train MAE: 0.1369,
                            Val Loss: 0.1574, Val MAE: 0.1570
2023-01-20 21:09:48,086:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-20 21:21:45,288:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1564999371767044
2023-01-20 21:21:45,290:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.20s, LR: 0.00070, Train Loss: 0.1352, Train MAE: 0.1352,
                            Val Loss: 0.1569, Val MAE: 0.1565
2023-01-20 21:21:45,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-20 21:33:44,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.01s, LR: 0.00070, Train Loss: 0.1335, Train MAE: 0.1335,
                            Val Loss: 0.1695, Val MAE: 0.1692
2023-01-20 21:33:44,305:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-20 21:45:42,994:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14374901354312897
2023-01-20 21:45:43,009:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.70s, LR: 0.00070, Train Loss: 0.1321, Train MAE: 0.1321,
                            Val Loss: 0.1441, Val MAE: 0.1437
2023-01-20 21:45:43,009:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-20 21:57:35,045:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.03s, LR: 0.00070, Train Loss: 0.1313, Train MAE: 0.1313,
                            Val Loss: 0.1555, Val MAE: 0.1552
2023-01-20 21:57:35,064:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-20 22:09:24,783:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.72s, LR: 0.00070, Train Loss: 0.1296, Train MAE: 0.1296,
                            Val Loss: 0.1511, Val MAE: 0.1507
2023-01-20 22:09:24,784:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-20 22:22:18,967:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.18s, LR: 0.00070, Train Loss: 0.1288, Train MAE: 0.1288,
                            Val Loss: 0.1742, Val MAE: 0.1738
2023-01-20 22:22:18,968:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-20 22:33:25,328:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13554848730564117
2023-01-20 22:33:25,329:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.36s, LR: 0.00070, Train Loss: 0.1282, Train MAE: 0.1282,
                            Val Loss: 0.1359, Val MAE: 0.1355
2023-01-20 22:33:25,329:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-20 22:44:06,304:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.97s, LR: 0.00070, Train Loss: 0.1263, Train MAE: 0.1263,
                            Val Loss: 0.1425, Val MAE: 0.1422
2023-01-20 22:44:06,305:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-20 22:54:45,259:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.95s, LR: 0.00070, Train Loss: 0.1260, Train MAE: 0.1260,
                            Val Loss: 0.1451, Val MAE: 0.1447
2023-01-20 22:54:45,259:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-20 23:05:50,150:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.89s, LR: 0.00070, Train Loss: 0.1253, Train MAE: 0.1253,
                            Val Loss: 0.1500, Val MAE: 0.1497
2023-01-20 23:05:50,227:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-20 23:16:54,445:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1339627355337143
2023-01-20 23:16:54,630:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.40s, LR: 0.00070, Train Loss: 0.1245, Train MAE: 0.1245,
                            Val Loss: 0.1343, Val MAE: 0.1340
2023-01-20 23:16:54,630:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-20 23:27:58,975:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.34s, LR: 0.00070, Train Loss: 0.1237, Train MAE: 0.1237,
                            Val Loss: 0.1376, Val MAE: 0.1374
2023-01-20 23:27:59,106:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-20 23:39:05,445:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.34s, LR: 0.00070, Train Loss: 0.1230, Train MAE: 0.1230,
                            Val Loss: 0.1612, Val MAE: 0.1610
2023-01-20 23:39:05,529:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-20 23:50:19,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.59s, LR: 0.00070, Train Loss: 0.1223, Train MAE: 0.1223,
                            Val Loss: 0.1384, Val MAE: 0.1380
2023-01-20 23:50:19,821:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-21 00:02:04,772:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 704.95s, LR: 0.00070, Train Loss: 0.1214, Train MAE: 0.1214,
                            Val Loss: 0.1344, Val MAE: 0.1341
2023-01-21 00:02:04,828:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-21 00:13:29,746:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.85s, LR: 0.00070, Train Loss: 0.1208, Train MAE: 0.1208,
                            Val Loss: 0.1359, Val MAE: 0.1356
2023-01-21 00:13:29,900:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-21 00:24:49,754:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.77s, LR: 0.00070, Train Loss: 0.1207, Train MAE: 0.1207,
                            Val Loss: 0.1410, Val MAE: 0.1406
2023-01-21 00:24:49,852:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-21 00:36:18,256:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.34s, LR: 0.00070, Train Loss: 0.1196, Train MAE: 0.1196,
                            Val Loss: 0.1368, Val MAE: 0.1366
2023-01-21 00:36:18,410:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-21 00:47:41,691:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13095901906490326
2023-01-21 00:47:42,112:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.69s, LR: 0.00070, Train Loss: 0.1195, Train MAE: 0.1195,
                            Val Loss: 0.1313, Val MAE: 0.1310
2023-01-21 00:47:42,112:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-21 00:59:01,957:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.84s, LR: 0.00070, Train Loss: 0.1194, Train MAE: 0.1194,
                            Val Loss: 0.1315, Val MAE: 0.1312
2023-01-21 00:59:02,066:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-21 01:11:41,754:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 759.69s, LR: 0.00070, Train Loss: 0.1181, Train MAE: 0.1181,
                            Val Loss: 0.1407, Val MAE: 0.1404
2023-01-21 01:11:41,782:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-21 01:23:00,076:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.29s, LR: 0.00070, Train Loss: 0.1178, Train MAE: 0.1178,
                            Val Loss: 0.1319, Val MAE: 0.1317
2023-01-21 01:23:00,207:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-21 01:34:29,207:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12707796692848206
2023-01-21 01:34:29,436:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.22s, LR: 0.00070, Train Loss: 0.1175, Train MAE: 0.1175,
                            Val Loss: 0.1274, Val MAE: 0.1271
2023-01-21 01:34:29,436:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-21 01:45:45,737:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.27s, LR: 0.00070, Train Loss: 0.1166, Train MAE: 0.1166,
                            Val Loss: 0.1285, Val MAE: 0.1282
2023-01-21 01:45:45,816:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-21 01:57:06,910:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.06s, LR: 0.00070, Train Loss: 0.1169, Train MAE: 0.1169,
                            Val Loss: 0.1285, Val MAE: 0.1283
2023-01-21 01:57:07,066:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-21 02:08:25,877:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.81s, LR: 0.00070, Train Loss: 0.1160, Train MAE: 0.1160,
                            Val Loss: 0.1344, Val MAE: 0.1341
2023-01-21 02:08:25,892:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-21 02:19:41,085:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.19s, LR: 0.00070, Train Loss: 0.1154, Train MAE: 0.1154,
                            Val Loss: 0.1376, Val MAE: 0.1373
2023-01-21 02:19:41,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-21 02:31:04,240:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.95s, LR: 0.00070, Train Loss: 0.1148, Train MAE: 0.1148,
                            Val Loss: 0.1277, Val MAE: 0.1274
2023-01-21 02:31:04,262:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-21 02:42:27,053:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12637902796268463
2023-01-21 02:42:27,219:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.96s, LR: 0.00070, Train Loss: 0.1143, Train MAE: 0.1143,
                            Val Loss: 0.1266, Val MAE: 0.1264
2023-01-21 02:42:27,220:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-21 02:53:47,770:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.55s, LR: 0.00070, Train Loss: 0.1142, Train MAE: 0.1142,
                            Val Loss: 0.1275, Val MAE: 0.1273
2023-01-21 02:53:47,945:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-21 03:05:09,658:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.71s, LR: 0.00070, Train Loss: 0.1137, Train MAE: 0.1137,
                            Val Loss: 0.1324, Val MAE: 0.1321
2023-01-21 03:05:09,719:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-21 03:16:29,513:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.79s, LR: 0.00070, Train Loss: 0.1135, Train MAE: 0.1135,
                            Val Loss: 0.1270, Val MAE: 0.1267
2023-01-21 03:16:29,594:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-21 03:27:49,412:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12414108216762543
2023-01-21 03:27:49,516:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.92s, LR: 0.00070, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.1244, Val MAE: 0.1241
2023-01-21 03:27:49,516:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-21 03:39:09,451:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12226051092147827
2023-01-21 03:39:09,674:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.16s, LR: 0.00070, Train Loss: 0.1122, Train MAE: 0.1122,
                            Val Loss: 0.1225, Val MAE: 0.1223
2023-01-21 03:39:09,674:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-21 03:50:37,230:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.55s, LR: 0.00070, Train Loss: 0.1124, Train MAE: 0.1124,
                            Val Loss: 0.1252, Val MAE: 0.1250
2023-01-21 03:50:37,259:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-21 04:03:16,530:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 759.18s, LR: 0.00070, Train Loss: 0.1120, Train MAE: 0.1120,
                            Val Loss: 0.1237, Val MAE: 0.1235
2023-01-21 04:03:16,617:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-21 04:14:47,563:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.95s, LR: 0.00070, Train Loss: 0.1122, Train MAE: 0.1122,
                            Val Loss: 0.1498, Val MAE: 0.1495
2023-01-21 04:14:47,600:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-21 04:26:15,661:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.06s, LR: 0.00070, Train Loss: 0.1116, Train MAE: 0.1116,
                            Val Loss: 0.1278, Val MAE: 0.1276
2023-01-21 04:26:15,754:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-21 04:39:32,231:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12198738753795624
2023-01-21 04:39:32,369:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 796.53s, LR: 0.00070, Train Loss: 0.1111, Train MAE: 0.1111,
                            Val Loss: 0.1222, Val MAE: 0.1220
2023-01-21 04:39:32,377:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-21 04:53:07,988:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12034916132688522
2023-01-21 04:53:07,991:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 815.61s, LR: 0.00070, Train Loss: 0.1113, Train MAE: 0.1113,
                            Val Loss: 0.1206, Val MAE: 0.1203
2023-01-21 04:53:07,992:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-21 05:05:27,493:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.50s, LR: 0.00070, Train Loss: 0.1108, Train MAE: 0.1108,
                            Val Loss: 0.1260, Val MAE: 0.1258
2023-01-21 05:05:27,494:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-21 05:17:43,899:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 736.40s, LR: 0.00070, Train Loss: 0.1104, Train MAE: 0.1104,
                            Val Loss: 0.1238, Val MAE: 0.1236
2023-01-21 05:17:43,899:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-21 05:30:04,526:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.63s, LR: 0.00070, Train Loss: 0.1099, Train MAE: 0.1099,
                            Val Loss: 0.1229, Val MAE: 0.1227
2023-01-21 05:30:04,527:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-21 05:42:22,008:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.48s, LR: 0.00070, Train Loss: 0.1097, Train MAE: 0.1097,
                            Val Loss: 0.1403, Val MAE: 0.1401
2023-01-21 05:42:22,009:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-21 05:54:48,167:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.16s, LR: 0.00070, Train Loss: 0.1095, Train MAE: 0.1095,
                            Val Loss: 0.1260, Val MAE: 0.1258
2023-01-21 05:54:48,168:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-21 06:07:03,787:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 735.62s, LR: 0.00070, Train Loss: 0.1093, Train MAE: 0.1093,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-21 06:07:03,788:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-21 06:19:18,484:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.70s, LR: 0.00070, Train Loss: 0.1089, Train MAE: 0.1089,
                            Val Loss: 0.1211, Val MAE: 0.1209
2023-01-21 06:19:18,485:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-21 06:31:30,645:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.16s, LR: 0.00070, Train Loss: 0.1087, Train MAE: 0.1087,
                            Val Loss: 0.1230, Val MAE: 0.1228
2023-01-21 06:31:30,645:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-21 06:43:45,348:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.70s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1227, Val MAE: 0.1225
2023-01-21 06:43:45,349:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-21 06:55:53,558:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1200179010629654
2023-01-21 06:55:53,559:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.21s, LR: 0.00070, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.1202, Val MAE: 0.1200
2023-01-21 06:55:53,559:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-21 07:09:16,649:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 803.09s, LR: 0.00070, Train Loss: 0.1080, Train MAE: 0.1080,
                            Val Loss: 0.1229, Val MAE: 0.1226
2023-01-21 07:09:16,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-21 07:21:27,978:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11838924884796143
2023-01-21 07:21:27,980:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 731.33s, LR: 0.00070, Train Loss: 0.1078, Train MAE: 0.1078,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-21 07:21:27,980:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-21 07:33:41,383:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 733.40s, LR: 0.00070, Train Loss: 0.1076, Train MAE: 0.1076,
                            Val Loss: 0.1206, Val MAE: 0.1204
2023-01-21 07:33:41,383:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-21 07:45:51,740:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.36s, LR: 0.00070, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.1208, Val MAE: 0.1206
2023-01-21 07:45:51,741:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-21 07:58:03,046:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 731.30s, LR: 0.00070, Train Loss: 0.1074, Train MAE: 0.1074,
                            Val Loss: 0.1255, Val MAE: 0.1253
2023-01-21 07:58:03,047:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-21 08:10:10,106:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.06s, LR: 0.00070, Train Loss: 0.1067, Train MAE: 0.1067,
                            Val Loss: 0.1207, Val MAE: 0.1205
2023-01-21 08:10:10,107:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-21 08:22:21,708:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 731.60s, LR: 0.00070, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.1240, Val MAE: 0.1237
2023-01-21 08:22:21,709:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-21 08:34:31,664:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 729.95s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1191, Val MAE: 0.1189
2023-01-21 08:34:31,665:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-21 08:46:38,567:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.90s, LR: 0.00070, Train Loss: 0.1066, Train MAE: 0.1066,
                            Val Loss: 0.1200, Val MAE: 0.1198
2023-01-21 08:46:38,568:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-21 08:58:40,555:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.99s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1222, Val MAE: 0.1220
2023-01-21 08:58:40,556:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-21 09:10:46,930:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11836645007133484
2023-01-21 09:10:46,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.38s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-21 09:10:46,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-21 09:23:00,785:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 733.85s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-21 09:23:00,785:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-21 09:35:04,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.94s, LR: 0.00070, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.1287, Val MAE: 0.1286
2023-01-21 09:35:04,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-21 09:47:04,068:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.34s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1250, Val MAE: 0.1248
2023-01-21 09:47:04,069:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-21 09:59:01,743:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11809109896421432
2023-01-21 09:59:01,745:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.68s, LR: 0.00070, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.1183, Val MAE: 0.1181
2023-01-21 09:59:01,745:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-21 10:12:20,413:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 798.67s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1231, Val MAE: 0.1229
2023-01-21 10:12:20,414:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-21 10:24:19,696:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.28s, LR: 0.00070, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.1240, Val MAE: 0.1238
2023-01-21 10:24:19,696:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-21 10:36:16,024:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.33s, LR: 0.00070, Train Loss: 0.1049, Train MAE: 0.1049,
                            Val Loss: 0.1228, Val MAE: 0.1226
2023-01-21 10:36:16,024:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-21 10:48:14,978:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.95s, LR: 0.00070, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.1239, Val MAE: 0.1237
2023-01-21 10:48:14,978:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-21 11:00:09,163:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.18s, LR: 0.00070, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.1233, Val MAE: 0.1231
2023-01-21 11:00:09,164:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-21 11:12:02,648:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 713.48s, LR: 0.00070, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.1266, Val MAE: 0.1264
2023-01-21 11:12:02,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-21 11:24:00,042:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11693673580884933
2023-01-21 11:24:00,043:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.39s, LR: 0.00070, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.1171, Val MAE: 0.1169
2023-01-21 11:24:00,044:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-21 11:36:00,207:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.16s, LR: 0.00070, Train Loss: 0.1043, Train MAE: 0.1043,
                            Val Loss: 0.1213, Val MAE: 0.1211
2023-01-21 11:36:00,208:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-21 11:49:20,279:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 800.07s, LR: 0.00070, Train Loss: 0.1043, Train MAE: 0.1043,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-21 11:49:20,280:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-21 12:02:55,912:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 815.63s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1176, Val MAE: 0.1173
2023-01-21 12:02:55,913:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-21 12:15:29,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 753.81s, LR: 0.00070, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-21 12:15:29,723:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-21 12:27:25,198:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.47s, LR: 0.00070, Train Loss: 0.1037, Train MAE: 0.1037,
                            Val Loss: 0.1185, Val MAE: 0.1183
2023-01-21 12:27:25,199:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-21 12:39:21,427:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.23s, LR: 0.00070, Train Loss: 0.1037, Train MAE: 0.1037,
                            Val Loss: 0.1189, Val MAE: 0.1187
2023-01-21 12:39:21,427:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-21 12:51:16,284:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.86s, LR: 0.00070, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.1206, Val MAE: 0.1204
2023-01-21 12:51:16,285:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-21 13:03:14,454:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.17s, LR: 0.00070, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.1222, Val MAE: 0.1220
2023-01-21 13:03:14,455:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-21 13:16:25,288:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 790.83s, LR: 0.00070, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-21 13:16:25,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-21 13:28:24,779:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.49s, LR: 0.00070, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-21 13:28:24,780:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-21 13:40:28,433:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.65s, LR: 0.00070, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1173, Val MAE: 0.1171
2023-01-21 13:40:28,434:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-21 13:52:24,105:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11681647598743439
2023-01-21 13:52:24,106:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.67s, LR: 0.00070, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.1170, Val MAE: 0.1168
2023-01-21 13:52:24,107:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-21 14:04:19,694:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11655433475971222
2023-01-21 14:04:19,695:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.59s, LR: 0.00070, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.1168, Val MAE: 0.1166
2023-01-21 14:04:19,696:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-21 14:16:18,061:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.36s, LR: 0.00070, Train Loss: 0.1029, Train MAE: 0.1029,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-21 14:16:18,061:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-21 14:28:08,160:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.10s, LR: 0.00070, Train Loss: 0.1026, Train MAE: 0.1026,
                            Val Loss: 0.1219, Val MAE: 0.1217
2023-01-21 14:28:08,161:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-21 14:40:09,326:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.16s, LR: 0.00070, Train Loss: 0.1024, Train MAE: 0.1024,
                            Val Loss: 0.1229, Val MAE: 0.1227
2023-01-21 14:40:09,326:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-21 14:52:10,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.29s, LR: 0.00070, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.1172, Val MAE: 0.1170
2023-01-21 14:52:10,619:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-21 15:03:52,196:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.58s, LR: 0.00070, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.1172, Val MAE: 0.1170
2023-01-21 15:03:52,197:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-21 15:15:18,767:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 686.57s, LR: 0.00070, Train Loss: 0.1020, Train MAE: 0.1020,
                            Val Loss: 0.1241, Val MAE: 0.1239
2023-01-21 15:15:18,768:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-21 15:26:44,376:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.61s, LR: 0.00070, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.1196, Val MAE: 0.1194
2023-01-21 15:26:44,376:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-21 15:38:00,645:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.27s, LR: 0.00070, Train Loss: 0.1019, Train MAE: 0.1019,
                            Val Loss: 0.1182, Val MAE: 0.1180
2023-01-21 15:38:00,646:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-21 15:49:16,676:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.03s, LR: 0.00070, Train Loss: 0.1017, Train MAE: 0.1017,
                            Val Loss: 0.1177, Val MAE: 0.1175
2023-01-21 15:49:16,677:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-21 16:00:36,783:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.11s, LR: 0.00070, Train Loss: 0.1017, Train MAE: 0.1017,
                            Val Loss: 0.1171, Val MAE: 0.1169
2023-01-21 16:00:36,784:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-21 16:11:58,488:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1156901866197586
2023-01-21 16:11:58,489:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.70s, LR: 0.00070, Train Loss: 0.1015, Train MAE: 0.1015,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-21 16:11:58,489:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-21 16:24:32,820:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 754.33s, LR: 0.00070, Train Loss: 0.1017, Train MAE: 0.1017,
                            Val Loss: 0.1189, Val MAE: 0.1188
2023-01-21 16:24:32,820:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-21 16:35:55,994:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.17s, LR: 0.00070, Train Loss: 0.1014, Train MAE: 0.1014,
                            Val Loss: 0.1164, Val MAE: 0.1162
2023-01-21 16:35:55,994:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-21 16:47:23,279:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.28s, LR: 0.00070, Train Loss: 0.1014, Train MAE: 0.1014,
                            Val Loss: 0.1173, Val MAE: 0.1171
2023-01-21 16:47:23,279:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-21 16:58:37,710:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 674.43s, LR: 0.00070, Train Loss: 0.1013, Train MAE: 0.1013,
                            Val Loss: 0.1191, Val MAE: 0.1189
2023-01-21 16:58:37,710:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-21 17:10:06,946:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.24s, LR: 0.00070, Train Loss: 0.1014, Train MAE: 0.1014,
                            Val Loss: 0.1187, Val MAE: 0.1185
2023-01-21 17:10:06,947:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-21 17:21:27,552:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.61s, LR: 0.00070, Train Loss: 0.1011, Train MAE: 0.1011,
                            Val Loss: 0.1178, Val MAE: 0.1176
2023-01-21 17:21:27,553:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-21 17:32:57,595:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.04s, LR: 0.00070, Train Loss: 0.1012, Train MAE: 0.1012,
                            Val Loss: 0.1188, Val MAE: 0.1186
2023-01-21 17:32:57,596:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-21 17:44:27,190:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.59s, LR: 0.00070, Train Loss: 0.1010, Train MAE: 0.1010,
                            Val Loss: 0.1164, Val MAE: 0.1162
2023-01-21 17:44:27,192:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-21 17:55:42,915:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11561700701713562
2023-01-21 17:55:42,917:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.72s, LR: 0.00070, Train Loss: 0.1011, Train MAE: 0.1011,
                            Val Loss: 0.1158, Val MAE: 0.1156
2023-01-21 17:55:42,917:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-21 18:07:14,232:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.31s, LR: 0.00070, Train Loss: 0.1008, Train MAE: 0.1008,
                            Val Loss: 0.1177, Val MAE: 0.1175
2023-01-21 18:07:14,232:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-21 18:18:29,441:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.21s, LR: 0.00070, Train Loss: 0.1005, Train MAE: 0.1005,
                            Val Loss: 0.1170, Val MAE: 0.1168
2023-01-21 18:18:29,441:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-21 18:30:02,817:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11517199128866196
2023-01-21 18:30:02,818:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.38s, LR: 0.00070, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.1154, Val MAE: 0.1152
2023-01-21 18:30:02,818:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-21 18:41:15,304:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11434125155210495
2023-01-21 18:41:15,306:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.49s, LR: 0.00070, Train Loss: 0.1005, Train MAE: 0.1005,
                            Val Loss: 0.1145, Val MAE: 0.1143
2023-01-21 18:41:15,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-21 18:52:39,894:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.59s, LR: 0.00070, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-21 18:52:39,894:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-21 19:04:43,216:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.32s, LR: 0.00070, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1187, Val MAE: 0.1185
2023-01-21 19:04:43,216:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-21 19:16:07,784:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.57s, LR: 0.00070, Train Loss: 0.1001, Train MAE: 0.1001,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-21 19:16:07,785:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-21 19:27:17,248:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.46s, LR: 0.00070, Train Loss: 0.1004, Train MAE: 0.1004,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-21 19:27:17,248:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-21 19:38:26,255:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.01s, LR: 0.00070, Train Loss: 0.1001, Train MAE: 0.1001,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-21 19:38:26,255:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-21 19:38:26,256:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-21 19:45:38,983:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1173
2023-01-21 19:45:38,984:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0988
2023-01-21 19:45:38,985:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-21 19:45:38,985:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 122.0000
2023-01-21 19:45:38,985:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87417.6751s
2023-01-21 19:45:39,305:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 707.1137s
2023-01-21 19:45:39,338:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-21 19:45:40,719:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0988)]
2023-01-21 19:45:40,719:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1173)]
