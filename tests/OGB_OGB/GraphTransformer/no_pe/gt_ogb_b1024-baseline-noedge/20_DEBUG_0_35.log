2023-01-20 19:13:13,889:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-20 19:13:13,890:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-20 19:28:20,793:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-20 19:28:51,258:ogbdata.py:332 -             __init__(): Time taken: 937.3687s
2023-01-20 19:28:51,259:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-20 19:28:51,259:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-20 19:28:51,259:ogbdata.py:348 -             __init__(): [I] Data load time: 937.3692s
2023-01-20 19:28:51,259:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/no_pe/gt_ogb_b1024-baseline-noedge/20_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-20 19:28:51,259:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-20 19:28:51,261:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:28:51,262:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:28:51,262:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:28:51,402:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-20 19:28:51,421:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536741
2023-01-20 19:28:51,421:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-20 19:28:51,421:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:28:51,421:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:28:51,421:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:29:02,458:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-20 19:29:02,458:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-20 19:29:02,468:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-20 19:42:41,080:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2187342792749405
2023-01-20 19:42:41,093:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 818.62s, LR: 0.00070, Train Loss: 0.3245, Train MAE: 0.3245,
                            Val Loss: 0.2191, Val MAE: 0.2187
2023-01-20 19:42:41,093:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-20 19:53:17,856:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.20100347697734833
2023-01-20 19:53:17,858:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.76s, LR: 0.00070, Train Loss: 0.1866, Train MAE: 0.1866,
                            Val Loss: 0.2013, Val MAE: 0.2010
2023-01-20 19:53:17,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-20 20:03:54,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.13s, LR: 0.00070, Train Loss: 0.1721, Train MAE: 0.1721,
                            Val Loss: 0.2101, Val MAE: 0.2097
2023-01-20 20:03:54,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-20 20:14:31,872:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.88s, LR: 0.00070, Train Loss: 0.1648, Train MAE: 0.1648,
                            Val Loss: 0.3325, Val MAE: 0.3323
2023-01-20 20:14:31,873:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-20 20:25:07,750:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.17934159934520721
2023-01-20 20:25:07,752:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.88s, LR: 0.00070, Train Loss: 0.1588, Train MAE: 0.1588,
                            Val Loss: 0.1796, Val MAE: 0.1793
2023-01-20 20:25:07,752:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-20 20:35:40,068:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.31s, LR: 0.00070, Train Loss: 0.1551, Train MAE: 0.1551,
                            Val Loss: 0.2987, Val MAE: 0.2984
2023-01-20 20:35:40,068:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-20 20:46:16,488:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1606912761926651
2023-01-20 20:46:16,490:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.42s, LR: 0.00070, Train Loss: 0.1516, Train MAE: 0.1516,
                            Val Loss: 0.1610, Val MAE: 0.1607
2023-01-20 20:46:16,490:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-20 20:56:50,091:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 633.60s, LR: 0.00070, Train Loss: 0.1496, Train MAE: 0.1496,
                            Val Loss: 0.1755, Val MAE: 0.1752
2023-01-20 20:56:50,091:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-20 21:07:27,907:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15673303604125977
2023-01-20 21:07:27,908:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.82s, LR: 0.00070, Train Loss: 0.1478, Train MAE: 0.1478,
                            Val Loss: 0.1570, Val MAE: 0.1567
2023-01-20 21:07:27,909:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-20 21:18:04,523:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.61s, LR: 0.00070, Train Loss: 0.1465, Train MAE: 0.1465,
                            Val Loss: 0.2018, Val MAE: 0.2016
2023-01-20 21:18:04,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-20 21:28:47,247:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14510683715343475
2023-01-20 21:28:47,260:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 642.74s, LR: 0.00070, Train Loss: 0.1442, Train MAE: 0.1442,
                            Val Loss: 0.1454, Val MAE: 0.1451
2023-01-20 21:28:47,260:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-20 21:39:36,878:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.62s, LR: 0.00070, Train Loss: 0.1439, Train MAE: 0.1439,
                            Val Loss: 0.1670, Val MAE: 0.1667
2023-01-20 21:39:36,894:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-20 21:51:39,646:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.75s, LR: 0.00070, Train Loss: 0.1425, Train MAE: 0.1425,
                            Val Loss: 0.2004, Val MAE: 0.2001
2023-01-20 21:51:39,669:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-20 22:03:39,493:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.82s, LR: 0.00070, Train Loss: 0.1404, Train MAE: 0.1404,
                            Val Loss: 0.1544, Val MAE: 0.1542
2023-01-20 22:03:39,494:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-20 22:16:55,754:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 796.26s, LR: 0.00070, Train Loss: 0.1381, Train MAE: 0.1381,
                            Val Loss: 0.1474, Val MAE: 0.1472
2023-01-20 22:16:55,755:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-20 22:28:48,491:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.74s, LR: 0.00070, Train Loss: 0.1368, Train MAE: 0.1368,
                            Val Loss: 0.1566, Val MAE: 0.1563
2023-01-20 22:28:48,492:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-20 22:40:48,887:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.39s, LR: 0.00070, Train Loss: 0.1377, Train MAE: 0.1377,
                            Val Loss: 0.2091, Val MAE: 0.2089
2023-01-20 22:40:48,888:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-20 22:51:40,194:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.31s, LR: 0.00070, Train Loss: 0.1383, Train MAE: 0.1383,
                            Val Loss: 0.1824, Val MAE: 0.1822
2023-01-20 22:51:40,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-20 23:03:15,016:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1382724642753601
2023-01-20 23:03:15,017:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.82s, LR: 0.00070, Train Loss: 0.1338, Train MAE: 0.1338,
                            Val Loss: 0.1385, Val MAE: 0.1383
2023-01-20 23:03:15,017:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-20 23:15:10,347:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13742710649967194
2023-01-20 23:15:10,350:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.33s, LR: 0.00070, Train Loss: 0.1327, Train MAE: 0.1327,
                            Val Loss: 0.1376, Val MAE: 0.1374
2023-01-20 23:15:10,350:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-20 23:27:07,735:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.38s, LR: 0.00070, Train Loss: 0.1330, Train MAE: 0.1330,
                            Val Loss: 0.1511, Val MAE: 0.1509
2023-01-20 23:27:07,735:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-20 23:39:07,033:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.30s, LR: 0.00070, Train Loss: 0.1321, Train MAE: 0.1321,
                            Val Loss: 0.1525, Val MAE: 0.1523
2023-01-20 23:39:07,034:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-20 23:51:08,358:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.32s, LR: 0.00070, Train Loss: 0.1303, Train MAE: 0.1303,
                            Val Loss: 0.1452, Val MAE: 0.1450
2023-01-20 23:51:08,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-21 00:03:08,044:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.68s, LR: 0.00070, Train Loss: 0.1291, Train MAE: 0.1291,
                            Val Loss: 0.1646, Val MAE: 0.1644
2023-01-21 00:03:08,044:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-21 00:15:08,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.99s, LR: 0.00070, Train Loss: 0.1276, Train MAE: 0.1276,
                            Val Loss: 0.1701, Val MAE: 0.1699
2023-01-21 00:15:08,038:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-21 00:27:06,208:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.17s, LR: 0.00070, Train Loss: 0.1270, Train MAE: 0.1270,
                            Val Loss: 0.1495, Val MAE: 0.1493
2023-01-21 00:27:06,208:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-21 00:39:02,885:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.68s, LR: 0.00070, Train Loss: 0.1270, Train MAE: 0.1270,
                            Val Loss: 0.1459, Val MAE: 0.1457
2023-01-21 00:39:02,886:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-21 00:50:59,549:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12992599606513977
2023-01-21 00:50:59,551:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.66s, LR: 0.00070, Train Loss: 0.1263, Train MAE: 0.1263,
                            Val Loss: 0.1301, Val MAE: 0.1299
2023-01-21 00:50:59,551:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-21 01:02:56,553:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.00s, LR: 0.00070, Train Loss: 0.1247, Train MAE: 0.1247,
                            Val Loss: 0.1433, Val MAE: 0.1431
2023-01-21 01:02:56,553:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-21 01:16:09,576:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 793.02s, LR: 0.00070, Train Loss: 0.1282, Train MAE: 0.1282,
                            Val Loss: 0.1391, Val MAE: 0.1389
2023-01-21 01:16:09,576:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-21 01:28:09,390:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1297132819890976
2023-01-21 01:28:09,392:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.82s, LR: 0.00070, Train Loss: 0.1261, Train MAE: 0.1261,
                            Val Loss: 0.1299, Val MAE: 0.1297
2023-01-21 01:28:09,392:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-21 01:40:08,811:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.42s, LR: 0.00070, Train Loss: 0.1244, Train MAE: 0.1244,
                            Val Loss: 0.1330, Val MAE: 0.1328
2023-01-21 01:40:08,812:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-21 01:52:11,435:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12431884557008743
2023-01-21 01:52:11,436:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.62s, LR: 0.00070, Train Loss: 0.1229, Train MAE: 0.1229,
                            Val Loss: 0.1245, Val MAE: 0.1243
2023-01-21 01:52:11,436:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-21 02:04:14,839:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.40s, LR: 0.00070, Train Loss: 0.1237, Train MAE: 0.1237,
                            Val Loss: 0.1466, Val MAE: 0.1464
2023-01-21 02:04:14,840:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-21 02:16:16,037:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.20s, LR: 0.00070, Train Loss: 0.1224, Train MAE: 0.1224,
                            Val Loss: 0.1268, Val MAE: 0.1266
2023-01-21 02:16:16,037:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-21 02:28:18,541:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.50s, LR: 0.00070, Train Loss: 0.1209, Train MAE: 0.1209,
                            Val Loss: 0.1563, Val MAE: 0.1561
2023-01-21 02:28:18,541:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-21 02:40:21,433:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.89s, LR: 0.00070, Train Loss: 0.1231, Train MAE: 0.1231,
                            Val Loss: 0.1491, Val MAE: 0.1490
2023-01-21 02:40:21,433:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-21 02:52:26,021:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.59s, LR: 0.00070, Train Loss: 0.1209, Train MAE: 0.1209,
                            Val Loss: 0.1357, Val MAE: 0.1355
2023-01-21 02:52:26,021:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-21 03:04:26,090:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.07s, LR: 0.00070, Train Loss: 0.1196, Train MAE: 0.1196,
                            Val Loss: 0.1320, Val MAE: 0.1318
2023-01-21 03:04:26,090:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-21 03:16:28,685:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.59s, LR: 0.00070, Train Loss: 0.1193, Train MAE: 0.1193,
                            Val Loss: 0.1276, Val MAE: 0.1274
2023-01-21 03:16:28,685:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-21 03:28:34,826:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.14s, LR: 0.00070, Train Loss: 0.1181, Train MAE: 0.1181,
                            Val Loss: 0.1375, Val MAE: 0.1373
2023-01-21 03:28:34,826:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-21 03:40:36,077:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.25s, LR: 0.00070, Train Loss: 0.1179, Train MAE: 0.1179,
                            Val Loss: 0.1359, Val MAE: 0.1357
2023-01-21 03:40:36,077:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-21 03:52:39,027:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.95s, LR: 0.00070, Train Loss: 0.1168, Train MAE: 0.1168,
                            Val Loss: 0.1286, Val MAE: 0.1284
2023-01-21 03:52:39,027:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-21 04:04:42,739:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.71s, LR: 0.00070, Train Loss: 0.1165, Train MAE: 0.1165,
                            Val Loss: 0.1321, Val MAE: 0.1320
2023-01-21 04:04:42,740:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-21 04:17:59,069:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 796.33s, LR: 0.00070, Train Loss: 0.1163, Train MAE: 0.1163,
                            Val Loss: 0.1314, Val MAE: 0.1312
2023-01-21 04:17:59,070:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-21 04:30:07,928:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.86s, LR: 0.00070, Train Loss: 0.1157, Train MAE: 0.1157,
                            Val Loss: 0.1267, Val MAE: 0.1266
2023-01-21 04:30:07,953:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-21 04:42:18,928:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.97s, LR: 0.00070, Train Loss: 0.1149, Train MAE: 0.1149,
                            Val Loss: 0.1270, Val MAE: 0.1268
2023-01-21 04:42:18,929:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-21 04:54:31,832:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1226261630654335
2023-01-21 04:54:31,834:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.90s, LR: 0.00070, Train Loss: 0.1146, Train MAE: 0.1146,
                            Val Loss: 0.1228, Val MAE: 0.1226
2023-01-21 04:54:31,834:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-21 05:06:38,586:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.75s, LR: 0.00070, Train Loss: 0.1137, Train MAE: 0.1137,
                            Val Loss: 0.1264, Val MAE: 0.1262
2023-01-21 05:06:38,586:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-21 05:18:47,222:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.64s, LR: 0.00070, Train Loss: 0.1130, Train MAE: 0.1130,
                            Val Loss: 0.1241, Val MAE: 0.1239
2023-01-21 05:18:47,223:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-21 05:30:55,086:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.86s, LR: 0.00070, Train Loss: 0.1137, Train MAE: 0.1137,
                            Val Loss: 0.1269, Val MAE: 0.1268
2023-01-21 05:30:55,086:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-21 05:43:05,252:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.17s, LR: 0.00070, Train Loss: 0.1126, Train MAE: 0.1126,
                            Val Loss: 0.1243, Val MAE: 0.1242
2023-01-21 05:43:05,253:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-21 05:55:14,522:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 729.27s, LR: 0.00070, Train Loss: 0.1115, Train MAE: 0.1115,
                            Val Loss: 0.1255, Val MAE: 0.1253
2023-01-21 05:55:14,523:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-21 06:07:25,265:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.74s, LR: 0.00070, Train Loss: 0.1117, Train MAE: 0.1117,
                            Val Loss: 0.1265, Val MAE: 0.1263
2023-01-21 06:07:25,266:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-21 06:19:32,869:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12256551533937454
2023-01-21 06:19:32,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.60s, LR: 0.00070, Train Loss: 0.1108, Train MAE: 0.1108,
                            Val Loss: 0.1228, Val MAE: 0.1226
2023-01-21 06:19:32,871:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-21 06:31:40,270:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12141761183738708
2023-01-21 06:31:40,272:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.40s, LR: 0.00070, Train Loss: 0.1109, Train MAE: 0.1109,
                            Val Loss: 0.1216, Val MAE: 0.1214
2023-01-21 06:31:40,272:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-21 06:43:52,118:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12089404463768005
2023-01-21 06:43:52,119:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 731.85s, LR: 0.00070, Train Loss: 0.1102, Train MAE: 0.1102,
                            Val Loss: 0.1211, Val MAE: 0.1209
2023-01-21 06:43:52,120:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-21 06:55:57,923:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.80s, LR: 0.00070, Train Loss: 0.1100, Train MAE: 0.1100,
                            Val Loss: 0.1222, Val MAE: 0.1220
2023-01-21 06:55:57,924:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-21 07:08:06,120:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12051718682050705
2023-01-21 07:08:06,121:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.20s, LR: 0.00070, Train Loss: 0.1097, Train MAE: 0.1097,
                            Val Loss: 0.1207, Val MAE: 0.1205
2023-01-21 07:08:06,122:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-21 07:21:34,456:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.119255430996418
2023-01-21 07:21:34,458:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 808.34s, LR: 0.00070, Train Loss: 0.1093, Train MAE: 0.1093,
                            Val Loss: 0.1194, Val MAE: 0.1193
2023-01-21 07:21:34,458:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-21 07:33:43,094:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.63s, LR: 0.00070, Train Loss: 0.1086, Train MAE: 0.1086,
                            Val Loss: 0.1209, Val MAE: 0.1207
2023-01-21 07:33:43,095:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-21 07:45:53,990:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.89s, LR: 0.00070, Train Loss: 0.1089, Train MAE: 0.1089,
                            Val Loss: 0.1226, Val MAE: 0.1224
2023-01-21 07:45:53,991:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-21 07:58:06,946:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.95s, LR: 0.00070, Train Loss: 0.1086, Train MAE: 0.1086,
                            Val Loss: 0.1202, Val MAE: 0.1200
2023-01-21 07:58:06,947:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-21 08:10:16,285:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 729.34s, LR: 0.00070, Train Loss: 0.1091, Train MAE: 0.1091,
                            Val Loss: 0.1242, Val MAE: 0.1240
2023-01-21 08:10:16,285:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-21 08:22:27,033:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.75s, LR: 0.00070, Train Loss: 0.1076, Train MAE: 0.1076,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-21 08:22:27,034:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-21 08:34:42,130:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 735.10s, LR: 0.00070, Train Loss: 0.1074, Train MAE: 0.1074,
                            Val Loss: 0.1197, Val MAE: 0.1195
2023-01-21 08:34:42,130:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-21 08:46:54,156:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.02s, LR: 0.00070, Train Loss: 0.1070, Train MAE: 0.1070,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-21 08:46:54,156:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-21 08:59:03,780:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 729.62s, LR: 0.00070, Train Loss: 0.1073, Train MAE: 0.1073,
                            Val Loss: 0.1196, Val MAE: 0.1194
2023-01-21 08:59:03,781:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-21 09:11:12,711:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.93s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1198, Val MAE: 0.1196
2023-01-21 09:11:12,711:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-21 09:23:22,670:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.118560291826725
2023-01-21 09:23:22,671:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 729.96s, LR: 0.00070, Train Loss: 0.1076, Train MAE: 0.1076,
                            Val Loss: 0.1187, Val MAE: 0.1186
2023-01-21 09:23:22,671:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-21 09:35:29,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.30s, LR: 0.00070, Train Loss: 0.1061, Train MAE: 0.1061,
                            Val Loss: 0.1234, Val MAE: 0.1232
2023-01-21 09:35:29,972:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-21 09:47:02,427:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11849021911621094
2023-01-21 09:47:02,428:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.46s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1187, Val MAE: 0.1185
2023-01-21 09:47:02,429:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-21 09:58:05,288:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1184038296341896
2023-01-21 09:58:05,290:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.86s, LR: 0.00070, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-21 09:58:05,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-21 10:09:10,387:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11709214746952057
2023-01-21 10:09:10,388:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.10s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1173, Val MAE: 0.1171
2023-01-21 10:09:10,388:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-21 10:21:23,610:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 733.22s, LR: 0.00070, Train Loss: 0.1059, Train MAE: 0.1059,
                            Val Loss: 0.1183, Val MAE: 0.1181
2023-01-21 10:21:23,611:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-21 10:32:24,135:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11633335053920746
2023-01-21 10:32:24,136:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.53s, LR: 0.00070, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.1165, Val MAE: 0.1163
2023-01-21 10:32:24,137:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-21 10:43:33,154:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.02s, LR: 0.00070, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.1184, Val MAE: 0.1182
2023-01-21 10:43:33,155:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-21 10:54:28,424:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.27s, LR: 0.00070, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.1193, Val MAE: 0.1191
2023-01-21 10:54:28,424:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-21 11:05:11,057:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11600877344608307
2023-01-21 11:05:11,058:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 642.63s, LR: 0.00070, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1162, Val MAE: 0.1160
2023-01-21 11:05:11,058:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-21 11:15:49,524:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.46s, LR: 0.00070, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1247, Val MAE: 0.1245
2023-01-21 11:15:49,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-21 11:26:41,680:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.16s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1181, Val MAE: 0.1179
2023-01-21 11:26:41,681:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-21 11:37:43,039:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.36s, LR: 0.00070, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1190, Val MAE: 0.1188
2023-01-21 11:37:43,040:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-21 11:48:51,801:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.76s, LR: 0.00070, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1171, Val MAE: 0.1169
2023-01-21 11:48:51,802:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-21 11:59:54,538:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.74s, LR: 0.00070, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1171, Val MAE: 0.1169
2023-01-21 11:59:54,539:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-21 12:11:02,623:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.08s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1183, Val MAE: 0.1181
2023-01-21 12:11:02,624:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-21 12:22:08,975:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.35s, LR: 0.00070, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.1165, Val MAE: 0.1163
2023-01-21 12:22:08,975:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-21 12:33:08,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.89s, LR: 0.00070, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1172, Val MAE: 0.1170
2023-01-21 12:33:08,870:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-21 12:44:10,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.65s, LR: 0.00070, Train Loss: 0.1028, Train MAE: 0.1028,
                            Val Loss: 0.1176, Val MAE: 0.1174
2023-01-21 12:44:10,526:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-21 12:55:11,137:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.61s, LR: 0.00070, Train Loss: 0.1028, Train MAE: 0.1028,
                            Val Loss: 0.1170, Val MAE: 0.1168
2023-01-21 12:55:11,138:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-21 13:07:14,029:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.89s, LR: 0.00070, Train Loss: 0.1138, Train MAE: 0.1138,
                            Val Loss: 0.3265, Val MAE: 0.3264
2023-01-21 13:07:14,030:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-21 13:18:09,891:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.86s, LR: 0.00070, Train Loss: 0.2315, Train MAE: 0.2315,
                            Val Loss: 0.2732, Val MAE: 0.2730
2023-01-21 13:18:09,892:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-21 13:29:06,291:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.40s, LR: 0.00070, Train Loss: 0.1930, Train MAE: 0.1930,
                            Val Loss: 0.1849, Val MAE: 0.1847
2023-01-21 13:29:06,292:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-21 13:40:03,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.44s, LR: 0.00070, Train Loss: 0.1678, Train MAE: 0.1678,
                            Val Loss: 0.1804, Val MAE: 0.1802
2023-01-21 13:40:03,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-21 13:51:00,254:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.52s, LR: 0.00070, Train Loss: 0.1587, Train MAE: 0.1587,
                            Val Loss: 0.1702, Val MAE: 0.1700
2023-01-21 13:51:00,255:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-21 14:01:51,597:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.34s, LR: 0.00070, Train Loss: 0.1494, Train MAE: 0.1494,
                            Val Loss: 0.1535, Val MAE: 0.1533
2023-01-21 14:01:51,597:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-21 14:12:36,701:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.10s, LR: 0.00035, Train Loss: 0.1382, Train MAE: 0.1382,
                            Val Loss: 0.1439, Val MAE: 0.1437
2023-01-21 14:12:36,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-21 14:23:26,108:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.41s, LR: 0.00035, Train Loss: 0.1307, Train MAE: 0.1307,
                            Val Loss: 0.1375, Val MAE: 0.1373
2023-01-21 14:23:26,109:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-21 14:34:18,401:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.29s, LR: 0.00035, Train Loss: 0.1255, Train MAE: 0.1255,
                            Val Loss: 0.1326, Val MAE: 0.1323
2023-01-21 14:34:18,401:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-21 14:45:16,053:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.65s, LR: 0.00035, Train Loss: 0.1241, Train MAE: 0.1241,
                            Val Loss: 0.1327, Val MAE: 0.1325
2023-01-21 14:45:16,053:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-21 14:56:18,026:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.97s, LR: 0.00035, Train Loss: 0.1192, Train MAE: 0.1192,
                            Val Loss: 0.1270, Val MAE: 0.1268
2023-01-21 14:56:18,026:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-21 15:07:15,127:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.10s, LR: 0.00035, Train Loss: 0.1165, Train MAE: 0.1165,
                            Val Loss: 0.1240, Val MAE: 0.1239
2023-01-21 15:07:15,128:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-21 15:18:14,045:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.92s, LR: 0.00035, Train Loss: 0.1137, Train MAE: 0.1137,
                            Val Loss: 0.1264, Val MAE: 0.1263
2023-01-21 15:18:14,046:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-21 15:29:10,653:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.61s, LR: 0.00035, Train Loss: 0.1116, Train MAE: 0.1116,
                            Val Loss: 0.1214, Val MAE: 0.1212
2023-01-21 15:29:10,653:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-21 15:40:11,558:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.90s, LR: 0.00035, Train Loss: 0.1099, Train MAE: 0.1099,
                            Val Loss: 0.1240, Val MAE: 0.1238
2023-01-21 15:40:11,559:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-21 15:52:16,935:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.38s, LR: 0.00035, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1178, Val MAE: 0.1177
2023-01-21 15:52:16,936:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-21 16:03:11,221:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.28s, LR: 0.00035, Train Loss: 0.1074, Train MAE: 0.1074,
                            Val Loss: 0.1182, Val MAE: 0.1181
2023-01-21 16:03:11,222:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-21 16:14:12,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.18s, LR: 0.00035, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1174, Val MAE: 0.1172
2023-01-21 16:14:12,407:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-21 16:25:19,984:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.58s, LR: 0.00035, Train Loss: 0.1054, Train MAE: 0.1054,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-21 16:25:19,985:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-21 16:36:29,335:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11599735170602798
2023-01-21 16:36:29,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.35s, LR: 0.00035, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.1162, Val MAE: 0.1160
2023-01-21 16:36:29,337:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-21 16:47:31,670:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11475683003664017
2023-01-21 16:47:31,672:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.33s, LR: 0.00035, Train Loss: 0.1040, Train MAE: 0.1040,
                            Val Loss: 0.1149, Val MAE: 0.1148
2023-01-21 16:47:31,672:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-21 16:58:40,807:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.13s, LR: 0.00035, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.1172, Val MAE: 0.1170
2023-01-21 16:58:40,808:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-21 17:09:51,048:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.24s, LR: 0.00035, Train Loss: 0.1028, Train MAE: 0.1028,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-21 17:09:51,048:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-21 17:20:57,966:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11422978341579437
2023-01-21 17:20:57,967:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.92s, LR: 0.00035, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.1144, Val MAE: 0.1142
2023-01-21 17:20:57,968:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-21 17:32:01,166:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11411258578300476
2023-01-21 17:32:01,168:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.20s, LR: 0.00035, Train Loss: 0.1016, Train MAE: 0.1016,
                            Val Loss: 0.1143, Val MAE: 0.1141
2023-01-21 17:32:01,168:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-21 17:43:02,024:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11322350054979324
2023-01-21 17:43:02,025:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.86s, LR: 0.00035, Train Loss: 0.1012, Train MAE: 0.1012,
                            Val Loss: 0.1134, Val MAE: 0.1132
2023-01-21 17:43:02,025:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-21 17:54:05,053:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.03s, LR: 0.00035, Train Loss: 0.1010, Train MAE: 0.1010,
                            Val Loss: 0.1145, Val MAE: 0.1143
2023-01-21 17:54:05,054:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-21 18:05:14,762:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.71s, LR: 0.00035, Train Loss: 0.1007, Train MAE: 0.1007,
                            Val Loss: 0.1140, Val MAE: 0.1138
2023-01-21 18:05:14,762:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-21 18:16:20,277:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11236267536878586
2023-01-21 18:16:20,279:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.52s, LR: 0.00035, Train Loss: 0.1001, Train MAE: 0.1001,
                            Val Loss: 0.1126, Val MAE: 0.1124
2023-01-21 18:16:20,279:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-21 18:27:33,180:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.90s, LR: 0.00035, Train Loss: 0.0998, Train MAE: 0.0998,
                            Val Loss: 0.1135, Val MAE: 0.1133
2023-01-21 18:27:33,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-21 18:39:48,101:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.92s, LR: 0.00035, Train Loss: 0.0997, Train MAE: 0.0997,
                            Val Loss: 0.1144, Val MAE: 0.1142
2023-01-21 18:39:48,102:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-21 18:50:50,747:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.64s, LR: 0.00035, Train Loss: 0.0994, Train MAE: 0.0994,
                            Val Loss: 0.1142, Val MAE: 0.1141
2023-01-21 18:50:50,748:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-21 19:01:38,105:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11187895387411118
2023-01-21 19:01:38,107:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.36s, LR: 0.00035, Train Loss: 0.0992, Train MAE: 0.0992,
                            Val Loss: 0.1121, Val MAE: 0.1119
2023-01-21 19:01:38,107:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-21 19:12:37,689:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.58s, LR: 0.00035, Train Loss: 0.0989, Train MAE: 0.0989,
                            Val Loss: 0.1124, Val MAE: 0.1122
2023-01-21 19:12:37,689:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-21 19:23:31,905:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.21s, LR: 0.00035, Train Loss: 0.0988, Train MAE: 0.0988,
                            Val Loss: 0.1155, Val MAE: 0.1153
2023-01-21 19:23:31,905:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-21 19:34:28,310:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.40s, LR: 0.00035, Train Loss: 0.0984, Train MAE: 0.0984,
                            Val Loss: 0.1123, Val MAE: 0.1122
2023-01-21 19:34:28,311:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-21 19:34:28,311:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-21 19:41:46,210:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1122
2023-01-21 19:41:46,211:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0953
2023-01-21 19:41:46,212:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-21 19:41:46,212:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 124.0000
2023-01-21 19:41:46,212:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87174.7905s
2023-01-21 19:41:46,212:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 693.8065s
2023-01-21 19:41:46,257:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-21 19:41:46,461:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0953)]
2023-01-21 19:41:46,462:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1122)]
