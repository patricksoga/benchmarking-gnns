2023-01-20 19:13:16,168:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-20 19:13:16,168:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-20 19:29:24,889:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-20 19:29:56,342:ogbdata.py:332 -             __init__(): Time taken: 1000.1738s
2023-01-20 19:29:56,342:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-20 19:29:56,342:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-20 19:29:56,342:ogbdata.py:348 -             __init__(): [I] Data load time: 1000.1744s
2023-01-20 19:29:56,343:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/no_pe/gt_ogb_b1024-baseline-noedge/20_DEBUG_0_41.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [41]}
2023-01-20 19:29:56,343:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-20 19:29:56,349:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:29:56,349:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:29:56,349:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:29:56,438:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-20 19:29:56,440:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536741
2023-01-20 19:29:56,440:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2023-01-20 19:29:56,441:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:29:56,441:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:29:56,441:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:30:06,526:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-20 19:30:06,526:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-20 19:30:06,540:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-20 19:45:07,065:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2571786940097809
2023-01-20 19:45:07,067:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 900.53s, LR: 0.00070, Train Loss: 0.3152, Train MAE: 0.3152,
                            Val Loss: 0.2576, Val MAE: 0.2572
2023-01-20 19:45:07,067:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-20 19:57:06,967:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.90s, LR: 0.00070, Train Loss: 0.1809, Train MAE: 0.1809,
                            Val Loss: 0.2620, Val MAE: 0.2616
2023-01-20 19:57:06,968:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-20 20:09:14,597:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.23220400512218475
2023-01-20 20:09:14,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.63s, LR: 0.00070, Train Loss: 0.1635, Train MAE: 0.1635,
                            Val Loss: 0.2327, Val MAE: 0.2322
2023-01-20 20:09:14,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-20 20:21:22,678:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.18391239643096924
2023-01-20 20:21:22,679:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.08s, LR: 0.00070, Train Loss: 0.1552, Train MAE: 0.1552,
                            Val Loss: 0.1843, Val MAE: 0.1839
2023-01-20 20:21:22,679:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-20 20:33:30,488:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.81s, LR: 0.00070, Train Loss: 0.1499, Train MAE: 0.1499,
                            Val Loss: 0.2033, Val MAE: 0.2029
2023-01-20 20:33:30,488:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-20 20:45:37,633:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16720682382583618
2023-01-20 20:45:37,634:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.15s, LR: 0.00070, Train Loss: 0.1453, Train MAE: 0.1453,
                            Val Loss: 0.1676, Val MAE: 0.1672
2023-01-20 20:45:37,635:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-20 20:57:42,435:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.80s, LR: 0.00070, Train Loss: 0.1424, Train MAE: 0.1424,
                            Val Loss: 0.1982, Val MAE: 0.1978
2023-01-20 20:57:42,436:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-20 21:09:49,126:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16259337961673737
2023-01-20 21:09:49,127:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.69s, LR: 0.00070, Train Loss: 0.1398, Train MAE: 0.1398,
                            Val Loss: 0.1629, Val MAE: 0.1626
2023-01-20 21:09:49,128:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-20 21:21:51,517:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.39s, LR: 0.00070, Train Loss: 0.1375, Train MAE: 0.1375,
                            Val Loss: 0.1707, Val MAE: 0.1703
2023-01-20 21:21:51,517:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-20 21:33:54,062:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.54s, LR: 0.00070, Train Loss: 0.1355, Train MAE: 0.1355,
                            Val Loss: 0.1650, Val MAE: 0.1647
2023-01-20 21:33:54,063:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-20 21:45:57,167:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.10s, LR: 0.00070, Train Loss: 0.1335, Train MAE: 0.1335,
                            Val Loss: 0.1636, Val MAE: 0.1632
2023-01-20 21:45:57,168:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-20 21:58:00,836:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14837464690208435
2023-01-20 21:58:00,837:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.67s, LR: 0.00070, Train Loss: 0.1314, Train MAE: 0.1314,
                            Val Loss: 0.1487, Val MAE: 0.1484
2023-01-20 21:58:00,838:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-20 22:11:15,701:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 794.86s, LR: 0.00070, Train Loss: 0.1313, Train MAE: 0.1313,
                            Val Loss: 0.1532, Val MAE: 0.1529
2023-01-20 22:11:15,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-20 22:23:38,403:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.70s, LR: 0.00070, Train Loss: 0.1296, Train MAE: 0.1296,
                            Val Loss: 0.1631, Val MAE: 0.1628
2023-01-20 22:23:38,404:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-20 22:36:58,515:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 800.11s, LR: 0.00070, Train Loss: 0.1285, Train MAE: 0.1285,
                            Val Loss: 0.1527, Val MAE: 0.1524
2023-01-20 22:36:58,515:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-20 22:49:03,317:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14052997529506683
2023-01-20 22:49:03,319:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.80s, LR: 0.00070, Train Loss: 0.1277, Train MAE: 0.1277,
                            Val Loss: 0.1409, Val MAE: 0.1405
2023-01-20 22:49:03,319:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-20 23:01:19,418:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13423259556293488
2023-01-20 23:01:19,420:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 736.10s, LR: 0.00070, Train Loss: 0.1265, Train MAE: 0.1265,
                            Val Loss: 0.1346, Val MAE: 0.1342
2023-01-20 23:01:19,420:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-20 23:13:22,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.59s, LR: 0.00070, Train Loss: 0.1257, Train MAE: 0.1257,
                            Val Loss: 0.1390, Val MAE: 0.1387
2023-01-20 23:13:22,015:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-20 23:25:31,469:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 729.45s, LR: 0.00070, Train Loss: 0.1250, Train MAE: 0.1250,
                            Val Loss: 0.1558, Val MAE: 0.1555
2023-01-20 23:25:31,470:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-20 23:37:55,404:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 743.93s, LR: 0.00070, Train Loss: 0.1245, Train MAE: 0.1245,
                            Val Loss: 0.1386, Val MAE: 0.1384
2023-01-20 23:37:55,404:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-20 23:51:00,992:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 785.59s, LR: 0.00070, Train Loss: 0.1236, Train MAE: 0.1236,
                            Val Loss: 0.1432, Val MAE: 0.1429
2023-01-20 23:51:00,992:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-21 00:03:29,798:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.80s, LR: 0.00070, Train Loss: 0.1227, Train MAE: 0.1227,
                            Val Loss: 0.1643, Val MAE: 0.1640
2023-01-21 00:03:29,798:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-21 00:15:23,659:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 713.86s, LR: 0.00070, Train Loss: 0.1226, Train MAE: 0.1226,
                            Val Loss: 0.1429, Val MAE: 0.1426
2023-01-21 00:15:23,659:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-21 00:27:16,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.96s, LR: 0.00070, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.1423, Val MAE: 0.1421
2023-01-21 00:27:16,618:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-21 00:39:15,444:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13378047943115234
2023-01-21 00:39:15,446:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.83s, LR: 0.00070, Train Loss: 0.1216, Train MAE: 0.1216,
                            Val Loss: 0.1340, Val MAE: 0.1338
2023-01-21 00:39:15,446:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-21 00:51:15,003:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.56s, LR: 0.00070, Train Loss: 0.1206, Train MAE: 0.1206,
                            Val Loss: 0.1466, Val MAE: 0.1463
2023-01-21 00:51:15,003:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-21 01:03:20,411:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.41s, LR: 0.00070, Train Loss: 0.1200, Train MAE: 0.1200,
                            Val Loss: 0.1377, Val MAE: 0.1374
2023-01-21 01:03:20,411:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-21 01:15:18,810:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12810258567333221
2023-01-21 01:15:18,812:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.40s, LR: 0.00070, Train Loss: 0.1195, Train MAE: 0.1195,
                            Val Loss: 0.1283, Val MAE: 0.1281
2023-01-21 01:15:18,812:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-21 01:27:33,663:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.85s, LR: 0.00070, Train Loss: 0.1189, Train MAE: 0.1189,
                            Val Loss: 0.1374, Val MAE: 0.1372
2023-01-21 01:27:33,664:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-21 01:41:16,375:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 822.71s, LR: 0.00070, Train Loss: 0.1185, Train MAE: 0.1185,
                            Val Loss: 0.1306, Val MAE: 0.1303
2023-01-21 01:41:16,376:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-21 01:53:12,487:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.11s, LR: 0.00070, Train Loss: 0.1186, Train MAE: 0.1186,
                            Val Loss: 0.1483, Val MAE: 0.1480
2023-01-21 01:53:12,488:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-21 02:05:10,500:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1272279918193817
2023-01-21 02:05:10,501:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.01s, LR: 0.00070, Train Loss: 0.1177, Train MAE: 0.1177,
                            Val Loss: 0.1275, Val MAE: 0.1272
2023-01-21 02:05:10,501:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-21 02:17:08,805:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.30s, LR: 0.00070, Train Loss: 0.1177, Train MAE: 0.1177,
                            Val Loss: 0.1295, Val MAE: 0.1293
2023-01-21 02:17:08,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-21 02:29:07,414:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.61s, LR: 0.00070, Train Loss: 0.1169, Train MAE: 0.1169,
                            Val Loss: 0.1303, Val MAE: 0.1301
2023-01-21 02:29:07,414:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-21 02:41:07,212:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.80s, LR: 0.00070, Train Loss: 0.1163, Train MAE: 0.1163,
                            Val Loss: 0.1286, Val MAE: 0.1284
2023-01-21 02:41:07,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-21 02:53:03,480:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12538200616836548
2023-01-21 02:53:03,482:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.27s, LR: 0.00070, Train Loss: 0.1168, Train MAE: 0.1168,
                            Val Loss: 0.1256, Val MAE: 0.1254
2023-01-21 02:53:03,482:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-21 03:05:06,090:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.61s, LR: 0.00070, Train Loss: 0.1156, Train MAE: 0.1156,
                            Val Loss: 0.1364, Val MAE: 0.1362
2023-01-21 03:05:06,090:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-21 03:17:03,238:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12395849078893661
2023-01-21 03:17:03,240:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.15s, LR: 0.00070, Train Loss: 0.1154, Train MAE: 0.1154,
                            Val Loss: 0.1242, Val MAE: 0.1240
2023-01-21 03:17:03,240:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-21 03:29:06,567:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.33s, LR: 0.00070, Train Loss: 0.1153, Train MAE: 0.1153,
                            Val Loss: 0.1288, Val MAE: 0.1285
2023-01-21 03:29:06,567:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-21 03:41:07,663:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.10s, LR: 0.00070, Train Loss: 0.1147, Train MAE: 0.1147,
                            Val Loss: 0.1253, Val MAE: 0.1251
2023-01-21 03:41:07,664:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-21 03:53:10,626:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.96s, LR: 0.00070, Train Loss: 0.1142, Train MAE: 0.1142,
                            Val Loss: 0.1273, Val MAE: 0.1271
2023-01-21 03:53:10,627:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-21 04:05:11,219:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.59s, LR: 0.00070, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.1283, Val MAE: 0.1281
2023-01-21 04:05:11,219:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-21 04:17:09,334:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.11s, LR: 0.00070, Train Loss: 0.1135, Train MAE: 0.1135,
                            Val Loss: 0.1256, Val MAE: 0.1254
2023-01-21 04:17:09,335:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-21 04:29:05,930:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.59s, LR: 0.00070, Train Loss: 0.1132, Train MAE: 0.1132,
                            Val Loss: 0.1262, Val MAE: 0.1260
2023-01-21 04:29:05,930:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-21 04:42:18,328:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 792.40s, LR: 0.00070, Train Loss: 0.1129, Train MAE: 0.1129,
                            Val Loss: 0.1285, Val MAE: 0.1283
2023-01-21 04:42:18,329:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-21 04:54:15,020:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.69s, LR: 0.00070, Train Loss: 0.1123, Train MAE: 0.1123,
                            Val Loss: 0.1270, Val MAE: 0.1268
2023-01-21 04:54:15,020:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-21 05:06:54,585:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 759.56s, LR: 0.00070, Train Loss: 0.1118, Train MAE: 0.1118,
                            Val Loss: 0.1287, Val MAE: 0.1285
2023-01-21 05:06:54,586:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-21 05:18:55,948:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.36s, LR: 0.00070, Train Loss: 0.1120, Train MAE: 0.1120,
                            Val Loss: 0.1304, Val MAE: 0.1302
2023-01-21 05:18:55,948:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-21 05:32:01,713:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 785.76s, LR: 0.00070, Train Loss: 0.1119, Train MAE: 0.1119,
                            Val Loss: 0.1282, Val MAE: 0.1280
2023-01-21 05:32:01,713:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-21 05:44:52,532:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.82s, LR: 0.00070, Train Loss: 0.1113, Train MAE: 0.1113,
                            Val Loss: 0.1255, Val MAE: 0.1253
2023-01-21 05:44:52,533:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-21 05:57:00,210:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12244302779436111
2023-01-21 05:57:00,211:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.68s, LR: 0.00070, Train Loss: 0.1112, Train MAE: 0.1112,
                            Val Loss: 0.1227, Val MAE: 0.1224
2023-01-21 05:57:00,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-21 06:09:02,534:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.32s, LR: 0.00070, Train Loss: 0.1108, Train MAE: 0.1108,
                            Val Loss: 0.1237, Val MAE: 0.1235
2023-01-21 06:09:02,534:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-21 06:21:02,891:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.36s, LR: 0.00070, Train Loss: 0.1106, Train MAE: 0.1106,
                            Val Loss: 0.1234, Val MAE: 0.1232
2023-01-21 06:21:02,892:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-21 06:33:05,059:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.17s, LR: 0.00070, Train Loss: 0.1106, Train MAE: 0.1106,
                            Val Loss: 0.1268, Val MAE: 0.1266
2023-01-21 06:33:05,059:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-21 06:45:03,934:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12225385010242462
2023-01-21 06:45:03,935:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.88s, LR: 0.00070, Train Loss: 0.1104, Train MAE: 0.1104,
                            Val Loss: 0.1225, Val MAE: 0.1223
2023-01-21 06:45:03,936:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-21 06:57:08,601:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.66s, LR: 0.00070, Train Loss: 0.1098, Train MAE: 0.1098,
                            Val Loss: 0.1304, Val MAE: 0.1302
2023-01-21 06:57:08,601:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-21 07:09:12,428:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.83s, LR: 0.00070, Train Loss: 0.1098, Train MAE: 0.1098,
                            Val Loss: 0.1328, Val MAE: 0.1326
2023-01-21 07:09:12,428:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-21 07:21:13,310:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12149176001548767
2023-01-21 07:21:13,312:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.88s, LR: 0.00070, Train Loss: 0.1095, Train MAE: 0.1095,
                            Val Loss: 0.1217, Val MAE: 0.1215
2023-01-21 07:21:13,312:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-21 07:33:14,683:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.37s, LR: 0.00070, Train Loss: 0.1094, Train MAE: 0.1094,
                            Val Loss: 0.1264, Val MAE: 0.1262
2023-01-21 07:33:14,683:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-21 07:46:35,419:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 800.74s, LR: 0.00070, Train Loss: 0.1093, Train MAE: 0.1093,
                            Val Loss: 0.1235, Val MAE: 0.1233
2023-01-21 07:46:35,420:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-21 07:58:34,424:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12032455950975418
2023-01-21 07:58:34,426:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.01s, LR: 0.00070, Train Loss: 0.1093, Train MAE: 0.1093,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-21 07:58:34,426:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-21 08:10:49,637:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 735.21s, LR: 0.00070, Train Loss: 0.1084, Train MAE: 0.1084,
                            Val Loss: 0.1259, Val MAE: 0.1257
2023-01-21 08:10:49,638:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-21 08:23:40,410:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11969632655382156
2023-01-21 08:23:40,411:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.77s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1199, Val MAE: 0.1197
2023-01-21 08:23:40,412:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-21 08:35:44,996:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.58s, LR: 0.00070, Train Loss: 0.1084, Train MAE: 0.1084,
                            Val Loss: 0.1290, Val MAE: 0.1288
2023-01-21 08:35:44,997:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-21 08:47:42,195:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.20s, LR: 0.00070, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.1219, Val MAE: 0.1217
2023-01-21 08:47:42,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-21 08:59:37,885:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.69s, LR: 0.00070, Train Loss: 0.1078, Train MAE: 0.1078,
                            Val Loss: 0.1228, Val MAE: 0.1227
2023-01-21 08:59:37,886:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-21 09:11:33,574:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.69s, LR: 0.00070, Train Loss: 0.1077, Train MAE: 0.1077,
                            Val Loss: 0.1238, Val MAE: 0.1236
2023-01-21 09:11:33,575:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-21 09:23:28,944:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.37s, LR: 0.00070, Train Loss: 0.1073, Train MAE: 0.1073,
                            Val Loss: 0.1242, Val MAE: 0.1240
2023-01-21 09:23:28,945:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-21 09:35:25,066:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.12s, LR: 0.00070, Train Loss: 0.1073, Train MAE: 0.1073,
                            Val Loss: 0.1265, Val MAE: 0.1263
2023-01-21 09:35:25,066:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-21 09:47:20,807:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.74s, LR: 0.00070, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.1230, Val MAE: 0.1229
2023-01-21 09:47:20,807:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-21 09:59:14,386:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 713.58s, LR: 0.00070, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.1316, Val MAE: 0.1314
2023-01-21 09:59:14,387:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-21 10:11:04,202:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.81s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1209, Val MAE: 0.1207
2023-01-21 10:11:04,203:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-21 10:22:52,178:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11891426891088486
2023-01-21 10:22:52,180:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.98s, LR: 0.00070, Train Loss: 0.1069, Train MAE: 0.1069,
                            Val Loss: 0.1191, Val MAE: 0.1189
2023-01-21 10:22:52,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-21 10:34:39,235:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.05s, LR: 0.00070, Train Loss: 0.1064, Train MAE: 0.1064,
                            Val Loss: 0.1227, Val MAE: 0.1225
2023-01-21 10:34:39,236:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-21 10:47:50,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 791.24s, LR: 0.00070, Train Loss: 0.1064, Train MAE: 0.1064,
                            Val Loss: 0.1213, Val MAE: 0.1211
2023-01-21 10:47:50,477:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-21 10:59:36,468:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1181592270731926
2023-01-21 10:59:36,470:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.99s, LR: 0.00070, Train Loss: 0.1062, Train MAE: 0.1062,
                            Val Loss: 0.1183, Val MAE: 0.1182
2023-01-21 10:59:36,470:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-21 11:11:24,247:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.78s, LR: 0.00070, Train Loss: 0.1061, Train MAE: 0.1061,
                            Val Loss: 0.1230, Val MAE: 0.1229
2023-01-21 11:11:24,248:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-21 11:23:13,372:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.12s, LR: 0.00070, Train Loss: 0.1057, Train MAE: 0.1057,
                            Val Loss: 0.1220, Val MAE: 0.1218
2023-01-21 11:23:13,372:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-21 11:35:11,309:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.94s, LR: 0.00070, Train Loss: 0.1057, Train MAE: 0.1057,
                            Val Loss: 0.1246, Val MAE: 0.1245
2023-01-21 11:35:11,309:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-21 11:47:09,857:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.55s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1193, Val MAE: 0.1191
2023-01-21 11:47:09,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-21 11:59:17,316:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.46s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1184, Val MAE: 0.1182
2023-01-21 11:59:17,317:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-21 12:12:12,177:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.86s, LR: 0.00070, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.1280, Val MAE: 0.1278
2023-01-21 12:12:12,177:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-21 12:24:02,270:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.09s, LR: 0.00070, Train Loss: 0.1054, Train MAE: 0.1054,
                            Val Loss: 0.1190, Val MAE: 0.1188
2023-01-21 12:24:02,271:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-21 12:35:49,251:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.98s, LR: 0.00070, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1206, Val MAE: 0.1205
2023-01-21 12:35:49,251:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-21 12:47:36,018:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.77s, LR: 0.00070, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.1244, Val MAE: 0.1242
2023-01-21 12:47:36,019:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-21 12:59:22,713:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.69s, LR: 0.00070, Train Loss: 0.1049, Train MAE: 0.1049,
                            Val Loss: 0.1230, Val MAE: 0.1228
2023-01-21 12:59:22,714:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-21 13:11:08,378:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.66s, LR: 0.00070, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.1198, Val MAE: 0.1196
2023-01-21 13:11:08,379:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-21 13:22:55,210:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11807339638471603
2023-01-21 13:22:55,211:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.83s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1183, Val MAE: 0.1181
2023-01-21 13:22:55,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-21 13:34:40,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.78s, LR: 0.00070, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1216, Val MAE: 0.1215
2023-01-21 13:34:40,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-21 13:47:34,131:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 773.14s, LR: 0.00070, Train Loss: 0.1042, Train MAE: 0.1042,
                            Val Loss: 0.1216, Val MAE: 0.1214
2023-01-21 13:47:34,132:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-21 13:59:17,773:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.64s, LR: 0.00070, Train Loss: 0.1042, Train MAE: 0.1042,
                            Val Loss: 0.1208, Val MAE: 0.1206
2023-01-21 13:59:17,774:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-21 14:11:00,279:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11776100844144821
2023-01-21 14:11:00,281:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.51s, LR: 0.00070, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1179, Val MAE: 0.1178
2023-01-21 14:11:00,281:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-21 14:22:41,163:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.88s, LR: 0.00070, Train Loss: 0.1038, Train MAE: 0.1038,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-21 14:22:41,164:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-21 14:34:28,003:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.84s, LR: 0.00070, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1198, Val MAE: 0.1197
2023-01-21 14:34:28,004:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-21 14:47:35,013:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 787.01s, LR: 0.00070, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1185, Val MAE: 0.1184
2023-01-21 14:47:35,014:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-21 14:59:41,841:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.83s, LR: 0.00070, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1216, Val MAE: 0.1214
2023-01-21 14:59:41,842:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-21 15:12:16,649:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 754.81s, LR: 0.00070, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.1181, Val MAE: 0.1179
2023-01-21 15:12:16,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-21 15:24:02,784:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.13s, LR: 0.00070, Train Loss: 0.1032, Train MAE: 0.1032,
                            Val Loss: 0.1183, Val MAE: 0.1181
2023-01-21 15:24:02,784:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-21 15:35:50,580:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11666320264339447
2023-01-21 15:35:50,581:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.80s, LR: 0.00070, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.1169, Val MAE: 0.1167
2023-01-21 15:35:50,582:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-21 15:47:36,160:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.58s, LR: 0.00070, Train Loss: 0.1029, Train MAE: 0.1029,
                            Val Loss: 0.1389, Val MAE: 0.1388
2023-01-21 15:47:36,160:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-21 15:59:23,730:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.57s, LR: 0.00070, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.1176, Val MAE: 0.1174
2023-01-21 15:59:23,731:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-21 16:11:14,499:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.77s, LR: 0.00070, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.1209, Val MAE: 0.1207
2023-01-21 16:11:14,499:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-21 16:23:08,948:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.45s, LR: 0.00070, Train Loss: 0.1029, Train MAE: 0.1029,
                            Val Loss: 0.1188, Val MAE: 0.1186
2023-01-21 16:23:08,949:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-21 16:35:02,101:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11660874634981155
2023-01-21 16:35:02,103:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 713.15s, LR: 0.00070, Train Loss: 0.1027, Train MAE: 0.1027,
                            Val Loss: 0.1168, Val MAE: 0.1166
2023-01-21 16:35:02,103:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-21 16:48:06,670:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.57s, LR: 0.00070, Train Loss: 0.1024, Train MAE: 0.1024,
                            Val Loss: 0.1177, Val MAE: 0.1175
2023-01-21 16:48:06,671:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-21 17:00:00,506:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11569368839263916
2023-01-21 17:00:00,508:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 713.84s, LR: 0.00070, Train Loss: 0.1026, Train MAE: 0.1026,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-21 17:00:00,508:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-21 17:11:55,615:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.11s, LR: 0.00070, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.1181, Val MAE: 0.1179
2023-01-21 17:11:55,616:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-21 17:23:51,111:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.49s, LR: 0.00070, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.1204, Val MAE: 0.1202
2023-01-21 17:23:51,111:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-21 17:35:44,885:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 713.77s, LR: 0.00070, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.1171, Val MAE: 0.1169
2023-01-21 17:35:44,886:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-21 17:47:36,745:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 711.86s, LR: 0.00070, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.1270, Val MAE: 0.1268
2023-01-21 17:47:36,745:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-21 17:59:29,599:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.85s, LR: 0.00070, Train Loss: 0.1018, Train MAE: 0.1018,
                            Val Loss: 0.1174, Val MAE: 0.1172
2023-01-21 17:59:29,600:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-21 18:11:25,853:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.25s, LR: 0.00070, Train Loss: 0.1020, Train MAE: 0.1020,
                            Val Loss: 0.1258, Val MAE: 0.1256
2023-01-21 18:11:25,854:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-21 18:23:20,018:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.16s, LR: 0.00070, Train Loss: 0.1017, Train MAE: 0.1017,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-21 18:23:20,019:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-21 18:35:13,651:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 713.63s, LR: 0.00070, Train Loss: 0.1016, Train MAE: 0.1016,
                            Val Loss: 0.1182, Val MAE: 0.1180
2023-01-21 18:35:13,652:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-21 18:47:06,056:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.40s, LR: 0.00070, Train Loss: 0.1015, Train MAE: 0.1015,
                            Val Loss: 0.1194, Val MAE: 0.1192
2023-01-21 18:47:06,057:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-21 18:58:40,103:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.05s, LR: 0.00070, Train Loss: 0.1017, Train MAE: 0.1017,
                            Val Loss: 0.1173, Val MAE: 0.1171
2023-01-21 18:58:40,104:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-21 19:10:30,868:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.76s, LR: 0.00070, Train Loss: 0.1014, Train MAE: 0.1014,
                            Val Loss: 0.1166, Val MAE: 0.1165
2023-01-21 19:10:30,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-21 19:22:22,684:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 711.81s, LR: 0.00070, Train Loss: 0.1013, Train MAE: 0.1013,
                            Val Loss: 0.1190, Val MAE: 0.1189
2023-01-21 19:22:22,684:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-21 19:34:17,455:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.77s, LR: 0.00070, Train Loss: 0.1014, Train MAE: 0.1014,
                            Val Loss: 0.1174, Val MAE: 0.1172
2023-01-21 19:34:17,456:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-21 19:34:17,456:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-21 19:43:04,575:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1172
2023-01-21 19:43:04,576:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0990
2023-01-21 19:43:04,576:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-21 19:43:04,576:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 118.0000
2023-01-21 19:43:04,576:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87188.1357s
2023-01-21 19:43:04,577:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 728.1587s
2023-01-21 19:43:04,613:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-21 19:43:04,636:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0990)]
2023-01-21 19:43:04,636:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1172)]
