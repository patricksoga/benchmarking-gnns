2023-01-20 19:13:17,120:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-20 19:13:17,120:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-20 19:26:03,872:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-20 19:26:53,943:ogbdata.py:332 -             __init__(): Time taken: 816.8229s
2023-01-20 19:26:53,943:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-20 19:26:53,943:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-20 19:26:53,944:ogbdata.py:348 -             __init__(): [I] Data load time: 816.8235s
2023-01-20 19:26:53,944:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/no_pe/gt_ogb_b1024-baseline-noedge/20_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-20 19:26:53,944:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-20 19:26:54,039:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:26:54,039:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:26:54,039:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:26:54,844:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-20 19:26:54,846:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536741
2023-01-20 19:26:54,846:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-20 19:26:54,847:pe_layer.py:99 -             __init__(): no_pe
2023-01-20 19:26:54,847:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 19:26:54,847:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 19:28:04,474:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-20 19:28:04,474:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-20 19:28:04,770:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-20 19:44:14,739:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.20825549960136414
2023-01-20 19:44:15,353:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 970.58s, LR: 0.00070, Train Loss: 0.3136, Train MAE: 0.3136,
                            Val Loss: 0.2087, Val MAE: 0.2083
2023-01-20 19:44:15,353:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-20 19:55:52,152:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.80s, LR: 0.00070, Train Loss: 0.1801, Train MAE: 0.1801,
                            Val Loss: 0.2858, Val MAE: 0.2855
2023-01-20 19:55:52,388:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-20 20:07:25,725:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.18857254087924957
2023-01-20 20:07:26,289:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.90s, LR: 0.00070, Train Loss: 0.1644, Train MAE: 0.1644,
                            Val Loss: 0.1890, Val MAE: 0.1886
2023-01-20 20:07:26,289:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-20 20:19:22,762:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.44s, LR: 0.00070, Train Loss: 0.1567, Train MAE: 0.1567,
                            Val Loss: 0.2591, Val MAE: 0.2588
2023-01-20 20:19:22,978:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-20 20:30:55,583:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.18671144545078278
2023-01-20 20:30:55,636:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.66s, LR: 0.00070, Train Loss: 0.1513, Train MAE: 0.1513,
                            Val Loss: 0.1871, Val MAE: 0.1867
2023-01-20 20:30:55,653:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-20 20:42:33,037:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.38s, LR: 0.00070, Train Loss: 0.1466, Train MAE: 0.1466,
                            Val Loss: 0.2140, Val MAE: 0.2137
2023-01-20 20:42:33,051:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-20 20:54:13,377:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15531307458877563
2023-01-20 20:54:14,251:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.20s, LR: 0.00070, Train Loss: 0.1448, Train MAE: 0.1448,
                            Val Loss: 0.1557, Val MAE: 0.1553
2023-01-20 20:54:14,252:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-20 21:05:51,322:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.04s, LR: 0.00070, Train Loss: 0.1411, Train MAE: 0.1411,
                            Val Loss: 0.2629, Val MAE: 0.2627
2023-01-20 21:05:51,499:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-20 21:17:26,784:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.28s, LR: 0.00070, Train Loss: 0.1395, Train MAE: 0.1395,
                            Val Loss: 0.1705, Val MAE: 0.1701
2023-01-20 21:17:26,933:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-20 21:28:59,172:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.24s, LR: 0.00070, Train Loss: 0.1369, Train MAE: 0.1369,
                            Val Loss: 0.1655, Val MAE: 0.1651
2023-01-20 21:28:59,181:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-20 21:40:37,037:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1472516655921936
2023-01-20 21:40:37,065:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.88s, LR: 0.00070, Train Loss: 0.1352, Train MAE: 0.1352,
                            Val Loss: 0.1476, Val MAE: 0.1473
2023-01-20 21:40:37,065:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-20 21:52:11,735:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.67s, LR: 0.00070, Train Loss: 0.1339, Train MAE: 0.1339,
                            Val Loss: 0.1647, Val MAE: 0.1644
2023-01-20 21:52:11,771:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-20 22:03:39,730:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.96s, LR: 0.00070, Train Loss: 0.1320, Train MAE: 0.1320,
                            Val Loss: 0.1535, Val MAE: 0.1531
2023-01-20 22:03:39,880:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-20 22:15:21,634:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.75s, LR: 0.00070, Train Loss: 0.1314, Train MAE: 0.1314,
                            Val Loss: 0.1673, Val MAE: 0.1670
2023-01-20 22:15:21,820:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-20 22:28:04,272:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.45s, LR: 0.00070, Train Loss: 0.1302, Train MAE: 0.1302,
                            Val Loss: 0.1507, Val MAE: 0.1504
2023-01-20 22:28:04,433:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-20 22:39:40,254:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.82s, LR: 0.00070, Train Loss: 0.1292, Train MAE: 0.1292,
                            Val Loss: 0.1576, Val MAE: 0.1573
2023-01-20 22:39:40,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-20 22:51:36,428:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1381371170282364
2023-01-20 22:51:36,932:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.57s, LR: 0.00070, Train Loss: 0.1280, Train MAE: 0.1280,
                            Val Loss: 0.1384, Val MAE: 0.1381
2023-01-20 22:51:36,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-20 23:03:09,013:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.99s, LR: 0.00070, Train Loss: 0.1274, Train MAE: 0.1274,
                            Val Loss: 0.1421, Val MAE: 0.1419
2023-01-20 23:03:09,089:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-20 23:14:40,147:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.06s, LR: 0.00070, Train Loss: 0.1259, Train MAE: 0.1259,
                            Val Loss: 0.1662, Val MAE: 0.1659
2023-01-20 23:14:40,246:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-20 23:26:11,644:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.35s, LR: 0.00070, Train Loss: 0.1253, Train MAE: 0.1253,
                            Val Loss: 0.1413, Val MAE: 0.1410
2023-01-20 23:26:11,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-20 23:37:54,688:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.96s, LR: 0.00070, Train Loss: 0.1251, Train MAE: 0.1251,
                            Val Loss: 0.1500, Val MAE: 0.1497
2023-01-20 23:37:54,771:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-20 23:49:41,919:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.15s, LR: 0.00070, Train Loss: 0.1237, Train MAE: 0.1237,
                            Val Loss: 0.1515, Val MAE: 0.1512
2023-01-20 23:49:42,002:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-21 00:01:17,109:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.11s, LR: 0.00070, Train Loss: 0.1234, Train MAE: 0.1234,
                            Val Loss: 0.1397, Val MAE: 0.1395
2023-01-21 00:01:17,167:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-21 00:12:52,973:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13783469796180725
2023-01-21 00:12:53,106:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.94s, LR: 0.00070, Train Loss: 0.1226, Train MAE: 0.1226,
                            Val Loss: 0.1381, Val MAE: 0.1378
2023-01-21 00:12:53,168:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-21 00:24:26,800:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.30s, LR: 0.00070, Train Loss: 0.1222, Train MAE: 0.1222,
                            Val Loss: 0.1382, Val MAE: 0.1380
2023-01-21 00:24:27,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-21 00:36:00,496:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13532990217208862
2023-01-21 00:36:02,696:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.48s, LR: 0.00070, Train Loss: 0.1216, Train MAE: 0.1216,
                            Val Loss: 0.1356, Val MAE: 0.1353
2023-01-21 00:36:02,754:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-21 00:47:34,405:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13290129601955414
2023-01-21 00:47:34,990:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.15s, LR: 0.00070, Train Loss: 0.1208, Train MAE: 0.1208,
                            Val Loss: 0.1331, Val MAE: 0.1329
2023-01-21 00:47:34,990:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-21 00:59:13,784:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.53s, LR: 0.00070, Train Loss: 0.1203, Train MAE: 0.1203,
                            Val Loss: 0.1427, Val MAE: 0.1425
2023-01-21 00:59:13,867:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-21 01:10:42,804:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.94s, LR: 0.00070, Train Loss: 0.1197, Train MAE: 0.1197,
                            Val Loss: 0.1484, Val MAE: 0.1482
2023-01-21 01:10:42,895:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-21 01:23:44,183:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12779375910758972
2023-01-21 01:23:44,737:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 781.84s, LR: 0.00070, Train Loss: 0.1194, Train MAE: 0.1194,
                            Val Loss: 0.1280, Val MAE: 0.1278
2023-01-21 01:23:44,794:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-21 01:35:29,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.19s, LR: 0.00070, Train Loss: 0.1187, Train MAE: 0.1187,
                            Val Loss: 0.1332, Val MAE: 0.1329
2023-01-21 01:35:30,142:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-21 01:47:09,939:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.80s, LR: 0.00070, Train Loss: 0.1182, Train MAE: 0.1182,
                            Val Loss: 0.1329, Val MAE: 0.1327
2023-01-21 01:47:10,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-21 01:58:49,933:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.86s, LR: 0.00070, Train Loss: 0.1184, Train MAE: 0.1184,
                            Val Loss: 0.1623, Val MAE: 0.1621
2023-01-21 01:58:50,149:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-21 02:10:16,529:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 686.36s, LR: 0.00070, Train Loss: 0.1176, Train MAE: 0.1176,
                            Val Loss: 0.1545, Val MAE: 0.1543
2023-01-21 02:10:16,606:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-21 02:21:51,526:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.92s, LR: 0.00070, Train Loss: 0.1173, Train MAE: 0.1173,
                            Val Loss: 0.1297, Val MAE: 0.1294
2023-01-21 02:21:51,622:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-21 02:33:50,879:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.26s, LR: 0.00070, Train Loss: 0.1172, Train MAE: 0.1172,
                            Val Loss: 0.1338, Val MAE: 0.1336
2023-01-21 02:33:50,962:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-21 02:45:29,825:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.86s, LR: 0.00070, Train Loss: 0.1170, Train MAE: 0.1170,
                            Val Loss: 0.1331, Val MAE: 0.1329
2023-01-21 02:45:30,020:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-21 02:57:02,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.60s, LR: 0.00070, Train Loss: 0.1162, Train MAE: 0.1162,
                            Val Loss: 0.1406, Val MAE: 0.1404
2023-01-21 02:57:02,713:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-21 03:08:40,556:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.84s, LR: 0.00070, Train Loss: 0.1158, Train MAE: 0.1158,
                            Val Loss: 0.1345, Val MAE: 0.1343
2023-01-21 03:08:40,645:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-21 03:20:15,130:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.48s, LR: 0.00070, Train Loss: 0.1157, Train MAE: 0.1157,
                            Val Loss: 0.1343, Val MAE: 0.1341
2023-01-21 03:20:15,284:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-21 03:31:55,298:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12582740187644958
2023-01-21 03:31:55,791:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.51s, LR: 0.00070, Train Loss: 0.1155, Train MAE: 0.1155,
                            Val Loss: 0.1260, Val MAE: 0.1258
2023-01-21 03:31:55,792:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-21 03:43:41,273:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.41s, LR: 0.00070, Train Loss: 0.1146, Train MAE: 0.1146,
                            Val Loss: 0.1446, Val MAE: 0.1444
2023-01-21 03:43:41,376:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-21 03:55:18,191:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.81s, LR: 0.00070, Train Loss: 0.1145, Train MAE: 0.1145,
                            Val Loss: 0.1488, Val MAE: 0.1486
2023-01-21 03:55:18,225:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-21 04:06:51,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.09s, LR: 0.00070, Train Loss: 0.1144, Train MAE: 0.1144,
                            Val Loss: 0.1277, Val MAE: 0.1275
2023-01-21 04:06:51,457:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-21 04:19:41,490:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.03s, LR: 0.00070, Train Loss: 0.1136, Train MAE: 0.1136,
                            Val Loss: 0.1418, Val MAE: 0.1416
2023-01-21 04:19:41,513:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-21 04:31:23,126:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12489289790391922
2023-01-21 04:31:23,138:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.62s, LR: 0.00070, Train Loss: 0.1136, Train MAE: 0.1136,
                            Val Loss: 0.1251, Val MAE: 0.1249
2023-01-21 04:31:23,139:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-21 04:43:02,480:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.18s, LR: 0.00070, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.1272, Val MAE: 0.1270
2023-01-21 04:43:02,774:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-21 04:54:45,851:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.08s, LR: 0.00070, Train Loss: 0.1128, Train MAE: 0.1128,
                            Val Loss: 0.1377, Val MAE: 0.1375
2023-01-21 04:54:45,960:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-21 05:06:21,893:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1228293776512146
2023-01-21 05:06:22,364:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.40s, LR: 0.00070, Train Loss: 0.1127, Train MAE: 0.1127,
                            Val Loss: 0.1230, Val MAE: 0.1228
2023-01-21 05:06:22,365:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-21 05:18:09,366:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12274638563394547
2023-01-21 05:18:09,842:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.34s, LR: 0.00070, Train Loss: 0.1123, Train MAE: 0.1123,
                            Val Loss: 0.1230, Val MAE: 0.1227
2023-01-21 05:18:10,005:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-21 05:29:55,591:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.59s, LR: 0.00070, Train Loss: 0.1119, Train MAE: 0.1119,
                            Val Loss: 0.1251, Val MAE: 0.1249
2023-01-21 05:29:55,683:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-21 05:42:24,784:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12232812494039536
2023-01-21 05:42:25,998:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.18s, LR: 0.00070, Train Loss: 0.1115, Train MAE: 0.1115,
                            Val Loss: 0.1225, Val MAE: 0.1223
2023-01-21 05:42:26,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-21 05:54:04,706:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.59s, LR: 0.00070, Train Loss: 0.1115, Train MAE: 0.1115,
                            Val Loss: 0.1234, Val MAE: 0.1232
2023-01-21 05:54:04,706:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-21 06:06:00,999:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.29s, LR: 0.00070, Train Loss: 0.1115, Train MAE: 0.1115,
                            Val Loss: 0.1291, Val MAE: 0.1289
2023-01-21 06:06:01,000:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-21 06:18:30,159:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12179798632860184
2023-01-21 06:18:30,160:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.16s, LR: 0.00070, Train Loss: 0.1112, Train MAE: 0.1112,
                            Val Loss: 0.1220, Val MAE: 0.1218
2023-01-21 06:18:30,161:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-21 06:31:28,959:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.80s, LR: 0.00070, Train Loss: 0.1106, Train MAE: 0.1106,
                            Val Loss: 0.1278, Val MAE: 0.1276
2023-01-21 06:31:28,959:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-21 06:44:08,219:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12012166529893875
2023-01-21 06:44:08,220:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 759.26s, LR: 0.00070, Train Loss: 0.1109, Train MAE: 0.1109,
                            Val Loss: 0.1203, Val MAE: 0.1201
2023-01-21 06:44:08,220:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-21 06:56:57,359:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.14s, LR: 0.00070, Train Loss: 0.1105, Train MAE: 0.1105,
                            Val Loss: 0.1249, Val MAE: 0.1247
2023-01-21 06:56:57,360:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-21 07:09:41,299:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.94s, LR: 0.00070, Train Loss: 0.1103, Train MAE: 0.1103,
                            Val Loss: 0.1280, Val MAE: 0.1278
2023-01-21 07:09:41,300:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-21 07:23:40,463:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 839.16s, LR: 0.00070, Train Loss: 0.1098, Train MAE: 0.1098,
                            Val Loss: 0.1288, Val MAE: 0.1286
2023-01-21 07:23:40,464:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-21 07:36:30,744:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.28s, LR: 0.00070, Train Loss: 0.1118, Train MAE: 0.1118,
                            Val Loss: 0.1262, Val MAE: 0.1261
2023-01-21 07:36:30,745:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-21 07:49:23,085:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.34s, LR: 0.00070, Train Loss: 0.1098, Train MAE: 0.1098,
                            Val Loss: 0.1269, Val MAE: 0.1267
2023-01-21 07:49:23,085:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-21 08:03:11,757:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11881903558969498
2023-01-21 08:03:11,759:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 828.67s, LR: 0.00070, Train Loss: 0.1097, Train MAE: 0.1097,
                            Val Loss: 0.1190, Val MAE: 0.1188
2023-01-21 08:03:11,759:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-21 08:15:42,233:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.47s, LR: 0.00070, Train Loss: 0.1093, Train MAE: 0.1093,
                            Val Loss: 0.1220, Val MAE: 0.1218
2023-01-21 08:15:42,234:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-21 08:28:13,060:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.83s, LR: 0.00070, Train Loss: 0.1095, Train MAE: 0.1095,
                            Val Loss: 0.1218, Val MAE: 0.1216
2023-01-21 08:28:13,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-21 08:40:41,515:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.45s, LR: 0.00070, Train Loss: 0.1089, Train MAE: 0.1089,
                            Val Loss: 0.1278, Val MAE: 0.1276
2023-01-21 08:40:41,515:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-21 08:53:05,799:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.28s, LR: 0.00070, Train Loss: 0.1087, Train MAE: 0.1087,
                            Val Loss: 0.1226, Val MAE: 0.1224
2023-01-21 08:53:05,800:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-21 09:05:31,751:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 745.95s, LR: 0.00070, Train Loss: 0.1087, Train MAE: 0.1087,
                            Val Loss: 0.1261, Val MAE: 0.1259
2023-01-21 09:05:31,751:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-21 09:18:01,983:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.23s, LR: 0.00070, Train Loss: 0.1084, Train MAE: 0.1084,
                            Val Loss: 0.1220, Val MAE: 0.1218
2023-01-21 09:18:01,984:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-21 09:30:30,567:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.58s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-21 09:30:30,568:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-21 09:43:00,995:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.43s, LR: 0.00070, Train Loss: 0.1082, Train MAE: 0.1082,
                            Val Loss: 0.1330, Val MAE: 0.1328
2023-01-21 09:43:00,995:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-21 09:55:33,445:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 752.45s, LR: 0.00070, Train Loss: 0.1082, Train MAE: 0.1082,
                            Val Loss: 0.1198, Val MAE: 0.1196
2023-01-21 09:55:33,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-21 10:08:03,098:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.65s, LR: 0.00070, Train Loss: 0.1078, Train MAE: 0.1078,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-21 10:08:03,098:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-21 10:20:30,994:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 747.89s, LR: 0.00070, Train Loss: 0.1076, Train MAE: 0.1076,
                            Val Loss: 0.1259, Val MAE: 0.1257
2023-01-21 10:20:30,995:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-21 10:33:00,255:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.26s, LR: 0.00070, Train Loss: 0.1079, Train MAE: 0.1079,
                            Val Loss: 0.1424, Val MAE: 0.1422
2023-01-21 10:33:00,256:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-21 10:46:32,558:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11777990311384201
2023-01-21 10:46:32,559:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 812.30s, LR: 0.00070, Train Loss: 0.1073, Train MAE: 0.1073,
                            Val Loss: 0.1180, Val MAE: 0.1178
2023-01-21 10:46:32,560:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-21 10:58:58,882:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.32s, LR: 0.00070, Train Loss: 0.1075, Train MAE: 0.1075,
                            Val Loss: 0.1219, Val MAE: 0.1217
2023-01-21 10:58:58,882:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-21 11:11:22,213:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 743.33s, LR: 0.00070, Train Loss: 0.1069, Train MAE: 0.1069,
                            Val Loss: 0.1199, Val MAE: 0.1197
2023-01-21 11:11:22,213:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-21 11:23:46,677:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.46s, LR: 0.00070, Train Loss: 0.1071, Train MAE: 0.1071,
                            Val Loss: 0.1210, Val MAE: 0.1209
2023-01-21 11:23:46,677:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-21 11:36:15,945:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.27s, LR: 0.00070, Train Loss: 0.1070, Train MAE: 0.1070,
                            Val Loss: 0.1225, Val MAE: 0.1224
2023-01-21 11:36:15,945:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-21 11:48:47,113:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.17s, LR: 0.00070, Train Loss: 0.1069, Train MAE: 0.1069,
                            Val Loss: 0.1206, Val MAE: 0.1204
2023-01-21 11:48:47,114:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-21 12:01:15,487:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.37s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1181, Val MAE: 0.1179
2023-01-21 12:01:15,487:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-21 12:13:48,569:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 753.08s, LR: 0.00070, Train Loss: 0.1062, Train MAE: 0.1062,
                            Val Loss: 0.1221, Val MAE: 0.1219
2023-01-21 12:13:48,570:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-21 12:26:23,237:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 754.67s, LR: 0.00070, Train Loss: 0.1064, Train MAE: 0.1064,
                            Val Loss: 0.1257, Val MAE: 0.1255
2023-01-21 12:26:23,238:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-21 12:38:52,051:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.81s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1183, Val MAE: 0.1181
2023-01-21 12:38:52,051:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-21 12:51:18,243:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.19s, LR: 0.00070, Train Loss: 0.1062, Train MAE: 0.1062,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-21 12:51:18,244:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-21 13:03:47,131:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.89s, LR: 0.00070, Train Loss: 0.1061, Train MAE: 0.1061,
                            Val Loss: 0.1266, Val MAE: 0.1264
2023-01-21 13:03:47,132:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-21 13:16:16,049:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.92s, LR: 0.00070, Train Loss: 0.1057, Train MAE: 0.1057,
                            Val Loss: 0.1271, Val MAE: 0.1269
2023-01-21 13:16:16,049:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-21 13:28:45,987:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.94s, LR: 0.00070, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.1219, Val MAE: 0.1217
2023-01-21 13:28:45,988:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-21 13:42:24,227:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 818.24s, LR: 0.00070, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.1189, Val MAE: 0.1187
2023-01-21 13:42:24,228:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-21 13:54:52,051:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 747.82s, LR: 0.00070, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.1195, Val MAE: 0.1193
2023-01-21 13:54:52,052:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-21 14:07:25,658:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 753.61s, LR: 0.00070, Train Loss: 0.1052, Train MAE: 0.1052,
                            Val Loss: 0.1187, Val MAE: 0.1186
2023-01-21 14:07:25,659:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-21 14:19:53,011:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11478032171726227
2023-01-21 14:19:53,013:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 747.35s, LR: 0.00035, Train Loss: 0.0985, Train MAE: 0.0985,
                            Val Loss: 0.1150, Val MAE: 0.1148
2023-01-21 14:19:53,013:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-21 14:32:22,591:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11332391202449799
2023-01-21 14:32:22,592:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.58s, LR: 0.00035, Train Loss: 0.0975, Train MAE: 0.0975,
                            Val Loss: 0.1135, Val MAE: 0.1133
2023-01-21 14:32:22,593:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-21 14:44:53,357:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11264213174581528
2023-01-21 14:44:53,359:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.77s, LR: 0.00035, Train Loss: 0.0971, Train MAE: 0.0971,
                            Val Loss: 0.1128, Val MAE: 0.1126
2023-01-21 14:44:53,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-21 14:57:17,770:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11136097460985184
2023-01-21 14:57:17,771:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.41s, LR: 0.00035, Train Loss: 0.0967, Train MAE: 0.0967,
                            Val Loss: 0.1116, Val MAE: 0.1114
2023-01-21 14:57:17,772:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-21 15:09:49,741:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.97s, LR: 0.00035, Train Loss: 0.0963, Train MAE: 0.0963,
                            Val Loss: 0.1121, Val MAE: 0.1119
2023-01-21 15:09:49,742:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-21 15:22:23,611:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 753.87s, LR: 0.00035, Train Loss: 0.0961, Train MAE: 0.0961,
                            Val Loss: 0.1152, Val MAE: 0.1151
2023-01-21 15:22:23,612:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-21 15:34:52,457:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.84s, LR: 0.00035, Train Loss: 0.0961, Train MAE: 0.0961,
                            Val Loss: 0.1118, Val MAE: 0.1116
2023-01-21 15:34:52,459:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-21 15:47:24,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.95s, LR: 0.00035, Train Loss: 0.0958, Train MAE: 0.0958,
                            Val Loss: 0.1138, Val MAE: 0.1136
2023-01-21 15:47:24,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-21 15:59:53,127:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.72s, LR: 0.00035, Train Loss: 0.0959, Train MAE: 0.0959,
                            Val Loss: 0.1151, Val MAE: 0.1149
2023-01-21 15:59:53,127:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-21 16:12:16,226:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11057765781879425
2023-01-21 16:12:16,227:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 743.10s, LR: 0.00035, Train Loss: 0.0954, Train MAE: 0.0954,
                            Val Loss: 0.1108, Val MAE: 0.1106
2023-01-21 16:12:16,228:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-21 16:24:40,170:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 743.94s, LR: 0.00035, Train Loss: 0.0953, Train MAE: 0.0953,
                            Val Loss: 0.1154, Val MAE: 0.1152
2023-01-21 16:24:40,170:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-21 16:37:05,212:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 745.04s, LR: 0.00035, Train Loss: 0.0952, Train MAE: 0.0952,
                            Val Loss: 0.1136, Val MAE: 0.1134
2023-01-21 16:37:05,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-21 16:50:39,606:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 814.39s, LR: 0.00035, Train Loss: 0.0951, Train MAE: 0.0951,
                            Val Loss: 0.1115, Val MAE: 0.1114
2023-01-21 16:50:39,606:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-21 17:02:54,254:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.65s, LR: 0.00035, Train Loss: 0.0950, Train MAE: 0.0950,
                            Val Loss: 0.1120, Val MAE: 0.1118
2023-01-21 17:02:54,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-21 17:15:13,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.61s, LR: 0.00035, Train Loss: 0.0949, Train MAE: 0.0949,
                            Val Loss: 0.1127, Val MAE: 0.1125
2023-01-21 17:15:13,871:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-21 17:27:28,169:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.30s, LR: 0.00035, Train Loss: 0.0948, Train MAE: 0.0948,
                            Val Loss: 0.1123, Val MAE: 0.1121
2023-01-21 17:27:28,170:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-21 17:39:42,797:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11039667576551437
2023-01-21 17:39:42,799:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.63s, LR: 0.00035, Train Loss: 0.0946, Train MAE: 0.0946,
                            Val Loss: 0.1106, Val MAE: 0.1104
2023-01-21 17:39:42,800:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-21 17:51:59,524:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 736.72s, LR: 0.00035, Train Loss: 0.0945, Train MAE: 0.0945,
                            Val Loss: 0.1119, Val MAE: 0.1117
2023-01-21 17:51:59,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-21 18:04:14,837:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 735.31s, LR: 0.00035, Train Loss: 0.0944, Train MAE: 0.0944,
                            Val Loss: 0.1112, Val MAE: 0.1110
2023-01-21 18:04:14,838:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-21 18:16:29,238:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.40s, LR: 0.00035, Train Loss: 0.0943, Train MAE: 0.0943,
                            Val Loss: 0.1152, Val MAE: 0.1150
2023-01-21 18:16:29,239:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-21 18:28:40,953:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 731.71s, LR: 0.00035, Train Loss: 0.0942, Train MAE: 0.0942,
                            Val Loss: 0.1111, Val MAE: 0.1110
2023-01-21 18:28:40,954:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-21 18:40:53,827:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.87s, LR: 0.00035, Train Loss: 0.0944, Train MAE: 0.0944,
                            Val Loss: 0.1120, Val MAE: 0.1118
2023-01-21 18:40:53,827:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-21 18:53:12,821:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.99s, LR: 0.00035, Train Loss: 0.0942, Train MAE: 0.0942,
                            Val Loss: 0.1130, Val MAE: 0.1128
2023-01-21 18:53:12,821:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-21 19:05:40,888:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11037157475948334
2023-01-21 19:05:40,889:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.07s, LR: 0.00035, Train Loss: 0.0940, Train MAE: 0.0940,
                            Val Loss: 0.1106, Val MAE: 0.1104
2023-01-21 19:05:40,889:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-21 19:18:11,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.98s, LR: 0.00035, Train Loss: 0.0941, Train MAE: 0.0941,
                            Val Loss: 0.1115, Val MAE: 0.1113
2023-01-21 19:18:11,867:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-21 19:30:37,929:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.06s, LR: 0.00035, Train Loss: 0.0939, Train MAE: 0.0939,
                            Val Loss: 0.1112, Val MAE: 0.1110
2023-01-21 19:30:37,929:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-21 19:30:37,930:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-21 19:39:48,250:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1110
2023-01-21 19:39:48,252:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0918
2023-01-21 19:39:48,252:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-21 19:39:48,252:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 117.0000
2023-01-21 19:39:48,252:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87173.4055s
2023-01-21 19:39:48,274:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 733.4945s
2023-01-21 19:39:48,351:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-21 19:39:48,671:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0918)]
2023-01-21 19:39:48,672:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1110)]
