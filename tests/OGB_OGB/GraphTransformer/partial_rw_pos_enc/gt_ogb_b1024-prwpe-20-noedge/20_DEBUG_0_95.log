2023-01-22 02:27:53,109:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-22 02:27:53,109:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-22 02:38:31,290:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-22 02:39:02,904:ogbdata.py:332 -             __init__(): Time taken: 669.7947s
2023-01-22 02:39:02,904:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-22 02:39:02,904:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-22 02:39:02,904:ogbdata.py:348 -             __init__(): [I] Data load time: 669.7951s
2023-01-22 02:39:02,904:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': True, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/partial_rw_pos_enc/gt_ogb_b1024-prwpe-20-noedge/20_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-22 02:39:02,904:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-22 02:39:02,923:pe_layer.py:99 -             __init__(): partial_rw_pos_enc
2023-01-22 02:39:02,963:pe_layer.py:194 -             __init__(): Using 20 dimension positional encoding
2023-01-22 02:39:02,963:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:39:02,963:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:39:03,000:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-22 02:39:03,003:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 538421
2023-01-22 02:39:03,003:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-22 02:39:03,004:pe_layer.py:99 -             __init__(): partial_rw_pos_enc
2023-01-22 02:39:03,004:pe_layer.py:194 -             __init__(): Using 20 dimension positional encoding
2023-01-22 02:39:03,004:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:39:03,004:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:39:10,507:main_OGB_graph_regression.py:78 -   train_val_pipeline(): [!] Adding partial random walk graph positional encoding (20).
2023-01-22 02:39:10,507:positional_encs.py:134 - add_rw_pos_encodings(): Adding PE to train graphs...
2023-01-22 06:28:23,470:positional_encs.py:136 - add_rw_pos_encodings(): Adding PE to val graphs...
2023-01-22 06:33:20,781:main_OGB_graph_regression.py:80 -   train_val_pipeline(): Time PE:14057.777958869934
2023-01-22 06:33:20,856:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-22 06:33:20,857:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-22 06:33:20,887:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-22 06:46:34,806:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.22656512260437012
2023-01-22 06:46:34,808:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 793.92s, LR: 0.00070, Train Loss: 0.3103, Train MAE: 0.3103,
                            Val Loss: 0.2269, Val MAE: 0.2266
2023-01-22 06:46:34,808:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-22 06:57:09,287:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.18202190101146698
2023-01-22 06:57:09,288:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.48s, LR: 0.00070, Train Loss: 0.1753, Train MAE: 0.1753,
                            Val Loss: 0.1824, Val MAE: 0.1820
2023-01-22 06:57:09,289:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-22 07:07:42,379:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1719820499420166
2023-01-22 07:07:42,380:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 633.09s, LR: 0.00070, Train Loss: 0.1594, Train MAE: 0.1594,
                            Val Loss: 0.1723, Val MAE: 0.1720
2023-01-22 07:07:42,380:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-22 07:18:15,523:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 633.14s, LR: 0.00070, Train Loss: 0.1524, Train MAE: 0.1524,
                            Val Loss: 0.2149, Val MAE: 0.2146
2023-01-22 07:18:15,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-22 07:28:47,890:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.37s, LR: 0.00070, Train Loss: 0.1465, Train MAE: 0.1465,
                            Val Loss: 0.2753, Val MAE: 0.2750
2023-01-22 07:28:47,891:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-22 07:39:20,547:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15344440937042236
2023-01-22 07:39:20,549:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.66s, LR: 0.00070, Train Loss: 0.1435, Train MAE: 0.1435,
                            Val Loss: 0.1538, Val MAE: 0.1534
2023-01-22 07:39:20,549:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-22 07:49:52,334:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.78s, LR: 0.00070, Train Loss: 0.1399, Train MAE: 0.1399,
                            Val Loss: 0.2502, Val MAE: 0.2499
2023-01-22 07:49:52,334:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-22 08:01:17,526:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14729174971580505
2023-01-22 08:01:17,527:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.19s, LR: 0.00070, Train Loss: 0.1376, Train MAE: 0.1376,
                            Val Loss: 0.1476, Val MAE: 0.1473
2023-01-22 08:01:17,528:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-22 08:11:46,785:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.26s, LR: 0.00070, Train Loss: 0.1353, Train MAE: 0.1353,
                            Val Loss: 0.1658, Val MAE: 0.1655
2023-01-22 08:11:46,786:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-22 08:22:18,209:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.42s, LR: 0.00070, Train Loss: 0.1334, Train MAE: 0.1334,
                            Val Loss: 0.1851, Val MAE: 0.1848
2023-01-22 08:22:18,210:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-22 08:32:50,527:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.32s, LR: 0.00070, Train Loss: 0.1316, Train MAE: 0.1316,
                            Val Loss: 0.1522, Val MAE: 0.1519
2023-01-22 08:32:50,527:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-22 08:43:23,042:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14000478386878967
2023-01-22 08:43:23,043:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.52s, LR: 0.00070, Train Loss: 0.1302, Train MAE: 0.1302,
                            Val Loss: 0.1403, Val MAE: 0.1400
2023-01-22 08:43:23,044:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-22 08:53:55,044:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.00s, LR: 0.00070, Train Loss: 0.1294, Train MAE: 0.1294,
                            Val Loss: 0.1783, Val MAE: 0.1780
2023-01-22 08:53:55,045:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-22 09:04:27,404:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.36s, LR: 0.00070, Train Loss: 0.1275, Train MAE: 0.1275,
                            Val Loss: 0.1450, Val MAE: 0.1447
2023-01-22 09:04:27,405:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-22 09:14:59,317:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.91s, LR: 0.00070, Train Loss: 0.1271, Train MAE: 0.1271,
                            Val Loss: 0.1639, Val MAE: 0.1636
2023-01-22 09:14:59,318:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-22 09:25:31,726:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.41s, LR: 0.00070, Train Loss: 0.1261, Train MAE: 0.1261,
                            Val Loss: 0.1717, Val MAE: 0.1714
2023-01-22 09:25:31,726:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-22 09:36:03,153:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.43s, LR: 0.00070, Train Loss: 0.1247, Train MAE: 0.1247,
                            Val Loss: 0.1581, Val MAE: 0.1579
2023-01-22 09:36:03,154:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-22 09:46:35,005:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.85s, LR: 0.00070, Train Loss: 0.1245, Train MAE: 0.1245,
                            Val Loss: 0.1607, Val MAE: 0.1604
2023-01-22 09:46:35,006:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-22 09:57:07,307:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1390906423330307
2023-01-22 09:57:07,308:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.30s, LR: 0.00070, Train Loss: 0.1234, Train MAE: 0.1234,
                            Val Loss: 0.1394, Val MAE: 0.1391
2023-01-22 09:57:07,308:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-22 10:07:39,153:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13387005031108856
2023-01-22 10:07:39,154:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.85s, LR: 0.00070, Train Loss: 0.1230, Train MAE: 0.1230,
                            Val Loss: 0.1341, Val MAE: 0.1339
2023-01-22 10:07:39,155:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-22 10:18:11,799:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.64s, LR: 0.00070, Train Loss: 0.1223, Train MAE: 0.1223,
                            Val Loss: 0.1363, Val MAE: 0.1360
2023-01-22 10:18:11,799:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-22 10:28:43,724:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.92s, LR: 0.00070, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.1398, Val MAE: 0.1396
2023-01-22 10:28:43,725:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-22 10:39:14,832:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.11s, LR: 0.00070, Train Loss: 0.1208, Train MAE: 0.1208,
                            Val Loss: 0.1412, Val MAE: 0.1410
2023-01-22 10:39:14,833:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-22 10:50:36,271:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12926064431667328
2023-01-22 10:50:36,271:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.44s, LR: 0.00070, Train Loss: 0.1202, Train MAE: 0.1202,
                            Val Loss: 0.1295, Val MAE: 0.1293
2023-01-22 10:50:36,272:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-22 11:01:07,454:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.18s, LR: 0.00070, Train Loss: 0.1197, Train MAE: 0.1197,
                            Val Loss: 0.1496, Val MAE: 0.1493
2023-01-22 11:01:07,455:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-22 11:11:41,149:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 633.69s, LR: 0.00070, Train Loss: 0.1195, Train MAE: 0.1195,
                            Val Loss: 0.1399, Val MAE: 0.1397
2023-01-22 11:11:41,150:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-22 11:22:16,887:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.74s, LR: 0.00070, Train Loss: 0.1186, Train MAE: 0.1186,
                            Val Loss: 0.1683, Val MAE: 0.1681
2023-01-22 11:22:16,887:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-22 11:32:51,597:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.126982182264328
2023-01-22 11:32:51,599:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.71s, LR: 0.00070, Train Loss: 0.1187, Train MAE: 0.1187,
                            Val Loss: 0.1272, Val MAE: 0.1270
2023-01-22 11:32:51,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-22 11:43:24,126:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.53s, LR: 0.00070, Train Loss: 0.1185, Train MAE: 0.1185,
                            Val Loss: 0.1317, Val MAE: 0.1315
2023-01-22 11:43:24,127:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-22 11:53:59,503:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.38s, LR: 0.00070, Train Loss: 0.1174, Train MAE: 0.1174,
                            Val Loss: 0.1483, Val MAE: 0.1481
2023-01-22 11:53:59,503:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-22 12:04:33,119:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 633.62s, LR: 0.00070, Train Loss: 0.1171, Train MAE: 0.1171,
                            Val Loss: 0.1361, Val MAE: 0.1359
2023-01-22 12:04:33,120:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-22 12:15:09,469:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.35s, LR: 0.00070, Train Loss: 0.1169, Train MAE: 0.1169,
                            Val Loss: 0.1274, Val MAE: 0.1272
2023-01-22 12:15:09,469:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-22 12:25:46,339:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.87s, LR: 0.00070, Train Loss: 0.1160, Train MAE: 0.1160,
                            Val Loss: 0.1337, Val MAE: 0.1334
2023-01-22 12:25:46,340:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-22 12:36:23,262:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.92s, LR: 0.00070, Train Loss: 0.1161, Train MAE: 0.1161,
                            Val Loss: 0.1316, Val MAE: 0.1314
2023-01-22 12:36:23,262:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-22 12:46:59,985:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.72s, LR: 0.00070, Train Loss: 0.1157, Train MAE: 0.1157,
                            Val Loss: 0.1372, Val MAE: 0.1371
2023-01-22 12:46:59,985:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-22 12:57:35,257:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.27s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1280, Val MAE: 0.1278
2023-01-22 12:57:35,257:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-22 13:08:10,498:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.24s, LR: 0.00070, Train Loss: 0.1146, Train MAE: 0.1146,
                            Val Loss: 0.1319, Val MAE: 0.1317
2023-01-22 13:08:10,499:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-22 13:18:44,859:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.36s, LR: 0.00070, Train Loss: 0.1144, Train MAE: 0.1144,
                            Val Loss: 0.1399, Val MAE: 0.1397
2023-01-22 13:18:44,860:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-22 13:29:20,625:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.76s, LR: 0.00070, Train Loss: 0.1143, Train MAE: 0.1143,
                            Val Loss: 0.1275, Val MAE: 0.1273
2023-01-22 13:29:20,626:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-22 13:39:56,099:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1222381666302681
2023-01-22 13:39:56,101:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.47s, LR: 0.00070, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.1225, Val MAE: 0.1222
2023-01-22 13:39:56,101:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-22 13:51:23,282:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.18s, LR: 0.00070, Train Loss: 0.1138, Train MAE: 0.1138,
                            Val Loss: 0.1227, Val MAE: 0.1225
2023-01-22 13:51:23,282:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-22 14:01:58,976:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.69s, LR: 0.00070, Train Loss: 0.1132, Train MAE: 0.1132,
                            Val Loss: 0.1320, Val MAE: 0.1318
2023-01-22 14:01:58,976:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-22 14:12:35,425:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.45s, LR: 0.00070, Train Loss: 0.1127, Train MAE: 0.1127,
                            Val Loss: 0.1285, Val MAE: 0.1283
2023-01-22 14:12:35,425:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-22 14:23:11,353:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12073111534118652
2023-01-22 14:23:11,354:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.93s, LR: 0.00070, Train Loss: 0.1126, Train MAE: 0.1126,
                            Val Loss: 0.1209, Val MAE: 0.1207
2023-01-22 14:23:11,355:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-22 14:33:46,765:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.41s, LR: 0.00070, Train Loss: 0.1123, Train MAE: 0.1123,
                            Val Loss: 0.1265, Val MAE: 0.1263
2023-01-22 14:33:46,765:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-22 14:44:21,703:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.94s, LR: 0.00070, Train Loss: 0.1121, Train MAE: 0.1121,
                            Val Loss: 0.1617, Val MAE: 0.1615
2023-01-22 14:44:21,703:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-22 14:54:56,570:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.87s, LR: 0.00070, Train Loss: 0.1121, Train MAE: 0.1121,
                            Val Loss: 0.1253, Val MAE: 0.1251
2023-01-22 14:54:56,571:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-22 15:05:32,411:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11969196051359177
2023-01-22 15:05:32,413:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.84s, LR: 0.00070, Train Loss: 0.1117, Train MAE: 0.1117,
                            Val Loss: 0.1199, Val MAE: 0.1197
2023-01-22 15:05:32,413:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-22 15:16:07,846:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.43s, LR: 0.00070, Train Loss: 0.1118, Train MAE: 0.1118,
                            Val Loss: 0.1204, Val MAE: 0.1202
2023-01-22 15:16:07,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-22 15:26:41,944:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.08s, LR: 0.00070, Train Loss: 0.1113, Train MAE: 0.1113,
                            Val Loss: 0.1238, Val MAE: 0.1236
2023-01-22 15:26:41,944:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-22 15:37:17,285:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11963149905204773
2023-01-22 15:37:17,286:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.34s, LR: 0.00070, Train Loss: 0.1110, Train MAE: 0.1110,
                            Val Loss: 0.1198, Val MAE: 0.1196
2023-01-22 15:37:17,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-22 15:48:06,154:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.87s, LR: 0.00070, Train Loss: 0.1103, Train MAE: 0.1103,
                            Val Loss: 0.1299, Val MAE: 0.1297
2023-01-22 15:48:06,155:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-22 15:59:13,081:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.93s, LR: 0.00070, Train Loss: 0.1102, Train MAE: 0.1102,
                            Val Loss: 0.1229, Val MAE: 0.1227
2023-01-22 15:59:13,082:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-22 16:09:52,800:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.72s, LR: 0.00070, Train Loss: 0.1102, Train MAE: 0.1102,
                            Val Loss: 0.1422, Val MAE: 0.1420
2023-01-22 16:09:52,800:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-22 16:20:41,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.24s, LR: 0.00070, Train Loss: 0.1099, Train MAE: 0.1099,
                            Val Loss: 0.1208, Val MAE: 0.1206
2023-01-22 16:20:41,058:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-22 16:31:16,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.95s, LR: 0.00070, Train Loss: 0.1095, Train MAE: 0.1095,
                            Val Loss: 0.1208, Val MAE: 0.1206
2023-01-22 16:31:16,014:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-22 16:41:51,219:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11892484873533249
2023-01-22 16:41:51,221:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.21s, LR: 0.00070, Train Loss: 0.1093, Train MAE: 0.1093,
                            Val Loss: 0.1191, Val MAE: 0.1189
2023-01-22 16:41:51,221:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-22 16:53:14,290:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11834558844566345
2023-01-22 16:53:14,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.07s, LR: 0.00070, Train Loss: 0.1088, Train MAE: 0.1088,
                            Val Loss: 0.1185, Val MAE: 0.1183
2023-01-22 16:53:14,292:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-22 17:03:45,462:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.17s, LR: 0.00070, Train Loss: 0.1086, Train MAE: 0.1086,
                            Val Loss: 0.1206, Val MAE: 0.1204
2023-01-22 17:03:45,462:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-22 17:14:16,081:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.62s, LR: 0.00070, Train Loss: 0.1089, Train MAE: 0.1089,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-22 17:14:16,082:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-22 17:24:46,327:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11702395230531693
2023-01-22 17:24:46,328:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.25s, LR: 0.00070, Train Loss: 0.1084, Train MAE: 0.1084,
                            Val Loss: 0.1172, Val MAE: 0.1170
2023-01-22 17:24:46,328:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-22 17:35:16,674:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.35s, LR: 0.00070, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.1224, Val MAE: 0.1222
2023-01-22 17:35:16,675:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-22 17:45:47,090:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.41s, LR: 0.00070, Train Loss: 0.1077, Train MAE: 0.1077,
                            Val Loss: 0.1180, Val MAE: 0.1178
2023-01-22 17:45:47,091:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-22 17:56:16,675:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.58s, LR: 0.00070, Train Loss: 0.1078, Train MAE: 0.1078,
                            Val Loss: 0.1215, Val MAE: 0.1214
2023-01-22 17:56:16,676:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-22 18:06:46,813:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.14s, LR: 0.00070, Train Loss: 0.1077, Train MAE: 0.1077,
                            Val Loss: 0.1215, Val MAE: 0.1213
2023-01-22 18:06:46,813:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-22 18:17:16,359:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.55s, LR: 0.00070, Train Loss: 0.1077, Train MAE: 0.1077,
                            Val Loss: 0.1193, Val MAE: 0.1191
2023-01-22 18:17:16,360:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-22 18:27:45,087:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.73s, LR: 0.00070, Train Loss: 0.1074, Train MAE: 0.1074,
                            Val Loss: 0.1206, Val MAE: 0.1204
2023-01-22 18:27:45,087:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-22 18:38:14,189:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.10s, LR: 0.00070, Train Loss: 0.1070, Train MAE: 0.1070,
                            Val Loss: 0.1236, Val MAE: 0.1234
2023-01-22 18:38:14,189:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-22 18:48:44,031:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.84s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1218, Val MAE: 0.1216
2023-01-22 18:48:44,031:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-22 18:59:15,051:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.02s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1174, Val MAE: 0.1172
2023-01-22 18:59:15,052:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-22 19:09:45,763:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.71s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1182, Val MAE: 0.1180
2023-01-22 19:09:45,763:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-22 19:20:16,785:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.02s, LR: 0.00070, Train Loss: 0.1062, Train MAE: 0.1062,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-22 19:20:16,785:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-22 19:30:47,713:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11573909968137741
2023-01-22 19:30:47,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.93s, LR: 0.00070, Train Loss: 0.1058, Train MAE: 0.1058,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-22 19:30:47,714:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-22 19:41:17,995:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.28s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1188, Val MAE: 0.1186
2023-01-22 19:41:18,008:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-22 19:52:40,388:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.38s, LR: 0.00070, Train Loss: 0.1057, Train MAE: 0.1057,
                            Val Loss: 0.1199, Val MAE: 0.1197
2023-01-22 19:52:40,407:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-22 20:03:11,248:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.84s, LR: 0.00070, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.1194, Val MAE: 0.1192
2023-01-22 20:03:11,249:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-22 20:13:42,415:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.17s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1225, Val MAE: 0.1223
2023-01-22 20:13:42,416:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-22 20:24:12,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.70s, LR: 0.00070, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.1168, Val MAE: 0.1166
2023-01-22 20:24:12,117:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-22 20:34:42,322:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11571480333805084
2023-01-22 20:34:42,335:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.22s, LR: 0.00070, Train Loss: 0.1052, Train MAE: 0.1052,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-22 20:34:42,336:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-22 20:45:11,815:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.48s, LR: 0.00070, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-22 20:45:11,815:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-22 20:55:40,893:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.08s, LR: 0.00070, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.1160, Val MAE: 0.1158
2023-01-22 20:55:40,894:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-22 21:06:10,096:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.20s, LR: 0.00070, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1170, Val MAE: 0.1169
2023-01-22 21:06:10,096:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-22 21:16:38,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.60s, LR: 0.00070, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.1216, Val MAE: 0.1214
2023-01-22 21:16:38,701:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-22 21:27:07,213:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.51s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1175, Val MAE: 0.1174
2023-01-22 21:27:07,214:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-22 21:37:36,280:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.07s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1216, Val MAE: 0.1214
2023-01-22 21:37:36,281:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-22 21:48:05,263:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.98s, LR: 0.00070, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1178, Val MAE: 0.1176
2023-01-22 21:48:05,264:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-22 21:58:47,193:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11487366259098053
2023-01-22 21:58:47,194:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.93s, LR: 0.00070, Train Loss: 0.1038, Train MAE: 0.1038,
                            Val Loss: 0.1150, Val MAE: 0.1149
2023-01-22 21:58:47,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-22 22:09:53,131:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.94s, LR: 0.00070, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1166, Val MAE: 0.1165
2023-01-22 22:09:53,132:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-22 22:20:20,252:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 627.12s, LR: 0.00070, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.1258, Val MAE: 0.1257
2023-01-22 22:20:20,273:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-22 22:30:47,424:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 627.15s, LR: 0.00070, Train Loss: 0.1040, Train MAE: 0.1040,
                            Val Loss: 0.1178, Val MAE: 0.1176
2023-01-22 22:30:47,432:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-22 22:41:13,438:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 626.01s, LR: 0.00070, Train Loss: 0.1029, Train MAE: 0.1029,
                            Val Loss: 0.1179, Val MAE: 0.1177
2023-01-22 22:41:13,452:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-22 22:52:32,467:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.01s, LR: 0.00070, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1153, Val MAE: 0.1151
2023-01-22 22:52:32,493:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-22 23:02:58,029:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 625.54s, LR: 0.00070, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.1162, Val MAE: 0.1161
2023-01-22 23:02:58,029:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-22 23:13:23,162:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 625.13s, LR: 0.00070, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1168, Val MAE: 0.1166
2023-01-22 23:13:23,162:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-22 23:23:52,415:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.25s, LR: 0.00070, Train Loss: 0.1029, Train MAE: 0.1029,
                            Val Loss: 0.1155, Val MAE: 0.1153
2023-01-22 23:23:52,415:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-22 23:34:18,189:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 625.77s, LR: 0.00070, Train Loss: 0.1025, Train MAE: 0.1025,
                            Val Loss: 0.1190, Val MAE: 0.1188
2023-01-22 23:34:18,190:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-22 23:44:44,449:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1145898699760437
2023-01-22 23:44:44,450:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 626.26s, LR: 0.00070, Train Loss: 0.1028, Train MAE: 0.1028,
                            Val Loss: 0.1148, Val MAE: 0.1146
2023-01-22 23:44:44,450:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-22 23:55:13,467:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11429271847009659
2023-01-22 23:55:13,501:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.05s, LR: 0.00070, Train Loss: 0.1027, Train MAE: 0.1027,
                            Val Loss: 0.1145, Val MAE: 0.1143
2023-01-22 23:55:13,501:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-23 00:05:40,353:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11256443709135056
2023-01-23 00:05:40,359:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 626.86s, LR: 0.00070, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.1127, Val MAE: 0.1126
2023-01-23 00:05:40,360:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
