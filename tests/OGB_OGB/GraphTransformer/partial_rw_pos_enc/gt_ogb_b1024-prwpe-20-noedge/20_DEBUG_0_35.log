2023-01-20 05:12:01,062:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2023-01-20 05:12:01,062:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-20 05:17:03,906:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-20 05:17:03,907:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-20 05:33:20,502:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-20 05:33:54,058:ogbdata.py:330 -             __init__(): Time taken: 1010.1504s
2023-01-20 05:33:54,058:ogbdata.py:343 -             __init__(): train, test, val sizes: 3378606,147037,73545
2023-01-20 05:33:54,058:ogbdata.py:344 -             __init__(): [I] Finished loading.
2023-01-20 05:33:54,058:ogbdata.py:345 -             __init__(): [I] Data load time: 1010.1511s
2023-01-20 05:33:54,058:main_OGB_graph_regression.py:355 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': True, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/partial_rw_pos_enc/gt_ogb_b1024-prwpe-20-noedge/20_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-20 05:33:54,058:main_OGB_graph_regression.py:356 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b128-prwpe', 'job_num': 20}
2023-01-20 05:33:54,062:pe_layer.py:99 -             __init__(): partial_rw_pos_enc
2023-01-20 05:33:54,158:pe_layer.py:194 -             __init__(): Using 20 dimension positional encoding
2023-01-20 05:33:54,159:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 05:33:54,159:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 05:33:54,230:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-20 05:33:54,244:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 538421
2023-01-20 05:33:54,244:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-20 05:33:54,245:pe_layer.py:99 -             __init__(): partial_rw_pos_enc
2023-01-20 05:33:54,245:pe_layer.py:194 -             __init__(): Using 20 dimension positional encoding
2023-01-20 05:33:54,245:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-20 05:33:54,245:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-20 05:34:05,954:main_OGB_graph_regression.py:78 -   train_val_pipeline(): [!] Adding partial random walk graph positional encoding (20).
2023-01-20 05:34:05,954:positional_encs.py:133 - add_rw_pos_encodings(): Adding PE to train graphs...
2023-01-20 09:50:09,223:positional_encs.py:135 - add_rw_pos_encodings(): Adding PE to val graphs...
2023-01-20 09:55:39,018:positional_encs.py:137 - add_rw_pos_encodings(): Adding PE to test graphs...
2023-01-20 10:06:43,995:main_OGB_graph_regression.py:80 -   train_val_pipeline(): Time PE:16369.750215530396
2023-01-20 10:06:44,204:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-20 10:06:44,204:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-20 10:06:44,205:main_OGB_graph_regression.py:122 -   train_val_pipeline(): Test Graphs: 147037
2023-01-20 10:06:44,316:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 1/1000
2023-01-20 10:24:46,010:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 1081.69s, LR: 0.00070, Train Loss: 0.3474, Train MAE: 0.3474,
                            Val Loss: 0.2266, Val Acc: 0.2263, Test MAE: nan
2023-01-20 10:24:46,020:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 2/1000
2023-01-20 10:38:37,250:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 831.23s, LR: 0.00070, Train Loss: 0.1859, Train MAE: 0.1859,
                            Val Loss: 0.2061, Val Acc: 0.2058, Test MAE: nan
2023-01-20 10:38:37,251:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 3/1000
2023-01-20 10:52:39,768:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 842.52s, LR: 0.00070, Train Loss: 0.1696, Train MAE: 0.1696,
                            Val Loss: 0.1783, Val Acc: 0.1781, Test MAE: nan
2023-01-20 10:52:39,769:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 4/1000
2023-01-20 11:06:38,370:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 838.60s, LR: 0.00070, Train Loss: 0.1619, Train MAE: 0.1619,
                            Val Loss: 0.1810, Val Acc: 0.1807, Test MAE: nan
2023-01-20 11:06:38,371:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 5/1000
2023-01-20 11:20:28,607:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 830.24s, LR: 0.00070, Train Loss: 0.1568, Train MAE: 0.1568,
                            Val Loss: 0.2279, Val Acc: 0.2278, Test MAE: nan
2023-01-20 11:20:28,607:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 6/1000
2023-01-20 11:35:43,904:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 915.30s, LR: 0.00070, Train Loss: 0.1517, Train MAE: 0.1517,
                            Val Loss: 0.1770, Val Acc: 0.1766, Test MAE: nan
2023-01-20 11:35:43,904:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 7/1000
2023-01-20 11:49:39,851:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 835.95s, LR: 0.00070, Train Loss: 0.1487, Train MAE: 0.1487,
                            Val Loss: 0.1633, Val Acc: 0.1630, Test MAE: nan
2023-01-20 11:49:39,851:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 8/1000
2023-01-20 12:03:38,933:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 839.08s, LR: 0.00070, Train Loss: 0.1476, Train MAE: 0.1476,
                            Val Loss: 0.2054, Val Acc: 0.2051, Test MAE: nan
2023-01-20 12:03:38,933:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 9/1000
2023-01-20 12:17:37,206:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 838.27s, LR: 0.00070, Train Loss: 0.1648, Train MAE: 0.1648,
                            Val Loss: 0.1842, Val Acc: 0.1839, Test MAE: nan
2023-01-20 12:17:37,207:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 10/1000
2023-01-20 12:31:31,306:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 834.10s, LR: 0.00070, Train Loss: 0.1568, Train MAE: 0.1568,
                            Val Loss: 0.1588, Val Acc: 0.1586, Test MAE: nan
2023-01-20 12:31:31,306:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 11/1000
2023-01-20 12:45:31,593:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 840.29s, LR: 0.00070, Train Loss: 0.1578, Train MAE: 0.1578,
                            Val Loss: 0.2085, Val Acc: 0.2083, Test MAE: nan
2023-01-20 12:45:31,593:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 12/1000
2023-01-20 12:59:29,477:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 837.88s, LR: 0.00070, Train Loss: 0.1512, Train MAE: 0.1512,
                            Val Loss: 0.1802, Val Acc: 0.1799, Test MAE: nan
2023-01-20 12:59:29,477:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 13/1000
2023-01-20 13:13:15,578:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 826.10s, LR: 0.00070, Train Loss: 0.1464, Train MAE: 0.1464,
                            Val Loss: 0.1838, Val Acc: 0.1835, Test MAE: nan
2023-01-20 13:13:15,578:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 14/1000
2023-01-20 13:27:02,261:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 826.68s, LR: 0.00070, Train Loss: 0.1477, Train MAE: 0.1477,
                            Val Loss: 0.1485, Val Acc: 0.1483, Test MAE: nan
2023-01-20 13:27:02,262:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 15/1000
2023-01-20 13:40:51,306:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 829.04s, LR: 0.00070, Train Loss: 0.1432, Train MAE: 0.1432,
                            Val Loss: 0.1665, Val Acc: 0.1663, Test MAE: nan
2023-01-20 13:40:51,306:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 16/1000
2023-01-20 13:54:32,149:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 820.84s, LR: 0.00070, Train Loss: 0.1416, Train MAE: 0.1416,
                            Val Loss: 0.1530, Val Acc: 0.1528, Test MAE: nan
2023-01-20 13:54:32,149:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 17/1000
2023-01-20 14:08:18,290:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 826.13s, LR: 0.00070, Train Loss: 0.1384, Train MAE: 0.1384,
                            Val Loss: 0.1813, Val Acc: 0.1812, Test MAE: nan
2023-01-20 14:08:18,291:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 18/1000
2023-01-20 14:22:01,877:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 823.59s, LR: 0.00070, Train Loss: 0.1357, Train MAE: 0.1357,
                            Val Loss: 0.1351, Val Acc: 0.1349, Test MAE: nan
2023-01-20 14:22:01,878:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 19/1000
2023-01-20 14:35:42,649:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 820.77s, LR: 0.00070, Train Loss: 0.1337, Train MAE: 0.1337,
                            Val Loss: 0.1519, Val Acc: 0.1517, Test MAE: nan
2023-01-20 14:35:42,649:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 20/1000
2023-01-20 14:49:26,158:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 823.51s, LR: 0.00070, Train Loss: 0.1327, Train MAE: 0.1327,
                            Val Loss: 0.1371, Val Acc: 0.1369, Test MAE: nan
2023-01-20 14:49:26,158:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 21/1000
2023-01-20 15:04:27,100:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 900.94s, LR: 0.00070, Train Loss: 0.1304, Train MAE: 0.1304,
                            Val Loss: 0.1429, Val Acc: 0.1428, Test MAE: nan
2023-01-20 15:04:27,100:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 22/1000
2023-01-20 15:18:14,419:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 827.31s, LR: 0.00070, Train Loss: 0.1296, Train MAE: 0.1296,
                            Val Loss: 0.1390, Val Acc: 0.1388, Test MAE: nan
2023-01-20 15:18:14,420:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 23/1000
2023-01-20 15:32:15,125:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 840.70s, LR: 0.00070, Train Loss: 0.1284, Train MAE: 0.1284,
                            Val Loss: 0.1357, Val Acc: 0.1355, Test MAE: nan
2023-01-20 15:32:15,125:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 24/1000
2023-01-20 15:46:04,375:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 829.25s, LR: 0.00070, Train Loss: 0.1275, Train MAE: 0.1275,
                            Val Loss: 0.1412, Val Acc: 0.1410, Test MAE: nan
2023-01-20 15:46:04,376:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 25/1000
2023-01-20 16:00:02,981:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 838.60s, LR: 0.00070, Train Loss: 0.1260, Train MAE: 0.1260,
                            Val Loss: 0.1696, Val Acc: 0.1695, Test MAE: nan
2023-01-20 16:00:02,981:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 26/1000
2023-01-20 16:14:01,577:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 838.60s, LR: 0.00070, Train Loss: 0.1255, Train MAE: 0.1255,
                            Val Loss: 0.1328, Val Acc: 0.1326, Test MAE: nan
2023-01-20 16:14:01,578:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 27/1000
2023-01-20 16:27:56,969:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 835.39s, LR: 0.00070, Train Loss: 0.1252, Train MAE: 0.1252,
                            Val Loss: 0.1341, Val Acc: 0.1340, Test MAE: nan
2023-01-20 16:27:56,970:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 28/1000
2023-01-20 16:41:54,177:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 837.21s, LR: 0.00070, Train Loss: 0.1244, Train MAE: 0.1244,
                            Val Loss: 0.1323, Val Acc: 0.1321, Test MAE: nan
2023-01-20 16:41:54,177:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 29/1000
2023-01-20 16:55:50,352:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 836.17s, LR: 0.00070, Train Loss: 0.1233, Train MAE: 0.1233,
                            Val Loss: 0.1286, Val Acc: 0.1285, Test MAE: nan
2023-01-20 16:55:50,352:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 30/1000
2023-01-20 17:09:45,111:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 834.76s, LR: 0.00070, Train Loss: 0.1225, Train MAE: 0.1225,
                            Val Loss: 0.1399, Val Acc: 0.1398, Test MAE: nan
2023-01-20 17:09:45,112:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 31/1000
2023-01-20 17:23:48,134:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 843.02s, LR: 0.00070, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.1295, Val Acc: 0.1294, Test MAE: nan
2023-01-20 17:23:48,134:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 32/1000
2023-01-20 17:37:38,304:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 830.16s, LR: 0.00070, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.1334, Val Acc: 0.1332, Test MAE: nan
2023-01-20 17:37:38,304:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 33/1000
2023-01-20 17:51:40,771:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 842.47s, LR: 0.00070, Train Loss: 0.1209, Train MAE: 0.1209,
                            Val Loss: 0.1304, Val Acc: 0.1302, Test MAE: nan
2023-01-20 17:51:40,771:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 34/1000
2023-01-20 18:05:39,116:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 838.34s, LR: 0.00070, Train Loss: 0.1198, Train MAE: 0.1198,
                            Val Loss: 0.1254, Val Acc: 0.1252, Test MAE: nan
2023-01-20 18:05:39,116:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 35/1000
2023-01-20 18:19:23,509:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 824.39s, LR: 0.00070, Train Loss: 0.1200, Train MAE: 0.1200,
                            Val Loss: 0.1376, Val Acc: 0.1375, Test MAE: nan
2023-01-20 18:19:23,509:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 36/1000
2023-01-20 18:34:36,083:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 912.57s, LR: 0.00070, Train Loss: 0.1191, Train MAE: 0.1191,
                            Val Loss: 0.1432, Val Acc: 0.1430, Test MAE: nan
2023-01-20 18:34:36,084:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 37/1000
2023-01-20 18:48:34,845:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 838.76s, LR: 0.00070, Train Loss: 0.1181, Train MAE: 0.1181,
                            Val Loss: 0.1339, Val Acc: 0.1337, Test MAE: nan
2023-01-20 18:48:34,846:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 38/1000
2023-01-20 19:02:30,274:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 835.43s, LR: 0.00070, Train Loss: 0.1176, Train MAE: 0.1176,
                            Val Loss: 0.1355, Val Acc: 0.1354, Test MAE: nan
2023-01-20 19:02:30,275:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 39/1000
2023-01-20 19:16:05,859:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 815.58s, LR: 0.00070, Train Loss: 0.1177, Train MAE: 0.1177,
                            Val Loss: 0.1323, Val Acc: 0.1322, Test MAE: nan
2023-01-20 19:16:05,860:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 40/1000
2023-01-20 19:29:04,022:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 778.16s, LR: 0.00070, Train Loss: 0.1169, Train MAE: 0.1169,
                            Val Loss: 0.1214, Val Acc: 0.1212, Test MAE: nan
2023-01-20 19:29:04,127:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 41/1000
2023-01-20 19:41:22,440:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 738.31s, LR: 0.00070, Train Loss: 0.1172, Train MAE: 0.1172,
                            Val Loss: 0.1234, Val Acc: 0.1232, Test MAE: nan
2023-01-20 19:41:22,475:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 42/1000
2023-01-20 19:53:42,616:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 740.14s, LR: 0.00070, Train Loss: 0.1162, Train MAE: 0.1162,
                            Val Loss: 0.1489, Val Acc: 0.1488, Test MAE: nan
2023-01-20 19:53:42,673:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 43/1000
2023-01-20 20:06:02,487:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 739.81s, LR: 0.00070, Train Loss: 0.1154, Train MAE: 0.1154,
                            Val Loss: 0.1344, Val Acc: 0.1343, Test MAE: nan
2023-01-20 20:06:02,571:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 44/1000
2023-01-20 20:18:15,731:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 733.16s, LR: 0.00070, Train Loss: 0.1145, Train MAE: 0.1145,
                            Val Loss: 0.1233, Val Acc: 0.1231, Test MAE: nan
2023-01-20 20:18:15,769:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 45/1000
2023-01-20 20:30:34,737:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 738.97s, LR: 0.00070, Train Loss: 0.1147, Train MAE: 0.1147,
                            Val Loss: 0.1350, Val Acc: 0.1348, Test MAE: nan
2023-01-20 20:30:34,825:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 46/1000
2023-01-20 20:42:51,219:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 736.39s, LR: 0.00070, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.1249, Val Acc: 0.1248, Test MAE: nan
2023-01-20 20:42:51,365:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 47/1000
2023-01-20 20:55:08,442:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 737.08s, LR: 0.00070, Train Loss: 0.1134, Train MAE: 0.1134,
                            Val Loss: 0.1211, Val Acc: 0.1209, Test MAE: nan
2023-01-20 20:55:08,463:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 48/1000
2023-01-20 21:07:25,917:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 737.45s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1204, Val Acc: 0.1202, Test MAE: nan
2023-01-20 21:07:25,953:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 49/1000
2023-01-20 21:19:44,113:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 738.16s, LR: 0.00070, Train Loss: 0.1142, Train MAE: 0.1142,
                            Val Loss: 0.1213, Val Acc: 0.1211, Test MAE: nan
2023-01-20 21:19:44,176:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 50/1000
2023-01-20 21:32:08,444:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 744.27s, LR: 0.00070, Train Loss: 0.1124, Train MAE: 0.1124,
                            Val Loss: 0.1222, Val Acc: 0.1220, Test MAE: nan
2023-01-20 21:32:08,466:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 51/1000
2023-01-20 21:45:44,371:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 815.90s, LR: 0.00070, Train Loss: 0.1125, Train MAE: 0.1125,
                            Val Loss: 0.1235, Val Acc: 0.1233, Test MAE: nan
2023-01-20 21:45:44,395:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 52/1000
2023-01-20 21:58:03,780:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 739.38s, LR: 0.00070, Train Loss: 0.1114, Train MAE: 0.1114,
                            Val Loss: 0.1417, Val Acc: 0.1415, Test MAE: nan
2023-01-20 21:58:03,802:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 53/1000
2023-01-20 22:10:29,092:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 745.29s, LR: 0.00070, Train Loss: 0.1119, Train MAE: 0.1119,
                            Val Loss: 0.1206, Val Acc: 0.1204, Test MAE: nan
2023-01-20 22:10:29,108:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 54/1000
2023-01-20 22:22:51,860:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 742.75s, LR: 0.00070, Train Loss: 0.1126, Train MAE: 0.1126,
                            Val Loss: 0.1228, Val Acc: 0.1226, Test MAE: nan
2023-01-20 22:22:51,964:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 55/1000
2023-01-20 22:35:10,548:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 738.58s, LR: 0.00070, Train Loss: 0.1118, Train MAE: 0.1118,
                            Val Loss: 0.1356, Val Acc: 0.1355, Test MAE: nan
2023-01-20 22:35:10,562:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 56/1000
2023-01-20 22:47:18,631:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 728.07s, LR: 0.00070, Train Loss: 0.1102, Train MAE: 0.1102,
                            Val Loss: 0.1201, Val Acc: 0.1199, Test MAE: nan
2023-01-20 22:47:18,761:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 57/1000
2023-01-20 22:59:31,538:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 732.78s, LR: 0.00070, Train Loss: 0.1127, Train MAE: 0.1127,
                            Val Loss: 0.1275, Val Acc: 0.1273, Test MAE: nan
2023-01-20 22:59:31,575:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 58/1000
2023-01-20 23:11:48,418:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 736.84s, LR: 0.00070, Train Loss: 0.1115, Train MAE: 0.1115,
                            Val Loss: 0.1232, Val Acc: 0.1231, Test MAE: nan
2023-01-20 23:11:48,649:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 59/1000
2023-01-20 23:24:03,791:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 735.14s, LR: 0.00070, Train Loss: 0.1099, Train MAE: 0.1099,
                            Val Loss: 0.1161, Val Acc: 0.1160, Test MAE: nan
2023-01-20 23:24:03,885:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 60/1000
2023-01-20 23:36:14,032:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 730.15s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1193, Val Acc: 0.1191, Test MAE: nan
2023-01-20 23:36:14,053:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 61/1000
2023-01-20 23:48:27,230:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 733.18s, LR: 0.00070, Train Loss: 0.1094, Train MAE: 0.1094,
                            Val Loss: 0.1275, Val Acc: 0.1273, Test MAE: nan
2023-01-20 23:48:27,285:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 62/1000
2023-01-21 00:00:41,070:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 733.78s, LR: 0.00070, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.1218, Val Acc: 0.1216, Test MAE: nan
2023-01-21 00:00:41,108:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 63/1000
2023-01-21 00:12:56,417:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 735.31s, LR: 0.00070, Train Loss: 0.1086, Train MAE: 0.1086,
                            Val Loss: 0.1246, Val Acc: 0.1244, Test MAE: nan
2023-01-21 00:12:56,473:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 64/1000
2023-01-21 00:25:16,590:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 740.12s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1304, Val Acc: 0.1302, Test MAE: nan
2023-01-21 00:25:16,662:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 65/1000
2023-01-21 00:37:31,025:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 734.36s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1443, Val Acc: 0.1441, Test MAE: nan
2023-01-21 00:37:31,068:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 66/1000
2023-01-21 00:51:07,726:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 816.66s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1187, Val Acc: 0.1185, Test MAE: nan
2023-01-21 00:51:07,790:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 67/1000
2023-01-21 01:03:20,441:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 732.65s, LR: 0.00070, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.1331, Val Acc: 0.1329, Test MAE: nan
2023-01-21 01:03:20,488:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 68/1000
2023-01-21 01:15:33,883:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 733.35s, LR: 0.00070, Train Loss: 0.1085, Train MAE: 0.1085,
                            Val Loss: 0.1180, Val Acc: 0.1178, Test MAE: nan
2023-01-21 01:15:33,969:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 69/1000
2023-01-21 01:27:48,996:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 735.03s, LR: 0.00070, Train Loss: 0.1073, Train MAE: 0.1073,
                            Val Loss: 0.1217, Val Acc: 0.1215, Test MAE: nan
2023-01-21 01:27:49,051:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 70/1000
2023-01-21 01:40:04,319:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 735.27s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1183, Val Acc: 0.1181, Test MAE: nan
2023-01-21 01:40:04,382:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 71/1000
2023-01-21 01:52:18,134:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 733.71s, LR: 0.00070, Train Loss: 0.1052, Train MAE: 0.1052,
                            Val Loss: 0.1233, Val Acc: 0.1231, Test MAE: nan
2023-01-21 01:52:18,147:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 72/1000
2023-01-21 02:04:32,566:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 734.42s, LR: 0.00070, Train Loss: 0.1052, Train MAE: 0.1052,
                            Val Loss: 0.1206, Val Acc: 0.1205, Test MAE: nan
2023-01-21 02:04:32,712:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 73/1000
2023-01-21 02:16:50,669:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 737.96s, LR: 0.00070, Train Loss: 0.1049, Train MAE: 0.1049,
                            Val Loss: 0.1149, Val Acc: 0.1147, Test MAE: nan
2023-01-21 02:16:50,702:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 74/1000
2023-01-21 02:29:11,036:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 740.28s, LR: 0.00070, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1230, Val Acc: 0.1228, Test MAE: nan
2023-01-21 02:29:11,128:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 75/1000
2023-01-21 02:41:33,955:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 742.82s, LR: 0.00070, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.1396, Val Acc: 0.1394, Test MAE: nan
2023-01-21 02:41:33,989:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 76/1000
2023-01-21 02:53:46,516:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 732.53s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1173, Val Acc: 0.1171, Test MAE: nan
2023-01-21 02:53:46,579:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 77/1000
2023-01-21 03:06:01,955:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 735.38s, LR: 0.00070, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.1244, Val Acc: 0.1242, Test MAE: nan
2023-01-21 03:06:02,002:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 78/1000
2023-01-21 03:18:15,704:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 733.70s, LR: 0.00070, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1189, Val Acc: 0.1187, Test MAE: nan
2023-01-21 03:18:15,717:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 79/1000
2023-01-21 03:30:31,585:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 735.87s, LR: 0.00070, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.1204, Val Acc: 0.1203, Test MAE: nan
2023-01-21 03:30:31,615:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 80/1000
2023-01-21 03:42:48,931:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 737.32s, LR: 0.00070, Train Loss: 0.1032, Train MAE: 0.1032,
                            Val Loss: 0.1140, Val Acc: 0.1139, Test MAE: nan
2023-01-21 03:42:48,963:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 81/1000
2023-01-21 03:56:18,737:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 809.77s, LR: 0.00070, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1159, Val Acc: 0.1157, Test MAE: nan
2023-01-21 03:56:18,776:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 82/1000
2023-01-21 04:08:30,102:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 731.33s, LR: 0.00070, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1185, Val Acc: 0.1183, Test MAE: nan
2023-01-21 04:08:30,116:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 83/1000
2023-01-21 04:20:46,500:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 736.38s, LR: 0.00070, Train Loss: 0.1276, Train MAE: 0.1276,
                            Val Loss: 0.2513, Val Acc: 0.2511, Test MAE: nan
2023-01-21 04:20:46,547:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 84/1000
2023-01-21 04:33:12,841:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 746.29s, LR: 0.00070, Train Loss: 0.1921, Train MAE: 0.1921,
                            Val Loss: 0.2189, Val Acc: 0.2186, Test MAE: nan
2023-01-21 04:33:12,962:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 85/1000
2023-01-21 04:45:28,322:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 735.36s, LR: 0.00070, Train Loss: 0.1760, Train MAE: 0.1760,
                            Val Loss: 0.1651, Val Acc: 0.1649, Test MAE: nan
2023-01-21 04:45:28,527:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 86/1000
2023-01-21 04:57:39,411:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 730.88s, LR: 0.00070, Train Loss: 0.1832, Train MAE: 0.1832,
                            Val Loss: 0.1967, Val Acc: 0.1965, Test MAE: nan
2023-01-21 04:57:39,433:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 87/1000
2023-01-21 05:09:50,843:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 731.41s, LR: 0.00070, Train Loss: 0.1623, Train MAE: 0.1623,
                            Val Loss: 0.1606, Val Acc: 0.1604, Test MAE: nan
2023-01-21 05:09:50,956:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 88/1000
2023-01-21 05:22:04,774:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 733.82s, LR: 0.00070, Train Loss: 0.1560, Train MAE: 0.1560,
                            Val Loss: 0.1773, Val Acc: 0.1771, Test MAE: nan
2023-01-21 05:22:04,937:main_OGB_graph_regression.py:160 -   train_val_pipeline(): Epoch 89/1000
2023-01-21 05:34:17,705:main_OGB_graph_regression.py:202 -   train_val_pipeline(): 	Time: 732.77s, LR: 0.00070, Train Loss: 0.1619, Train MAE: 0.1619,
                            Val Loss: 0.2375, Val Acc: 0.2372, Test MAE: nan
2023-01-21 05:34:17,752:main_OGB_graph_regression.py:229 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-21 05:34:17,752:main_OGB_graph_regression.py:230 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
