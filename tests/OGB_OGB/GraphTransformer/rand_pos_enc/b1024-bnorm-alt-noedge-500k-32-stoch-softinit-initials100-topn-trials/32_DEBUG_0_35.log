2023-01-23 06:46:30,679:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-23 06:46:30,679:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 06:57:15,311:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 06:57:43,116:ogbdata.py:332 -             __init__(): Time taken: 672.4367s
2023-01-23 06:57:43,117:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 06:57:43,117:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 06:57:43,117:ogbdata.py:348 -             __init__(): [I] Data load time: 672.4374s
2023-01-23 06:57:43,117:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 100, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '1', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials/32_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-23 06:57:43,117:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-23 06:57:43,123:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:57:44,369:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:57:44,369:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:57:44,369:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:57:44,384:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 06:57:44,387:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 544241
2023-01-23 06:57:44,388:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-23 06:57:44,388:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:57:44,392:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:57:44,393:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:57:44,393:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:57:44,413:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-23 08:18:20,175:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4835.7872631549835
2023-01-23 08:18:20,263:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-23 08:18:20,263:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-23 08:18:20,272:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-23 08:31:30,586:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8932682871818542
2023-01-23 08:31:30,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 790.32s, LR: 0.00070, Train Loss: 0.5915, Train MAE: 0.5915,
                            Val Loss: 0.8934, Val MAE: 0.8933
2023-01-23 08:31:30,588:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-23 08:42:27,016:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.43s, LR: 0.00070, Train Loss: 0.4224, Train MAE: 0.4224,
                            Val Loss: 1.1943, Val MAE: 1.1940
2023-01-23 08:42:27,018:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-23 08:53:23,040:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.02s, LR: 0.00070, Train Loss: 0.3876, Train MAE: 0.3876,
                            Val Loss: 0.9417, Val MAE: 0.9414
2023-01-23 08:53:23,041:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-23 09:04:18,766:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.72s, LR: 0.00070, Train Loss: 0.3596, Train MAE: 0.3596,
                            Val Loss: 1.2131, Val MAE: 1.2131
2023-01-23 09:04:18,768:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-23 09:15:15,661:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8101648092269897
2023-01-23 09:15:15,663:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.89s, LR: 0.00070, Train Loss: 0.3558, Train MAE: 0.3558,
                            Val Loss: 0.8104, Val MAE: 0.8102
2023-01-23 09:15:15,664:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-23 09:26:12,923:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.26s, LR: 0.00070, Train Loss: 0.3441, Train MAE: 0.3441,
                            Val Loss: 1.4162, Val MAE: 1.4157
2023-01-23 09:26:12,924:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-23 09:37:09,165:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.24s, LR: 0.00070, Train Loss: 0.3336, Train MAE: 0.3336,
                            Val Loss: 1.6357, Val MAE: 1.6355
2023-01-23 09:37:09,167:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-23 09:49:04,309:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.14s, LR: 0.00070, Train Loss: 0.3371, Train MAE: 0.3371,
                            Val Loss: 1.2866, Val MAE: 1.2866
2023-01-23 09:49:04,310:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-23 10:00:02,863:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.55s, LR: 0.00070, Train Loss: 0.3171, Train MAE: 0.3171,
                            Val Loss: 1.2618, Val MAE: 1.2618
2023-01-23 10:00:02,865:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-23 10:11:00,254:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.39s, LR: 0.00070, Train Loss: 0.3175, Train MAE: 0.3175,
                            Val Loss: 1.5906, Val MAE: 1.5904
2023-01-23 10:11:00,255:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-23 10:21:58,304:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.05s, LR: 0.00070, Train Loss: 0.3049, Train MAE: 0.3049,
                            Val Loss: 1.9557, Val MAE: 1.9554
2023-01-23 10:21:58,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-23 10:32:57,197:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.89s, LR: 0.00070, Train Loss: 0.3061, Train MAE: 0.3061,
                            Val Loss: 0.9574, Val MAE: 0.9570
2023-01-23 10:32:57,199:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-23 10:43:54,570:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.6690346598625183
2023-01-23 10:43:54,572:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.37s, LR: 0.00070, Train Loss: 0.3006, Train MAE: 0.3006,
                            Val Loss: 0.6692, Val MAE: 0.6690
2023-01-23 10:43:54,573:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-23 10:54:52,996:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.42s, LR: 0.00070, Train Loss: 0.2973, Train MAE: 0.2973,
                            Val Loss: 1.8771, Val MAE: 1.8764
2023-01-23 10:54:52,997:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-23 11:05:51,309:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.31s, LR: 0.00070, Train Loss: 0.2927, Train MAE: 0.2927,
                            Val Loss: 1.1693, Val MAE: 1.1694
2023-01-23 11:05:51,310:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-23 11:16:48,686:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5384883880615234
2023-01-23 11:16:48,689:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.38s, LR: 0.00070, Train Loss: 0.2824, Train MAE: 0.2824,
                            Val Loss: 0.5388, Val MAE: 0.5385
2023-01-23 11:16:48,690:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-23 11:27:46,547:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.86s, LR: 0.00070, Train Loss: 0.2718, Train MAE: 0.2718,
                            Val Loss: 0.8512, Val MAE: 0.8513
2023-01-23 11:27:46,548:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-23 11:38:44,440:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.40483686327934265
2023-01-23 11:38:44,442:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.89s, LR: 0.00070, Train Loss: 0.2623, Train MAE: 0.2623,
                            Val Loss: 0.4048, Val MAE: 0.4048
2023-01-23 11:38:44,443:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-23 11:49:41,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.42s, LR: 0.00070, Train Loss: 0.2478, Train MAE: 0.2478,
                            Val Loss: 0.5553, Val MAE: 0.5553
2023-01-23 11:49:41,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-23 12:00:39,447:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.58s, LR: 0.00070, Train Loss: 0.2303, Train MAE: 0.2303,
                            Val Loss: 1.6403, Val MAE: 1.6405
2023-01-23 12:00:39,449:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-23 12:11:36,725:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.28s, LR: 0.00070, Train Loss: 0.2272, Train MAE: 0.2272,
                            Val Loss: 1.0592, Val MAE: 1.0590
2023-01-23 12:11:36,726:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-23 12:22:34,678:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.95s, LR: 0.00070, Train Loss: 0.2233, Train MAE: 0.2233,
                            Val Loss: 1.1732, Val MAE: 1.1731
2023-01-23 12:22:34,680:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-23 12:33:32,174:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.49s, LR: 0.00070, Train Loss: 0.2306, Train MAE: 0.2306,
                            Val Loss: 1.2387, Val MAE: 1.2387
2023-01-23 12:33:32,175:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-23 12:45:27,330:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.15s, LR: 0.00070, Train Loss: 0.2857, Train MAE: 0.2857,
                            Val Loss: 0.6256, Val MAE: 0.6258
2023-01-23 12:45:27,332:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-23 12:56:25,029:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3539533019065857
2023-01-23 12:56:25,031:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.70s, LR: 0.00070, Train Loss: 0.2223, Train MAE: 0.2223,
                            Val Loss: 0.3541, Val MAE: 0.3540
2023-01-23 12:56:25,032:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-23 13:07:22,817:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.78s, LR: 0.00070, Train Loss: 0.2073, Train MAE: 0.2073,
                            Val Loss: 1.2220, Val MAE: 1.2213
2023-01-23 13:07:22,819:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-23 13:18:19,479:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.66s, LR: 0.00070, Train Loss: 0.2098, Train MAE: 0.2098,
                            Val Loss: 0.7345, Val MAE: 0.7344
2023-01-23 13:18:19,480:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-23 13:29:18,166:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.68s, LR: 0.00070, Train Loss: 0.2319, Train MAE: 0.2319,
                            Val Loss: 1.4044, Val MAE: 1.4046
2023-01-23 13:29:18,166:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-23 13:40:15,241:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.07s, LR: 0.00070, Train Loss: 0.2026, Train MAE: 0.2026,
                            Val Loss: 0.9883, Val MAE: 0.9885
2023-01-23 13:40:15,242:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-23 13:51:11,630:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.39s, LR: 0.00070, Train Loss: 0.1936, Train MAE: 0.1936,
                            Val Loss: 0.6779, Val MAE: 0.6778
2023-01-23 13:51:11,631:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-23 14:02:11,423:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.79s, LR: 0.00070, Train Loss: 0.2008, Train MAE: 0.2008,
                            Val Loss: 0.5725, Val MAE: 0.5725
2023-01-23 14:02:11,424:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-23 14:13:08,426:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.00s, LR: 0.00070, Train Loss: 0.2307, Train MAE: 0.2307,
                            Val Loss: 0.6847, Val MAE: 0.6846
2023-01-23 14:13:08,427:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-23 14:24:05,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.10s, LR: 0.00070, Train Loss: 0.1957, Train MAE: 0.1957,
                            Val Loss: 0.5012, Val MAE: 0.5011
2023-01-23 14:24:05,525:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-23 14:35:02,977:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.45s, LR: 0.00070, Train Loss: 0.2105, Train MAE: 0.2105,
                            Val Loss: 0.9916, Val MAE: 0.9913
2023-01-23 14:35:02,978:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-23 14:46:00,216:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.24s, LR: 0.00070, Train Loss: 0.1843, Train MAE: 0.1843,
                            Val Loss: 0.6791, Val MAE: 0.6792
2023-01-23 14:46:00,217:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-23 14:56:57,663:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.44s, LR: 0.00070, Train Loss: 0.1954, Train MAE: 0.1954,
                            Val Loss: 0.5110, Val MAE: 0.5109
2023-01-23 14:56:57,664:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-23 15:07:54,621:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.96s, LR: 0.00070, Train Loss: 0.1830, Train MAE: 0.1830,
                            Val Loss: 0.8183, Val MAE: 0.8183
2023-01-23 15:07:54,622:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-23 15:18:52,253:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.63s, LR: 0.00070, Train Loss: 0.1805, Train MAE: 0.1805,
                            Val Loss: 0.6944, Val MAE: 0.6944
2023-01-23 15:18:52,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-23 15:29:49,831:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.58s, LR: 0.00070, Train Loss: 0.1792, Train MAE: 0.1792,
                            Val Loss: 0.8677, Val MAE: 0.8681
2023-01-23 15:29:49,832:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-23 15:40:46,276:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.44s, LR: 0.00070, Train Loss: 0.1764, Train MAE: 0.1764,
                            Val Loss: 0.8937, Val MAE: 0.8938
2023-01-23 15:40:46,277:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-23 15:52:41,199:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.92s, LR: 0.00070, Train Loss: 0.2075, Train MAE: 0.2075,
                            Val Loss: 4.4398, Val MAE: 4.4384
2023-01-23 15:52:41,200:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-23 16:03:40,896:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.70s, LR: 0.00035, Train Loss: 0.2834, Train MAE: 0.2834,
                            Val Loss: 1.1475, Val MAE: 1.1477
2023-01-23 16:03:40,897:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-23 16:14:37,991:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.09s, LR: 0.00035, Train Loss: 0.2218, Train MAE: 0.2218,
                            Val Loss: 0.3590, Val MAE: 0.3591
2023-01-23 16:14:37,992:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-23 16:25:33,710:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3490302562713623
2023-01-23 16:25:33,712:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.72s, LR: 0.00035, Train Loss: 0.1729, Train MAE: 0.1729,
                            Val Loss: 0.3491, Val MAE: 0.3490
2023-01-23 16:25:33,712:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-23 16:36:31,431:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.72s, LR: 0.00035, Train Loss: 0.1650, Train MAE: 0.1650,
                            Val Loss: 0.5423, Val MAE: 0.5424
2023-01-23 16:36:31,432:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-23 16:47:27,292:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.34513935446739197
2023-01-23 16:47:27,330:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.90s, LR: 0.00035, Train Loss: 0.1657, Train MAE: 0.1657,
                            Val Loss: 0.3453, Val MAE: 0.3451
2023-01-23 16:47:27,331:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-23 16:58:15,945:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.61s, LR: 0.00035, Train Loss: 0.1621, Train MAE: 0.1621,
                            Val Loss: 0.3884, Val MAE: 0.3885
2023-01-23 16:58:15,946:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-23 17:09:05,586:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.64s, LR: 0.00035, Train Loss: 0.1614, Train MAE: 0.1614,
                            Val Loss: 1.3276, Val MAE: 1.3280
2023-01-23 17:09:05,587:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-23 17:19:54,273:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.69s, LR: 0.00035, Train Loss: 0.1615, Train MAE: 0.1615,
                            Val Loss: 0.7695, Val MAE: 0.7697
2023-01-23 17:19:54,274:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-23 17:30:43,233:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.96s, LR: 0.00035, Train Loss: 0.1589, Train MAE: 0.1589,
                            Val Loss: 0.6763, Val MAE: 0.6764
2023-01-23 17:30:43,234:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-23 17:41:34,164:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.93s, LR: 0.00035, Train Loss: 0.1567, Train MAE: 0.1567,
                            Val Loss: 0.4950, Val MAE: 0.4949
2023-01-23 17:41:34,165:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-23 17:52:33,800:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.63s, LR: 0.00035, Train Loss: 0.1550, Train MAE: 0.1550,
                            Val Loss: 0.5830, Val MAE: 0.5832
2023-01-23 17:52:33,801:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-23 18:03:33,659:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.86s, LR: 0.00035, Train Loss: 0.1549, Train MAE: 0.1549,
                            Val Loss: 0.7996, Val MAE: 0.7998
2023-01-23 18:03:33,660:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-23 18:14:35,535:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.87s, LR: 0.00035, Train Loss: 0.1540, Train MAE: 0.1540,
                            Val Loss: 0.5590, Val MAE: 0.5591
2023-01-23 18:14:35,536:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-23 18:25:36,580:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.04s, LR: 0.00035, Train Loss: 0.1527, Train MAE: 0.1527,
                            Val Loss: 0.4669, Val MAE: 0.4669
2023-01-23 18:25:36,581:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-23 18:36:36,390:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.81s, LR: 0.00035, Train Loss: 0.1516, Train MAE: 0.1516,
                            Val Loss: 0.6638, Val MAE: 0.6638
2023-01-23 18:36:36,391:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-23 18:47:36,685:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.29s, LR: 0.00035, Train Loss: 0.1509, Train MAE: 0.1509,
                            Val Loss: 0.8675, Val MAE: 0.8674
2023-01-23 18:47:36,686:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-23 18:59:32,173:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.49s, LR: 0.00035, Train Loss: 0.1516, Train MAE: 0.1516,
                            Val Loss: 0.5465, Val MAE: 0.5466
2023-01-23 18:59:32,174:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-23 19:10:32,392:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.22s, LR: 0.00035, Train Loss: 0.1492, Train MAE: 0.1492,
                            Val Loss: 0.7573, Val MAE: 0.7574
2023-01-23 19:10:32,393:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-23 19:21:31,243:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.85s, LR: 0.00035, Train Loss: 0.1486, Train MAE: 0.1486,
                            Val Loss: 0.4877, Val MAE: 0.4877
2023-01-23 19:21:31,244:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-23 19:32:20,443:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.20s, LR: 0.00035, Train Loss: 0.1993, Train MAE: 0.1993,
                            Val Loss: 1.0823, Val MAE: 1.0823
2023-01-23 19:32:20,444:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-23 19:43:10,760:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.31s, LR: 0.00035, Train Loss: 0.4370, Train MAE: 0.4370,
                            Val Loss: 0.6931, Val MAE: 0.6925
2023-01-23 19:43:10,761:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-23 19:53:59,992:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.23s, LR: 0.00017, Train Loss: 0.3719, Train MAE: 0.3719,
                            Val Loss: 0.4323, Val MAE: 0.4322
2023-01-23 19:53:59,993:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-23 20:04:48,400:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.41s, LR: 0.00017, Train Loss: 0.3466, Train MAE: 0.3466,
                            Val Loss: 0.5273, Val MAE: 0.5271
2023-01-23 20:04:48,401:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-23 20:15:37,857:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.45s, LR: 0.00017, Train Loss: 0.3208, Train MAE: 0.3208,
                            Val Loss: 0.4744, Val MAE: 0.4743
2023-01-23 20:15:37,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-23 20:26:26,654:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.80s, LR: 0.00017, Train Loss: 0.3046, Train MAE: 0.3046,
                            Val Loss: 0.5214, Val MAE: 0.5214
2023-01-23 20:26:26,655:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-23 20:37:15,432:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.78s, LR: 0.00017, Train Loss: 0.2900, Train MAE: 0.2900,
                            Val Loss: 0.3515, Val MAE: 0.3512
2023-01-23 20:37:15,434:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-23 20:48:04,742:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.34486496448516846
2023-01-23 20:48:04,743:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.31s, LR: 0.00017, Train Loss: 0.2782, Train MAE: 0.2782,
                            Val Loss: 0.3452, Val MAE: 0.3449
2023-01-23 20:48:04,744:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-23 20:58:54,289:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.54s, LR: 0.00017, Train Loss: 0.2691, Train MAE: 0.2691,
                            Val Loss: 0.3571, Val MAE: 0.3569
2023-01-23 20:58:54,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-23 21:09:42,982:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.69s, LR: 0.00017, Train Loss: 0.2601, Train MAE: 0.2601,
                            Val Loss: 0.3734, Val MAE: 0.3732
2023-01-23 21:09:42,983:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-23 21:20:31,311:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.33s, LR: 0.00017, Train Loss: 0.2529, Train MAE: 0.2529,
                            Val Loss: 0.3567, Val MAE: 0.3565
2023-01-23 21:20:31,312:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-23 21:31:20,447:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.13s, LR: 0.00017, Train Loss: 0.2473, Train MAE: 0.2473,
                            Val Loss: 0.6128, Val MAE: 0.6128
2023-01-23 21:31:20,449:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-23 21:42:09,905:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.46s, LR: 0.00017, Train Loss: 0.2430, Train MAE: 0.2430,
                            Val Loss: 0.5185, Val MAE: 0.5184
2023-01-23 21:42:09,906:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-23 21:52:58,878:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.97s, LR: 0.00017, Train Loss: 0.2444, Train MAE: 0.2444,
                            Val Loss: 0.4151, Val MAE: 0.4148
2023-01-23 21:52:58,879:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-23 22:04:41,702:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.82s, LR: 0.00017, Train Loss: 0.2372, Train MAE: 0.2372,
                            Val Loss: 0.5145, Val MAE: 0.5146
2023-01-23 22:04:41,703:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-23 22:15:31,194:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.49s, LR: 0.00017, Train Loss: 0.2320, Train MAE: 0.2320,
                            Val Loss: 0.5737, Val MAE: 0.5735
2023-01-23 22:15:31,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-23 22:26:19,298:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.10s, LR: 0.00017, Train Loss: 0.2266, Train MAE: 0.2266,
                            Val Loss: 0.5398, Val MAE: 0.5398
2023-01-23 22:26:19,299:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-23 22:37:07,973:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.67s, LR: 0.00017, Train Loss: 0.2246, Train MAE: 0.2246,
                            Val Loss: 0.5851, Val MAE: 0.5851
2023-01-23 22:37:07,974:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-23 22:47:57,521:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.55s, LR: 0.00017, Train Loss: 0.2198, Train MAE: 0.2198,
                            Val Loss: 0.4438, Val MAE: 0.4435
2023-01-23 22:47:57,522:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-23 22:58:47,435:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.91s, LR: 0.00017, Train Loss: 0.2160, Train MAE: 0.2160,
                            Val Loss: 0.6014, Val MAE: 0.6015
2023-01-23 22:58:47,436:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-23 23:09:36,192:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.76s, LR: 0.00017, Train Loss: 0.2138, Train MAE: 0.2138,
                            Val Loss: 0.6162, Val MAE: 0.6162
2023-01-23 23:09:36,193:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-23 23:20:24,845:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.65s, LR: 0.00017, Train Loss: 0.2109, Train MAE: 0.2109,
                            Val Loss: 0.5331, Val MAE: 0.5331
2023-01-23 23:20:24,846:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-23 23:31:14,701:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.85s, LR: 0.00017, Train Loss: 0.2112, Train MAE: 0.2112,
                            Val Loss: 0.6823, Val MAE: 0.6819
2023-01-23 23:31:14,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-23 23:42:04,128:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.43s, LR: 0.00017, Train Loss: 0.2142, Train MAE: 0.2142,
                            Val Loss: 0.4443, Val MAE: 0.4444
2023-01-23 23:42:04,129:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-23 23:52:53,450:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.32s, LR: 0.00009, Train Loss: 0.2003, Train MAE: 0.2003,
                            Val Loss: 0.7575, Val MAE: 0.7578
2023-01-23 23:52:53,451:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-24 00:03:42,982:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.53s, LR: 0.00009, Train Loss: 0.1979, Train MAE: 0.1979,
                            Val Loss: 0.5076, Val MAE: 0.5072
2023-01-24 00:03:42,984:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-24 00:14:32,402:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2974819839000702
2023-01-24 00:14:32,404:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.42s, LR: 0.00009, Train Loss: 0.1964, Train MAE: 0.1964,
                            Val Loss: 0.2975, Val MAE: 0.2975
2023-01-24 00:14:32,404:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-24 00:25:20,895:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.49s, LR: 0.00009, Train Loss: 0.1956, Train MAE: 0.1956,
                            Val Loss: 0.5655, Val MAE: 0.5657
2023-01-24 00:25:20,896:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-24 00:36:10,024:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.13s, LR: 0.00009, Train Loss: 0.1940, Train MAE: 0.1940,
                            Val Loss: 0.4299, Val MAE: 0.4295
2023-01-24 00:36:10,025:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-24 00:46:59,970:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.94s, LR: 0.00009, Train Loss: 0.1928, Train MAE: 0.1928,
                            Val Loss: 0.6070, Val MAE: 0.6072
2023-01-24 00:46:59,971:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-24 00:57:49,130:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.16s, LR: 0.00009, Train Loss: 0.1924, Train MAE: 0.1924,
                            Val Loss: 0.5651, Val MAE: 0.5653
2023-01-24 00:57:49,131:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-24 01:09:32,497:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2360302060842514
2023-01-24 01:09:32,499:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.37s, LR: 0.00009, Train Loss: 0.1908, Train MAE: 0.1908,
                            Val Loss: 0.2362, Val MAE: 0.2360
2023-01-24 01:09:32,499:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-24 01:20:21,232:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.73s, LR: 0.00009, Train Loss: 0.1900, Train MAE: 0.1900,
                            Val Loss: 0.5165, Val MAE: 0.5166
2023-01-24 01:20:21,232:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-24 01:31:10,835:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.60s, LR: 0.00009, Train Loss: 0.1926, Train MAE: 0.1926,
                            Val Loss: 0.3044, Val MAE: 0.3042
2023-01-24 01:31:10,835:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-24 01:41:59,701:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.86s, LR: 0.00009, Train Loss: 0.1910, Train MAE: 0.1910,
                            Val Loss: 0.5389, Val MAE: 0.5385
2023-01-24 01:41:59,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-24 01:52:48,599:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.90s, LR: 0.00009, Train Loss: 0.1901, Train MAE: 0.1901,
                            Val Loss: 0.2547, Val MAE: 0.2544
2023-01-24 01:52:48,600:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-24 02:03:38,426:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.83s, LR: 0.00009, Train Loss: 0.1894, Train MAE: 0.1894,
                            Val Loss: 0.4179, Val MAE: 0.4175
2023-01-24 02:03:38,427:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-24 02:14:27,575:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.15s, LR: 0.00009, Train Loss: 0.1879, Train MAE: 0.1879,
                            Val Loss: 0.3469, Val MAE: 0.3469
2023-01-24 02:14:27,576:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-24 02:25:16,053:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.48s, LR: 0.00009, Train Loss: 0.1866, Train MAE: 0.1866,
                            Val Loss: 0.3949, Val MAE: 0.3947
2023-01-24 02:25:16,054:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-24 02:36:04,697:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.64s, LR: 0.00009, Train Loss: 0.1862, Train MAE: 0.1862,
                            Val Loss: 0.2661, Val MAE: 0.2658
2023-01-24 02:36:04,699:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-24 02:46:54,976:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.28s, LR: 0.00009, Train Loss: 0.1853, Train MAE: 0.1853,
                            Val Loss: 0.5647, Val MAE: 0.5648
2023-01-24 02:46:54,977:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-24 02:57:43,731:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.75s, LR: 0.00009, Train Loss: 0.1855, Train MAE: 0.1855,
                            Val Loss: 0.3727, Val MAE: 0.3727
2023-01-24 02:57:43,732:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-24 03:08:32,543:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.81s, LR: 0.00009, Train Loss: 0.1836, Train MAE: 0.1836,
                            Val Loss: 0.5677, Val MAE: 0.5678
2023-01-24 03:08:32,544:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-24 03:19:21,210:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.66s, LR: 0.00009, Train Loss: 0.1826, Train MAE: 0.1826,
                            Val Loss: 0.3851, Val MAE: 0.3851
2023-01-24 03:19:21,211:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-24 03:30:10,580:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.37s, LR: 0.00009, Train Loss: 0.1830, Train MAE: 0.1830,
                            Val Loss: 0.3050, Val MAE: 0.3048
2023-01-24 03:30:10,581:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-24 03:40:59,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.12s, LR: 0.00009, Train Loss: 0.1813, Train MAE: 0.1813,
                            Val Loss: 0.2499, Val MAE: 0.2497
2023-01-24 03:40:59,701:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-24 03:51:48,664:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.96s, LR: 0.00009, Train Loss: 0.1808, Train MAE: 0.1808,
                            Val Loss: 0.5537, Val MAE: 0.5539
2023-01-24 03:51:48,665:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-24 04:02:38,220:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.55s, LR: 0.00009, Train Loss: 0.1812, Train MAE: 0.1812,
                            Val Loss: 0.2543, Val MAE: 0.2541
2023-01-24 04:02:38,221:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-24 04:14:21,472:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.21001356840133667
2023-01-24 04:14:21,474:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.25s, LR: 0.00004, Train Loss: 0.1775, Train MAE: 0.1775,
                            Val Loss: 0.2102, Val MAE: 0.2100
2023-01-24 04:14:21,475:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-24 04:25:10,144:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.67s, LR: 0.00004, Train Loss: 0.1767, Train MAE: 0.1767,
                            Val Loss: 0.3874, Val MAE: 0.3874
2023-01-24 04:25:10,145:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-24 04:35:58,341:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.19s, LR: 0.00004, Train Loss: 0.1765, Train MAE: 0.1765,
                            Val Loss: 0.2756, Val MAE: 0.2754
2023-01-24 04:35:58,342:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-24 04:46:48,129:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.79s, LR: 0.00004, Train Loss: 0.1758, Train MAE: 0.1758,
                            Val Loss: 0.2306, Val MAE: 0.2305
2023-01-24 04:46:48,130:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-24 04:57:36,941:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.81s, LR: 0.00004, Train Loss: 0.1751, Train MAE: 0.1751,
                            Val Loss: 0.3543, Val MAE: 0.3540
2023-01-24 04:57:36,943:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-24 05:08:25,450:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.51s, LR: 0.00004, Train Loss: 0.1748, Train MAE: 0.1748,
                            Val Loss: 0.2186, Val MAE: 0.2184
2023-01-24 05:08:25,451:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-24 05:19:14,093:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.64s, LR: 0.00004, Train Loss: 0.1745, Train MAE: 0.1745,
                            Val Loss: 0.2534, Val MAE: 0.2532
2023-01-24 05:19:14,094:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-24 05:30:03,100:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.01s, LR: 0.00004, Train Loss: 0.1743, Train MAE: 0.1743,
                            Val Loss: 0.2409, Val MAE: 0.2407
2023-01-24 05:30:03,102:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-24 05:40:51,201:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.10s, LR: 0.00004, Train Loss: 0.1739, Train MAE: 0.1739,
                            Val Loss: 0.4543, Val MAE: 0.4544
2023-01-24 05:40:51,202:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-24 05:51:39,566:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.36s, LR: 0.00004, Train Loss: 0.1735, Train MAE: 0.1735,
                            Val Loss: 0.3613, Val MAE: 0.3611
2023-01-24 05:51:39,567:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-24 06:02:28,290:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.72s, LR: 0.00004, Train Loss: 0.1731, Train MAE: 0.1731,
                            Val Loss: 0.2912, Val MAE: 0.2909
2023-01-24 06:02:28,291:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-24 06:13:15,989:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.70s, LR: 0.00004, Train Loss: 0.1734, Train MAE: 0.1734,
                            Val Loss: 0.2567, Val MAE: 0.2565
2023-01-24 06:13:15,990:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-24 06:24:03,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.39s, LR: 0.00004, Train Loss: 0.1729, Train MAE: 0.1729,
                            Val Loss: 0.2859, Val MAE: 0.2857
2023-01-24 06:24:03,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-24 06:34:50,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.31s, LR: 0.00004, Train Loss: 0.1725, Train MAE: 0.1725,
                            Val Loss: 0.5557, Val MAE: 0.5559
2023-01-24 06:34:50,701:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-24 06:45:39,461:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.76s, LR: 0.00004, Train Loss: 0.1722, Train MAE: 0.1722,
                            Val Loss: 0.3034, Val MAE: 0.3031
2023-01-24 06:45:39,463:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-24 06:56:27,893:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.43s, LR: 0.00004, Train Loss: 0.1718, Train MAE: 0.1718,
                            Val Loss: 0.3667, Val MAE: 0.3664
2023-01-24 06:56:27,894:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-24 07:08:10,742:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.85s, LR: 0.00004, Train Loss: 0.1715, Train MAE: 0.1715,
                            Val Loss: 0.4525, Val MAE: 0.4525
2023-01-24 07:08:10,743:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-24 07:08:10,744:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-24 07:15:28,242:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.4525
2023-01-24 07:15:28,243:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.4056
2023-01-24 07:15:28,245:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-24 07:15:28,246:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 124.0000
2023-01-24 07:15:28,247:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87463.8589s
2023-01-24 07:15:28,248:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 657.5232s
2023-01-24 07:15:28,274:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-24 07:15:28,510:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.4056)]
2023-01-24 07:15:28,510:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.4525)]
