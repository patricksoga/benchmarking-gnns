2023-01-23 06:46:33,192:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-23 06:46:33,192:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 06:58:24,990:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 06:58:54,074:ogbdata.py:332 -             __init__(): Time taken: 740.8814s
2023-01-23 06:58:54,074:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 06:58:54,074:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 06:58:54,074:ogbdata.py:348 -             __init__(): [I] Data load time: 740.8819s
2023-01-23 06:58:54,074:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 100, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '1', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials/32_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-23 06:58:54,074:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-23 06:58:54,076:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:58:56,111:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:58:56,111:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:58:56,111:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:58:56,126:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 06:58:56,130:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 544241
2023-01-23 06:58:56,130:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-23 06:58:56,131:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:58:56,135:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:58:56,135:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:58:56,135:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:58:56,156:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-23 08:20:53,545:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4917.414363384247
2023-01-23 08:20:53,571:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-23 08:20:53,571:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-23 08:20:53,596:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-23 08:33:46,084:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 3.611938238143921
2023-01-23 08:33:46,086:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.49s, LR: 0.00070, Train Loss: 0.6491, Train MAE: 0.6491,
                            Val Loss: 3.6133, Val MAE: 3.6119
2023-01-23 08:33:46,086:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-23 08:44:26,262:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.6237876415252686
2023-01-23 08:44:26,264:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.18s, LR: 0.00070, Train Loss: 0.4280, Train MAE: 0.4280,
                            Val Loss: 1.6239, Val MAE: 1.6238
2023-01-23 08:44:26,264:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-23 08:55:02,885:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.0915977954864502
2023-01-23 08:55:02,887:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.62s, LR: 0.00070, Train Loss: 0.4439, Train MAE: 0.4439,
                            Val Loss: 1.0919, Val MAE: 1.0916
2023-01-23 08:55:02,888:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-23 09:05:31,291:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.40s, LR: 0.00070, Train Loss: 0.4429, Train MAE: 0.4429,
                            Val Loss: 1.8850, Val MAE: 1.8846
2023-01-23 09:05:31,293:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-23 09:15:59,186:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 627.89s, LR: 0.00070, Train Loss: 0.4062, Train MAE: 0.4062,
                            Val Loss: 1.1031, Val MAE: 1.1030
2023-01-23 09:15:59,188:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-23 09:26:27,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.26s, LR: 0.00070, Train Loss: 0.4285, Train MAE: 0.4285,
                            Val Loss: 1.5104, Val MAE: 1.5099
2023-01-23 09:26:27,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-23 09:36:54,613:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 627.17s, LR: 0.00070, Train Loss: 0.3918, Train MAE: 0.3918,
                            Val Loss: 1.2417, Val MAE: 1.2418
2023-01-23 09:36:54,614:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-23 09:48:12,600:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.98s, LR: 0.00070, Train Loss: 0.4295, Train MAE: 0.4295,
                            Val Loss: 1.5060, Val MAE: 1.5056
2023-01-23 09:48:12,601:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-23 09:58:42,535:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.7723411321640015
2023-01-23 09:58:42,537:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.94s, LR: 0.00070, Train Loss: 0.3936, Train MAE: 0.3936,
                            Val Loss: 0.7725, Val MAE: 0.7723
2023-01-23 09:58:42,538:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-23 10:09:10,762:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.22s, LR: 0.00070, Train Loss: 0.3954, Train MAE: 0.3954,
                            Val Loss: 0.9255, Val MAE: 0.9252
2023-01-23 10:09:10,764:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-23 10:19:39,282:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.52s, LR: 0.00070, Train Loss: 0.3772, Train MAE: 0.3772,
                            Val Loss: 1.2136, Val MAE: 1.2133
2023-01-23 10:19:39,283:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-23 10:30:06,150:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 626.87s, LR: 0.00070, Train Loss: 0.3703, Train MAE: 0.3703,
                            Val Loss: 1.3870, Val MAE: 1.3865
2023-01-23 10:30:06,151:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-23 10:40:31,756:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 625.60s, LR: 0.00070, Train Loss: 0.3570, Train MAE: 0.3570,
                            Val Loss: 1.4471, Val MAE: 1.4467
2023-01-23 10:40:31,757:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-23 10:51:00,740:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.98s, LR: 0.00070, Train Loss: 0.3542, Train MAE: 0.3542,
                            Val Loss: 1.3519, Val MAE: 1.3515
2023-01-23 10:51:00,741:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-23 11:01:23,565:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.7482715845108032
2023-01-23 11:01:23,567:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 622.83s, LR: 0.00070, Train Loss: 0.3592, Train MAE: 0.3592,
                            Val Loss: 0.7484, Val MAE: 0.7483
2023-01-23 11:01:23,568:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-23 11:11:49,391:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 625.82s, LR: 0.00070, Train Loss: 0.3601, Train MAE: 0.3601,
                            Val Loss: 1.2998, Val MAE: 1.2995
2023-01-23 11:11:49,392:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-23 11:22:14,684:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 625.29s, LR: 0.00070, Train Loss: 0.3597, Train MAE: 0.3597,
                            Val Loss: 1.2133, Val MAE: 1.2130
2023-01-23 11:22:14,685:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-23 11:32:33,804:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 619.12s, LR: 0.00070, Train Loss: 0.3854, Train MAE: 0.3854,
                            Val Loss: 0.8837, Val MAE: 0.8833
2023-01-23 11:32:33,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-23 11:42:51,183:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 617.38s, LR: 0.00070, Train Loss: 0.3464, Train MAE: 0.3464,
                            Val Loss: 1.0160, Val MAE: 1.0156
2023-01-23 11:42:51,183:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-23 11:53:09,416:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 618.23s, LR: 0.00070, Train Loss: 0.3365, Train MAE: 0.3365,
                            Val Loss: 1.6901, Val MAE: 1.6892
2023-01-23 11:53:09,417:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-23 12:03:27,671:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 618.25s, LR: 0.00070, Train Loss: 0.4136, Train MAE: 0.4136,
                            Val Loss: 0.9457, Val MAE: 0.9455
2023-01-23 12:03:27,673:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-23 12:13:45,800:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 618.13s, LR: 0.00070, Train Loss: 0.4296, Train MAE: 0.4296,
                            Val Loss: 1.9848, Val MAE: 1.9840
2023-01-23 12:13:45,801:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-23 12:24:05,575:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 619.77s, LR: 0.00070, Train Loss: 0.3994, Train MAE: 0.3994,
                            Val Loss: 0.7656, Val MAE: 0.7654
2023-01-23 12:24:05,576:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-23 12:35:11,581:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.00s, LR: 0.00070, Train Loss: 0.3873, Train MAE: 0.3873,
                            Val Loss: 1.3328, Val MAE: 1.3326
2023-01-23 12:35:11,582:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-23 12:45:26,376:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 614.79s, LR: 0.00070, Train Loss: 0.3835, Train MAE: 0.3835,
                            Val Loss: 0.9102, Val MAE: 0.9101
2023-01-23 12:45:26,377:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-23 12:55:40,966:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 614.59s, LR: 0.00070, Train Loss: 0.3628, Train MAE: 0.3628,
                            Val Loss: 2.2662, Val MAE: 2.2653
2023-01-23 12:55:40,967:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-23 13:05:56,392:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 615.42s, LR: 0.00070, Train Loss: 0.3473, Train MAE: 0.3473,
                            Val Loss: 0.7528, Val MAE: 0.7525
2023-01-23 13:05:56,393:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-23 13:16:11,462:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.40383848547935486
2023-01-23 13:16:11,464:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 615.07s, LR: 0.00070, Train Loss: 0.3382, Train MAE: 0.3382,
                            Val Loss: 0.4040, Val MAE: 0.4038
2023-01-23 13:16:11,465:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-23 13:26:27,832:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 616.37s, LR: 0.00070, Train Loss: 0.3359, Train MAE: 0.3359,
                            Val Loss: 1.1852, Val MAE: 1.1847
2023-01-23 13:26:27,833:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-23 13:36:49,296:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 621.46s, LR: 0.00070, Train Loss: 0.3277, Train MAE: 0.3277,
                            Val Loss: 2.0673, Val MAE: 2.0669
2023-01-23 13:36:49,297:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-23 13:47:06,377:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 617.08s, LR: 0.00070, Train Loss: 0.3240, Train MAE: 0.3240,
                            Val Loss: 0.9605, Val MAE: 0.9602
2023-01-23 13:47:06,378:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-23 13:57:18,446:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 612.07s, LR: 0.00070, Train Loss: 0.3204, Train MAE: 0.3204,
                            Val Loss: 0.8746, Val MAE: 0.8743
2023-01-23 13:57:18,447:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-23 14:07:35,280:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 616.83s, LR: 0.00070, Train Loss: 0.3317, Train MAE: 0.3317,
                            Val Loss: 0.8233, Val MAE: 0.8233
2023-01-23 14:07:35,281:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-23 14:17:48,224:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 612.94s, LR: 0.00070, Train Loss: 0.3247, Train MAE: 0.3247,
                            Val Loss: 2.5170, Val MAE: 2.5161
2023-01-23 14:17:48,225:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-23 14:28:03,273:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 615.05s, LR: 0.00070, Train Loss: 0.4363, Train MAE: 0.4363,
                            Val Loss: 1.1590, Val MAE: 1.1588
2023-01-23 14:28:03,274:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-23 14:38:23,345:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 620.07s, LR: 0.00070, Train Loss: 0.4863, Train MAE: 0.4863,
                            Val Loss: 1.3930, Val MAE: 1.3926
2023-01-23 14:38:23,346:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-23 14:48:42,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 619.38s, LR: 0.00070, Train Loss: 0.4178, Train MAE: 0.4178,
                            Val Loss: 1.0246, Val MAE: 1.0245
2023-01-23 14:48:42,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-23 14:58:59,625:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 616.89s, LR: 0.00070, Train Loss: 0.3896, Train MAE: 0.3896,
                            Val Loss: 1.8211, Val MAE: 1.8209
2023-01-23 14:58:59,626:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-23 15:09:16,856:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 617.23s, LR: 0.00070, Train Loss: 0.3695, Train MAE: 0.3695,
                            Val Loss: 2.2327, Val MAE: 2.2319
2023-01-23 15:09:16,857:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-23 15:19:31,466:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 614.61s, LR: 0.00070, Train Loss: 0.3562, Train MAE: 0.3562,
                            Val Loss: 1.5086, Val MAE: 1.5083
2023-01-23 15:19:31,467:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-23 15:30:30,505:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.04s, LR: 0.00070, Train Loss: 0.3465, Train MAE: 0.3465,
                            Val Loss: 1.2709, Val MAE: 1.2711
2023-01-23 15:30:30,507:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-23 15:40:45,066:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 614.56s, LR: 0.00070, Train Loss: 0.3448, Train MAE: 0.3448,
                            Val Loss: 0.5426, Val MAE: 0.5424
2023-01-23 15:40:45,067:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-23 15:50:54,335:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 609.27s, LR: 0.00070, Train Loss: 0.3414, Train MAE: 0.3414,
                            Val Loss: 0.6472, Val MAE: 0.6471
2023-01-23 15:50:54,335:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-23 16:01:07,903:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 613.57s, LR: 0.00070, Train Loss: 0.3387, Train MAE: 0.3387,
                            Val Loss: 0.8675, Val MAE: 0.8672
2023-01-23 16:01:07,904:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-23 16:11:17,970:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 610.06s, LR: 0.00035, Train Loss: 0.3260, Train MAE: 0.3260,
                            Val Loss: 0.5953, Val MAE: 0.5952
2023-01-23 16:11:17,971:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-23 16:21:35,081:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 617.11s, LR: 0.00035, Train Loss: 0.3205, Train MAE: 0.3205,
                            Val Loss: 0.4889, Val MAE: 0.4888
2023-01-23 16:21:35,082:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-23 16:31:51,318:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 616.24s, LR: 0.00035, Train Loss: 0.3163, Train MAE: 0.3163,
                            Val Loss: 0.8586, Val MAE: 0.8582
2023-01-23 16:31:51,319:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-23 16:42:03,821:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 612.50s, LR: 0.00035, Train Loss: 0.3113, Train MAE: 0.3113,
                            Val Loss: 0.7773, Val MAE: 0.7774
2023-01-23 16:42:03,822:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-23 16:52:25,110:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 621.29s, LR: 0.00035, Train Loss: 0.3150, Train MAE: 0.3150,
                            Val Loss: 2.1964, Val MAE: 2.1956
2023-01-23 16:52:25,130:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-23 17:04:09,366:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 704.22s, LR: 0.00035, Train Loss: 0.3113, Train MAE: 0.3113,
                            Val Loss: 0.8072, Val MAE: 0.8072
2023-01-23 17:04:09,413:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-23 17:14:20,692:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 611.28s, LR: 0.00035, Train Loss: 0.3049, Train MAE: 0.3049,
                            Val Loss: 0.6755, Val MAE: 0.6751
2023-01-23 17:14:20,692:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-23 17:24:27,463:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 606.77s, LR: 0.00035, Train Loss: 0.3013, Train MAE: 0.3013,
                            Val Loss: 1.0003, Val MAE: 1.0002
2023-01-23 17:24:27,464:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-23 17:34:28,868:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 601.40s, LR: 0.00035, Train Loss: 0.3004, Train MAE: 0.3004,
                            Val Loss: 1.0270, Val MAE: 1.0271
2023-01-23 17:34:28,869:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-23 17:44:30,838:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 601.97s, LR: 0.00035, Train Loss: 0.2985, Train MAE: 0.2985,
                            Val Loss: 0.6980, Val MAE: 0.6976
2023-01-23 17:44:30,838:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-23 17:54:32,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 601.89s, LR: 0.00035, Train Loss: 0.2951, Train MAE: 0.2951,
                            Val Loss: 0.5696, Val MAE: 0.5694
2023-01-23 17:54:32,728:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-23 18:04:34,239:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 601.51s, LR: 0.00035, Train Loss: 0.2966, Train MAE: 0.2966,
                            Val Loss: 0.7975, Val MAE: 0.7971
2023-01-23 18:04:34,240:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-23 18:14:39,120:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 604.88s, LR: 0.00035, Train Loss: 0.2964, Train MAE: 0.2964,
                            Val Loss: 0.4543, Val MAE: 0.4541
2023-01-23 18:14:39,121:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-23 18:25:28,115:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.99s, LR: 0.00035, Train Loss: 0.2951, Train MAE: 0.2951,
                            Val Loss: 0.4756, Val MAE: 0.4753
2023-01-23 18:25:28,116:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-23 18:35:28,617:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 600.50s, LR: 0.00035, Train Loss: 0.2884, Train MAE: 0.2884,
                            Val Loss: 0.7043, Val MAE: 0.7041
2023-01-23 18:35:28,618:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-23 18:45:33,277:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 604.66s, LR: 0.00035, Train Loss: 0.2801, Train MAE: 0.2801,
                            Val Loss: 0.6241, Val MAE: 0.6237
2023-01-23 18:45:33,278:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-23 18:55:40,936:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.39733657240867615
2023-01-23 18:55:40,938:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 607.66s, LR: 0.00017, Train Loss: 0.2647, Train MAE: 0.2647,
                            Val Loss: 0.3976, Val MAE: 0.3973
2023-01-23 18:55:40,938:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-23 19:05:44,442:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 603.50s, LR: 0.00017, Train Loss: 0.2588, Train MAE: 0.2588,
                            Val Loss: 0.4371, Val MAE: 0.4368
2023-01-23 19:05:44,443:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-23 19:15:50,989:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 606.55s, LR: 0.00017, Train Loss: 0.2543, Train MAE: 0.2543,
                            Val Loss: 0.5396, Val MAE: 0.5393
2023-01-23 19:15:50,990:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-23 19:25:50,367:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3380691707134247
2023-01-23 19:25:50,368:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 599.38s, LR: 0.00017, Train Loss: 0.2529, Train MAE: 0.2529,
                            Val Loss: 0.3382, Val MAE: 0.3381
2023-01-23 19:25:50,369:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-23 19:35:56,166:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3202868700027466
2023-01-23 19:35:56,168:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 605.80s, LR: 0.00017, Train Loss: 0.2510, Train MAE: 0.2510,
                            Val Loss: 0.3205, Val MAE: 0.3203
2023-01-23 19:35:56,168:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-23 19:45:59,186:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 603.02s, LR: 0.00017, Train Loss: 0.2465, Train MAE: 0.2465,
                            Val Loss: 0.5435, Val MAE: 0.5436
2023-01-23 19:45:59,188:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-23 19:56:03,289:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 604.10s, LR: 0.00017, Train Loss: 0.2436, Train MAE: 0.2436,
                            Val Loss: 0.8723, Val MAE: 0.8722
2023-01-23 19:56:03,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-23 20:06:01,262:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 597.97s, LR: 0.00017, Train Loss: 0.2463, Train MAE: 0.2463,
                            Val Loss: 0.5657, Val MAE: 0.5658
2023-01-23 20:06:01,262:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-23 20:15:59,697:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 598.43s, LR: 0.00017, Train Loss: 0.2443, Train MAE: 0.2443,
                            Val Loss: 0.3893, Val MAE: 0.3891
2023-01-23 20:15:59,698:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-23 20:26:03,202:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3178410232067108
2023-01-23 20:26:03,204:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 603.50s, LR: 0.00017, Train Loss: 0.2444, Train MAE: 0.2444,
                            Val Loss: 0.3180, Val MAE: 0.3178
2023-01-23 20:26:03,204:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-23 20:36:00,789:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 597.58s, LR: 0.00017, Train Loss: 0.2397, Train MAE: 0.2397,
                            Val Loss: 0.3522, Val MAE: 0.3521
2023-01-23 20:36:00,790:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-23 20:45:57,331:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 596.54s, LR: 0.00017, Train Loss: 0.2372, Train MAE: 0.2372,
                            Val Loss: 0.8035, Val MAE: 0.8037
2023-01-23 20:45:57,333:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-23 20:55:54,205:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 596.87s, LR: 0.00017, Train Loss: 0.2339, Train MAE: 0.2339,
                            Val Loss: 0.3549, Val MAE: 0.3548
2023-01-23 20:55:54,206:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-23 21:05:49,653:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 595.45s, LR: 0.00017, Train Loss: 0.2327, Train MAE: 0.2327,
                            Val Loss: 0.6463, Val MAE: 0.6463
2023-01-23 21:05:49,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-23 21:16:30,743:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.09s, LR: 0.00017, Train Loss: 0.2305, Train MAE: 0.2305,
                            Val Loss: 0.9357, Val MAE: 0.9357
2023-01-23 21:16:30,743:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-23 21:26:26,434:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 595.69s, LR: 0.00017, Train Loss: 0.2316, Train MAE: 0.2316,
                            Val Loss: 0.5045, Val MAE: 0.5043
2023-01-23 21:26:26,435:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-23 21:36:28,405:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 601.97s, LR: 0.00017, Train Loss: 0.2270, Train MAE: 0.2270,
                            Val Loss: 0.5027, Val MAE: 0.5028
2023-01-23 21:36:28,406:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-23 21:46:30,483:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 602.08s, LR: 0.00017, Train Loss: 0.2275, Train MAE: 0.2275,
                            Val Loss: 0.5376, Val MAE: 0.5376
2023-01-23 21:46:30,484:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-23 21:56:29,019:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 598.53s, LR: 0.00017, Train Loss: 0.2531, Train MAE: 0.2531,
                            Val Loss: 0.4844, Val MAE: 0.4842
2023-01-23 21:56:29,020:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-23 22:06:23,227:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 594.21s, LR: 0.00017, Train Loss: 0.2608, Train MAE: 0.2608,
                            Val Loss: 0.3842, Val MAE: 0.3841
2023-01-23 22:06:23,228:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-23 22:16:18,311:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 595.08s, LR: 0.00017, Train Loss: 0.2323, Train MAE: 0.2323,
                            Val Loss: 0.5166, Val MAE: 0.5167
2023-01-23 22:16:18,312:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-23 22:26:14,062:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 595.75s, LR: 0.00017, Train Loss: 0.2266, Train MAE: 0.2266,
                            Val Loss: 0.5927, Val MAE: 0.5929
2023-01-23 22:26:14,063:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-23 22:36:09,009:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 594.94s, LR: 0.00017, Train Loss: 0.2231, Train MAE: 0.2231,
                            Val Loss: 0.6130, Val MAE: 0.6132
2023-01-23 22:36:09,009:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-23 22:46:05,829:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 596.82s, LR: 0.00017, Train Loss: 0.2231, Train MAE: 0.2231,
                            Val Loss: 0.3970, Val MAE: 0.3968
2023-01-23 22:46:05,830:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-23 22:56:03,069:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 597.24s, LR: 0.00017, Train Loss: 0.2204, Train MAE: 0.2204,
                            Val Loss: 0.6610, Val MAE: 0.6611
2023-01-23 22:56:03,071:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-23 23:05:59,458:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 596.39s, LR: 0.00017, Train Loss: 0.2188, Train MAE: 0.2188,
                            Val Loss: 0.4991, Val MAE: 0.4993
2023-01-23 23:05:59,459:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-23 23:15:58,354:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 598.89s, LR: 0.00009, Train Loss: 0.2127, Train MAE: 0.2127,
                            Val Loss: 0.4654, Val MAE: 0.4654
2023-01-23 23:15:58,354:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-23 23:25:57,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 599.12s, LR: 0.00009, Train Loss: 0.2119, Train MAE: 0.2119,
                            Val Loss: 0.3723, Val MAE: 0.3723
2023-01-23 23:25:57,478:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-23 23:35:50,849:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.289896160364151
2023-01-23 23:35:50,850:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 593.37s, LR: 0.00009, Train Loss: 0.2121, Train MAE: 0.2121,
                            Val Loss: 0.2901, Val MAE: 0.2899
2023-01-23 23:35:50,851:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-23 23:45:44,336:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 593.48s, LR: 0.00009, Train Loss: 0.2108, Train MAE: 0.2108,
                            Val Loss: 0.5087, Val MAE: 0.5088
2023-01-23 23:45:44,337:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-23 23:55:40,711:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 596.37s, LR: 0.00009, Train Loss: 0.2124, Train MAE: 0.2124,
                            Val Loss: 0.3705, Val MAE: 0.3704
2023-01-23 23:55:40,712:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-24 00:06:21,175:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.46s, LR: 0.00009, Train Loss: 0.2199, Train MAE: 0.2199,
                            Val Loss: 0.3444, Val MAE: 0.3443
2023-01-24 00:06:21,176:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-24 00:16:20,311:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 599.13s, LR: 0.00009, Train Loss: 0.2171, Train MAE: 0.2171,
                            Val Loss: 0.3792, Val MAE: 0.3789
2023-01-24 00:16:20,312:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-24 00:26:13,166:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 592.85s, LR: 0.00009, Train Loss: 0.2139, Train MAE: 0.2139,
                            Val Loss: 0.3388, Val MAE: 0.3387
2023-01-24 00:26:13,167:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-24 00:36:11,121:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 597.95s, LR: 0.00009, Train Loss: 0.2134, Train MAE: 0.2134,
                            Val Loss: 0.4524, Val MAE: 0.4525
2023-01-24 00:36:11,122:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-24 00:46:08,485:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 597.36s, LR: 0.00009, Train Loss: 0.2124, Train MAE: 0.2124,
                            Val Loss: 0.3480, Val MAE: 0.3478
2023-01-24 00:46:08,485:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-24 00:56:00,684:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 592.20s, LR: 0.00009, Train Loss: 0.2107, Train MAE: 0.2107,
                            Val Loss: 0.4527, Val MAE: 0.4526
2023-01-24 00:56:00,684:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-24 01:05:52,579:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 591.89s, LR: 0.00009, Train Loss: 0.2094, Train MAE: 0.2094,
                            Val Loss: 0.3729, Val MAE: 0.3728
2023-01-24 01:05:52,580:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-24 01:15:42,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 590.12s, LR: 0.00009, Train Loss: 0.2084, Train MAE: 0.2084,
                            Val Loss: 0.2938, Val MAE: 0.2937
2023-01-24 01:15:42,701:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-24 01:25:36,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 594.03s, LR: 0.00009, Train Loss: 0.2078, Train MAE: 0.2078,
                            Val Loss: 0.2995, Val MAE: 0.2993
2023-01-24 01:25:36,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-24 01:35:30,385:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 593.66s, LR: 0.00009, Train Loss: 0.2070, Train MAE: 0.2070,
                            Val Loss: 0.6005, Val MAE: 0.6006
2023-01-24 01:35:30,386:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-24 01:45:21,067:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 590.68s, LR: 0.00009, Train Loss: 0.2068, Train MAE: 0.2068,
                            Val Loss: 0.4102, Val MAE: 0.4102
2023-01-24 01:45:21,068:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-24 01:55:13,720:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 592.65s, LR: 0.00009, Train Loss: 0.2063, Train MAE: 0.2063,
                            Val Loss: 0.5330, Val MAE: 0.5330
2023-01-24 01:55:13,721:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-24 02:05:10,178:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 596.46s, LR: 0.00009, Train Loss: 0.2054, Train MAE: 0.2054,
                            Val Loss: 0.4120, Val MAE: 0.4121
2023-01-24 02:05:10,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-24 02:15:05,151:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 594.97s, LR: 0.00009, Train Loss: 0.2053, Train MAE: 0.2053,
                            Val Loss: 0.6649, Val MAE: 0.6649
2023-01-24 02:15:05,152:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-24 02:24:56,515:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 591.36s, LR: 0.00004, Train Loss: 0.2017, Train MAE: 0.2017,
                            Val Loss: 0.4790, Val MAE: 0.4789
2023-01-24 02:24:56,516:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-24 02:34:44,659:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 588.14s, LR: 0.00004, Train Loss: 0.2010, Train MAE: 0.2010,
                            Val Loss: 0.2908, Val MAE: 0.2906
2023-01-24 02:34:44,661:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-24 02:45:20,583:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.92s, LR: 0.00004, Train Loss: 0.2007, Train MAE: 0.2007,
                            Val Loss: 0.3819, Val MAE: 0.3817
2023-01-24 02:45:20,584:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-24 02:55:14,209:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.27444136142730713
2023-01-24 02:55:14,211:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 593.63s, LR: 0.00004, Train Loss: 0.2005, Train MAE: 0.2005,
                            Val Loss: 0.2746, Val MAE: 0.2744
2023-01-24 02:55:14,211:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-24 03:05:02,040:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 587.83s, LR: 0.00004, Train Loss: 0.2000, Train MAE: 0.2000,
                            Val Loss: 0.4309, Val MAE: 0.4309
2023-01-24 03:05:02,040:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-24 03:14:46,732:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 584.69s, LR: 0.00004, Train Loss: 0.1995, Train MAE: 0.1995,
                            Val Loss: 0.3537, Val MAE: 0.3535
2023-01-24 03:14:46,733:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-24 03:24:30,695:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 583.96s, LR: 0.00004, Train Loss: 0.1992, Train MAE: 0.1992,
                            Val Loss: 0.4306, Val MAE: 0.4306
2023-01-24 03:24:30,696:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-24 03:34:20,285:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 589.59s, LR: 0.00004, Train Loss: 0.1991, Train MAE: 0.1991,
                            Val Loss: 0.3689, Val MAE: 0.3688
2023-01-24 03:34:20,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-24 03:44:10,649:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 590.36s, LR: 0.00004, Train Loss: 0.1988, Train MAE: 0.1988,
                            Val Loss: 0.4004, Val MAE: 0.4002
2023-01-24 03:44:10,650:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-24 03:54:00,968:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 590.32s, LR: 0.00004, Train Loss: 0.1987, Train MAE: 0.1987,
                            Val Loss: 0.3100, Val MAE: 0.3100
2023-01-24 03:54:00,969:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-24 04:03:46,855:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 585.89s, LR: 0.00004, Train Loss: 0.1981, Train MAE: 0.1981,
                            Val Loss: 0.3138, Val MAE: 0.3137
2023-01-24 04:03:46,856:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-24 04:13:30,191:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 583.33s, LR: 0.00004, Train Loss: 0.1979, Train MAE: 0.1979,
                            Val Loss: 0.4575, Val MAE: 0.4576
2023-01-24 04:13:30,192:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-24 04:23:14,862:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 584.67s, LR: 0.00004, Train Loss: 0.1978, Train MAE: 0.1978,
                            Val Loss: 0.5347, Val MAE: 0.5347
2023-01-24 04:23:14,863:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-24 04:32:59,391:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 584.53s, LR: 0.00004, Train Loss: 0.1979, Train MAE: 0.1979,
                            Val Loss: 0.2863, Val MAE: 0.2860
2023-01-24 04:32:59,392:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-24 04:42:43,761:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 584.37s, LR: 0.00004, Train Loss: 0.1977, Train MAE: 0.1977,
                            Val Loss: 0.2920, Val MAE: 0.2920
2023-01-24 04:42:43,762:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-24 04:52:34,100:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 590.34s, LR: 0.00004, Train Loss: 0.1973, Train MAE: 0.1973,
                            Val Loss: 0.3352, Val MAE: 0.3350
2023-01-24 04:52:34,101:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-24 05:02:23,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 589.24s, LR: 0.00004, Train Loss: 0.1971, Train MAE: 0.1971,
                            Val Loss: 0.4840, Val MAE: 0.4840
2023-01-24 05:02:23,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-24 05:12:11,689:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 588.35s, LR: 0.00004, Train Loss: 0.1967, Train MAE: 0.1967,
                            Val Loss: 0.5723, Val MAE: 0.5723
2023-01-24 05:12:11,690:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-24 05:21:59,874:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 588.18s, LR: 0.00004, Train Loss: 0.1967, Train MAE: 0.1967,
                            Val Loss: 0.4994, Val MAE: 0.4993
2023-01-24 05:21:59,876:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-24 05:32:33,633:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 633.76s, LR: 0.00004, Train Loss: 0.1974, Train MAE: 0.1974,
                            Val Loss: 0.3809, Val MAE: 0.3808
2023-01-24 05:32:33,634:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 126/1000
2023-01-24 05:42:14,805:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 581.17s, LR: 0.00002, Train Loss: 0.1947, Train MAE: 0.1947,
                            Val Loss: 0.3614, Val MAE: 0.3612
2023-01-24 05:42:14,806:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 127/1000
2023-01-24 05:51:56,207:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 581.40s, LR: 0.00002, Train Loss: 0.1943, Train MAE: 0.1943,
                            Val Loss: 0.3304, Val MAE: 0.3302
2023-01-24 05:51:56,208:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 128/1000
2023-01-24 06:01:37,790:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2735590934753418
2023-01-24 06:01:37,792:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 581.58s, LR: 0.00002, Train Loss: 0.1940, Train MAE: 0.1940,
                            Val Loss: 0.2737, Val MAE: 0.2736
2023-01-24 06:01:37,792:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 129/1000
2023-01-24 06:11:17,151:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 579.36s, LR: 0.00002, Train Loss: 0.1940, Train MAE: 0.1940,
                            Val Loss: 0.3687, Val MAE: 0.3687
2023-01-24 06:11:17,152:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 130/1000
2023-01-24 06:20:55,992:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 578.84s, LR: 0.00002, Train Loss: 0.1940, Train MAE: 0.1940,
                            Val Loss: 0.2960, Val MAE: 0.2957
2023-01-24 06:20:55,993:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 131/1000
2023-01-24 06:30:36,631:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 580.64s, LR: 0.00002, Train Loss: 0.1938, Train MAE: 0.1938,
                            Val Loss: 0.4945, Val MAE: 0.4945
2023-01-24 06:30:36,632:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 132/1000
2023-01-24 06:40:23,108:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 586.47s, LR: 0.00002, Train Loss: 0.1956, Train MAE: 0.1956,
                            Val Loss: 0.4440, Val MAE: 0.4439
2023-01-24 06:40:23,109:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 133/1000
2023-01-24 06:50:10,586:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 587.48s, LR: 0.00002, Train Loss: 0.1961, Train MAE: 0.1961,
                            Val Loss: 0.4894, Val MAE: 0.4893
2023-01-24 06:50:10,587:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 134/1000
2023-01-24 06:59:55,836:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.239199697971344
2023-01-24 06:59:55,837:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 585.25s, LR: 0.00002, Train Loss: 0.1949, Train MAE: 0.1949,
                            Val Loss: 0.2394, Val MAE: 0.2392
2023-01-24 06:59:55,838:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-24 06:59:55,838:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-24 07:06:19,934:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.2392
2023-01-24 07:06:19,955:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.2073
2023-01-24 07:06:19,956:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-24 07:06:19,957:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 133.0000
2023-01-24 07:06:19,959:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 86843.8283s
2023-01-24 07:06:20,076:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 608.5237s
2023-01-24 07:06:20,148:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-24 07:06:20,521:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.2073)]
2023-01-24 07:06:20,522:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.2392)]
