2023-01-23 06:47:17,779:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA TITAN X (Pascal)
2023-01-23 06:47:17,779:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 06:57:54,271:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 06:58:24,831:ogbdata.py:332 -             __init__(): Time taken: 667.0517s
2023-01-23 06:58:24,831:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 06:58:24,831:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 06:58:24,831:ogbdata.py:348 -             __init__(): [I] Data load time: 667.0520s
2023-01-23 06:58:24,832:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 100, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '1', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-23 06:58:24,832:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-23 06:58:24,839:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:58:31,714:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:58:31,714:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:58:31,714:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:58:31,743:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 06:58:31,764:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 544241
2023-01-23 06:58:31,764:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-23 06:58:31,765:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:58:31,770:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:58:31,770:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:58:31,770:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:58:31,804:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-23 08:21:58,137:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:5006.372086048126
2023-01-23 08:21:58,156:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-23 08:21:58,156:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-23 08:21:58,186:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-23 08:37:39,804:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.7887519001960754
2023-01-23 08:37:39,806:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 941.62s, LR: 0.00070, Train Loss: 0.5370, Train MAE: 0.5370,
                            Val Loss: 0.7890, Val MAE: 0.7888
2023-01-23 08:37:39,807:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-23 08:50:11,425:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4953885078430176
2023-01-23 08:50:11,428:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.62s, LR: 0.00070, Train Loss: 0.3758, Train MAE: 0.3758,
                            Val Loss: 0.4957, Val MAE: 0.4954
2023-01-23 08:50:11,428:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-23 09:01:47,312:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.88s, LR: 0.00070, Train Loss: 0.3188, Train MAE: 0.3188,
                            Val Loss: 0.6097, Val MAE: 0.6097
2023-01-23 09:01:47,313:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-23 09:13:37,434:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4392618238925934
2023-01-23 09:13:37,437:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.12s, LR: 0.00070, Train Loss: 0.3190, Train MAE: 0.3190,
                            Val Loss: 0.4395, Val MAE: 0.4393
2023-01-23 09:13:37,437:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-23 09:26:03,509:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.42018941044807434
2023-01-23 09:26:03,512:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.07s, LR: 0.00070, Train Loss: 0.2813, Train MAE: 0.2813,
                            Val Loss: 0.4204, Val MAE: 0.4202
2023-01-23 09:26:03,512:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-23 09:38:10,364:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.85s, LR: 0.00070, Train Loss: 0.2586, Train MAE: 0.2586,
                            Val Loss: 0.4278, Val MAE: 0.4276
2023-01-23 09:38:10,366:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-23 09:50:41,566:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.20s, LR: 0.00070, Train Loss: 0.2408, Train MAE: 0.2408,
                            Val Loss: 0.5453, Val MAE: 0.5451
2023-01-23 09:50:41,568:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-23 10:03:11,114:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3281552493572235
2023-01-23 10:03:11,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.55s, LR: 0.00070, Train Loss: 0.2435, Train MAE: 0.2435,
                            Val Loss: 0.3285, Val MAE: 0.3282
2023-01-23 10:03:11,117:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-23 10:14:31,962:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.84s, LR: 0.00070, Train Loss: 0.2187, Train MAE: 0.2187,
                            Val Loss: 0.3702, Val MAE: 0.3700
2023-01-23 10:14:31,964:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-23 10:25:51,317:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.35s, LR: 0.00070, Train Loss: 0.2068, Train MAE: 0.2068,
                            Val Loss: 0.5160, Val MAE: 0.5159
2023-01-23 10:25:51,319:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-23 10:37:10,665:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.34s, LR: 0.00070, Train Loss: 0.1980, Train MAE: 0.1980,
                            Val Loss: 0.3965, Val MAE: 0.3964
2023-01-23 10:37:10,667:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-23 10:48:31,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.37s, LR: 0.00070, Train Loss: 0.1961, Train MAE: 0.1961,
                            Val Loss: 0.3388, Val MAE: 0.3386
2023-01-23 10:48:31,040:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-23 11:00:31,099:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2657831311225891
2023-01-23 11:00:31,102:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.06s, LR: 0.00070, Train Loss: 0.1898, Train MAE: 0.1898,
                            Val Loss: 0.2661, Val MAE: 0.2658
2023-01-23 11:00:31,103:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-23 11:13:00,985:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.88s, LR: 0.00070, Train Loss: 0.1825, Train MAE: 0.1825,
                            Val Loss: 0.3897, Val MAE: 0.3897
2023-01-23 11:13:00,986:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-23 11:25:32,371:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.38s, LR: 0.00070, Train Loss: 0.1805, Train MAE: 0.1805,
                            Val Loss: 0.3857, Val MAE: 0.3856
2023-01-23 11:25:32,372:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-23 11:38:02,299:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.93s, LR: 0.00070, Train Loss: 0.1750, Train MAE: 0.1750,
                            Val Loss: 0.3990, Val MAE: 0.3989
2023-01-23 11:38:02,301:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-23 11:50:31,923:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.62s, LR: 0.00070, Train Loss: 0.1706, Train MAE: 0.1706,
                            Val Loss: 0.3995, Val MAE: 0.3993
2023-01-23 11:50:31,925:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-23 12:03:03,261:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.34s, LR: 0.00070, Train Loss: 0.1711, Train MAE: 0.1711,
                            Val Loss: 0.3068, Val MAE: 0.3066
2023-01-23 12:03:03,263:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-23 12:15:33,819:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.55s, LR: 0.00070, Train Loss: 0.1655, Train MAE: 0.1655,
                            Val Loss: 0.2973, Val MAE: 0.2972
2023-01-23 12:15:33,820:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-23 12:28:03,615:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.79s, LR: 0.00070, Train Loss: 0.1647, Train MAE: 0.1647,
                            Val Loss: 0.3719, Val MAE: 0.3718
2023-01-23 12:28:03,616:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-23 12:40:33,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.77s, LR: 0.00070, Train Loss: 0.1626, Train MAE: 0.1626,
                            Val Loss: 0.2984, Val MAE: 0.2983
2023-01-23 12:40:33,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-23 12:53:04,331:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.23325836658477783
2023-01-23 12:53:04,333:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.95s, LR: 0.00070, Train Loss: 0.1593, Train MAE: 0.1593,
                            Val Loss: 0.2334, Val MAE: 0.2333
2023-01-23 12:53:04,334:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-23 13:05:33,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 749.64s, LR: 0.00070, Train Loss: 0.1585, Train MAE: 0.1585,
                            Val Loss: 0.2471, Val MAE: 0.2469
2023-01-23 13:05:33,973:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-23 13:18:01,259:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.22451944649219513
2023-01-23 13:18:01,263:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 747.29s, LR: 0.00070, Train Loss: 0.1587, Train MAE: 0.1587,
                            Val Loss: 0.2247, Val MAE: 0.2245
2023-01-23 13:18:01,263:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-23 13:29:20,894:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.63s, LR: 0.00070, Train Loss: 0.2088, Train MAE: 0.2088,
                            Val Loss: 0.3110, Val MAE: 0.3108
2023-01-23 13:29:20,894:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-23 13:40:38,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.83s, LR: 0.00070, Train Loss: 0.1565, Train MAE: 0.1565,
                            Val Loss: 0.3450, Val MAE: 0.3449
2023-01-23 13:40:38,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-23 13:51:55,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.56s, LR: 0.00070, Train Loss: 0.1531, Train MAE: 0.1531,
                            Val Loss: 0.3245, Val MAE: 0.3245
2023-01-23 13:51:55,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-23 14:03:29,458:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.16s, LR: 0.00070, Train Loss: 0.1497, Train MAE: 0.1497,
                            Val Loss: 0.3231, Val MAE: 0.3230
2023-01-23 14:03:29,459:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-23 14:14:59,855:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.39s, LR: 0.00070, Train Loss: 0.1489, Train MAE: 0.1489,
                            Val Loss: 0.4839, Val MAE: 0.4840
2023-01-23 14:14:59,857:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-23 14:26:16,146:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.29s, LR: 0.00070, Train Loss: 0.1465, Train MAE: 0.1465,
                            Val Loss: 0.3064, Val MAE: 0.3063
2023-01-23 14:26:16,147:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-23 14:37:33,441:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.21794018149375916
2023-01-23 14:37:33,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.30s, LR: 0.00070, Train Loss: 0.1787, Train MAE: 0.1787,
                            Val Loss: 0.2181, Val MAE: 0.2179
2023-01-23 14:37:33,444:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-23 14:48:51,109:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.66s, LR: 0.00070, Train Loss: 0.1591, Train MAE: 0.1591,
                            Val Loss: 0.2388, Val MAE: 0.2386
2023-01-23 14:48:51,111:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-23 15:00:07,189:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.200041264295578
2023-01-23 15:00:07,191:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.08s, LR: 0.00070, Train Loss: 0.1529, Train MAE: 0.1529,
                            Val Loss: 0.2003, Val MAE: 0.2000
2023-01-23 15:00:07,191:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-23 15:12:27,436:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.24s, LR: 0.00070, Train Loss: 0.1457, Train MAE: 0.1457,
                            Val Loss: 0.3087, Val MAE: 0.3086
2023-01-23 15:12:27,437:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-23 15:24:54,068:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.63s, LR: 0.00070, Train Loss: 0.1441, Train MAE: 0.1441,
                            Val Loss: 0.4645, Val MAE: 0.4646
2023-01-23 15:24:54,069:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-23 15:36:10,082:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1935218870639801
2023-01-23 15:36:10,084:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.01s, LR: 0.00070, Train Loss: 0.1408, Train MAE: 0.1408,
                            Val Loss: 0.1937, Val MAE: 0.1935
2023-01-23 15:36:10,084:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-23 15:47:26,604:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.52s, LR: 0.00070, Train Loss: 0.1401, Train MAE: 0.1401,
                            Val Loss: 0.2676, Val MAE: 0.2674
2023-01-23 15:47:26,606:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-23 15:58:42,304:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.70s, LR: 0.00070, Train Loss: 0.1379, Train MAE: 0.1379,
                            Val Loss: 0.5201, Val MAE: 0.5202
2023-01-23 15:58:42,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-23 16:09:59,297:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.99s, LR: 0.00070, Train Loss: 0.1375, Train MAE: 0.1375,
                            Val Loss: 0.5551, Val MAE: 0.5549
2023-01-23 16:09:59,298:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-23 16:21:16,388:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.09s, LR: 0.00070, Train Loss: 0.1366, Train MAE: 0.1366,
                            Val Loss: 0.2163, Val MAE: 0.2161
2023-01-23 16:21:16,389:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-23 16:33:30,171:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 733.78s, LR: 0.00070, Train Loss: 0.1357, Train MAE: 0.1357,
                            Val Loss: 0.3470, Val MAE: 0.3470
2023-01-23 16:33:30,172:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-23 16:44:48,262:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.09s, LR: 0.00070, Train Loss: 0.1341, Train MAE: 0.1341,
                            Val Loss: 0.4582, Val MAE: 0.4583
2023-01-23 16:44:48,263:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-23 16:58:47,017:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 838.73s, LR: 0.00070, Train Loss: 0.1336, Train MAE: 0.1336,
                            Val Loss: 0.2810, Val MAE: 0.2810
2023-01-23 16:58:47,049:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-23 17:09:46,528:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.48s, LR: 0.00070, Train Loss: 0.1325, Train MAE: 0.1325,
                            Val Loss: 0.2562, Val MAE: 0.2561
2023-01-23 17:09:46,529:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-23 17:20:43,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.76s, LR: 0.00070, Train Loss: 0.1328, Train MAE: 0.1328,
                            Val Loss: 0.3160, Val MAE: 0.3160
2023-01-23 17:20:43,295:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-23 17:31:39,991:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.69s, LR: 0.00070, Train Loss: 0.1314, Train MAE: 0.1314,
                            Val Loss: 0.3351, Val MAE: 0.3351
2023-01-23 17:31:39,992:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-23 17:42:35,538:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.55s, LR: 0.00070, Train Loss: 0.1307, Train MAE: 0.1307,
                            Val Loss: 0.2556, Val MAE: 0.2555
2023-01-23 17:42:35,539:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-23 17:53:30,215:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.67s, LR: 0.00070, Train Loss: 0.1300, Train MAE: 0.1300,
                            Val Loss: 0.4157, Val MAE: 0.4158
2023-01-23 17:53:30,216:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-23 18:04:26,309:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.09s, LR: 0.00070, Train Loss: 0.1296, Train MAE: 0.1296,
                            Val Loss: 0.4169, Val MAE: 0.4170
2023-01-23 18:04:26,310:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-23 18:15:22,086:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.77s, LR: 0.00070, Train Loss: 0.1288, Train MAE: 0.1288,
                            Val Loss: 0.3903, Val MAE: 0.3902
2023-01-23 18:15:22,087:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-23 18:26:17,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.21s, LR: 0.00070, Train Loss: 0.1281, Train MAE: 0.1281,
                            Val Loss: 0.2127, Val MAE: 0.2126
2023-01-23 18:26:17,296:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-23 18:37:11,040:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.74s, LR: 0.00070, Train Loss: 0.1274, Train MAE: 0.1274,
                            Val Loss: 0.3876, Val MAE: 0.3876
2023-01-23 18:37:11,041:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-23 18:48:03,976:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.93s, LR: 0.00035, Train Loss: 0.1189, Train MAE: 0.1189,
                            Val Loss: 0.3250, Val MAE: 0.3250
2023-01-23 18:48:03,978:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-23 18:58:55,572:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.59s, LR: 0.00035, Train Loss: 0.1180, Train MAE: 0.1180,
                            Val Loss: 0.1986, Val MAE: 0.1985
2023-01-23 18:58:55,573:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-23 19:09:46,635:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.06s, LR: 0.00035, Train Loss: 0.1174, Train MAE: 0.1174,
                            Val Loss: 0.2540, Val MAE: 0.2540
2023-01-23 19:09:46,636:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-23 19:20:37,043:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.41s, LR: 0.00035, Train Loss: 0.1170, Train MAE: 0.1170,
                            Val Loss: 0.3040, Val MAE: 0.3041
2023-01-23 19:20:37,044:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-23 19:31:24,789:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.74s, LR: 0.00035, Train Loss: 0.1163, Train MAE: 0.1163,
                            Val Loss: 0.2098, Val MAE: 0.2097
2023-01-23 19:31:24,790:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-23 19:43:09,710:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.17066164314746857
2023-01-23 19:43:09,712:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 704.92s, LR: 0.00035, Train Loss: 0.1159, Train MAE: 0.1159,
                            Val Loss: 0.1708, Val MAE: 0.1707
2023-01-23 19:43:09,713:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-23 19:53:55,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.87s, LR: 0.00035, Train Loss: 0.1157, Train MAE: 0.1157,
                            Val Loss: 0.2411, Val MAE: 0.2410
2023-01-23 19:53:55,589:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-23 20:04:40,172:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16968731582164764
2023-01-23 20:04:40,174:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.58s, LR: 0.00035, Train Loss: 0.1153, Train MAE: 0.1153,
                            Val Loss: 0.1698, Val MAE: 0.1697
2023-01-23 20:04:40,175:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-23 20:15:23,773:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.60s, LR: 0.00035, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.2648, Val MAE: 0.2648
2023-01-23 20:15:23,775:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-23 20:26:08,082:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.31s, LR: 0.00035, Train Loss: 0.1151, Train MAE: 0.1151,
                            Val Loss: 0.1712, Val MAE: 0.1710
2023-01-23 20:26:08,083:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-23 20:36:51,978:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.89s, LR: 0.00035, Train Loss: 0.1145, Train MAE: 0.1145,
                            Val Loss: 0.2435, Val MAE: 0.2434
2023-01-23 20:36:51,980:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-23 20:47:35,329:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.35s, LR: 0.00035, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.3318, Val MAE: 0.3318
2023-01-23 20:47:35,330:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-23 20:58:18,411:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.08s, LR: 0.00035, Train Loss: 0.1138, Train MAE: 0.1138,
                            Val Loss: 0.3225, Val MAE: 0.3226
2023-01-23 20:58:18,412:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-23 21:09:00,237:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.82s, LR: 0.00035, Train Loss: 0.1136, Train MAE: 0.1136,
                            Val Loss: 0.1959, Val MAE: 0.1958
2023-01-23 21:09:00,238:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-23 21:19:40,802:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13080903887748718
2023-01-23 21:19:40,804:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.57s, LR: 0.00035, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.1310, Val MAE: 0.1308
2023-01-23 21:19:40,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-23 21:30:18,780:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.97s, LR: 0.00035, Train Loss: 0.1131, Train MAE: 0.1131,
                            Val Loss: 0.1610, Val MAE: 0.1608
2023-01-23 21:30:18,780:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-23 21:40:56,569:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.79s, LR: 0.00035, Train Loss: 0.1128, Train MAE: 0.1128,
                            Val Loss: 0.2873, Val MAE: 0.2873
2023-01-23 21:40:56,570:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-23 21:51:55,797:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.23s, LR: 0.00035, Train Loss: 0.1127, Train MAE: 0.1127,
                            Val Loss: 0.3510, Val MAE: 0.3511
2023-01-23 21:51:55,797:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-23 22:03:40,063:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 704.26s, LR: 0.00035, Train Loss: 0.1125, Train MAE: 0.1125,
                            Val Loss: 0.2627, Val MAE: 0.2626
2023-01-23 22:03:40,064:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-23 22:15:22,066:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.00s, LR: 0.00035, Train Loss: 0.1122, Train MAE: 0.1122,
                            Val Loss: 0.1947, Val MAE: 0.1946
2023-01-23 22:15:22,067:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-23 22:27:02,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.34s, LR: 0.00035, Train Loss: 0.1123, Train MAE: 0.1123,
                            Val Loss: 0.3034, Val MAE: 0.3034
2023-01-23 22:27:02,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-23 22:38:41,622:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.21s, LR: 0.00035, Train Loss: 0.1120, Train MAE: 0.1120,
                            Val Loss: 0.3434, Val MAE: 0.3434
2023-01-23 22:38:41,623:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-23 22:51:12,126:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 750.50s, LR: 0.00035, Train Loss: 0.1118, Train MAE: 0.1118,
                            Val Loss: 0.2660, Val MAE: 0.2660
2023-01-23 22:51:12,127:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-23 23:02:51,033:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.91s, LR: 0.00035, Train Loss: 0.1114, Train MAE: 0.1114,
                            Val Loss: 0.3258, Val MAE: 0.3258
2023-01-23 23:02:51,034:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-23 23:14:24,821:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.79s, LR: 0.00035, Train Loss: 0.1114, Train MAE: 0.1114,
                            Val Loss: 0.3297, Val MAE: 0.3298
2023-01-23 23:14:24,822:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-23 23:24:52,429:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 627.61s, LR: 0.00035, Train Loss: 0.1112, Train MAE: 0.1112,
                            Val Loss: 0.1922, Val MAE: 0.1921
2023-01-23 23:24:52,430:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-23 23:35:18,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 626.29s, LR: 0.00035, Train Loss: 0.1112, Train MAE: 0.1112,
                            Val Loss: 0.2898, Val MAE: 0.2897
2023-01-23 23:35:18,723:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-23 23:45:43,962:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 625.24s, LR: 0.00035, Train Loss: 0.1110, Train MAE: 0.1110,
                            Val Loss: 0.1880, Val MAE: 0.1879
2023-01-23 23:45:43,963:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-23 23:56:07,975:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 624.01s, LR: 0.00035, Train Loss: 0.1107, Train MAE: 0.1107,
                            Val Loss: 0.1440, Val MAE: 0.1438
2023-01-23 23:56:07,976:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-24 00:06:30,171:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 622.19s, LR: 0.00035, Train Loss: 0.1107, Train MAE: 0.1107,
                            Val Loss: 0.1684, Val MAE: 0.1683
2023-01-24 00:06:30,172:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-24 00:16:50,250:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 620.08s, LR: 0.00035, Train Loss: 0.1106, Train MAE: 0.1106,
                            Val Loss: 0.2393, Val MAE: 0.2392
2023-01-24 00:16:50,252:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-24 00:27:10,420:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 620.17s, LR: 0.00017, Train Loss: 0.1061, Train MAE: 0.1061,
                            Val Loss: 0.2762, Val MAE: 0.2762
2023-01-24 00:27:10,422:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-24 00:37:30,405:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12528002262115479
2023-01-24 00:37:30,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 619.98s, LR: 0.00017, Train Loss: 0.1057, Train MAE: 0.1057,
                            Val Loss: 0.1255, Val MAE: 0.1253
2023-01-24 00:37:30,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-24 00:47:50,480:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 620.07s, LR: 0.00017, Train Loss: 0.1054, Train MAE: 0.1054,
                            Val Loss: 0.1310, Val MAE: 0.1308
2023-01-24 00:47:50,481:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-24 00:58:09,909:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 619.43s, LR: 0.00017, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.1340, Val MAE: 0.1338
2023-01-24 00:58:09,911:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-24 01:08:29,127:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 619.22s, LR: 0.00017, Train Loss: 0.1050, Train MAE: 0.1050,
                            Val Loss: 0.1986, Val MAE: 0.1985
2023-01-24 01:08:29,128:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-24 01:18:46,634:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 617.51s, LR: 0.00017, Train Loss: 0.1049, Train MAE: 0.1049,
                            Val Loss: 0.2353, Val MAE: 0.2352
2023-01-24 01:18:46,635:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-24 01:29:02,647:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 616.01s, LR: 0.00017, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1691, Val MAE: 0.1689
2023-01-24 01:29:02,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-24 01:39:16,703:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 614.05s, LR: 0.00017, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.3236, Val MAE: 0.3236
2023-01-24 01:39:16,704:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-24 01:50:19,978:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.27s, LR: 0.00017, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1713, Val MAE: 0.1712
2023-01-24 01:50:19,979:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-24 02:00:29,527:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 609.55s, LR: 0.00017, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.2308, Val MAE: 0.2308
2023-01-24 02:00:29,528:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-24 02:10:39,020:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 609.49s, LR: 0.00017, Train Loss: 0.1043, Train MAE: 0.1043,
                            Val Loss: 0.2453, Val MAE: 0.2453
2023-01-24 02:10:39,021:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-24 02:20:48,154:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 609.13s, LR: 0.00017, Train Loss: 0.1042, Train MAE: 0.1042,
                            Val Loss: 0.1681, Val MAE: 0.1680
2023-01-24 02:20:48,156:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-24 02:30:57,257:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 609.10s, LR: 0.00017, Train Loss: 0.1040, Train MAE: 0.1040,
                            Val Loss: 0.1284, Val MAE: 0.1282
2023-01-24 02:30:57,258:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-24 02:41:06,456:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 609.20s, LR: 0.00017, Train Loss: 0.1038, Train MAE: 0.1038,
                            Val Loss: 0.2373, Val MAE: 0.2372
2023-01-24 02:41:06,458:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-24 02:51:11,416:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 604.96s, LR: 0.00017, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1752, Val MAE: 0.1751
2023-01-24 02:51:11,417:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-24 03:01:12,909:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 601.49s, LR: 0.00017, Train Loss: 0.1037, Train MAE: 0.1037,
                            Val Loss: 0.3034, Val MAE: 0.3035
2023-01-24 03:01:12,910:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-24 03:11:10,255:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 597.34s, LR: 0.00017, Train Loss: 0.1037, Train MAE: 0.1037,
                            Val Loss: 0.1797, Val MAE: 0.1796
2023-01-24 03:11:10,256:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-24 03:21:02,541:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 592.28s, LR: 0.00017, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1367, Val MAE: 0.1365
2023-01-24 03:21:02,542:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-24 03:30:51,036:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 588.49s, LR: 0.00009, Train Loss: 0.1012, Train MAE: 0.1012,
                            Val Loss: 0.1510, Val MAE: 0.1508
2023-01-24 03:30:51,037:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-24 03:40:37,094:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 586.06s, LR: 0.00009, Train Loss: 0.1009, Train MAE: 0.1009,
                            Val Loss: 0.1400, Val MAE: 0.1398
2023-01-24 03:40:37,095:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-24 03:50:22,370:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 585.27s, LR: 0.00009, Train Loss: 0.1009, Train MAE: 0.1009,
                            Val Loss: 0.1509, Val MAE: 0.1508
2023-01-24 03:50:22,371:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-24 04:00:07,417:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 585.05s, LR: 0.00009, Train Loss: 0.1007, Train MAE: 0.1007,
                            Val Loss: 0.1894, Val MAE: 0.1892
2023-01-24 04:00:07,418:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-24 04:09:52,322:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 584.90s, LR: 0.00009, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.1997, Val MAE: 0.1996
2023-01-24 04:09:52,323:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-24 04:19:36,706:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 584.38s, LR: 0.00009, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.1608, Val MAE: 0.1606
2023-01-24 04:19:36,707:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-24 04:29:19,543:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12203989177942276
2023-01-24 04:29:19,545:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 582.84s, LR: 0.00009, Train Loss: 0.1005, Train MAE: 0.1005,
                            Val Loss: 0.1222, Val MAE: 0.1220
2023-01-24 04:29:19,545:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-24 04:39:49,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.44s, LR: 0.00009, Train Loss: 0.1009, Train MAE: 0.1009,
                            Val Loss: 0.1549, Val MAE: 0.1548
2023-01-24 04:39:49,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-24 04:49:28,406:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 578.42s, LR: 0.00009, Train Loss: 0.1008, Train MAE: 0.1008,
                            Val Loss: 0.2481, Val MAE: 0.2480
2023-01-24 04:49:28,407:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-24 04:59:06,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 578.46s, LR: 0.00009, Train Loss: 0.1007, Train MAE: 0.1007,
                            Val Loss: 0.1271, Val MAE: 0.1270
2023-01-24 04:59:06,871:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-24 05:08:44,060:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 577.19s, LR: 0.00009, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1452, Val MAE: 0.1451
2023-01-24 05:08:44,061:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-24 05:18:20,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 576.42s, LR: 0.00009, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.2309, Val MAE: 0.2308
2023-01-24 05:18:20,477:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-24 05:27:56,808:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 576.33s, LR: 0.00009, Train Loss: 0.1005, Train MAE: 0.1005,
                            Val Loss: 0.1280, Val MAE: 0.1278
2023-01-24 05:27:56,809:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-24 05:37:49,440:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 592.63s, LR: 0.00009, Train Loss: 0.1004, Train MAE: 0.1004,
                            Val Loss: 0.1346, Val MAE: 0.1344
2023-01-24 05:37:49,441:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-24 05:48:29,467:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.02s, LR: 0.00009, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1254, Val MAE: 0.1252
2023-01-24 05:48:29,468:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-24 05:59:08,740:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.27s, LR: 0.00009, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1268, Val MAE: 0.1265
2023-01-24 05:59:08,741:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-24 06:09:45,206:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.46s, LR: 0.00009, Train Loss: 0.1001, Train MAE: 0.1001,
                            Val Loss: 0.1258, Val MAE: 0.1256
2023-01-24 06:09:45,207:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-24 06:20:19,836:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.63s, LR: 0.00009, Train Loss: 0.0999, Train MAE: 0.0999,
                            Val Loss: 0.1302, Val MAE: 0.1301
2023-01-24 06:20:19,836:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-24 06:30:01,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 581.50s, LR: 0.00009, Train Loss: 0.0999, Train MAE: 0.0999,
                            Val Loss: 0.1347, Val MAE: 0.1346
2023-01-24 06:30:01,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-24 06:39:29,912:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 568.57s, LR: 0.00009, Train Loss: 0.0998, Train MAE: 0.0998,
                            Val Loss: 0.1499, Val MAE: 0.1498
2023-01-24 06:39:29,913:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-24 06:48:58,473:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 568.56s, LR: 0.00009, Train Loss: 0.0997, Train MAE: 0.0997,
                            Val Loss: 0.1346, Val MAE: 0.1345
2023-01-24 06:48:58,474:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-24 06:58:26,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 568.39s, LR: 0.00009, Train Loss: 0.0997, Train MAE: 0.0997,
                            Val Loss: 0.2626, Val MAE: 0.2626
2023-01-24 06:58:26,872:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-24 07:07:55,232:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 568.36s, LR: 0.00009, Train Loss: 0.0997, Train MAE: 0.0997,
                            Val Loss: 0.1246, Val MAE: 0.1244
2023-01-24 07:07:55,234:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-24 07:07:55,234:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-24 07:14:55,264:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1244
2023-01-24 07:14:55,265:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.1003
2023-01-24 07:14:55,266:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-24 07:14:55,267:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 123.0000
2023-01-24 07:14:55,268:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87383.5040s
2023-01-24 07:14:55,269:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 660.9434s
2023-01-24 07:14:55,282:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-24 07:14:55,374:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.1003)]
2023-01-24 07:14:55,374:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1244)]
