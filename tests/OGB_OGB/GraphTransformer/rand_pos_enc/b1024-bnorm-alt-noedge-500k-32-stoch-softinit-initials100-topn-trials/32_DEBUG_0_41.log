2023-01-23 06:47:09,326:main_utils.py:62 -            gpu_setup(): cuda available with GPU: Quadro RTX 6000
2023-01-23 06:47:09,326:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 06:57:00,226:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 06:57:35,162:ogbdata.py:332 -             __init__(): Time taken: 625.8358s
2023-01-23 06:57:35,163:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 06:57:35,163:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 06:57:35,163:ogbdata.py:348 -             __init__(): [I] Data load time: 625.8362s
2023-01-23 06:57:35,163:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 100, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '1', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials/32_DEBUG_0_41.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [41]}
2023-01-23 06:57:35,163:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-23 06:57:35,197:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:57:37,212:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:57:37,212:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:57:37,212:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:57:37,230:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 06:57:37,237:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 544241
2023-01-23 06:57:37,237:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2023-01-23 06:57:37,238:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 06:57:37,241:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 06:57:37,242:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 06:57:37,242:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 06:57:37,258:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-23 08:07:23,177:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4185.939761161804
2023-01-23 08:07:23,280:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-23 08:07:23,280:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-23 08:07:23,291:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-23 08:18:51,533:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5099469423294067
2023-01-23 08:18:51,535:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.24s, LR: 0.00070, Train Loss: 0.5008, Train MAE: 0.5008,
                            Val Loss: 0.5103, Val MAE: 0.5099
2023-01-23 08:18:51,535:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-23 08:28:17,075:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.46370866894721985
2023-01-23 08:28:17,077:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 565.54s, LR: 0.00070, Train Loss: 0.3160, Train MAE: 0.3160,
                            Val Loss: 0.4642, Val MAE: 0.4637
2023-01-23 08:28:17,078:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-23 08:38:16,933:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 599.85s, LR: 0.00070, Train Loss: 0.2665, Train MAE: 0.2665,
                            Val Loss: 0.5870, Val MAE: 0.5867
2023-01-23 08:38:16,935:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-23 08:48:07,778:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3584299087524414
2023-01-23 08:48:07,780:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 590.84s, LR: 0.00070, Train Loss: 0.2300, Train MAE: 0.2300,
                            Val Loss: 0.3586, Val MAE: 0.3584
2023-01-23 08:48:07,781:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-23 08:57:33,374:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 565.59s, LR: 0.00070, Train Loss: 0.2118, Train MAE: 0.2118,
                            Val Loss: 0.5750, Val MAE: 0.5748
2023-01-23 08:57:33,376:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-23 09:07:39,303:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.346984326839447
2023-01-23 09:07:39,306:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 605.93s, LR: 0.00070, Train Loss: 0.1952, Train MAE: 0.1952,
                            Val Loss: 0.3473, Val MAE: 0.3470
2023-01-23 09:07:39,307:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-23 09:17:48,773:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 609.46s, LR: 0.00070, Train Loss: 0.1830, Train MAE: 0.1830,
                            Val Loss: 0.7032, Val MAE: 0.7029
2023-01-23 09:17:48,775:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-23 09:29:14,329:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.55s, LR: 0.00070, Train Loss: 0.1777, Train MAE: 0.1777,
                            Val Loss: 0.4225, Val MAE: 0.4224
2023-01-23 09:29:14,331:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-23 09:38:32,826:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3241419494152069
2023-01-23 09:38:32,828:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 558.50s, LR: 0.00070, Train Loss: 0.1691, Train MAE: 0.1691,
                            Val Loss: 0.3243, Val MAE: 0.3241
2023-01-23 09:38:32,830:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-23 09:47:50,940:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.25634869933128357
2023-01-23 09:47:50,942:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 558.11s, LR: 0.00070, Train Loss: 0.1690, Train MAE: 0.1690,
                            Val Loss: 0.2566, Val MAE: 0.2563
2023-01-23 09:47:50,943:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-23 09:57:15,064:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 564.12s, LR: 0.00070, Train Loss: 0.1613, Train MAE: 0.1613,
                            Val Loss: 0.3345, Val MAE: 0.3343
2023-01-23 09:57:15,066:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-23 10:06:38,509:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.24903370440006256
2023-01-23 10:06:38,511:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 563.44s, LR: 0.00070, Train Loss: 0.1581, Train MAE: 0.1581,
                            Val Loss: 0.2492, Val MAE: 0.2490
2023-01-23 10:06:38,512:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-23 10:16:45,154:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 606.64s, LR: 0.00070, Train Loss: 0.1549, Train MAE: 0.1549,
                            Val Loss: 0.5614, Val MAE: 0.5613
2023-01-23 10:16:45,156:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-23 10:26:19,915:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 574.76s, LR: 0.00070, Train Loss: 0.1532, Train MAE: 0.1532,
                            Val Loss: 0.2885, Val MAE: 0.2884
2023-01-23 10:26:19,917:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-23 10:35:42,813:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 562.89s, LR: 0.00070, Train Loss: 0.1507, Train MAE: 0.1507,
                            Val Loss: 0.2567, Val MAE: 0.2565
2023-01-23 10:35:42,815:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-23 10:45:05,930:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 563.11s, LR: 0.00070, Train Loss: 0.1625, Train MAE: 0.1625,
                            Val Loss: 0.2747, Val MAE: 0.2746
2023-01-23 10:45:05,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-23 10:54:37,405:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1928628534078598
2023-01-23 10:54:37,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 571.47s, LR: 0.00070, Train Loss: 0.1456, Train MAE: 0.1456,
                            Val Loss: 0.1930, Val MAE: 0.1929
2023-01-23 10:54:37,409:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-23 11:03:58,571:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 561.16s, LR: 0.00070, Train Loss: 0.1435, Train MAE: 0.1435,
                            Val Loss: 0.2594, Val MAE: 0.2593
2023-01-23 11:03:58,572:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-23 11:13:11,006:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 552.43s, LR: 0.00070, Train Loss: 0.1412, Train MAE: 0.1412,
                            Val Loss: 0.1951, Val MAE: 0.1949
2023-01-23 11:13:11,007:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-23 11:22:14,477:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 543.47s, LR: 0.00070, Train Loss: 0.1391, Train MAE: 0.1391,
                            Val Loss: 0.2475, Val MAE: 0.2474
2023-01-23 11:22:14,477:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-23 11:31:35,512:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 561.03s, LR: 0.00070, Train Loss: 0.1393, Train MAE: 0.1393,
                            Val Loss: 0.3193, Val MAE: 0.3193
2023-01-23 11:31:35,512:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-23 11:40:56,840:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 561.33s, LR: 0.00070, Train Loss: 0.1358, Train MAE: 0.1358,
                            Val Loss: 0.2607, Val MAE: 0.2607
2023-01-23 11:40:56,842:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-23 11:50:18,592:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 561.75s, LR: 0.00070, Train Loss: 0.1347, Train MAE: 0.1347,
                            Val Loss: 0.2468, Val MAE: 0.2468
2023-01-23 11:50:18,593:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-23 12:01:10,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.81s, LR: 0.00070, Train Loss: 0.1346, Train MAE: 0.1346,
                            Val Loss: 0.2581, Val MAE: 0.2580
2023-01-23 12:01:10,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-23 12:10:31,642:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 561.23s, LR: 0.00070, Train Loss: 0.1316, Train MAE: 0.1316,
                            Val Loss: 0.1978, Val MAE: 0.1977
2023-01-23 12:10:31,644:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-23 12:19:42,734:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 551.09s, LR: 0.00070, Train Loss: 0.1300, Train MAE: 0.1300,
                            Val Loss: 0.1984, Val MAE: 0.1982
2023-01-23 12:19:42,735:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-23 12:28:49,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 546.74s, LR: 0.00070, Train Loss: 0.1299, Train MAE: 0.1299,
                            Val Loss: 0.2147, Val MAE: 0.2146
2023-01-23 12:28:49,478:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-23 12:38:04,095:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 554.62s, LR: 0.00070, Train Loss: 0.1276, Train MAE: 0.1276,
                            Val Loss: 0.2058, Val MAE: 0.2056
2023-01-23 12:38:04,097:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-23 12:47:24,099:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 560.00s, LR: 0.00070, Train Loss: 0.1269, Train MAE: 0.1269,
                            Val Loss: 0.1967, Val MAE: 0.1966
2023-01-23 12:47:24,101:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-23 12:56:44,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 560.83s, LR: 0.00070, Train Loss: 0.1256, Train MAE: 0.1256,
                            Val Loss: 0.2805, Val MAE: 0.2803
2023-01-23 12:56:44,931:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-23 13:05:58,453:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 553.52s, LR: 0.00070, Train Loss: 0.1253, Train MAE: 0.1253,
                            Val Loss: 0.2001, Val MAE: 0.2000
2023-01-23 13:05:58,453:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-23 13:15:17,604:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14240127801895142
2023-01-23 13:15:17,605:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 559.15s, LR: 0.00070, Train Loss: 0.1237, Train MAE: 0.1237,
                            Val Loss: 0.1426, Val MAE: 0.1424
2023-01-23 13:15:17,605:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-23 13:24:37,372:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1380884349346161
2023-01-23 13:24:37,374:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 559.77s, LR: 0.00070, Train Loss: 0.1238, Train MAE: 0.1238,
                            Val Loss: 0.1383, Val MAE: 0.1381
2023-01-23 13:24:37,376:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-23 13:33:37,849:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 540.47s, LR: 0.00070, Train Loss: 0.1219, Train MAE: 0.1219,
                            Val Loss: 0.2626, Val MAE: 0.2625
2023-01-23 13:33:37,850:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-23 13:42:43,774:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 545.92s, LR: 0.00070, Train Loss: 0.1215, Train MAE: 0.1215,
                            Val Loss: 0.2701, Val MAE: 0.2700
2023-01-23 13:42:43,775:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-23 13:51:43,766:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 539.99s, LR: 0.00070, Train Loss: 0.1204, Train MAE: 0.1204,
                            Val Loss: 0.2091, Val MAE: 0.2090
2023-01-23 13:51:43,767:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-23 14:01:02,402:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 558.63s, LR: 0.00070, Train Loss: 0.1195, Train MAE: 0.1195,
                            Val Loss: 0.2026, Val MAE: 0.2025
2023-01-23 14:01:02,403:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-23 14:11:04,764:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 602.36s, LR: 0.00070, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.1650, Val MAE: 0.1649
2023-01-23 14:11:04,765:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-23 14:21:06,206:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 601.44s, LR: 0.00070, Train Loss: 0.1195, Train MAE: 0.1195,
                            Val Loss: 0.3964, Val MAE: 0.3965
2023-01-23 14:21:06,207:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-23 14:31:09,703:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 603.49s, LR: 0.00070, Train Loss: 0.1176, Train MAE: 0.1176,
                            Val Loss: 0.2185, Val MAE: 0.2184
2023-01-23 14:31:09,704:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-23 14:42:40,225:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.52s, LR: 0.00070, Train Loss: 0.1168, Train MAE: 0.1168,
                            Val Loss: 0.1691, Val MAE: 0.1690
2023-01-23 14:42:40,226:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-23 14:52:28,302:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 588.08s, LR: 0.00070, Train Loss: 0.1165, Train MAE: 0.1165,
                            Val Loss: 0.1834, Val MAE: 0.1833
2023-01-23 14:52:28,304:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-23 15:01:37,816:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 549.51s, LR: 0.00070, Train Loss: 0.1153, Train MAE: 0.1153,
                            Val Loss: 0.1862, Val MAE: 0.1860
2023-01-23 15:01:37,817:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-23 15:10:19,572:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 521.75s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.2829, Val MAE: 0.2829
2023-01-23 15:10:19,574:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-23 15:19:16,286:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 536.71s, LR: 0.00070, Train Loss: 0.1145, Train MAE: 0.1145,
                            Val Loss: 0.2674, Val MAE: 0.2674
2023-01-23 15:19:16,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-23 15:27:53,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 517.30s, LR: 0.00070, Train Loss: 0.1137, Train MAE: 0.1137,
                            Val Loss: 0.4329, Val MAE: 0.4329
2023-01-23 15:27:53,589:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-23 15:36:28,373:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 514.78s, LR: 0.00070, Train Loss: 0.1131, Train MAE: 0.1131,
                            Val Loss: 0.1571, Val MAE: 0.1569
2023-01-23 15:36:28,375:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-23 15:45:28,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 540.35s, LR: 0.00070, Train Loss: 0.1128, Train MAE: 0.1128,
                            Val Loss: 0.1485, Val MAE: 0.1483
2023-01-23 15:45:28,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-23 15:54:35,007:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 546.28s, LR: 0.00070, Train Loss: 0.1126, Train MAE: 0.1126,
                            Val Loss: 0.1781, Val MAE: 0.1779
2023-01-23 15:54:35,008:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-23 16:03:40,670:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13532328605651855
2023-01-23 16:03:40,672:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 545.66s, LR: 0.00035, Train Loss: 0.1049, Train MAE: 0.1049,
                            Val Loss: 0.1355, Val MAE: 0.1353
2023-01-23 16:03:40,673:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-23 16:12:47,347:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 546.67s, LR: 0.00035, Train Loss: 0.1040, Train MAE: 0.1040,
                            Val Loss: 0.2159, Val MAE: 0.2158
2023-01-23 16:12:47,348:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-23 16:21:47,071:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 539.72s, LR: 0.00035, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.1593, Val MAE: 0.1591
2023-01-23 16:21:47,073:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-23 16:30:52,619:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 545.55s, LR: 0.00035, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.1604, Val MAE: 0.1602
2023-01-23 16:30:52,620:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-23 16:39:56,119:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 543.50s, LR: 0.00035, Train Loss: 0.1026, Train MAE: 0.1026,
                            Val Loss: 0.1981, Val MAE: 0.1980
2023-01-23 16:39:56,121:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-23 16:48:38,658:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 522.54s, LR: 0.00035, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.2202, Val MAE: 0.2201
2023-01-23 16:48:38,659:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-23 16:57:39,217:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 540.55s, LR: 0.00035, Train Loss: 0.1019, Train MAE: 0.1019,
                            Val Loss: 0.2857, Val MAE: 0.2857
2023-01-23 16:57:39,219:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-23 17:05:55,651:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 496.43s, LR: 0.00035, Train Loss: 0.1016, Train MAE: 0.1016,
                            Val Loss: 0.1363, Val MAE: 0.1362
2023-01-23 17:05:55,651:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-23 17:15:30,396:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 574.74s, LR: 0.00035, Train Loss: 0.1016, Train MAE: 0.1016,
                            Val Loss: 0.1415, Val MAE: 0.1413
2023-01-23 17:15:30,397:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-23 17:23:45,541:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 495.14s, LR: 0.00035, Train Loss: 0.1012, Train MAE: 0.1012,
                            Val Loss: 0.1396, Val MAE: 0.1394
2023-01-23 17:23:45,542:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-23 17:31:57,312:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1302669644355774
2023-01-23 17:31:57,314:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 491.77s, LR: 0.00035, Train Loss: 0.1010, Train MAE: 0.1010,
                            Val Loss: 0.1304, Val MAE: 0.1303
2023-01-23 17:31:57,315:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-23 17:40:10,936:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 493.62s, LR: 0.00035, Train Loss: 0.1008, Train MAE: 0.1008,
                            Val Loss: 0.1353, Val MAE: 0.1351
2023-01-23 17:40:10,937:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-23 17:48:30,253:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 499.31s, LR: 0.00035, Train Loss: 0.1005, Train MAE: 0.1005,
                            Val Loss: 0.1379, Val MAE: 0.1377
2023-01-23 17:48:30,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-23 17:56:52,120:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 501.86s, LR: 0.00035, Train Loss: 0.1004, Train MAE: 0.1004,
                            Val Loss: 0.2177, Val MAE: 0.2177
2023-01-23 17:56:52,121:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-23 18:05:10,921:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 498.80s, LR: 0.00035, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1846, Val MAE: 0.1844
2023-01-23 18:05:10,923:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-23 18:13:24,596:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 493.67s, LR: 0.00035, Train Loss: 0.1000, Train MAE: 0.1000,
                            Val Loss: 0.1745, Val MAE: 0.1743
2023-01-23 18:13:24,598:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-23 18:21:36,958:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 492.36s, LR: 0.00035, Train Loss: 0.0998, Train MAE: 0.0998,
                            Val Loss: 0.1440, Val MAE: 0.1438
2023-01-23 18:21:36,960:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-23 18:29:48,332:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 491.37s, LR: 0.00035, Train Loss: 0.0996, Train MAE: 0.0996,
                            Val Loss: 0.1465, Val MAE: 0.1464
2023-01-23 18:29:48,334:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-23 18:38:00,192:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 491.86s, LR: 0.00035, Train Loss: 0.0995, Train MAE: 0.0995,
                            Val Loss: 0.1909, Val MAE: 0.1907
2023-01-23 18:38:00,194:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-23 18:46:12,029:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 491.83s, LR: 0.00035, Train Loss: 0.0994, Train MAE: 0.0994,
                            Val Loss: 0.1636, Val MAE: 0.1635
2023-01-23 18:46:12,030:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-23 18:54:23,636:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11575143784284592
2023-01-23 18:54:23,638:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 491.61s, LR: 0.00035, Train Loss: 0.0995, Train MAE: 0.0995,
                            Val Loss: 0.1159, Val MAE: 0.1158
2023-01-23 18:54:23,639:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-23 19:02:36,371:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 492.73s, LR: 0.00035, Train Loss: 0.0991, Train MAE: 0.0991,
                            Val Loss: 0.2130, Val MAE: 0.2130
2023-01-23 19:02:36,373:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-23 19:10:40,338:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.96s, LR: 0.00035, Train Loss: 0.0989, Train MAE: 0.0989,
                            Val Loss: 0.1342, Val MAE: 0.1340
2023-01-23 19:10:40,339:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-23 19:18:44,233:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.89s, LR: 0.00035, Train Loss: 0.0989, Train MAE: 0.0989,
                            Val Loss: 0.2063, Val MAE: 0.2062
2023-01-23 19:18:44,235:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-23 19:26:47,753:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.52s, LR: 0.00035, Train Loss: 0.0988, Train MAE: 0.0988,
                            Val Loss: 0.1285, Val MAE: 0.1283
2023-01-23 19:26:47,754:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-23 19:36:04,518:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 556.76s, LR: 0.00035, Train Loss: 0.0985, Train MAE: 0.0985,
                            Val Loss: 0.2129, Val MAE: 0.2129
2023-01-23 19:36:04,519:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-23 19:44:08,074:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.55s, LR: 0.00035, Train Loss: 0.0986, Train MAE: 0.0986,
                            Val Loss: 0.3759, Val MAE: 0.3760
2023-01-23 19:44:08,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-23 19:52:12,303:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 484.23s, LR: 0.00035, Train Loss: 0.0983, Train MAE: 0.0983,
                            Val Loss: 0.1576, Val MAE: 0.1574
2023-01-23 19:52:12,304:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-23 20:00:16,284:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.98s, LR: 0.00035, Train Loss: 0.0982, Train MAE: 0.0982,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-23 20:00:16,285:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-23 20:08:19,738:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.45s, LR: 0.00035, Train Loss: 0.0982, Train MAE: 0.0982,
                            Val Loss: 0.1424, Val MAE: 0.1422
2023-01-23 20:08:19,739:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-23 20:16:22,144:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 482.40s, LR: 0.00035, Train Loss: 0.0980, Train MAE: 0.0980,
                            Val Loss: 0.1458, Val MAE: 0.1457
2023-01-23 20:16:22,146:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-23 20:24:28,252:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.11s, LR: 0.00035, Train Loss: 0.0978, Train MAE: 0.0978,
                            Val Loss: 0.3531, Val MAE: 0.3532
2023-01-23 20:24:28,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-23 20:32:35,841:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 487.59s, LR: 0.00035, Train Loss: 0.0978, Train MAE: 0.0978,
                            Val Loss: 0.1588, Val MAE: 0.1586
2023-01-23 20:32:35,842:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-23 20:40:42,744:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.90s, LR: 0.00035, Train Loss: 0.0977, Train MAE: 0.0977,
                            Val Loss: 0.1423, Val MAE: 0.1422
2023-01-23 20:40:42,746:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-23 20:48:47,979:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.23s, LR: 0.00035, Train Loss: 0.0975, Train MAE: 0.0975,
                            Val Loss: 0.1398, Val MAE: 0.1397
2023-01-23 20:48:47,981:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-23 20:56:54,456:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.47s, LR: 0.00035, Train Loss: 0.0975, Train MAE: 0.0975,
                            Val Loss: 0.2256, Val MAE: 0.2256
2023-01-23 20:56:54,458:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-23 21:05:00,054:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.59s, LR: 0.00035, Train Loss: 0.0974, Train MAE: 0.0974,
                            Val Loss: 0.2682, Val MAE: 0.2682
2023-01-23 21:05:00,056:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-23 21:13:04,777:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 484.72s, LR: 0.00017, Train Loss: 0.0935, Train MAE: 0.0935,
                            Val Loss: 0.1440, Val MAE: 0.1438
2023-01-23 21:13:04,779:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-23 21:21:09,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 484.82s, LR: 0.00017, Train Loss: 0.0931, Train MAE: 0.0931,
                            Val Loss: 0.1574, Val MAE: 0.1573
2023-01-23 21:21:09,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-23 21:29:13,027:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.43s, LR: 0.00017, Train Loss: 0.0929, Train MAE: 0.0929,
                            Val Loss: 0.1522, Val MAE: 0.1521
2023-01-23 21:29:13,029:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-23 21:37:15,926:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 482.90s, LR: 0.00017, Train Loss: 0.0928, Train MAE: 0.0928,
                            Val Loss: 0.1179, Val MAE: 0.1177
2023-01-23 21:37:15,928:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-23 21:45:18,526:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 482.60s, LR: 0.00017, Train Loss: 0.0926, Train MAE: 0.0926,
                            Val Loss: 0.1265, Val MAE: 0.1263
2023-01-23 21:45:18,527:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-23 21:54:33,413:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11267008632421494
2023-01-23 21:54:33,414:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 554.89s, LR: 0.00017, Train Loss: 0.0925, Train MAE: 0.0925,
                            Val Loss: 0.1129, Val MAE: 0.1127
2023-01-23 21:54:33,416:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-23 22:02:35,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 481.88s, LR: 0.00017, Train Loss: 0.0924, Train MAE: 0.0924,
                            Val Loss: 0.1626, Val MAE: 0.1625
2023-01-23 22:02:35,295:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-23 22:10:36,088:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.79s, LR: 0.00017, Train Loss: 0.0924, Train MAE: 0.0924,
                            Val Loss: 0.1372, Val MAE: 0.1371
2023-01-23 22:10:36,089:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-23 22:18:36,432:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.34s, LR: 0.00017, Train Loss: 0.0922, Train MAE: 0.0922,
                            Val Loss: 0.1141, Val MAE: 0.1139
2023-01-23 22:18:36,434:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-23 22:26:37,503:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 481.07s, LR: 0.00017, Train Loss: 0.0922, Train MAE: 0.0922,
                            Val Loss: 0.1603, Val MAE: 0.1602
2023-01-23 22:26:37,505:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-23 22:34:37,758:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.25s, LR: 0.00017, Train Loss: 0.0922, Train MAE: 0.0922,
                            Val Loss: 0.1588, Val MAE: 0.1587
2023-01-23 22:34:37,759:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-23 22:42:38,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.58s, LR: 0.00017, Train Loss: 0.0920, Train MAE: 0.0920,
                            Val Loss: 0.1524, Val MAE: 0.1523
2023-01-23 22:42:38,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-23 22:50:37,782:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 479.44s, LR: 0.00017, Train Loss: 0.0919, Train MAE: 0.0919,
                            Val Loss: 0.1441, Val MAE: 0.1440
2023-01-23 22:50:37,784:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-23 22:58:37,093:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 479.31s, LR: 0.00017, Train Loss: 0.0918, Train MAE: 0.0918,
                            Val Loss: 0.1649, Val MAE: 0.1648
2023-01-23 22:58:37,094:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-23 23:06:36,213:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 479.12s, LR: 0.00017, Train Loss: 0.0918, Train MAE: 0.0918,
                            Val Loss: 0.1790, Val MAE: 0.1789
2023-01-23 23:06:36,214:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-23 23:14:34,427:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 478.21s, LR: 0.00017, Train Loss: 0.0917, Train MAE: 0.0917,
                            Val Loss: 0.1524, Val MAE: 0.1522
2023-01-23 23:14:34,427:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-23 23:22:33,304:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 478.88s, LR: 0.00017, Train Loss: 0.0916, Train MAE: 0.0916,
                            Val Loss: 0.1350, Val MAE: 0.1348
2023-01-23 23:22:33,305:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-23 23:30:31,284:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 477.98s, LR: 0.00017, Train Loss: 0.0916, Train MAE: 0.0916,
                            Val Loss: 0.1512, Val MAE: 0.1511
2023-01-23 23:30:31,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-23 23:38:28,758:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 477.47s, LR: 0.00017, Train Loss: 0.0916, Train MAE: 0.0916,
                            Val Loss: 0.1475, Val MAE: 0.1474
2023-01-23 23:38:28,759:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-23 23:46:24,642:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.88s, LR: 0.00017, Train Loss: 0.0915, Train MAE: 0.0915,
                            Val Loss: 0.1309, Val MAE: 0.1307
2023-01-23 23:46:24,643:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-23 23:54:16,741:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 472.10s, LR: 0.00017, Train Loss: 0.0914, Train MAE: 0.0914,
                            Val Loss: 0.1520, Val MAE: 0.1518
2023-01-23 23:54:16,742:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-24 00:02:10,287:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.54s, LR: 0.00017, Train Loss: 0.0913, Train MAE: 0.0913,
                            Val Loss: 0.1349, Val MAE: 0.1347
2023-01-24 00:02:10,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-24 00:11:18,894:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11033415794372559
2023-01-24 00:11:18,896:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 548.61s, LR: 0.00009, Train Loss: 0.0893, Train MAE: 0.0893,
                            Val Loss: 0.1105, Val MAE: 0.1103
2023-01-24 00:11:18,897:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-24 00:19:12,814:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.92s, LR: 0.00009, Train Loss: 0.0890, Train MAE: 0.0890,
                            Val Loss: 0.1131, Val MAE: 0.1129
2023-01-24 00:19:12,815:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-24 00:27:06,289:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.47s, LR: 0.00009, Train Loss: 0.0889, Train MAE: 0.0889,
                            Val Loss: 0.1156, Val MAE: 0.1154
2023-01-24 00:27:06,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-24 00:34:57,159:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 470.87s, LR: 0.00009, Train Loss: 0.0888, Train MAE: 0.0888,
                            Val Loss: 0.1107, Val MAE: 0.1106
2023-01-24 00:34:57,161:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-24 00:42:46,755:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 469.59s, LR: 0.00009, Train Loss: 0.0888, Train MAE: 0.0888,
                            Val Loss: 0.1378, Val MAE: 0.1377
2023-01-24 00:42:46,756:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-24 00:50:34,316:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 467.56s, LR: 0.00009, Train Loss: 0.0887, Train MAE: 0.0887,
                            Val Loss: 0.1192, Val MAE: 0.1190
2023-01-24 00:50:34,318:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-24 00:58:22,712:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 468.39s, LR: 0.00009, Train Loss: 0.0886, Train MAE: 0.0886,
                            Val Loss: 0.1125, Val MAE: 0.1123
2023-01-24 00:58:22,713:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-24 01:06:07,834:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 465.12s, LR: 0.00009, Train Loss: 0.0886, Train MAE: 0.0886,
                            Val Loss: 0.1115, Val MAE: 0.1113
2023-01-24 01:06:07,835:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-24 01:13:52,269:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 464.43s, LR: 0.00009, Train Loss: 0.0885, Train MAE: 0.0885,
                            Val Loss: 0.1272, Val MAE: 0.1270
2023-01-24 01:13:52,270:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-24 01:21:35,836:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 463.57s, LR: 0.00009, Train Loss: 0.0885, Train MAE: 0.0885,
                            Val Loss: 0.1111, Val MAE: 0.1109
2023-01-24 01:21:35,837:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-24 01:29:20,601:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 464.76s, LR: 0.00009, Train Loss: 0.0885, Train MAE: 0.0885,
                            Val Loss: 0.1403, Val MAE: 0.1402
2023-01-24 01:29:20,602:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-24 01:37:01,710:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 461.11s, LR: 0.00009, Train Loss: 0.0884, Train MAE: 0.0884,
                            Val Loss: 0.1845, Val MAE: 0.1844
2023-01-24 01:37:01,711:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-24 01:44:43,602:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 461.89s, LR: 0.00009, Train Loss: 0.0884, Train MAE: 0.0884,
                            Val Loss: 0.1274, Val MAE: 0.1272
2023-01-24 01:44:43,603:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-24 01:52:19,717:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 456.11s, LR: 0.00009, Train Loss: 0.0883, Train MAE: 0.0883,
                            Val Loss: 0.1742, Val MAE: 0.1741
2023-01-24 01:52:19,718:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-24 01:59:56,163:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 456.44s, LR: 0.00009, Train Loss: 0.0883, Train MAE: 0.0883,
                            Val Loss: 0.1127, Val MAE: 0.1125
2023-01-24 01:59:56,164:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-24 02:07:31,644:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11027354001998901
2023-01-24 02:07:31,645:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 455.48s, LR: 0.00009, Train Loss: 0.0883, Train MAE: 0.0883,
                            Val Loss: 0.1105, Val MAE: 0.1103
2023-01-24 02:07:31,646:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-24 02:16:18,169:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 526.52s, LR: 0.00009, Train Loss: 0.0882, Train MAE: 0.0882,
                            Val Loss: 0.1125, Val MAE: 0.1123
2023-01-24 02:16:18,171:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 126/1000
2023-01-24 02:23:57,208:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 459.04s, LR: 0.00009, Train Loss: 0.0882, Train MAE: 0.0882,
                            Val Loss: 0.1138, Val MAE: 0.1136
2023-01-24 02:23:57,209:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 127/1000
2023-01-24 02:31:37,636:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 460.43s, LR: 0.00009, Train Loss: 0.0882, Train MAE: 0.0882,
                            Val Loss: 0.1135, Val MAE: 0.1133
2023-01-24 02:31:37,638:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 128/1000
2023-01-24 02:39:17,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 459.40s, LR: 0.00009, Train Loss: 0.0881, Train MAE: 0.0881,
                            Val Loss: 0.1115, Val MAE: 0.1113
2023-01-24 02:39:17,039:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 129/1000
2023-01-24 02:46:55,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 457.97s, LR: 0.00009, Train Loss: 0.0881, Train MAE: 0.0881,
                            Val Loss: 0.1624, Val MAE: 0.1623
2023-01-24 02:46:55,016:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 130/1000
2023-01-24 02:54:33,134:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 458.12s, LR: 0.00009, Train Loss: 0.0880, Train MAE: 0.0880,
                            Val Loss: 0.1324, Val MAE: 0.1322
2023-01-24 02:54:33,135:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 131/1000
2023-01-24 03:02:10,309:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 457.17s, LR: 0.00009, Train Loss: 0.0880, Train MAE: 0.0880,
                            Val Loss: 0.1292, Val MAE: 0.1290
2023-01-24 03:02:10,310:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 132/1000
2023-01-24 03:09:45,906:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 455.59s, LR: 0.00009, Train Loss: 0.0880, Train MAE: 0.0880,
                            Val Loss: 0.1118, Val MAE: 0.1116
2023-01-24 03:09:45,908:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 133/1000
2023-01-24 03:17:20,950:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 455.04s, LR: 0.00009, Train Loss: 0.0879, Train MAE: 0.0879,
                            Val Loss: 0.1167, Val MAE: 0.1165
2023-01-24 03:17:20,952:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 134/1000
2023-01-24 03:24:54,343:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 453.39s, LR: 0.00009, Train Loss: 0.0879, Train MAE: 0.0879,
                            Val Loss: 0.1193, Val MAE: 0.1191
2023-01-24 03:24:54,344:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 135/1000
2023-01-24 03:32:27,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 453.37s, LR: 0.00009, Train Loss: 0.0878, Train MAE: 0.0878,
                            Val Loss: 0.1121, Val MAE: 0.1119
2023-01-24 03:32:27,716:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 136/1000
2023-01-24 03:39:57,863:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 450.15s, LR: 0.00009, Train Loss: 0.0878, Train MAE: 0.0878,
                            Val Loss: 0.1122, Val MAE: 0.1120
2023-01-24 03:39:57,864:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 137/1000
2023-01-24 03:47:28,191:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 450.33s, LR: 0.00009, Train Loss: 0.0878, Train MAE: 0.0878,
                            Val Loss: 0.1238, Val MAE: 0.1236
2023-01-24 03:47:28,193:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 138/1000
2023-01-24 03:54:51,621:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 443.43s, LR: 0.00009, Train Loss: 0.0878, Train MAE: 0.0878,
                            Val Loss: 0.1107, Val MAE: 0.1105
2023-01-24 03:54:51,623:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 139/1000
2023-01-24 04:02:16,459:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 444.83s, LR: 0.00009, Train Loss: 0.0877, Train MAE: 0.0877,
                            Val Loss: 0.1129, Val MAE: 0.1127
2023-01-24 04:02:16,460:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 140/1000
2023-01-24 04:09:37,362:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 440.90s, LR: 0.00009, Train Loss: 0.0877, Train MAE: 0.0877,
                            Val Loss: 0.1172, Val MAE: 0.1170
2023-01-24 04:09:37,364:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 141/1000
2023-01-24 04:16:55,217:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 437.85s, LR: 0.00004, Train Loss: 0.0866, Train MAE: 0.0866,
                            Val Loss: 0.1114, Val MAE: 0.1112
2023-01-24 04:16:55,219:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 142/1000
2023-01-24 04:25:17,597:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10973144322633743
2023-01-24 04:25:17,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 502.38s, LR: 0.00004, Train Loss: 0.0864, Train MAE: 0.0864,
                            Val Loss: 0.1099, Val MAE: 0.1097
2023-01-24 04:25:17,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 143/1000
2023-01-24 04:32:27,340:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1094026118516922
2023-01-24 04:32:27,341:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 429.74s, LR: 0.00004, Train Loss: 0.0864, Train MAE: 0.0864,
                            Val Loss: 0.1096, Val MAE: 0.1094
2023-01-24 04:32:27,342:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 144/1000
2023-01-24 04:39:34,238:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 426.89s, LR: 0.00004, Train Loss: 0.0863, Train MAE: 0.0863,
                            Val Loss: 0.1099, Val MAE: 0.1097
2023-01-24 04:39:34,239:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 145/1000
2023-01-24 04:46:40,612:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 426.37s, LR: 0.00004, Train Loss: 0.0863, Train MAE: 0.0863,
                            Val Loss: 0.1100, Val MAE: 0.1097
2023-01-24 04:46:40,613:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 146/1000
2023-01-24 04:53:43,051:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 422.44s, LR: 0.00004, Train Loss: 0.0863, Train MAE: 0.0863,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-24 04:53:43,053:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 147/1000
2023-01-24 05:00:40,255:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 417.20s, LR: 0.00004, Train Loss: 0.0863, Train MAE: 0.0863,
                            Val Loss: 0.1124, Val MAE: 0.1122
2023-01-24 05:00:40,256:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 148/1000
2023-01-24 05:07:31,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 411.04s, LR: 0.00004, Train Loss: 0.0862, Train MAE: 0.0862,
                            Val Loss: 0.1114, Val MAE: 0.1112
2023-01-24 05:07:31,296:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 149/1000
2023-01-24 05:14:21,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 410.57s, LR: 0.00004, Train Loss: 0.0862, Train MAE: 0.0862,
                            Val Loss: 0.1100, Val MAE: 0.1098
2023-01-24 05:14:21,871:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 150/1000
2023-01-24 05:21:12,093:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 410.22s, LR: 0.00004, Train Loss: 0.0862, Train MAE: 0.0862,
                            Val Loss: 0.1110, Val MAE: 0.1108
2023-01-24 05:21:12,094:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 151/1000
2023-01-24 05:28:02,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 410.20s, LR: 0.00004, Train Loss: 0.0862, Train MAE: 0.0862,
                            Val Loss: 0.1096, Val MAE: 0.1094
2023-01-24 05:28:02,296:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 152/1000
2023-01-24 05:34:52,108:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 409.81s, LR: 0.00004, Train Loss: 0.0862, Train MAE: 0.0862,
                            Val Loss: 0.1100, Val MAE: 0.1098
2023-01-24 05:34:52,110:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 153/1000
2023-01-24 05:41:41,037:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 408.93s, LR: 0.00004, Train Loss: 0.0861, Train MAE: 0.0861,
                            Val Loss: 0.1098, Val MAE: 0.1096
2023-01-24 05:41:41,038:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 154/1000
2023-01-24 05:48:30,322:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 409.28s, LR: 0.00004, Train Loss: 0.0861, Train MAE: 0.0861,
                            Val Loss: 0.1099, Val MAE: 0.1097
2023-01-24 05:48:30,323:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 155/1000
2023-01-24 05:55:24,556:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 414.23s, LR: 0.00004, Train Loss: 0.0861, Train MAE: 0.0861,
                            Val Loss: 0.1128, Val MAE: 0.1127
2023-01-24 05:55:24,558:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 156/1000
2023-01-24 06:02:15,371:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 410.81s, LR: 0.00004, Train Loss: 0.0860, Train MAE: 0.0860,
                            Val Loss: 0.1126, Val MAE: 0.1125
2023-01-24 06:02:15,372:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 157/1000
2023-01-24 06:09:03,606:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 408.23s, LR: 0.00004, Train Loss: 0.0861, Train MAE: 0.0861,
                            Val Loss: 0.1107, Val MAE: 0.1105
2023-01-24 06:09:03,608:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 158/1000
2023-01-24 06:15:52,167:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 408.56s, LR: 0.00004, Train Loss: 0.0860, Train MAE: 0.0860,
                            Val Loss: 0.1139, Val MAE: 0.1137
2023-01-24 06:15:52,168:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 159/1000
2023-01-24 06:23:45,760:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.59s, LR: 0.00004, Train Loss: 0.0860, Train MAE: 0.0860,
                            Val Loss: 0.1102, Val MAE: 0.1100
2023-01-24 06:23:45,762:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 160/1000
2023-01-24 06:30:34,441:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 408.68s, LR: 0.00002, Train Loss: 0.0854, Train MAE: 0.0854,
                            Val Loss: 0.1101, Val MAE: 0.1098
2023-01-24 06:30:34,442:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 161/1000
2023-01-24 06:37:22,554:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10901585966348648
2023-01-24 06:37:22,555:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 408.11s, LR: 0.00002, Train Loss: 0.0853, Train MAE: 0.0853,
                            Val Loss: 0.1092, Val MAE: 0.1090
2023-01-24 06:37:22,556:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 162/1000
2023-01-24 06:44:11,603:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 409.05s, LR: 0.00002, Train Loss: 0.0853, Train MAE: 0.0853,
                            Val Loss: 0.1124, Val MAE: 0.1122
2023-01-24 06:44:11,604:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 163/1000
2023-01-24 06:51:05,630:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 414.03s, LR: 0.00002, Train Loss: 0.0853, Train MAE: 0.0853,
                            Val Loss: 0.1106, Val MAE: 0.1105
2023-01-24 06:51:05,632:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 164/1000
2023-01-24 06:57:59,522:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10881245136260986
2023-01-24 06:57:59,523:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 413.89s, LR: 0.00002, Train Loss: 0.0853, Train MAE: 0.0853,
                            Val Loss: 0.1090, Val MAE: 0.1088
2023-01-24 06:57:59,524:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-24 06:57:59,526:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-24 07:02:40,515:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1088
2023-01-24 07:02:40,516:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0840
2023-01-24 07:02:40,517:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-24 07:02:40,518:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 163.0000
2023-01-24 07:02:40,519:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 86703.2812s
2023-01-24 07:02:40,519:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 501.4394s
2023-01-24 07:02:40,577:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-initials100-topn-trials', 'job_num': 32}
2023-01-24 07:02:40,590:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0840)]
2023-01-24 07:02:40,591:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1088)]
