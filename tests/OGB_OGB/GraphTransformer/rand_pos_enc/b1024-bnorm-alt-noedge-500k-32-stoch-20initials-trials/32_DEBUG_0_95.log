2023-01-25 05:11:54,547:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-25 05:11:54,547:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:25:57,967:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:26:27,880:ogbdata.py:332 -             __init__(): Time taken: 873.3326s
2023-01-25 05:26:27,881:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:26:27,881:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:26:27,881:ogbdata.py:348 -             __init__(): [I] Data load time: 873.3333s
2023-01-25 05:26:27,881:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-25 05:26:27,881:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials', 'job_num': 32}
2023-01-25 05:26:27,883:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:26:34,413:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:26:34,414:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:26:34,414:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:26:34,429:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:26:34,432:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-25 05:26:34,432:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-25 05:26:34,432:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:26:34,434:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:26:34,434:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:26:34,434:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:26:34,454:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:37:28,776:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4254.34419465065
2023-01-25 06:37:28,784:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:37:28,784:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:37:28,934:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:51:04,408:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.35923171043396
2023-01-25 06:51:04,411:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 815.48s, LR: 0.00070, Train Loss: 0.7437, Train MAE: 0.7437,
                            Val Loss: 1.3595, Val MAE: 1.3592
2023-01-25 06:51:04,411:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 07:02:17,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.30s, LR: 0.00070, Train Loss: 0.5460, Train MAE: 0.5460,
                            Val Loss: 1.5447, Val MAE: 1.5444
2023-01-25 07:02:17,715:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:13:30,154:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.0747398138046265
2023-01-25 07:13:30,157:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.44s, LR: 0.00070, Train Loss: 0.4783, Train MAE: 0.4783,
                            Val Loss: 1.0750, Val MAE: 1.0747
2023-01-25 07:13:30,158:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:24:42,320:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.16s, LR: 0.00070, Train Loss: 0.4400, Train MAE: 0.4400,
                            Val Loss: 1.3445, Val MAE: 1.3444
2023-01-25 07:24:42,321:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:35:55,283:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9931066632270813
2023-01-25 07:35:55,285:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.96s, LR: 0.00070, Train Loss: 0.4961, Train MAE: 0.4961,
                            Val Loss: 0.9932, Val MAE: 0.9931
2023-01-25 07:35:55,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:47:08,203:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.92s, LR: 0.00070, Train Loss: 0.5132, Train MAE: 0.5132,
                            Val Loss: 1.1898, Val MAE: 1.1897
2023-01-25 07:47:08,205:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 07:58:20,958:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9930532574653625
2023-01-25 07:58:20,961:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.75s, LR: 0.00070, Train Loss: 0.5537, Train MAE: 0.5537,
                            Val Loss: 0.9933, Val MAE: 0.9931
2023-01-25 07:58:20,961:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 08:10:41,480:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.52s, LR: 0.00070, Train Loss: 0.5812, Train MAE: 0.5812,
                            Val Loss: 1.1819, Val MAE: 1.1815
2023-01-25 08:10:41,482:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:21:55,429:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9901941418647766
2023-01-25 08:21:55,431:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.95s, LR: 0.00070, Train Loss: 0.5817, Train MAE: 0.5817,
                            Val Loss: 0.9903, Val MAE: 0.9902
2023-01-25 08:21:55,432:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:33:08,013:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.6762031316757202
2023-01-25 08:33:08,015:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.58s, LR: 0.00070, Train Loss: 0.5305, Train MAE: 0.5305,
                            Val Loss: 0.6763, Val MAE: 0.6762
2023-01-25 08:33:08,016:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:44:20,484:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.47s, LR: 0.00070, Train Loss: 0.5121, Train MAE: 0.5121,
                            Val Loss: 1.2020, Val MAE: 1.2018
2023-01-25 08:44:20,486:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 08:55:32,425:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.94s, LR: 0.00070, Train Loss: 0.4912, Train MAE: 0.4912,
                            Val Loss: 1.0282, Val MAE: 1.0280
2023-01-25 08:55:32,426:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 09:06:43,944:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.52s, LR: 0.00070, Train Loss: 0.4708, Train MAE: 0.4708,
                            Val Loss: 1.3889, Val MAE: 1.3885
2023-01-25 09:06:43,946:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:17:54,867:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.92s, LR: 0.00070, Train Loss: 0.4763, Train MAE: 0.4763,
                            Val Loss: 0.7954, Val MAE: 0.7955
2023-01-25 09:17:54,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:29:06,136:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.27s, LR: 0.00070, Train Loss: 0.4680, Train MAE: 0.4680,
                            Val Loss: 1.1231, Val MAE: 1.1225
2023-01-25 09:29:06,138:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:40:16,441:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.30s, LR: 0.00070, Train Loss: 0.4592, Train MAE: 0.4592,
                            Val Loss: 1.3049, Val MAE: 1.3045
2023-01-25 09:40:16,442:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 09:51:39,010:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.57s, LR: 0.00070, Train Loss: 0.4466, Train MAE: 0.4466,
                            Val Loss: 0.7484, Val MAE: 0.7481
2023-01-25 09:51:39,011:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 10:03:21,191:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.18s, LR: 0.00070, Train Loss: 0.4834, Train MAE: 0.4834,
                            Val Loss: 1.0127, Val MAE: 1.0126
2023-01-25 10:03:21,192:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 10:15:09,918:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5646641850471497
2023-01-25 10:15:09,920:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.73s, LR: 0.00070, Train Loss: 0.5360, Train MAE: 0.5360,
                            Val Loss: 0.5649, Val MAE: 0.5647
2023-01-25 10:15:09,920:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:26:52,222:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.30s, LR: 0.00070, Train Loss: 0.4741, Train MAE: 0.4741,
                            Val Loss: 1.1376, Val MAE: 1.1373
2023-01-25 10:26:52,224:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 10:38:32,324:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.10s, LR: 0.00070, Train Loss: 0.4583, Train MAE: 0.4583,
                            Val Loss: 1.4538, Val MAE: 1.4535
2023-01-25 10:38:32,325:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 10:50:02,537:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.21s, LR: 0.00070, Train Loss: 0.4432, Train MAE: 0.4432,
                            Val Loss: 1.4866, Val MAE: 1.4863
2023-01-25 10:50:02,538:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 11:01:36,294:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.75s, LR: 0.00070, Train Loss: 0.4330, Train MAE: 0.4330,
                            Val Loss: 0.9923, Val MAE: 0.9921
2023-01-25 11:01:36,295:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 11:14:28,028:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.73s, LR: 0.00070, Train Loss: 0.4180, Train MAE: 0.4180,
                            Val Loss: 1.1016, Val MAE: 1.1014
2023-01-25 11:14:28,031:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:26:07,115:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.08s, LR: 0.00070, Train Loss: 0.4131, Train MAE: 0.4131,
                            Val Loss: 0.8789, Val MAE: 0.8790
2023-01-25 11:26:07,116:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 11:37:46,578:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.46s, LR: 0.00070, Train Loss: 0.4046, Train MAE: 0.4046,
                            Val Loss: 1.1509, Val MAE: 1.1507
2023-01-25 11:37:46,580:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 11:49:18,140:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.56s, LR: 0.00070, Train Loss: 0.4123, Train MAE: 0.4123,
                            Val Loss: 1.3577, Val MAE: 1.3573
2023-01-25 11:49:18,141:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 12:00:46,628:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.49s, LR: 0.00070, Train Loss: 0.4082, Train MAE: 0.4082,
                            Val Loss: 1.2798, Val MAE: 1.2796
2023-01-25 12:00:46,629:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 12:12:26,382:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.75s, LR: 0.00070, Train Loss: 0.3991, Train MAE: 0.3991,
                            Val Loss: 0.6347, Val MAE: 0.6343
2023-01-25 12:12:26,382:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 12:24:00,912:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.53s, LR: 0.00070, Train Loss: 0.4025, Train MAE: 0.4025,
                            Val Loss: 0.8403, Val MAE: 0.8402
2023-01-25 12:24:00,913:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 12:35:30,864:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.95s, LR: 0.00070, Train Loss: 0.3957, Train MAE: 0.3957,
                            Val Loss: 1.1461, Val MAE: 1.1458
2023-01-25 12:35:30,865:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 12:47:10,775:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.91s, LR: 0.00070, Train Loss: 0.3828, Train MAE: 0.3828,
                            Val Loss: 1.0634, Val MAE: 1.0632
2023-01-25 12:47:10,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 12:58:47,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.19s, LR: 0.00070, Train Loss: 0.3815, Train MAE: 0.3815,
                            Val Loss: 0.6177, Val MAE: 0.6174
2023-01-25 12:58:47,973:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 13:10:25,622:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.65s, LR: 0.00070, Train Loss: 0.3795, Train MAE: 0.3795,
                            Val Loss: 1.4552, Val MAE: 1.4548
2023-01-25 13:10:25,623:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 13:22:00,446:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.82s, LR: 0.00070, Train Loss: 0.3776, Train MAE: 0.3776,
                            Val Loss: 1.2836, Val MAE: 1.2833
2023-01-25 13:22:00,447:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 13:33:34,467:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.02s, LR: 0.00035, Train Loss: 0.3666, Train MAE: 0.3666,
                            Val Loss: 0.6943, Val MAE: 0.6941
2023-01-25 13:33:34,468:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 13:45:55,385:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.92s, LR: 0.00035, Train Loss: 0.3654, Train MAE: 0.3654,
                            Val Loss: 0.5974, Val MAE: 0.5972
2023-01-25 13:45:55,386:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 13:58:15,632:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.24s, LR: 0.00035, Train Loss: 0.3590, Train MAE: 0.3590,
                            Val Loss: 0.6210, Val MAE: 0.6209
2023-01-25 13:58:15,719:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 14:10:32,155:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 736.44s, LR: 0.00035, Train Loss: 0.3526, Train MAE: 0.3526,
                            Val Loss: 1.2651, Val MAE: 1.2651
2023-01-25 14:10:32,230:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 14:22:18,363:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.13s, LR: 0.00035, Train Loss: 0.3511, Train MAE: 0.3511,
                            Val Loss: 1.1211, Val MAE: 1.1211
2023-01-25 14:22:18,364:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 14:34:44,488:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.12s, LR: 0.00035, Train Loss: 0.3671, Train MAE: 0.3671,
                            Val Loss: 0.9143, Val MAE: 0.9141
2023-01-25 14:34:44,489:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 14:46:07,436:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.95s, LR: 0.00035, Train Loss: 0.3572, Train MAE: 0.3572,
                            Val Loss: 0.7407, Val MAE: 0.7405
2023-01-25 14:46:07,438:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 14:57:35,746:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.31s, LR: 0.00035, Train Loss: 0.3572, Train MAE: 0.3572,
                            Val Loss: 1.4930, Val MAE: 1.4926
2023-01-25 14:57:35,747:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 15:08:51,342:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.59s, LR: 0.00035, Train Loss: 0.3491, Train MAE: 0.3491,
                            Val Loss: 0.8492, Val MAE: 0.8493
2023-01-25 15:08:51,343:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 15:19:41,103:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.76s, LR: 0.00035, Train Loss: 0.3479, Train MAE: 0.3479,
                            Val Loss: 1.3812, Val MAE: 1.3812
2023-01-25 15:19:41,104:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 15:30:31,104:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5091171860694885
2023-01-25 15:30:31,106:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.00s, LR: 0.00035, Train Loss: 0.3442, Train MAE: 0.3442,
                            Val Loss: 0.5093, Val MAE: 0.5091
2023-01-25 15:30:31,107:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 15:41:21,217:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.43521183729171753
2023-01-25 15:41:21,219:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.11s, LR: 0.00035, Train Loss: 0.3401, Train MAE: 0.3401,
                            Val Loss: 0.4353, Val MAE: 0.4352
2023-01-25 15:41:21,219:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 15:52:11,859:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.64s, LR: 0.00035, Train Loss: 0.3358, Train MAE: 0.3358,
                            Val Loss: 0.4833, Val MAE: 0.4833
2023-01-25 15:52:11,860:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 16:03:02,442:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.58s, LR: 0.00035, Train Loss: 0.3363, Train MAE: 0.3363,
                            Val Loss: 1.1433, Val MAE: 1.1434
2023-01-25 16:03:02,444:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 16:13:52,580:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.14s, LR: 0.00035, Train Loss: 0.3603, Train MAE: 0.3603,
                            Val Loss: 1.1906, Val MAE: 1.1905
2023-01-25 16:13:52,581:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 16:24:46,666:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.08s, LR: 0.00035, Train Loss: 0.3602, Train MAE: 0.3602,
                            Val Loss: 0.4648, Val MAE: 0.4647
2023-01-25 16:24:46,677:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 16:35:39,289:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.61s, LR: 0.00035, Train Loss: 0.3455, Train MAE: 0.3455,
                            Val Loss: 0.4411, Val MAE: 0.4409
2023-01-25 16:35:39,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 16:46:29,723:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.43s, LR: 0.00035, Train Loss: 0.3385, Train MAE: 0.3385,
                            Val Loss: 0.6252, Val MAE: 0.6252
2023-01-25 16:46:29,725:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 16:57:22,829:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.10s, LR: 0.00035, Train Loss: 0.3335, Train MAE: 0.3335,
                            Val Loss: 0.5707, Val MAE: 0.5707
2023-01-25 16:57:22,845:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 17:08:21,175:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3988615572452545
2023-01-25 17:08:21,191:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.35s, LR: 0.00035, Train Loss: 0.3378, Train MAE: 0.3378,
                            Val Loss: 0.3990, Val MAE: 0.3989
2023-01-25 17:08:21,192:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 17:19:19,097:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.90s, LR: 0.00035, Train Loss: 0.3339, Train MAE: 0.3339,
                            Val Loss: 0.5033, Val MAE: 0.5032
2023-01-25 17:19:19,099:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 17:30:16,970:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.87s, LR: 0.00035, Train Loss: 0.3349, Train MAE: 0.3349,
                            Val Loss: 0.7538, Val MAE: 0.7540
2023-01-25 17:30:16,971:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 17:42:16,642:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.67s, LR: 0.00035, Train Loss: 0.3446, Train MAE: 0.3446,
                            Val Loss: 0.4356, Val MAE: 0.4355
2023-01-25 17:42:16,644:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 17:53:15,140:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.50s, LR: 0.00035, Train Loss: 0.3196, Train MAE: 0.3196,
                            Val Loss: 1.1719, Val MAE: 1.1721
2023-01-25 17:53:15,141:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 18:04:13,210:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.07s, LR: 0.00035, Train Loss: 0.3557, Train MAE: 0.3557,
                            Val Loss: 0.9992, Val MAE: 0.9992
2023-01-25 18:04:13,211:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 18:15:10,980:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.77s, LR: 0.00035, Train Loss: 0.3274, Train MAE: 0.3274,
                            Val Loss: 0.5236, Val MAE: 0.5236
2023-01-25 18:15:10,981:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 18:26:09,182:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.20s, LR: 0.00035, Train Loss: 0.3085, Train MAE: 0.3085,
                            Val Loss: 0.4683, Val MAE: 0.4683
2023-01-25 18:26:09,183:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 18:37:07,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.55s, LR: 0.00035, Train Loss: 0.2988, Train MAE: 0.2988,
                            Val Loss: 0.9029, Val MAE: 0.9033
2023-01-25 18:37:07,731:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 18:48:05,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.61s, LR: 0.00035, Train Loss: 0.3129, Train MAE: 0.3129,
                            Val Loss: 0.5721, Val MAE: 0.5721
2023-01-25 18:48:05,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 18:59:03,330:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.99s, LR: 0.00035, Train Loss: 0.3175, Train MAE: 0.3175,
                            Val Loss: 0.4014, Val MAE: 0.4012
2023-01-25 18:59:03,331:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 19:09:47,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.60s, LR: 0.00035, Train Loss: 0.3296, Train MAE: 0.3296,
                            Val Loss: 0.4146, Val MAE: 0.4145
2023-01-25 19:09:47,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 19:20:32,423:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.49s, LR: 0.00035, Train Loss: 0.3071, Train MAE: 0.3071,
                            Val Loss: 0.6823, Val MAE: 0.6824
2023-01-25 19:20:32,425:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 19:31:16,619:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.19s, LR: 0.00035, Train Loss: 0.3000, Train MAE: 0.3000,
                            Val Loss: 0.4263, Val MAE: 0.4260
2023-01-25 19:31:16,621:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 19:42:57,921:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.30s, LR: 0.00035, Train Loss: 0.3207, Train MAE: 0.3207,
                            Val Loss: 0.5175, Val MAE: 0.5175
2023-01-25 19:42:57,922:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 19:55:16,078:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.15s, LR: 0.00035, Train Loss: 0.3084, Train MAE: 0.3084,
                            Val Loss: 0.5595, Val MAE: 0.5593
2023-01-25 19:55:16,079:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 20:07:40,783:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.70s, LR: 0.00035, Train Loss: 0.2990, Train MAE: 0.2990,
                            Val Loss: 0.7471, Val MAE: 0.7473
2023-01-25 20:07:40,785:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 20:19:54,851:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.06s, LR: 0.00017, Train Loss: 0.2834, Train MAE: 0.2834,
                            Val Loss: 0.7289, Val MAE: 0.7291
2023-01-25 20:19:54,852:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 20:32:12,162:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.31s, LR: 0.00017, Train Loss: 0.2772, Train MAE: 0.2772,
                            Val Loss: 0.6787, Val MAE: 0.6789
2023-01-25 20:32:12,163:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 20:44:29,248:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.08s, LR: 0.00017, Train Loss: 0.2738, Train MAE: 0.2738,
                            Val Loss: 0.5785, Val MAE: 0.5787
2023-01-25 20:44:29,250:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 20:57:52,878:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 803.63s, LR: 0.00017, Train Loss: 0.2730, Train MAE: 0.2730,
                            Val Loss: 0.8179, Val MAE: 0.8182
2023-01-25 20:57:52,879:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 21:10:12,646:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.77s, LR: 0.00017, Train Loss: 0.2707, Train MAE: 0.2707,
                            Val Loss: 0.6875, Val MAE: 0.6877
2023-01-25 21:10:12,647:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 21:22:26,672:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 734.02s, LR: 0.00017, Train Loss: 0.2727, Train MAE: 0.2727,
                            Val Loss: 0.4669, Val MAE: 0.4668
2023-01-25 21:22:26,673:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 21:33:52,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.62s, LR: 0.00017, Train Loss: 0.2693, Train MAE: 0.2693,
                            Val Loss: 0.4104, Val MAE: 0.4104
2023-01-25 21:33:52,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-25 21:45:38,137:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.84s, LR: 0.00017, Train Loss: 0.2672, Train MAE: 0.2672,
                            Val Loss: 0.6500, Val MAE: 0.6502
2023-01-25 21:45:38,138:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-25 21:57:03,853:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.71s, LR: 0.00017, Train Loss: 0.2680, Train MAE: 0.2680,
                            Val Loss: 0.7070, Val MAE: 0.7072
2023-01-25 21:57:03,855:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-25 22:08:35,772:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.92s, LR: 0.00017, Train Loss: 0.2661, Train MAE: 0.2661,
                            Val Loss: 0.7154, Val MAE: 0.7155
2023-01-25 22:08:35,773:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-25 22:20:20,753:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 704.98s, LR: 0.00017, Train Loss: 0.2652, Train MAE: 0.2652,
                            Val Loss: 0.5888, Val MAE: 0.5889
2023-01-25 22:20:20,755:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-25 22:32:06,597:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.84s, LR: 0.00017, Train Loss: 0.2642, Train MAE: 0.2642,
                            Val Loss: 0.7647, Val MAE: 0.7649
2023-01-25 22:32:06,597:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-25 22:43:42,602:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.00s, LR: 0.00017, Train Loss: 0.2620, Train MAE: 0.2620,
                            Val Loss: 0.5231, Val MAE: 0.5231
2023-01-25 22:43:42,603:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-25 22:55:23,326:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.72s, LR: 0.00017, Train Loss: 0.2607, Train MAE: 0.2607,
                            Val Loss: 0.7615, Val MAE: 0.7617
2023-01-25 22:55:23,327:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-25 23:07:14,360:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 711.03s, LR: 0.00017, Train Loss: 0.2588, Train MAE: 0.2588,
                            Val Loss: 0.7669, Val MAE: 0.7672
2023-01-25 23:07:15,353:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-25 23:18:56,899:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.54s, LR: 0.00017, Train Loss: 0.2622, Train MAE: 0.2622,
                            Val Loss: 0.4214, Val MAE: 0.4213
2023-01-25 23:18:56,900:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-25 23:31:08,693:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3590114116668701
2023-01-25 23:31:08,695:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 731.79s, LR: 0.00009, Train Loss: 0.2524, Train MAE: 0.2524,
                            Val Loss: 0.3591, Val MAE: 0.3590
2023-01-25 23:31:08,696:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-25 23:42:38,400:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.70s, LR: 0.00009, Train Loss: 0.2508, Train MAE: 0.2508,
                            Val Loss: 0.6511, Val MAE: 0.6513
2023-01-25 23:42:38,400:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-25 23:54:00,678:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.28s, LR: 0.00009, Train Loss: 0.2505, Train MAE: 0.2505,
                            Val Loss: 0.4994, Val MAE: 0.4994
2023-01-25 23:54:00,679:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-26 00:05:32,687:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.01s, LR: 0.00009, Train Loss: 0.2672, Train MAE: 0.2672,
                            Val Loss: 0.4034, Val MAE: 0.4032
2023-01-26 00:05:32,688:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-26 00:18:08,250:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 755.56s, LR: 0.00009, Train Loss: 0.2663, Train MAE: 0.2663,
                            Val Loss: 0.6744, Val MAE: 0.6746
2023-01-26 00:18:08,252:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-26 00:29:35,546:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.29s, LR: 0.00009, Train Loss: 0.2514, Train MAE: 0.2514,
                            Val Loss: 0.6892, Val MAE: 0.6894
2023-01-26 00:29:35,546:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-26 00:41:11,842:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.29s, LR: 0.00009, Train Loss: 0.2502, Train MAE: 0.2502,
                            Val Loss: 0.5179, Val MAE: 0.5179
2023-01-26 00:41:11,843:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-26 00:52:51,646:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.80s, LR: 0.00009, Train Loss: 0.2489, Train MAE: 0.2489,
                            Val Loss: 0.5498, Val MAE: 0.5499
2023-01-26 00:52:51,647:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-26 01:04:08,194:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.33310097455978394
2023-01-26 01:04:08,196:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.55s, LR: 0.00009, Train Loss: 0.2482, Train MAE: 0.2482,
                            Val Loss: 0.3332, Val MAE: 0.3331
2023-01-26 01:04:08,197:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 01:14:59,411:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.21s, LR: 0.00009, Train Loss: 0.2475, Train MAE: 0.2475,
                            Val Loss: 0.5151, Val MAE: 0.5152
2023-01-26 01:14:59,412:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 01:25:50,674:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.26s, LR: 0.00009, Train Loss: 0.2475, Train MAE: 0.2475,
                            Val Loss: 0.5428, Val MAE: 0.5429
2023-01-26 01:25:50,675:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 01:36:40,039:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.36s, LR: 0.00009, Train Loss: 0.2465, Train MAE: 0.2465,
                            Val Loss: 0.6728, Val MAE: 0.6729
2023-01-26 01:36:40,040:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 01:47:29,092:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.05s, LR: 0.00009, Train Loss: 0.2455, Train MAE: 0.2455,
                            Val Loss: 0.6905, Val MAE: 0.6907
2023-01-26 01:47:29,094:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 01:58:18,638:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.54s, LR: 0.00009, Train Loss: 0.2452, Train MAE: 0.2452,
                            Val Loss: 0.6490, Val MAE: 0.6492
2023-01-26 01:58:18,639:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 02:09:08,523:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.88s, LR: 0.00009, Train Loss: 0.2445, Train MAE: 0.2445,
                            Val Loss: 0.7267, Val MAE: 0.7269
2023-01-26 02:09:08,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 02:19:58,468:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.94s, LR: 0.00009, Train Loss: 0.2442, Train MAE: 0.2442,
                            Val Loss: 0.3840, Val MAE: 0.3839
2023-01-26 02:19:58,470:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-26 02:30:48,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.57s, LR: 0.00009, Train Loss: 0.2438, Train MAE: 0.2438,
                            Val Loss: 0.5333, Val MAE: 0.5334
2023-01-26 02:30:48,039:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-26 02:41:37,389:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.35s, LR: 0.00009, Train Loss: 0.2432, Train MAE: 0.2432,
                            Val Loss: 0.5096, Val MAE: 0.5096
2023-01-26 02:41:37,390:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-26 02:52:27,704:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.31s, LR: 0.00009, Train Loss: 0.2428, Train MAE: 0.2428,
                            Val Loss: 0.5422, Val MAE: 0.5422
2023-01-26 02:52:27,704:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-26 03:03:17,511:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.81s, LR: 0.00009, Train Loss: 0.2424, Train MAE: 0.2424,
                            Val Loss: 0.3361, Val MAE: 0.3360
2023-01-26 03:03:17,512:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-26 03:15:05,583:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.07s, LR: 0.00009, Train Loss: 0.2421, Train MAE: 0.2421,
                            Val Loss: 0.5124, Val MAE: 0.5124
2023-01-26 03:15:05,584:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-26 03:26:03,631:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.05s, LR: 0.00009, Train Loss: 0.2417, Train MAE: 0.2417,
                            Val Loss: 0.6210, Val MAE: 0.6211
2023-01-26 03:26:03,632:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-26 03:37:25,808:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.18s, LR: 0.00009, Train Loss: 0.2412, Train MAE: 0.2412,
                            Val Loss: 0.5050, Val MAE: 0.5050
2023-01-26 03:37:25,808:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-26 03:49:14,919:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.11s, LR: 0.00009, Train Loss: 0.2410, Train MAE: 0.2410,
                            Val Loss: 0.7523, Val MAE: 0.7525
2023-01-26 03:49:14,920:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-26 04:00:19,230:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.31s, LR: 0.00009, Train Loss: 0.2405, Train MAE: 0.2405,
                            Val Loss: 0.6804, Val MAE: 0.6806
2023-01-26 04:00:19,231:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-26 04:12:20,102:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.87s, LR: 0.00004, Train Loss: 0.2375, Train MAE: 0.2375,
                            Val Loss: 0.4983, Val MAE: 0.4984
2023-01-26 04:12:20,103:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-26 04:24:21,256:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.15s, LR: 0.00004, Train Loss: 0.2369, Train MAE: 0.2369,
                            Val Loss: 0.5596, Val MAE: 0.5597
2023-01-26 04:24:21,257:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-26 04:36:21,690:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.43s, LR: 0.00004, Train Loss: 0.2368, Train MAE: 0.2368,
                            Val Loss: 0.4948, Val MAE: 0.4948
2023-01-26 04:36:21,691:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-26 04:48:22,203:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.51s, LR: 0.00004, Train Loss: 0.2366, Train MAE: 0.2366,
                            Val Loss: 0.4688, Val MAE: 0.4688
2023-01-26 04:48:22,204:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-26 04:59:30,216:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.01s, LR: 0.00004, Train Loss: 0.2363, Train MAE: 0.2363,
                            Val Loss: 0.5655, Val MAE: 0.5656
2023-01-26 04:59:30,216:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-26 05:11:31,245:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.03s, LR: 0.00004, Train Loss: 0.2362, Train MAE: 0.2362,
                            Val Loss: 0.6044, Val MAE: 0.6046
2023-01-26 05:11:31,246:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-26 05:23:31,581:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.33s, LR: 0.00004, Train Loss: 0.2359, Train MAE: 0.2359,
                            Val Loss: 0.6923, Val MAE: 0.6925
2023-01-26 05:23:31,582:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-26 05:35:31,710:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.13s, LR: 0.00004, Train Loss: 0.2356, Train MAE: 0.2356,
                            Val Loss: 0.5173, Val MAE: 0.5174
2023-01-26 05:35:31,711:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:35:31,711:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-26 05:43:24,502:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.5174
2023-01-26 05:43:24,503:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.4936
2023-01-26 05:43:24,504:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-26 05:43:24,506:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 119.0000
2023-01-26 05:43:24,506:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87410.0741s
2023-01-26 05:43:24,512:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 689.0226s
2023-01-26 05:43:24,553:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials', 'job_num': 32}
2023-01-26 05:43:24,722:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.4936)]
2023-01-26 05:43:24,723:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.5174)]
