2023-01-25 05:10:34,373:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-25 05:10:34,373:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:21:42,758:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:22:22,919:ogbdata.py:332 -             __init__(): Time taken: 708.5457s
2023-01-25 05:22:22,919:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:22:22,919:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:22:22,919:ogbdata.py:348 -             __init__(): [I] Data load time: 708.5463s
2023-01-25 05:22:22,920:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials/32_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-25 05:22:22,920:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials', 'job_num': 32}
2023-01-25 05:22:22,922:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:22:29,750:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:22:29,750:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:22:29,750:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:22:29,827:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:22:29,840:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-25 05:22:29,841:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-25 05:22:29,841:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:22:29,843:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:22:29,843:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:22:29,843:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:22:29,867:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:39:25,623:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4615.782415628433
2023-01-25 06:39:25,656:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:39:25,656:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:39:25,677:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:55:08,122:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 2.1000711917877197
2023-01-25 06:55:08,125:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 942.45s, LR: 0.00070, Train Loss: 0.6214, Train MAE: 0.6214,
                            Val Loss: 2.1005, Val MAE: 2.1001
2023-01-25 06:55:08,125:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 07:07:32,669:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.4558019638061523
2023-01-25 07:07:32,671:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.55s, LR: 0.00070, Train Loss: 0.4390, Train MAE: 0.4390,
                            Val Loss: 1.4563, Val MAE: 1.4558
2023-01-25 07:07:32,672:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:19:56,694:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.4496455192565918
2023-01-25 07:19:56,697:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.02s, LR: 0.00070, Train Loss: 0.4043, Train MAE: 0.4043,
                            Val Loss: 1.4499, Val MAE: 1.4496
2023-01-25 07:19:56,698:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:32:20,358:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.1506425142288208
2023-01-25 07:32:20,360:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 743.66s, LR: 0.00070, Train Loss: 0.5102, Train MAE: 0.5102,
                            Val Loss: 1.1508, Val MAE: 1.1506
2023-01-25 07:32:20,361:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:44:45,028:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.67s, LR: 0.00070, Train Loss: 0.4384, Train MAE: 0.4384,
                            Val Loss: 1.1918, Val MAE: 1.1915
2023-01-25 07:44:45,029:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:57:09,486:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8963027596473694
2023-01-25 07:57:09,489:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.46s, LR: 0.00070, Train Loss: 0.3955, Train MAE: 0.3955,
                            Val Loss: 0.8966, Val MAE: 0.8963
2023-01-25 07:57:09,490:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 08:08:52,081:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.59s, LR: 0.00070, Train Loss: 0.3674, Train MAE: 0.3674,
                            Val Loss: 1.0754, Val MAE: 1.0755
2023-01-25 08:08:52,083:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 08:21:14,843:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5462595820426941
2023-01-25 08:21:14,846:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.76s, LR: 0.00070, Train Loss: 0.3542, Train MAE: 0.3542,
                            Val Loss: 0.5465, Val MAE: 0.5463
2023-01-25 08:21:14,846:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:32:28,406:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.56s, LR: 0.00070, Train Loss: 0.4444, Train MAE: 0.4444,
                            Val Loss: 1.2500, Val MAE: 1.2499
2023-01-25 08:32:28,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:44:08,947:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.54s, LR: 0.00070, Train Loss: 0.3603, Train MAE: 0.3603,
                            Val Loss: 1.3437, Val MAE: 1.3435
2023-01-25 08:44:08,948:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:56:31,897:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.95s, LR: 0.00070, Train Loss: 0.3394, Train MAE: 0.3394,
                            Val Loss: 1.2418, Val MAE: 1.2417
2023-01-25 08:56:31,899:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 09:08:54,777:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.88s, LR: 0.00070, Train Loss: 0.5373, Train MAE: 0.5373,
                            Val Loss: 1.0566, Val MAE: 1.0564
2023-01-25 09:08:54,778:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 09:21:17,916:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 743.14s, LR: 0.00070, Train Loss: 0.4913, Train MAE: 0.4913,
                            Val Loss: 1.1352, Val MAE: 1.1351
2023-01-25 09:21:17,917:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:33:40,382:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.46s, LR: 0.00070, Train Loss: 0.4209, Train MAE: 0.4209,
                            Val Loss: 1.4346, Val MAE: 1.4338
2023-01-25 09:33:40,383:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:45:15,331:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.95s, LR: 0.00070, Train Loss: 0.3903, Train MAE: 0.3903,
                            Val Loss: 0.7651, Val MAE: 0.7646
2023-01-25 09:45:15,332:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:56:27,793:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.46s, LR: 0.00070, Train Loss: 0.3750, Train MAE: 0.3750,
                            Val Loss: 1.1774, Val MAE: 1.1773
2023-01-25 09:56:27,795:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 10:07:39,074:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.28s, LR: 0.00070, Train Loss: 0.3736, Train MAE: 0.3736,
                            Val Loss: 0.8083, Val MAE: 0.8082
2023-01-25 10:07:39,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 10:19:27,397:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.32s, LR: 0.00070, Train Loss: 0.3613, Train MAE: 0.3613,
                            Val Loss: 1.9047, Val MAE: 1.9040
2023-01-25 10:19:27,398:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 10:31:49,578:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.18s, LR: 0.00070, Train Loss: 0.3548, Train MAE: 0.3548,
                            Val Loss: 0.9275, Val MAE: 0.9272
2023-01-25 10:31:49,580:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:44:12,097:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.52s, LR: 0.00070, Train Loss: 0.3499, Train MAE: 0.3499,
                            Val Loss: 1.0428, Val MAE: 1.0428
2023-01-25 10:44:12,099:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 10:56:25,739:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 733.64s, LR: 0.00070, Train Loss: 0.3406, Train MAE: 0.3406,
                            Val Loss: 0.9365, Val MAE: 0.9365
2023-01-25 10:56:25,740:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 11:07:37,182:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.44s, LR: 0.00070, Train Loss: 0.3391, Train MAE: 0.3391,
                            Val Loss: 0.8379, Val MAE: 0.8378
2023-01-25 11:07:37,183:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 11:18:48,358:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.17s, LR: 0.00070, Train Loss: 0.3289, Train MAE: 0.3289,
                            Val Loss: 0.7601, Val MAE: 0.7601
2023-01-25 11:18:48,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 11:31:06,716:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.36s, LR: 0.00070, Train Loss: 0.3269, Train MAE: 0.3269,
                            Val Loss: 0.8163, Val MAE: 0.8162
2023-01-25 11:31:06,717:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:42:18,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.01s, LR: 0.00035, Train Loss: 0.3100, Train MAE: 0.3100,
                            Val Loss: 0.8278, Val MAE: 0.8276
2023-01-25 11:42:18,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 11:53:29,609:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.88s, LR: 0.00035, Train Loss: 0.3049, Train MAE: 0.3049,
                            Val Loss: 0.9585, Val MAE: 0.9585
2023-01-25 11:53:29,610:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 12:04:42,576:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.97s, LR: 0.00035, Train Loss: 0.3004, Train MAE: 0.3004,
                            Val Loss: 0.5795, Val MAE: 0.5790
2023-01-25 12:04:42,578:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 12:15:53,654:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4537542462348938
2023-01-25 12:15:53,656:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.08s, LR: 0.00035, Train Loss: 0.2975, Train MAE: 0.2975,
                            Val Loss: 0.4541, Val MAE: 0.4538
2023-01-25 12:15:53,656:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 12:27:03,969:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.31s, LR: 0.00035, Train Loss: 0.2950, Train MAE: 0.2950,
                            Val Loss: 0.6077, Val MAE: 0.6075
2023-01-25 12:27:03,971:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 12:38:16,324:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.35s, LR: 0.00035, Train Loss: 0.2929, Train MAE: 0.2929,
                            Val Loss: 0.5603, Val MAE: 0.5601
2023-01-25 12:38:16,325:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 12:49:26,881:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.55s, LR: 0.00035, Train Loss: 0.2917, Train MAE: 0.2917,
                            Val Loss: 0.6341, Val MAE: 0.6340
2023-01-25 12:49:26,881:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 13:01:30,775:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.89s, LR: 0.00035, Train Loss: 0.2898, Train MAE: 0.2898,
                            Val Loss: 0.6934, Val MAE: 0.6932
2023-01-25 13:01:30,776:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 13:13:51,590:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.81s, LR: 0.00035, Train Loss: 0.2884, Train MAE: 0.2884,
                            Val Loss: 0.5548, Val MAE: 0.5546
2023-01-25 13:13:51,592:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 13:26:04,289:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.37916049361228943
2023-01-25 13:26:04,291:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.70s, LR: 0.00035, Train Loss: 0.2873, Train MAE: 0.2873,
                            Val Loss: 0.3792, Val MAE: 0.3792
2023-01-25 13:26:04,292:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 13:37:35,576:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.28s, LR: 0.00035, Train Loss: 0.2853, Train MAE: 0.2853,
                            Val Loss: 0.5355, Val MAE: 0.5355
2023-01-25 13:37:35,577:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 13:49:57,147:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 741.57s, LR: 0.00035, Train Loss: 0.2863, Train MAE: 0.2863,
                            Val Loss: 1.0734, Val MAE: 1.0734
2023-01-25 13:49:57,148:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 14:02:18,199:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 741.05s, LR: 0.00035, Train Loss: 0.2846, Train MAE: 0.2846,
                            Val Loss: 0.3971, Val MAE: 0.3969
2023-01-25 14:02:18,200:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 14:14:17,711:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.51s, LR: 0.00035, Train Loss: 0.2831, Train MAE: 0.2831,
                            Val Loss: 1.1376, Val MAE: 1.1377
2023-01-25 14:14:17,712:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 14:25:27,518:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.81s, LR: 0.00035, Train Loss: 0.2741, Train MAE: 0.2741,
                            Val Loss: 0.7992, Val MAE: 0.7993
2023-01-25 14:25:27,520:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 14:36:36,581:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.06s, LR: 0.00035, Train Loss: 0.2736, Train MAE: 0.2736,
                            Val Loss: 1.6163, Val MAE: 1.6164
2023-01-25 14:36:36,582:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 14:48:53,985:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3699021637439728
2023-01-25 14:48:53,986:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.40s, LR: 0.00035, Train Loss: 0.2962, Train MAE: 0.2962,
                            Val Loss: 0.3699, Val MAE: 0.3699
2023-01-25 14:48:53,986:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 15:00:03,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.33s, LR: 0.00035, Train Loss: 0.2761, Train MAE: 0.2761,
                            Val Loss: 0.4333, Val MAE: 0.4331
2023-01-25 15:00:03,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 15:11:34,059:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.74s, LR: 0.00035, Train Loss: 0.2669, Train MAE: 0.2669,
                            Val Loss: 0.6204, Val MAE: 0.6205
2023-01-25 15:11:34,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 15:23:39,855:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.79s, LR: 0.00035, Train Loss: 0.2517, Train MAE: 0.2517,
                            Val Loss: 0.9325, Val MAE: 0.9327
2023-01-25 15:23:39,857:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 15:34:49,465:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.61s, LR: 0.00035, Train Loss: 0.2372, Train MAE: 0.2372,
                            Val Loss: 0.7644, Val MAE: 0.7647
2023-01-25 15:34:49,466:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 15:46:49,550:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.08s, LR: 0.00035, Train Loss: 0.2325, Train MAE: 0.2325,
                            Val Loss: 0.7754, Val MAE: 0.7756
2023-01-25 15:46:49,551:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 15:59:09,237:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.68s, LR: 0.00035, Train Loss: 0.2232, Train MAE: 0.2232,
                            Val Loss: 0.6725, Val MAE: 0.6728
2023-01-25 15:59:09,238:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 16:11:29,507:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.27s, LR: 0.00035, Train Loss: 0.2173, Train MAE: 0.2173,
                            Val Loss: 0.7241, Val MAE: 0.7243
2023-01-25 16:11:29,507:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 16:22:48,657:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.15s, LR: 0.00035, Train Loss: 0.2103, Train MAE: 0.2103,
                            Val Loss: 1.6868, Val MAE: 1.6870
2023-01-25 16:22:48,659:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 16:33:57,901:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.24s, LR: 0.00035, Train Loss: 0.2055, Train MAE: 0.2055,
                            Val Loss: 0.7686, Val MAE: 0.7689
2023-01-25 16:33:57,902:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 16:46:15,481:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.58s, LR: 0.00035, Train Loss: 0.2066, Train MAE: 0.2066,
                            Val Loss: 0.9631, Val MAE: 0.9633
2023-01-25 16:46:15,482:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 16:58:33,518:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.03s, LR: 0.00035, Train Loss: 0.2011, Train MAE: 0.2011,
                            Val Loss: 0.9462, Val MAE: 0.9464
2023-01-25 16:58:33,520:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 17:10:52,889:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.37s, LR: 0.00035, Train Loss: 0.1960, Train MAE: 0.1960,
                            Val Loss: 0.6540, Val MAE: 0.6542
2023-01-25 17:10:52,890:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 17:23:12,762:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.87s, LR: 0.00035, Train Loss: 0.1944, Train MAE: 0.1944,
                            Val Loss: 0.9377, Val MAE: 0.9379
2023-01-25 17:23:12,764:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 17:35:31,587:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.82s, LR: 0.00035, Train Loss: 0.1945, Train MAE: 0.1945,
                            Val Loss: 0.6304, Val MAE: 0.6305
2023-01-25 17:35:31,588:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 17:47:49,863:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2982107996940613
2023-01-25 17:47:49,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.28s, LR: 0.00035, Train Loss: 0.1900, Train MAE: 0.1900,
                            Val Loss: 0.2983, Val MAE: 0.2982
2023-01-25 17:47:49,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 18:00:08,051:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.18s, LR: 0.00035, Train Loss: 0.1988, Train MAE: 0.1988,
                            Val Loss: 0.7303, Val MAE: 0.7305
2023-01-25 18:00:08,052:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 18:13:30,683:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 802.63s, LR: 0.00035, Train Loss: 0.1882, Train MAE: 0.1882,
                            Val Loss: 0.8425, Val MAE: 0.8426
2023-01-25 18:13:30,684:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 18:25:47,985:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.30s, LR: 0.00035, Train Loss: 0.1882, Train MAE: 0.1882,
                            Val Loss: 0.7007, Val MAE: 0.7010
2023-01-25 18:25:47,986:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 18:38:00,230:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.24s, LR: 0.00035, Train Loss: 0.1876, Train MAE: 0.1876,
                            Val Loss: 0.6423, Val MAE: 0.6424
2023-01-25 18:38:00,232:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 18:49:40,193:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.96s, LR: 0.00035, Train Loss: 0.1830, Train MAE: 0.1830,
                            Val Loss: 0.6300, Val MAE: 0.6301
2023-01-25 18:49:40,194:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 19:01:57,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.33s, LR: 0.00035, Train Loss: 0.1828, Train MAE: 0.1828,
                            Val Loss: 0.8412, Val MAE: 0.8414
2023-01-25 19:01:57,526:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 19:14:14,365:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 736.84s, LR: 0.00035, Train Loss: 0.1849, Train MAE: 0.1849,
                            Val Loss: 0.6665, Val MAE: 0.6667
2023-01-25 19:14:14,366:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 19:26:03,443:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.07s, LR: 0.00035, Train Loss: 0.1812, Train MAE: 0.1812,
                            Val Loss: 0.4313, Val MAE: 0.4313
2023-01-25 19:26:03,444:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 19:37:12,625:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.18s, LR: 0.00035, Train Loss: 0.2181, Train MAE: 0.2181,
                            Val Loss: 0.5863, Val MAE: 0.5866
2023-01-25 19:37:12,627:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 19:48:20,133:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.50s, LR: 0.00035, Train Loss: 0.1854, Train MAE: 0.1854,
                            Val Loss: 0.5804, Val MAE: 0.5805
2023-01-25 19:48:20,133:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 19:59:27,971:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.84s, LR: 0.00035, Train Loss: 0.1816, Train MAE: 0.1816,
                            Val Loss: 0.5648, Val MAE: 0.5649
2023-01-25 19:59:27,972:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 20:10:35,365:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.39s, LR: 0.00035, Train Loss: 0.1786, Train MAE: 0.1786,
                            Val Loss: 0.7114, Val MAE: 0.7115
2023-01-25 20:10:35,365:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 20:21:42,453:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.09s, LR: 0.00035, Train Loss: 0.1777, Train MAE: 0.1777,
                            Val Loss: 0.5048, Val MAE: 0.5048
2023-01-25 20:21:42,454:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 20:32:48,261:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.81s, LR: 0.00035, Train Loss: 0.1794, Train MAE: 0.1794,
                            Val Loss: 0.6617, Val MAE: 0.6620
2023-01-25 20:32:48,262:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 20:43:55,408:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.14s, LR: 0.00035, Train Loss: 0.1775, Train MAE: 0.1775,
                            Val Loss: 0.8448, Val MAE: 0.8452
2023-01-25 20:43:55,409:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 20:55:01,285:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.88s, LR: 0.00035, Train Loss: 0.1749, Train MAE: 0.1749,
                            Val Loss: 0.7359, Val MAE: 0.7361
2023-01-25 20:55:01,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 21:06:07,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.24s, LR: 0.00017, Train Loss: 0.1661, Train MAE: 0.1661,
                            Val Loss: 0.8639, Val MAE: 0.8642
2023-01-25 21:06:07,526:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 21:17:12,881:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.35s, LR: 0.00017, Train Loss: 0.1653, Train MAE: 0.1653,
                            Val Loss: 0.5696, Val MAE: 0.5697
2023-01-25 21:17:12,882:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 21:29:21,815:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.93s, LR: 0.00017, Train Loss: 0.1645, Train MAE: 0.1645,
                            Val Loss: 0.5556, Val MAE: 0.5557
2023-01-25 21:29:21,816:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 21:40:28,057:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.24s, LR: 0.00017, Train Loss: 0.1641, Train MAE: 0.1641,
                            Val Loss: 0.5171, Val MAE: 0.5171
2023-01-25 21:40:28,058:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 21:51:28,013:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.95s, LR: 0.00017, Train Loss: 0.1633, Train MAE: 0.1633,
                            Val Loss: 0.6592, Val MAE: 0.6594
2023-01-25 21:51:28,014:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 22:02:28,287:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.27s, LR: 0.00017, Train Loss: 0.1631, Train MAE: 0.1631,
                            Val Loss: 0.5782, Val MAE: 0.5784
2023-01-25 22:02:28,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-25 22:13:30,668:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.38s, LR: 0.00017, Train Loss: 0.1626, Train MAE: 0.1626,
                            Val Loss: 0.5176, Val MAE: 0.5176
2023-01-25 22:13:30,669:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-25 22:24:36,140:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.47s, LR: 0.00017, Train Loss: 0.1621, Train MAE: 0.1621,
                            Val Loss: 0.5801, Val MAE: 0.5803
2023-01-25 22:24:36,141:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-25 22:35:40,532:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.39s, LR: 0.00017, Train Loss: 0.1616, Train MAE: 0.1616,
                            Val Loss: 0.6329, Val MAE: 0.6330
2023-01-25 22:35:40,533:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-25 22:46:44,482:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.95s, LR: 0.00017, Train Loss: 0.1611, Train MAE: 0.1611,
                            Val Loss: 0.5959, Val MAE: 0.5960
2023-01-25 22:46:44,483:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-25 22:57:46,696:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.21s, LR: 0.00017, Train Loss: 0.1607, Train MAE: 0.1607,
                            Val Loss: 0.5766, Val MAE: 0.5766
2023-01-25 22:57:46,697:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-25 23:08:51,136:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.44s, LR: 0.00017, Train Loss: 0.1604, Train MAE: 0.1604,
                            Val Loss: 0.7177, Val MAE: 0.7179
2023-01-25 23:08:51,137:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-25 23:19:56,159:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.02s, LR: 0.00017, Train Loss: 0.1602, Train MAE: 0.1602,
                            Val Loss: 1.0330, Val MAE: 1.0332
2023-01-25 23:19:56,160:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-25 23:30:59,473:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.31s, LR: 0.00017, Train Loss: 0.1597, Train MAE: 0.1597,
                            Val Loss: 0.6233, Val MAE: 0.6235
2023-01-25 23:30:59,475:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-25 23:41:58,521:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.05s, LR: 0.00017, Train Loss: 0.1595, Train MAE: 0.1595,
                            Val Loss: 0.5761, Val MAE: 0.5762
2023-01-25 23:41:58,523:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-25 23:52:59,030:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.51s, LR: 0.00017, Train Loss: 0.1592, Train MAE: 0.1592,
                            Val Loss: 0.6099, Val MAE: 0.6101
2023-01-25 23:52:59,031:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-26 00:04:01,248:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.22s, LR: 0.00009, Train Loss: 0.1549, Train MAE: 0.1549,
                            Val Loss: 0.6044, Val MAE: 0.6045
2023-01-26 00:04:01,250:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-26 00:15:03,264:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.01s, LR: 0.00009, Train Loss: 0.1545, Train MAE: 0.1545,
                            Val Loss: 0.5958, Val MAE: 0.5960
2023-01-26 00:15:03,265:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-26 00:26:06,958:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.27147629857063293
2023-01-26 00:26:06,959:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.69s, LR: 0.00009, Train Loss: 0.1543, Train MAE: 0.1543,
                            Val Loss: 0.2716, Val MAE: 0.2715
2023-01-26 00:26:06,960:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-26 00:38:13,827:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.87s, LR: 0.00009, Train Loss: 0.1540, Train MAE: 0.1540,
                            Val Loss: 0.4491, Val MAE: 0.4491
2023-01-26 00:38:13,828:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-26 00:49:16,741:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.91s, LR: 0.00009, Train Loss: 0.1539, Train MAE: 0.1539,
                            Val Loss: 0.7011, Val MAE: 0.7013
2023-01-26 00:49:16,743:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-26 01:00:19,436:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.69s, LR: 0.00009, Train Loss: 0.1535, Train MAE: 0.1535,
                            Val Loss: 0.5396, Val MAE: 0.5397
2023-01-26 01:00:19,437:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-26 01:11:17,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.28s, LR: 0.00009, Train Loss: 0.1533, Train MAE: 0.1533,
                            Val Loss: 0.6404, Val MAE: 0.6405
2023-01-26 01:11:17,715:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-26 01:22:14,995:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.28s, LR: 0.00009, Train Loss: 0.1532, Train MAE: 0.1532,
                            Val Loss: 0.6727, Val MAE: 0.6729
2023-01-26 01:22:14,997:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 01:33:12,832:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.83s, LR: 0.00009, Train Loss: 0.1530, Train MAE: 0.1530,
                            Val Loss: 0.4410, Val MAE: 0.4410
2023-01-26 01:33:12,833:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 01:44:09,107:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.27s, LR: 0.00009, Train Loss: 0.1528, Train MAE: 0.1528,
                            Val Loss: 0.6914, Val MAE: 0.6916
2023-01-26 01:44:09,108:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 01:55:05,924:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.81s, LR: 0.00009, Train Loss: 0.1527, Train MAE: 0.1527,
                            Val Loss: 0.6408, Val MAE: 0.6409
2023-01-26 01:55:05,925:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 02:06:05,131:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2589353322982788
2023-01-26 02:06:05,133:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.21s, LR: 0.00009, Train Loss: 0.1524, Train MAE: 0.1524,
                            Val Loss: 0.2590, Val MAE: 0.2589
2023-01-26 02:06:05,133:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 02:17:03,419:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.29s, LR: 0.00009, Train Loss: 0.1524, Train MAE: 0.1524,
                            Val Loss: 0.6321, Val MAE: 0.6322
2023-01-26 02:17:03,420:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 02:28:01,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.31s, LR: 0.00009, Train Loss: 0.1521, Train MAE: 0.1521,
                            Val Loss: 0.6887, Val MAE: 0.6889
2023-01-26 02:28:01,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 02:39:00,272:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.54s, LR: 0.00009, Train Loss: 0.1521, Train MAE: 0.1521,
                            Val Loss: 0.5242, Val MAE: 0.5243
2023-01-26 02:39:00,273:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-26 02:49:58,622:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.35s, LR: 0.00009, Train Loss: 0.1518, Train MAE: 0.1518,
                            Val Loss: 0.6553, Val MAE: 0.6555
2023-01-26 02:49:58,623:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-26 03:00:56,750:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.13s, LR: 0.00009, Train Loss: 0.1517, Train MAE: 0.1517,
                            Val Loss: 0.5679, Val MAE: 0.5680
2023-01-26 03:00:56,751:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-26 03:11:55,064:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.31s, LR: 0.00009, Train Loss: 0.1519, Train MAE: 0.1519,
                            Val Loss: 0.6045, Val MAE: 0.6046
2023-01-26 03:11:55,066:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-26 03:22:57,240:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.17s, LR: 0.00009, Train Loss: 0.1512, Train MAE: 0.1512,
                            Val Loss: 0.6365, Val MAE: 0.6366
2023-01-26 03:22:57,242:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-26 03:35:02,338:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.10s, LR: 0.00009, Train Loss: 0.1513, Train MAE: 0.1513,
                            Val Loss: 0.6878, Val MAE: 0.6879
2023-01-26 03:35:02,340:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-26 03:46:06,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.39s, LR: 0.00009, Train Loss: 0.1510, Train MAE: 0.1510,
                            Val Loss: 0.6099, Val MAE: 0.6101
2023-01-26 03:46:06,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-26 03:57:08,059:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.33s, LR: 0.00009, Train Loss: 0.1509, Train MAE: 0.1509,
                            Val Loss: 0.5346, Val MAE: 0.5347
2023-01-26 03:57:08,061:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-26 04:08:03,505:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.44s, LR: 0.00009, Train Loss: 0.1507, Train MAE: 0.1507,
                            Val Loss: 0.5276, Val MAE: 0.5277
2023-01-26 04:08:03,505:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-26 04:18:59,942:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.44s, LR: 0.00009, Train Loss: 0.1506, Train MAE: 0.1506,
                            Val Loss: 0.5852, Val MAE: 0.5853
2023-01-26 04:18:59,944:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-26 04:29:56,215:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.27s, LR: 0.00009, Train Loss: 0.1504, Train MAE: 0.1504,
                            Val Loss: 0.6926, Val MAE: 0.6928
2023-01-26 04:29:56,216:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-26 04:40:51,349:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.13s, LR: 0.00009, Train Loss: 0.1504, Train MAE: 0.1504,
                            Val Loss: 0.6705, Val MAE: 0.6707
2023-01-26 04:40:51,351:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-26 04:51:47,367:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.02s, LR: 0.00009, Train Loss: 0.1512, Train MAE: 0.1512,
                            Val Loss: 0.7400, Val MAE: 0.7403
2023-01-26 04:51:47,368:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-26 05:02:43,761:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.39s, LR: 0.00009, Train Loss: 0.1528, Train MAE: 0.1528,
                            Val Loss: 0.5399, Val MAE: 0.5400
2023-01-26 05:02:43,762:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-26 05:13:39,807:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.04s, LR: 0.00004, Train Loss: 0.1480, Train MAE: 0.1480,
                            Val Loss: 0.5971, Val MAE: 0.5973
2023-01-26 05:13:39,808:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-26 05:24:35,637:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.83s, LR: 0.00004, Train Loss: 0.1478, Train MAE: 0.1478,
                            Val Loss: 0.6422, Val MAE: 0.6423
2023-01-26 05:24:35,638:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:24:35,639:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-26 05:32:03,214:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.6423
2023-01-26 05:32:03,216:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.6034
2023-01-26 05:32:03,217:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-26 05:32:03,219:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 117.0000
2023-01-26 05:32:03,220:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 86973.3790s
2023-01-26 05:32:03,221:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 694.1517s
2023-01-26 05:32:03,223:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials', 'job_num': 32}
2023-01-26 05:32:03,246:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.6034)]
2023-01-26 05:32:03,246:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.6423)]
