2023-01-25 05:10:51,025:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA TITAN X (Pascal)
2023-01-25 05:10:51,025:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:22:07,011:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:22:36,218:ogbdata.py:332 -             __init__(): Time taken: 705.1926s
2023-01-25 05:22:36,218:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:22:36,218:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:22:36,218:ogbdata.py:348 -             __init__(): [I] Data load time: 705.1930s
2023-01-25 05:22:36,218:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials/32_DEBUG_0_41.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [41]}
2023-01-25 05:22:36,218:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials', 'job_num': 32}
2023-01-25 05:22:36,220:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:22:43,369:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:22:43,369:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:22:43,369:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:22:43,416:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:22:43,429:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-25 05:22:43,430:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2023-01-25 05:22:43,430:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:22:43,432:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:22:43,432:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:22:43,432:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:22:43,483:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:31:54,100:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4150.670469284058
2023-01-25 06:31:54,108:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:31:54,108:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:31:54,132:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:45:14,289:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 2.1520466804504395
2023-01-25 06:45:14,291:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 800.16s, LR: 0.00070, Train Loss: 0.6216, Train MAE: 0.6216,
                            Val Loss: 2.1529, Val MAE: 2.1520
2023-01-25 06:45:14,292:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 06:56:18,854:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.56s, LR: 0.00070, Train Loss: 0.5782, Train MAE: 0.5782,
                            Val Loss: 2.5737, Val MAE: 2.5731
2023-01-25 06:56:18,855:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:07:22,292:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.5163230895996094
2023-01-25 07:07:22,294:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.44s, LR: 0.00070, Train Loss: 0.5197, Train MAE: 0.5197,
                            Val Loss: 1.5166, Val MAE: 1.5163
2023-01-25 07:07:22,295:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:18:25,686:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.1278458833694458
2023-01-25 07:18:25,688:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.39s, LR: 0.00070, Train Loss: 0.6142, Train MAE: 0.6142,
                            Val Loss: 1.1282, Val MAE: 1.1278
2023-01-25 07:18:25,689:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:29:27,676:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.99s, LR: 0.00070, Train Loss: 0.5519, Train MAE: 0.5519,
                            Val Loss: 1.7076, Val MAE: 1.7070
2023-01-25 07:29:27,678:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:40:32,009:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.33s, LR: 0.00070, Train Loss: 0.4942, Train MAE: 0.4942,
                            Val Loss: 1.7482, Val MAE: 1.7479
2023-01-25 07:40:32,010:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 07:51:34,456:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.7155115008354187
2023-01-25 07:51:34,458:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.45s, LR: 0.00070, Train Loss: 0.4681, Train MAE: 0.4681,
                            Val Loss: 0.7160, Val MAE: 0.7155
2023-01-25 07:51:34,459:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 08:03:38,182:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.72s, LR: 0.00070, Train Loss: 0.4355, Train MAE: 0.4355,
                            Val Loss: 0.8328, Val MAE: 0.8327
2023-01-25 08:03:38,184:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:14:41,541:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.36s, LR: 0.00070, Train Loss: 0.4520, Train MAE: 0.4520,
                            Val Loss: 0.9204, Val MAE: 0.9203
2023-01-25 08:14:41,542:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:25:41,724:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.18s, LR: 0.00070, Train Loss: 0.5449, Train MAE: 0.5449,
                            Val Loss: 1.4111, Val MAE: 1.4107
2023-01-25 08:25:41,725:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:36:43,630:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.90s, LR: 0.00070, Train Loss: 0.4741, Train MAE: 0.4741,
                            Val Loss: 1.4380, Val MAE: 1.4376
2023-01-25 08:36:43,632:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 08:47:43,391:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5286001563072205
2023-01-25 08:47:43,393:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.76s, LR: 0.00070, Train Loss: 0.4406, Train MAE: 0.4406,
                            Val Loss: 0.5287, Val MAE: 0.5286
2023-01-25 08:47:43,394:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 08:58:38,670:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.27s, LR: 0.00070, Train Loss: 0.4168, Train MAE: 0.4168,
                            Val Loss: 0.5667, Val MAE: 0.5666
2023-01-25 08:58:38,671:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:09:30,678:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.01s, LR: 0.00070, Train Loss: 0.4231, Train MAE: 0.4231,
                            Val Loss: 1.5145, Val MAE: 1.5142
2023-01-25 09:09:30,680:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:20:21,158:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.48s, LR: 0.00070, Train Loss: 0.5701, Train MAE: 0.5701,
                            Val Loss: 1.4939, Val MAE: 1.4939
2023-01-25 09:20:21,160:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:31:09,616:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.46s, LR: 0.00070, Train Loss: 0.4967, Train MAE: 0.4967,
                            Val Loss: 1.1568, Val MAE: 1.1562
2023-01-25 09:31:09,617:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 09:41:56,907:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.29s, LR: 0.00070, Train Loss: 0.4773, Train MAE: 0.4773,
                            Val Loss: 0.8823, Val MAE: 0.8823
2023-01-25 09:41:56,909:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 09:52:43,881:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 646.97s, LR: 0.00070, Train Loss: 0.4652, Train MAE: 0.4652,
                            Val Loss: 2.3535, Val MAE: 2.3531
2023-01-25 09:52:43,883:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 10:03:31,235:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.35s, LR: 0.00070, Train Loss: 0.4465, Train MAE: 0.4465,
                            Val Loss: 0.9307, Val MAE: 0.9303
2023-01-25 10:03:31,236:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:14:16,897:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.66s, LR: 0.00070, Train Loss: 0.4307, Train MAE: 0.4307,
                            Val Loss: 1.4033, Val MAE: 1.4035
2023-01-25 10:14:16,898:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 10:25:01,753:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.85s, LR: 0.00070, Train Loss: 0.4201, Train MAE: 0.4201,
                            Val Loss: 1.2104, Val MAE: 1.2102
2023-01-25 10:25:01,754:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 10:35:46,767:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.01s, LR: 0.00070, Train Loss: 0.4101, Train MAE: 0.4101,
                            Val Loss: 1.4355, Val MAE: 1.4358
2023-01-25 10:35:46,769:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 10:46:31,453:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.68s, LR: 0.00070, Train Loss: 0.3953, Train MAE: 0.3953,
                            Val Loss: 1.1723, Val MAE: 1.1722
2023-01-25 10:46:31,454:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 10:58:11,163:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.71s, LR: 0.00070, Train Loss: 0.3811, Train MAE: 0.3811,
                            Val Loss: 0.7959, Val MAE: 0.7954
2023-01-25 10:58:11,164:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:08:54,304:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.14s, LR: 0.00070, Train Loss: 0.3791, Train MAE: 0.3791,
                            Val Loss: 0.7965, Val MAE: 0.7962
2023-01-25 11:08:54,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 11:19:38,465:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.16s, LR: 0.00070, Train Loss: 0.3772, Train MAE: 0.3772,
                            Val Loss: 1.0402, Val MAE: 1.0400
2023-01-25 11:19:38,466:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 11:30:21,952:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.48s, LR: 0.00070, Train Loss: 0.3869, Train MAE: 0.3869,
                            Val Loss: 0.5355, Val MAE: 0.5354
2023-01-25 11:30:21,953:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 11:41:05,178:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.22s, LR: 0.00070, Train Loss: 0.3716, Train MAE: 0.3716,
                            Val Loss: 0.8345, Val MAE: 0.8346
2023-01-25 11:41:05,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 11:51:48,407:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4336652159690857
2023-01-25 11:51:48,408:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.23s, LR: 0.00035, Train Loss: 0.3546, Train MAE: 0.3546,
                            Val Loss: 0.4339, Val MAE: 0.4337
2023-01-25 11:51:48,409:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 12:02:31,047:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 642.64s, LR: 0.00035, Train Loss: 0.3259, Train MAE: 0.3259,
                            Val Loss: 0.5152, Val MAE: 0.5151
2023-01-25 12:02:31,048:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 12:13:12,844:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.80s, LR: 0.00035, Train Loss: 0.3087, Train MAE: 0.3087,
                            Val Loss: 0.6400, Val MAE: 0.6399
2023-01-25 12:13:12,845:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 12:23:54,738:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.89s, LR: 0.00035, Train Loss: 0.3009, Train MAE: 0.3009,
                            Val Loss: 0.5117, Val MAE: 0.5118
2023-01-25 12:23:54,739:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 12:34:36,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.74s, LR: 0.00035, Train Loss: 0.3455, Train MAE: 0.3455,
                            Val Loss: 0.5943, Val MAE: 0.5940
2023-01-25 12:34:36,477:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 12:45:17,946:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.47s, LR: 0.00035, Train Loss: 0.3007, Train MAE: 0.3007,
                            Val Loss: 0.7253, Val MAE: 0.7254
2023-01-25 12:45:17,947:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 12:55:58,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.77s, LR: 0.00035, Train Loss: 0.2892, Train MAE: 0.2892,
                            Val Loss: 0.9287, Val MAE: 0.9290
2023-01-25 12:55:58,715:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 13:06:40,022:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.31s, LR: 0.00035, Train Loss: 0.2826, Train MAE: 0.2826,
                            Val Loss: 0.6860, Val MAE: 0.6861
2023-01-25 13:06:40,023:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 13:17:21,787:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.76s, LR: 0.00035, Train Loss: 0.2785, Train MAE: 0.2785,
                            Val Loss: 0.6627, Val MAE: 0.6628
2023-01-25 13:17:21,788:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 13:28:02,312:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.52s, LR: 0.00035, Train Loss: 0.2729, Train MAE: 0.2729,
                            Val Loss: 0.5796, Val MAE: 0.5796
2023-01-25 13:28:02,313:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 13:38:42,748:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.43s, LR: 0.00035, Train Loss: 0.2734, Train MAE: 0.2734,
                            Val Loss: 0.5735, Val MAE: 0.5736
2023-01-25 13:38:42,749:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 13:49:23,816:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.07s, LR: 0.00035, Train Loss: 0.2979, Train MAE: 0.2979,
                            Val Loss: 0.6003, Val MAE: 0.6001
2023-01-25 13:49:23,817:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 14:01:00,075:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3933197259902954
2023-01-25 14:01:00,077:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.26s, LR: 0.00035, Train Loss: 0.3028, Train MAE: 0.3028,
                            Val Loss: 0.3934, Val MAE: 0.3933
2023-01-25 14:01:00,078:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 14:11:41,640:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.56s, LR: 0.00035, Train Loss: 0.2716, Train MAE: 0.2716,
                            Val Loss: 0.4461, Val MAE: 0.4461
2023-01-25 14:11:41,641:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 14:22:30,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.65s, LR: 0.00035, Train Loss: 0.2775, Train MAE: 0.2775,
                            Val Loss: 0.4138, Val MAE: 0.4137
2023-01-25 14:22:30,293:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 14:33:19,124:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3851315379142761
2023-01-25 14:33:19,126:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.83s, LR: 0.00035, Train Loss: 0.2685, Train MAE: 0.2685,
                            Val Loss: 0.3853, Val MAE: 0.3851
2023-01-25 14:33:19,127:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 14:44:07,810:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.68s, LR: 0.00035, Train Loss: 0.2678, Train MAE: 0.2678,
                            Val Loss: 0.7929, Val MAE: 0.7931
2023-01-25 14:44:07,811:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 14:54:55,782:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.97s, LR: 0.00035, Train Loss: 0.2602, Train MAE: 0.2602,
                            Val Loss: 0.8217, Val MAE: 0.8220
2023-01-25 14:54:55,783:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 15:05:36,437:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.65s, LR: 0.00035, Train Loss: 0.2574, Train MAE: 0.2574,
                            Val Loss: 0.4619, Val MAE: 0.4619
2023-01-25 15:05:36,438:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 15:16:17,823:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3515569269657135
2023-01-25 15:16:17,825:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.39s, LR: 0.00035, Train Loss: 0.2549, Train MAE: 0.2549,
                            Val Loss: 0.3516, Val MAE: 0.3516
2023-01-25 15:16:17,825:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 15:26:57,997:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.17s, LR: 0.00035, Train Loss: 0.2520, Train MAE: 0.2520,
                            Val Loss: 0.5459, Val MAE: 0.5460
2023-01-25 15:26:57,998:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 15:37:38,523:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3130267858505249
2023-01-25 15:37:38,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.53s, LR: 0.00035, Train Loss: 0.2524, Train MAE: 0.2524,
                            Val Loss: 0.3132, Val MAE: 0.3130
2023-01-25 15:37:38,526:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 15:48:19,392:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.86s, LR: 0.00035, Train Loss: 0.2489, Train MAE: 0.2489,
                            Val Loss: 0.6654, Val MAE: 0.6657
2023-01-25 15:48:19,393:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 15:59:00,185:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.79s, LR: 0.00035, Train Loss: 0.2489, Train MAE: 0.2489,
                            Val Loss: 0.5695, Val MAE: 0.5697
2023-01-25 15:59:00,186:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 16:09:39,882:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.70s, LR: 0.00035, Train Loss: 0.2463, Train MAE: 0.2463,
                            Val Loss: 0.7322, Val MAE: 0.7325
2023-01-25 16:09:39,883:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 16:20:27,590:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.71s, LR: 0.00035, Train Loss: 0.3786, Train MAE: 0.3786,
                            Val Loss: 0.4148, Val MAE: 0.4147
2023-01-25 16:20:27,591:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 16:31:09,128:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.54s, LR: 0.00035, Train Loss: 0.2984, Train MAE: 0.2984,
                            Val Loss: 0.7149, Val MAE: 0.7152
2023-01-25 16:31:09,130:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 16:41:55,284:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 646.15s, LR: 0.00035, Train Loss: 0.2642, Train MAE: 0.2642,
                            Val Loss: 0.4603, Val MAE: 0.4603
2023-01-25 16:41:55,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 16:52:42,610:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.32s, LR: 0.00035, Train Loss: 0.2551, Train MAE: 0.2551,
                            Val Loss: 0.6226, Val MAE: 0.6227
2023-01-25 16:52:42,611:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 17:04:21,072:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.46s, LR: 0.00035, Train Loss: 0.2553, Train MAE: 0.2553,
                            Val Loss: 0.4927, Val MAE: 0.4927
2023-01-25 17:04:21,073:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 17:15:00,911:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.84s, LR: 0.00035, Train Loss: 0.2458, Train MAE: 0.2458,
                            Val Loss: 0.5454, Val MAE: 0.5454
2023-01-25 17:15:00,912:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 17:25:39,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.08s, LR: 0.00035, Train Loss: 0.2423, Train MAE: 0.2423,
                            Val Loss: 0.8130, Val MAE: 0.8133
2023-01-25 17:25:39,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 17:36:19,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.45s, LR: 0.00035, Train Loss: 0.2399, Train MAE: 0.2399,
                            Val Loss: 0.7218, Val MAE: 0.7221
2023-01-25 17:36:19,446:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 17:46:59,762:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.31s, LR: 0.00035, Train Loss: 0.2444, Train MAE: 0.2444,
                            Val Loss: 0.7256, Val MAE: 0.7258
2023-01-25 17:46:59,763:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 17:57:44,239:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.47s, LR: 0.00035, Train Loss: 0.2385, Train MAE: 0.2385,
                            Val Loss: 0.7341, Val MAE: 0.7343
2023-01-25 17:57:44,240:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 18:08:30,343:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 646.10s, LR: 0.00035, Train Loss: 0.2367, Train MAE: 0.2367,
                            Val Loss: 0.6616, Val MAE: 0.6617
2023-01-25 18:08:30,345:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 18:19:09,250:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.90s, LR: 0.00035, Train Loss: 0.2348, Train MAE: 0.2348,
                            Val Loss: 0.8368, Val MAE: 0.8371
2023-01-25 18:19:09,251:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 18:29:48,424:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.17s, LR: 0.00035, Train Loss: 0.2924, Train MAE: 0.2924,
                            Val Loss: 0.6871, Val MAE: 0.6867
2023-01-25 18:29:48,425:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 18:40:27,684:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.26s, LR: 0.00017, Train Loss: 0.5264, Train MAE: 0.5264,
                            Val Loss: 1.0890, Val MAE: 1.0887
2023-01-25 18:40:27,686:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 18:51:06,938:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.25s, LR: 0.00017, Train Loss: 0.4771, Train MAE: 0.4771,
                            Val Loss: 0.5265, Val MAE: 0.5263
2023-01-25 18:51:06,939:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 19:01:48,973:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 642.03s, LR: 0.00017, Train Loss: 0.4482, Train MAE: 0.4482,
                            Val Loss: 0.4813, Val MAE: 0.4812
2023-01-25 19:01:48,975:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 19:12:36,901:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.93s, LR: 0.00017, Train Loss: 0.4209, Train MAE: 0.4209,
                            Val Loss: 0.5405, Val MAE: 0.5402
2023-01-25 19:12:36,902:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 19:23:24,233:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.33s, LR: 0.00017, Train Loss: 0.4016, Train MAE: 0.4016,
                            Val Loss: 0.5019, Val MAE: 0.5019
2023-01-25 19:23:24,234:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 19:34:07,467:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.23s, LR: 0.00017, Train Loss: 0.3809, Train MAE: 0.3809,
                            Val Loss: 0.4484, Val MAE: 0.4484
2023-01-25 19:34:07,469:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 19:44:46,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.84s, LR: 0.00017, Train Loss: 0.3540, Train MAE: 0.3540,
                            Val Loss: 0.3882, Val MAE: 0.3880
2023-01-25 19:44:46,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 19:55:24,181:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.87s, LR: 0.00017, Train Loss: 0.3375, Train MAE: 0.3375,
                            Val Loss: 0.4886, Val MAE: 0.4884
2023-01-25 19:55:24,182:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 20:06:56,898:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.72s, LR: 0.00017, Train Loss: 0.3231, Train MAE: 0.3231,
                            Val Loss: 0.7761, Val MAE: 0.7763
2023-01-25 20:06:56,899:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 20:17:31,901:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.00s, LR: 0.00017, Train Loss: 0.3135, Train MAE: 0.3135,
                            Val Loss: 0.4750, Val MAE: 0.4750
2023-01-25 20:17:31,902:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 20:28:09,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.40s, LR: 0.00017, Train Loss: 0.3060, Train MAE: 0.3060,
                            Val Loss: 0.4067, Val MAE: 0.4065
2023-01-25 20:28:09,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 20:38:46,783:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.48s, LR: 0.00017, Train Loss: 0.2982, Train MAE: 0.2982,
                            Val Loss: 0.4955, Val MAE: 0.4956
2023-01-25 20:38:46,784:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-25 20:49:23,711:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.93s, LR: 0.00017, Train Loss: 0.2922, Train MAE: 0.2922,
                            Val Loss: 0.4632, Val MAE: 0.4631
2023-01-25 20:49:23,712:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-25 21:00:01,082:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.37s, LR: 0.00017, Train Loss: 0.2868, Train MAE: 0.2868,
                            Val Loss: 0.4356, Val MAE: 0.4356
2023-01-25 21:00:01,083:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-25 21:10:38,170:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.09s, LR: 0.00017, Train Loss: 0.2824, Train MAE: 0.2824,
                            Val Loss: 0.7428, Val MAE: 0.7430
2023-01-25 21:10:38,171:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-25 21:21:15,054:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.88s, LR: 0.00017, Train Loss: 0.2780, Train MAE: 0.2780,
                            Val Loss: 0.5177, Val MAE: 0.5177
2023-01-25 21:21:15,055:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-25 21:31:51,852:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.80s, LR: 0.00009, Train Loss: 0.2684, Train MAE: 0.2684,
                            Val Loss: 0.4094, Val MAE: 0.4093
2023-01-25 21:31:51,852:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-25 21:42:27,854:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.00s, LR: 0.00009, Train Loss: 0.2693, Train MAE: 0.2693,
                            Val Loss: 0.6120, Val MAE: 0.6120
2023-01-25 21:42:27,855:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-25 21:53:02,811:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.96s, LR: 0.00009, Train Loss: 0.2662, Train MAE: 0.2662,
                            Val Loss: 0.3205, Val MAE: 0.3203
2023-01-25 21:53:02,812:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-25 22:03:37,164:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.35s, LR: 0.00009, Train Loss: 0.2638, Train MAE: 0.2638,
                            Val Loss: 0.3803, Val MAE: 0.3802
2023-01-25 22:03:37,165:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-25 22:14:12,971:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.80s, LR: 0.00009, Train Loss: 0.2609, Train MAE: 0.2609,
                            Val Loss: 0.6180, Val MAE: 0.6182
2023-01-25 22:14:12,972:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-25 22:24:48,266:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.29s, LR: 0.00009, Train Loss: 0.2614, Train MAE: 0.2614,
                            Val Loss: 0.5352, Val MAE: 0.5352
2023-01-25 22:24:48,267:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-25 22:35:23,002:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 634.73s, LR: 0.00009, Train Loss: 0.2579, Train MAE: 0.2579,
                            Val Loss: 0.6099, Val MAE: 0.6100
2023-01-25 22:35:23,004:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-25 22:45:58,478:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.47s, LR: 0.00009, Train Loss: 0.2558, Train MAE: 0.2558,
                            Val Loss: 0.3781, Val MAE: 0.3780
2023-01-25 22:45:58,479:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-25 22:56:34,460:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.98s, LR: 0.00009, Train Loss: 0.2545, Train MAE: 0.2545,
                            Val Loss: 0.5258, Val MAE: 0.5258
2023-01-25 22:56:34,460:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-25 23:08:03,665:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.20s, LR: 0.00009, Train Loss: 0.2529, Train MAE: 0.2529,
                            Val Loss: 0.6259, Val MAE: 0.6260
2023-01-25 23:08:03,666:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-25 23:18:36,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.45s, LR: 0.00009, Train Loss: 0.2518, Train MAE: 0.2518,
                            Val Loss: 0.5298, Val MAE: 0.5298
2023-01-25 23:18:36,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-25 23:29:06,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.75s, LR: 0.00009, Train Loss: 0.2502, Train MAE: 0.2502,
                            Val Loss: 0.6749, Val MAE: 0.6751
2023-01-25 23:29:06,867:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-25 23:39:38,082:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.21s, LR: 0.00009, Train Loss: 0.2488, Train MAE: 0.2488,
                            Val Loss: 0.4770, Val MAE: 0.4770
2023-01-25 23:39:38,083:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-25 23:50:08,660:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.58s, LR: 0.00009, Train Loss: 0.2480, Train MAE: 0.2480,
                            Val Loss: 0.6620, Val MAE: 0.6622
2023-01-25 23:50:08,661:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 00:00:39,090:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.43s, LR: 0.00009, Train Loss: 0.2469, Train MAE: 0.2469,
                            Val Loss: 0.4539, Val MAE: 0.4539
2023-01-26 00:00:39,090:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 00:11:09,928:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3064853847026825
2023-01-26 00:11:09,929:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.84s, LR: 0.00009, Train Loss: 0.2460, Train MAE: 0.2460,
                            Val Loss: 0.3066, Val MAE: 0.3065
2023-01-26 00:11:09,930:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 00:21:40,341:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.41s, LR: 0.00009, Train Loss: 0.2446, Train MAE: 0.2446,
                            Val Loss: 0.3132, Val MAE: 0.3131
2023-01-26 00:21:40,342:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 00:32:10,264:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.92s, LR: 0.00009, Train Loss: 0.2438, Train MAE: 0.2438,
                            Val Loss: 0.4940, Val MAE: 0.4940
2023-01-26 00:32:10,265:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 00:42:40,750:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.48s, LR: 0.00009, Train Loss: 0.2474, Train MAE: 0.2474,
                            Val Loss: 0.6036, Val MAE: 0.6038
2023-01-26 00:42:40,751:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 00:53:11,076:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.29888710379600525
2023-01-26 00:53:11,078:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.33s, LR: 0.00009, Train Loss: 0.2444, Train MAE: 0.2444,
                            Val Loss: 0.2991, Val MAE: 0.2989
2023-01-26 00:53:11,079:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 01:03:41,252:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.17s, LR: 0.00009, Train Loss: 0.2423, Train MAE: 0.2423,
                            Val Loss: 0.3572, Val MAE: 0.3571
2023-01-26 01:03:41,253:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-26 01:14:11,303:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.05s, LR: 0.00009, Train Loss: 0.2416, Train MAE: 0.2416,
                            Val Loss: 0.4127, Val MAE: 0.4126
2023-01-26 01:14:11,304:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-26 01:24:41,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.56s, LR: 0.00009, Train Loss: 0.2418, Train MAE: 0.2418,
                            Val Loss: 0.4058, Val MAE: 0.4058
2023-01-26 01:24:41,867:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-26 01:35:12,817:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.95s, LR: 0.00009, Train Loss: 0.2413, Train MAE: 0.2413,
                            Val Loss: 0.5586, Val MAE: 0.5587
2023-01-26 01:35:12,818:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-26 01:45:42,589:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.77s, LR: 0.00009, Train Loss: 0.2402, Train MAE: 0.2402,
                            Val Loss: 0.4692, Val MAE: 0.4692
2023-01-26 01:45:42,590:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-26 01:57:07,594:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.00s, LR: 0.00009, Train Loss: 0.2392, Train MAE: 0.2392,
                            Val Loss: 0.4526, Val MAE: 0.4526
2023-01-26 01:57:07,595:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-26 02:07:35,308:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 627.71s, LR: 0.00009, Train Loss: 0.2380, Train MAE: 0.2380,
                            Val Loss: 0.5674, Val MAE: 0.5675
2023-01-26 02:07:35,309:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-26 02:18:05,613:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.30s, LR: 0.00009, Train Loss: 0.2372, Train MAE: 0.2372,
                            Val Loss: 0.4872, Val MAE: 0.4872
2023-01-26 02:18:05,615:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-26 02:28:35,088:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.47s, LR: 0.00009, Train Loss: 0.2367, Train MAE: 0.2367,
                            Val Loss: 0.4234, Val MAE: 0.4234
2023-01-26 02:28:35,089:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-26 02:39:04,860:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.77s, LR: 0.00009, Train Loss: 0.2871, Train MAE: 0.2871,
                            Val Loss: 0.3159, Val MAE: 0.3157
2023-01-26 02:39:04,862:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-26 02:49:34,989:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.29460880160331726
2023-01-26 02:49:34,991:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.13s, LR: 0.00009, Train Loss: 0.2698, Train MAE: 0.2698,
                            Val Loss: 0.2948, Val MAE: 0.2946
2023-01-26 02:49:34,992:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-26 03:00:05,629:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.64s, LR: 0.00009, Train Loss: 0.2565, Train MAE: 0.2565,
                            Val Loss: 0.3744, Val MAE: 0.3744
2023-01-26 03:00:05,630:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-26 03:10:35,739:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.11s, LR: 0.00009, Train Loss: 0.2568, Train MAE: 0.2568,
                            Val Loss: 0.3842, Val MAE: 0.3842
2023-01-26 03:10:35,740:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-26 03:21:05,443:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.70s, LR: 0.00009, Train Loss: 0.2577, Train MAE: 0.2577,
                            Val Loss: 0.4028, Val MAE: 0.4028
2023-01-26 03:21:05,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-26 03:31:35,067:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.62s, LR: 0.00009, Train Loss: 0.2481, Train MAE: 0.2481,
                            Val Loss: 0.5065, Val MAE: 0.5066
2023-01-26 03:31:35,068:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-26 03:42:05,645:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 630.58s, LR: 0.00009, Train Loss: 0.2485, Train MAE: 0.2485,
                            Val Loss: 0.4818, Val MAE: 0.4818
2023-01-26 03:42:05,645:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-26 03:52:35,198:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.55s, LR: 0.00009, Train Loss: 0.2480, Train MAE: 0.2480,
                            Val Loss: 0.3645, Val MAE: 0.3644
2023-01-26 03:52:35,199:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-26 04:03:04,290:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 629.09s, LR: 0.00009, Train Loss: 0.2463, Train MAE: 0.2463,
                            Val Loss: 0.5405, Val MAE: 0.5406
2023-01-26 04:03:04,291:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-26 04:13:37,840:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 633.55s, LR: 0.00009, Train Loss: 0.2427, Train MAE: 0.2427,
                            Val Loss: 0.4187, Val MAE: 0.4187
2023-01-26 04:13:37,841:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-26 04:24:10,730:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 632.89s, LR: 0.00009, Train Loss: 0.2411, Train MAE: 0.2411,
                            Val Loss: 0.3387, Val MAE: 0.3386
2023-01-26 04:24:10,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-26 04:34:47,137:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.41s, LR: 0.00009, Train Loss: 0.2398, Train MAE: 0.2398,
                            Val Loss: 0.3223, Val MAE: 0.3222
2023-01-26 04:34:47,138:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-26 04:45:23,712:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.57s, LR: 0.00009, Train Loss: 0.2399, Train MAE: 0.2399,
                            Val Loss: 0.3152, Val MAE: 0.3151
2023-01-26 04:45:23,713:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-26 04:56:54,793:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.08s, LR: 0.00009, Train Loss: 0.2361, Train MAE: 0.2361,
                            Val Loss: 0.3625, Val MAE: 0.3624
2023-01-26 04:56:54,794:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 126/1000
2023-01-26 05:07:31,137:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.34s, LR: 0.00009, Train Loss: 0.2352, Train MAE: 0.2352,
                            Val Loss: 0.4364, Val MAE: 0.4363
2023-01-26 05:07:31,138:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 127/1000
2023-01-26 05:18:02,719:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 631.58s, LR: 0.00009, Train Loss: 0.2339, Train MAE: 0.2339,
                            Val Loss: 0.4225, Val MAE: 0.4225
2023-01-26 05:18:02,720:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 128/1000
2023-01-26 05:28:31,097:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 628.38s, LR: 0.00009, Train Loss: 0.2327, Train MAE: 0.2327,
                            Val Loss: 0.4340, Val MAE: 0.4340
2023-01-26 05:28:31,098:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:28:31,098:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
