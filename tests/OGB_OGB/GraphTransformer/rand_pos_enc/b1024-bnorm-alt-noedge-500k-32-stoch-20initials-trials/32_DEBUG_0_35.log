2023-01-25 05:10:36,636:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-25 05:10:36,636:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:21:31,736:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:22:00,102:ogbdata.py:332 -             __init__(): Time taken: 683.4663s
2023-01-25 05:22:00,103:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:22:00,103:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:22:00,103:ogbdata.py:348 -             __init__(): [I] Data load time: 683.4669s
2023-01-25 05:22:00,103:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials/32_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-25 05:22:00,103:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials', 'job_num': 32}
2023-01-25 05:22:00,106:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:22:07,585:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:22:07,585:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:22:07,586:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:22:07,604:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:22:07,607:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-25 05:22:07,608:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-25 05:22:07,608:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:22:07,610:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:22:07,610:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:22:07,610:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:22:07,635:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:32:51,809:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4244.200833320618
2023-01-25 06:32:51,817:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:32:51,817:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:32:51,838:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:46:30,060:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.7921910285949707
2023-01-25 06:46:30,062:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 818.22s, LR: 0.00070, Train Loss: 0.6889, Train MAE: 0.6889,
                            Val Loss: 1.7926, Val MAE: 1.7922
2023-01-25 06:46:30,062:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 06:57:48,901:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.1439756155014038
2023-01-25 06:57:48,903:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.84s, LR: 0.00070, Train Loss: 0.5045, Train MAE: 0.5045,
                            Val Loss: 1.1441, Val MAE: 1.1440
2023-01-25 06:57:48,904:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:09:06,742:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9225926995277405
2023-01-25 07:09:06,744:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.84s, LR: 0.00070, Train Loss: 0.4561, Train MAE: 0.4561,
                            Val Loss: 0.9227, Val MAE: 0.9226
2023-01-25 07:09:06,745:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:20:25,455:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.71s, LR: 0.00070, Train Loss: 0.4292, Train MAE: 0.4292,
                            Val Loss: 9.0401, Val MAE: 9.0369
2023-01-25 07:20:25,457:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:31:46,784:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.33s, LR: 0.00070, Train Loss: 0.4064, Train MAE: 0.4064,
                            Val Loss: 5.2371, Val MAE: 5.2352
2023-01-25 07:31:46,785:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:43:07,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.08s, LR: 0.00070, Train Loss: 0.5824, Train MAE: 0.5824,
                            Val Loss: 1.4739, Val MAE: 1.4731
2023-01-25 07:43:07,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 07:54:29,354:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.48s, LR: 0.00070, Train Loss: 0.5076, Train MAE: 0.5076,
                            Val Loss: 1.4061, Val MAE: 1.4059
2023-01-25 07:54:29,355:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 08:06:50,520:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 741.16s, LR: 0.00070, Train Loss: 0.4767, Train MAE: 0.4767,
                            Val Loss: 1.1195, Val MAE: 1.1193
2023-01-25 08:06:50,521:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:18:10,552:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.03s, LR: 0.00070, Train Loss: 0.4773, Train MAE: 0.4773,
                            Val Loss: 1.3277, Val MAE: 1.3272
2023-01-25 08:18:10,554:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:29:30,018:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9140225648880005
2023-01-25 08:29:30,020:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.47s, LR: 0.00070, Train Loss: 0.4807, Train MAE: 0.4807,
                            Val Loss: 0.9141, Val MAE: 0.9140
2023-01-25 08:29:30,021:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:40:50,889:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9024224281311035
2023-01-25 08:40:50,892:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.87s, LR: 0.00070, Train Loss: 0.4388, Train MAE: 0.4388,
                            Val Loss: 0.9027, Val MAE: 0.9024
2023-01-25 08:40:50,893:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 08:52:12,235:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.34s, LR: 0.00070, Train Loss: 0.5311, Train MAE: 0.5311,
                            Val Loss: 1.5973, Val MAE: 1.5970
2023-01-25 08:52:12,237:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 09:03:32,141:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.90s, LR: 0.00070, Train Loss: 0.5203, Train MAE: 0.5203,
                            Val Loss: 1.0629, Val MAE: 1.0625
2023-01-25 09:03:32,143:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:14:50,286:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.14s, LR: 0.00070, Train Loss: 0.4643, Train MAE: 0.4643,
                            Val Loss: 1.2866, Val MAE: 1.2864
2023-01-25 09:14:50,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:26:09,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.43s, LR: 0.00070, Train Loss: 0.4616, Train MAE: 0.4616,
                            Val Loss: 1.0803, Val MAE: 1.0803
2023-01-25 09:26:09,723:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:37:26,971:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8695070743560791
2023-01-25 09:37:26,973:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.25s, LR: 0.00070, Train Loss: 0.5491, Train MAE: 0.5491,
                            Val Loss: 0.8697, Val MAE: 0.8695
2023-01-25 09:37:26,974:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 09:48:45,059:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.08s, LR: 0.00070, Train Loss: 0.4870, Train MAE: 0.4870,
                            Val Loss: 1.8313, Val MAE: 1.8308
2023-01-25 09:48:45,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 10:00:03,892:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.83s, LR: 0.00070, Train Loss: 0.4536, Train MAE: 0.4536,
                            Val Loss: 1.0873, Val MAE: 1.0870
2023-01-25 10:00:03,894:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 10:11:20,614:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.72s, LR: 0.00070, Train Loss: 0.4319, Train MAE: 0.4319,
                            Val Loss: 1.3159, Val MAE: 1.3156
2023-01-25 10:11:20,616:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:22:38,278:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5513941645622253
2023-01-25 10:22:38,279:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.66s, LR: 0.00070, Train Loss: 0.4255, Train MAE: 0.4255,
                            Val Loss: 0.5513, Val MAE: 0.5514
2023-01-25 10:22:38,279:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 10:33:56,721:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.44s, LR: 0.00070, Train Loss: 0.4276, Train MAE: 0.4276,
                            Val Loss: 1.4795, Val MAE: 1.4791
2023-01-25 10:33:56,722:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 10:45:13,508:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.79s, LR: 0.00070, Train Loss: 0.4476, Train MAE: 0.4476,
                            Val Loss: 1.3731, Val MAE: 1.3726
2023-01-25 10:45:13,510:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 10:56:31,357:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.85s, LR: 0.00070, Train Loss: 0.4104, Train MAE: 0.4104,
                            Val Loss: 0.9854, Val MAE: 0.9852
2023-01-25 10:56:31,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 11:08:48,834:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.47s, LR: 0.00070, Train Loss: 0.3988, Train MAE: 0.3988,
                            Val Loss: 1.2117, Val MAE: 1.2116
2023-01-25 11:08:48,835:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:20:06,383:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.55s, LR: 0.00070, Train Loss: 0.7147, Train MAE: 0.7147,
                            Val Loss: 0.9414, Val MAE: 0.9411
2023-01-25 11:20:06,384:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 11:31:23,451:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.07s, LR: 0.00070, Train Loss: 0.5712, Train MAE: 0.5712,
                            Val Loss: 0.6938, Val MAE: 0.6934
2023-01-25 11:31:23,452:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 11:42:39,286:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.83s, LR: 0.00070, Train Loss: 0.5442, Train MAE: 0.5442,
                            Val Loss: 1.4267, Val MAE: 1.4264
2023-01-25 11:42:39,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 11:53:56,623:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.33s, LR: 0.00070, Train Loss: 0.5320, Train MAE: 0.5320,
                            Val Loss: 0.8805, Val MAE: 0.8804
2023-01-25 11:53:56,624:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 12:05:14,055:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.43s, LR: 0.00070, Train Loss: 0.5167, Train MAE: 0.5167,
                            Val Loss: 0.9082, Val MAE: 0.9080
2023-01-25 12:05:14,056:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 12:16:30,645:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.59s, LR: 0.00070, Train Loss: 0.4920, Train MAE: 0.4920,
                            Val Loss: 0.9857, Val MAE: 0.9854
2023-01-25 12:16:30,647:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 12:27:47,688:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.04s, LR: 0.00070, Train Loss: 0.4783, Train MAE: 0.4783,
                            Val Loss: 0.9097, Val MAE: 0.9095
2023-01-25 12:27:47,689:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 12:39:04,355:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.67s, LR: 0.00070, Train Loss: 0.4605, Train MAE: 0.4605,
                            Val Loss: 1.2266, Val MAE: 1.2264
2023-01-25 12:39:04,357:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 12:50:22,395:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.04s, LR: 0.00070, Train Loss: 0.4389, Train MAE: 0.4389,
                            Val Loss: 1.2976, Val MAE: 1.2974
2023-01-25 12:50:22,396:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 13:01:42,013:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.62s, LR: 0.00070, Train Loss: 0.4262, Train MAE: 0.4262,
                            Val Loss: 0.8599, Val MAE: 0.8597
2023-01-25 13:01:42,014:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 13:13:00,652:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.64s, LR: 0.00070, Train Loss: 0.4186, Train MAE: 0.4186,
                            Val Loss: 1.2868, Val MAE: 1.2866
2023-01-25 13:13:00,653:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 13:24:18,338:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.68s, LR: 0.00070, Train Loss: 0.4051, Train MAE: 0.4051,
                            Val Loss: 0.7908, Val MAE: 0.7906
2023-01-25 13:24:18,339:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 13:35:35,413:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.07s, LR: 0.00035, Train Loss: 0.3874, Train MAE: 0.3874,
                            Val Loss: 1.1549, Val MAE: 1.1547
2023-01-25 13:35:35,414:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 13:46:52,049:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.63s, LR: 0.00035, Train Loss: 0.3819, Train MAE: 0.3819,
                            Val Loss: 1.2205, Val MAE: 1.2203
2023-01-25 13:46:52,050:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 13:58:10,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.92s, LR: 0.00035, Train Loss: 0.3792, Train MAE: 0.3792,
                            Val Loss: 1.2266, Val MAE: 1.2265
2023-01-25 13:58:10,973:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 14:09:29,052:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.08s, LR: 0.00035, Train Loss: 0.3746, Train MAE: 0.3746,
                            Val Loss: 0.8962, Val MAE: 0.8960
2023-01-25 14:09:29,054:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 14:21:46,816:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.76s, LR: 0.00035, Train Loss: 0.3722, Train MAE: 0.3722,
                            Val Loss: 0.8372, Val MAE: 0.8371
2023-01-25 14:21:46,817:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 14:33:05,668:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.85s, LR: 0.00035, Train Loss: 0.3665, Train MAE: 0.3665,
                            Val Loss: 1.3557, Val MAE: 1.3552
2023-01-25 14:33:05,669:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 14:44:23,539:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.87s, LR: 0.00035, Train Loss: 0.3652, Train MAE: 0.3652,
                            Val Loss: 1.7549, Val MAE: 1.7546
2023-01-25 14:44:23,540:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 14:55:42,413:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.87s, LR: 0.00035, Train Loss: 0.3616, Train MAE: 0.3616,
                            Val Loss: 1.5830, Val MAE: 1.5828
2023-01-25 14:55:42,414:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 15:07:00,394:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.98s, LR: 0.00035, Train Loss: 0.3592, Train MAE: 0.3592,
                            Val Loss: 1.1052, Val MAE: 1.1052
2023-01-25 15:07:00,395:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 15:18:19,069:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.67s, LR: 0.00035, Train Loss: 0.3568, Train MAE: 0.3568,
                            Val Loss: 0.9834, Val MAE: 0.9831
2023-01-25 15:18:19,071:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 15:29:37,688:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.62s, LR: 0.00035, Train Loss: 0.3551, Train MAE: 0.3551,
                            Val Loss: 0.9035, Val MAE: 0.9034
2023-01-25 15:29:37,690:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 15:40:55,543:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.85s, LR: 0.00035, Train Loss: 0.3532, Train MAE: 0.3532,
                            Val Loss: 0.7348, Val MAE: 0.7346
2023-01-25 15:40:55,545:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 15:52:13,614:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.07s, LR: 0.00035, Train Loss: 0.3518, Train MAE: 0.3518,
                            Val Loss: 1.4253, Val MAE: 1.4250
2023-01-25 15:52:13,616:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 16:03:33,776:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.16s, LR: 0.00035, Train Loss: 0.3511, Train MAE: 0.3511,
                            Val Loss: 1.3581, Val MAE: 1.3579
2023-01-25 16:03:33,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 16:14:53,390:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.61s, LR: 0.00035, Train Loss: 0.3503, Train MAE: 0.3503,
                            Val Loss: 0.9074, Val MAE: 0.9072
2023-01-25 16:14:53,392:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 16:26:13,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.99s, LR: 0.00035, Train Loss: 0.3507, Train MAE: 0.3507,
                            Val Loss: 0.8150, Val MAE: 0.8150
2023-01-25 16:26:13,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 16:37:33,335:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.95s, LR: 0.00017, Train Loss: 0.3428, Train MAE: 0.3428,
                            Val Loss: 1.0651, Val MAE: 1.0649
2023-01-25 16:37:33,337:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 16:48:53,307:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.97s, LR: 0.00017, Train Loss: 0.3417, Train MAE: 0.3417,
                            Val Loss: 0.8232, Val MAE: 0.8233
2023-01-25 16:48:53,308:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 17:00:13,562:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.25s, LR: 0.00017, Train Loss: 0.3407, Train MAE: 0.3407,
                            Val Loss: 0.7290, Val MAE: 0.7289
2023-01-25 17:00:13,564:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 17:11:33,293:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.73s, LR: 0.00017, Train Loss: 0.3390, Train MAE: 0.3390,
                            Val Loss: 1.0782, Val MAE: 1.0781
2023-01-25 17:11:33,295:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 17:22:52,878:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.58s, LR: 0.00017, Train Loss: 0.3386, Train MAE: 0.3386,
                            Val Loss: 1.6164, Val MAE: 1.6160
2023-01-25 17:22:52,879:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 17:35:10,874:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.99s, LR: 0.00017, Train Loss: 0.3371, Train MAE: 0.3371,
                            Val Loss: 0.8652, Val MAE: 0.8649
2023-01-25 17:35:10,876:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 17:46:29,719:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.84s, LR: 0.00017, Train Loss: 0.3345, Train MAE: 0.3345,
                            Val Loss: 1.2492, Val MAE: 1.2489
2023-01-25 17:46:29,721:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 17:57:49,570:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.85s, LR: 0.00017, Train Loss: 0.3340, Train MAE: 0.3340,
                            Val Loss: 1.3937, Val MAE: 1.3934
2023-01-25 17:57:49,571:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 18:09:08,546:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.97s, LR: 0.00017, Train Loss: 0.3330, Train MAE: 0.3330,
                            Val Loss: 1.0386, Val MAE: 1.0384
2023-01-25 18:09:08,548:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 18:20:29,071:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.52s, LR: 0.00017, Train Loss: 0.3319, Train MAE: 0.3319,
                            Val Loss: 1.3308, Val MAE: 1.3308
2023-01-25 18:20:29,072:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 18:31:48,656:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.58s, LR: 0.00017, Train Loss: 0.3307, Train MAE: 0.3307,
                            Val Loss: 1.6461, Val MAE: 1.6458
2023-01-25 18:31:48,657:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 18:43:07,297:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.64s, LR: 0.00017, Train Loss: 0.3307, Train MAE: 0.3307,
                            Val Loss: 0.7616, Val MAE: 0.7616
2023-01-25 18:43:07,299:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 18:54:28,107:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.81s, LR: 0.00017, Train Loss: 0.3294, Train MAE: 0.3294,
                            Val Loss: 0.7917, Val MAE: 0.7916
2023-01-25 18:54:28,108:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 19:05:47,142:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.03s, LR: 0.00017, Train Loss: 0.3294, Train MAE: 0.3294,
                            Val Loss: 1.1572, Val MAE: 1.1571
2023-01-25 19:05:47,143:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 19:17:06,347:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.20s, LR: 0.00017, Train Loss: 0.3292, Train MAE: 0.3292,
                            Val Loss: 1.0474, Val MAE: 1.0473
2023-01-25 19:17:06,349:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 19:28:25,381:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.03s, LR: 0.00017, Train Loss: 0.3268, Train MAE: 0.3268,
                            Val Loss: 0.8776, Val MAE: 0.8776
2023-01-25 19:28:25,382:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 19:39:42,404:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.02s, LR: 0.00009, Train Loss: 0.3221, Train MAE: 0.3221,
                            Val Loss: 0.6668, Val MAE: 0.6665
2023-01-25 19:39:42,405:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 19:50:59,829:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.42s, LR: 0.00009, Train Loss: 0.3211, Train MAE: 0.3211,
                            Val Loss: 0.6127, Val MAE: 0.6128
2023-01-25 19:50:59,830:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 20:02:15,948:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5220128893852234
2023-01-25 20:02:15,950:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.12s, LR: 0.00009, Train Loss: 0.3203, Train MAE: 0.3203,
                            Val Loss: 0.5220, Val MAE: 0.5220
2023-01-25 20:02:15,950:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 20:13:32,706:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.75s, LR: 0.00009, Train Loss: 0.3192, Train MAE: 0.3192,
                            Val Loss: 0.9013, Val MAE: 0.9008
2023-01-25 20:13:32,707:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 20:24:49,059:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4341786503791809
2023-01-25 20:24:49,061:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.35s, LR: 0.00009, Train Loss: 0.3186, Train MAE: 0.3186,
                            Val Loss: 0.4342, Val MAE: 0.4342
2023-01-25 20:24:49,061:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 20:36:06,082:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.02s, LR: 0.00009, Train Loss: 0.3176, Train MAE: 0.3176,
                            Val Loss: 0.8720, Val MAE: 0.8722
2023-01-25 20:36:06,083:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 20:48:21,694:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 735.61s, LR: 0.00009, Train Loss: 0.3168, Train MAE: 0.3168,
                            Val Loss: 0.7696, Val MAE: 0.7696
2023-01-25 20:48:21,695:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 20:59:39,661:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.97s, LR: 0.00009, Train Loss: 0.3162, Train MAE: 0.3162,
                            Val Loss: 0.8372, Val MAE: 0.8367
2023-01-25 20:59:39,662:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 21:10:57,776:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.11s, LR: 0.00009, Train Loss: 0.3155, Train MAE: 0.3155,
                            Val Loss: 0.7181, Val MAE: 0.7178
2023-01-25 21:10:57,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 21:22:15,805:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.03s, LR: 0.00009, Train Loss: 0.3147, Train MAE: 0.3147,
                            Val Loss: 0.5155, Val MAE: 0.5152
2023-01-25 21:22:15,806:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-25 21:33:34,831:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.02s, LR: 0.00009, Train Loss: 0.3146, Train MAE: 0.3146,
                            Val Loss: 0.5549, Val MAE: 0.5549
2023-01-25 21:33:34,833:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-25 21:44:52,606:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.77s, LR: 0.00009, Train Loss: 0.3138, Train MAE: 0.3138,
                            Val Loss: 0.9831, Val MAE: 0.9825
2023-01-25 21:44:52,607:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-25 21:56:12,562:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.95s, LR: 0.00009, Train Loss: 0.3132, Train MAE: 0.3132,
                            Val Loss: 0.5011, Val MAE: 0.5008
2023-01-25 21:56:12,563:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-25 22:07:30,794:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.23s, LR: 0.00009, Train Loss: 0.3130, Train MAE: 0.3130,
                            Val Loss: 0.5220, Val MAE: 0.5221
2023-01-25 22:07:30,795:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-25 22:18:48,648:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.85s, LR: 0.00009, Train Loss: 0.3121, Train MAE: 0.3121,
                            Val Loss: 0.7345, Val MAE: 0.7346
2023-01-25 22:18:48,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-25 22:30:05,872:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.22s, LR: 0.00009, Train Loss: 0.3111, Train MAE: 0.3111,
                            Val Loss: 0.4366, Val MAE: 0.4366
2023-01-25 22:30:05,874:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-25 22:41:22,057:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.18s, LR: 0.00009, Train Loss: 0.3100, Train MAE: 0.3100,
                            Val Loss: 0.7782, Val MAE: 0.7783
2023-01-25 22:41:22,057:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-25 22:52:40,551:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3653942048549652
2023-01-25 22:52:40,552:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.49s, LR: 0.00009, Train Loss: 0.3089, Train MAE: 0.3089,
                            Val Loss: 0.3655, Val MAE: 0.3654
2023-01-25 22:52:40,553:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-25 23:03:59,050:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.50s, LR: 0.00009, Train Loss: 0.3077, Train MAE: 0.3077,
                            Val Loss: 0.4675, Val MAE: 0.4674
2023-01-25 23:03:59,051:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-25 23:15:17,361:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.31s, LR: 0.00009, Train Loss: 0.3047, Train MAE: 0.3047,
                            Val Loss: 0.4918, Val MAE: 0.4918
2023-01-25 23:15:17,363:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-25 23:26:35,864:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3572961986064911
2023-01-25 23:26:35,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.50s, LR: 0.00009, Train Loss: 0.3011, Train MAE: 0.3011,
                            Val Loss: 0.3574, Val MAE: 0.3573
2023-01-25 23:26:35,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-25 23:37:52,941:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.07s, LR: 0.00009, Train Loss: 0.2987, Train MAE: 0.2987,
                            Val Loss: 0.4132, Val MAE: 0.4130
2023-01-25 23:37:52,942:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-25 23:49:10,874:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.93s, LR: 0.00009, Train Loss: 0.2945, Train MAE: 0.2945,
                            Val Loss: 0.4174, Val MAE: 0.4173
2023-01-25 23:49:10,876:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-26 00:01:26,088:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 735.21s, LR: 0.00009, Train Loss: 0.2919, Train MAE: 0.2919,
                            Val Loss: 0.5828, Val MAE: 0.5830
2023-01-26 00:01:26,090:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-26 00:12:44,693:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.60s, LR: 0.00009, Train Loss: 0.2916, Train MAE: 0.2916,
                            Val Loss: 0.6403, Val MAE: 0.6405
2023-01-26 00:12:44,694:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-26 00:24:01,413:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.72s, LR: 0.00009, Train Loss: 0.2892, Train MAE: 0.2892,
                            Val Loss: 0.4976, Val MAE: 0.4975
2023-01-26 00:24:01,414:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-26 00:35:19,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.29s, LR: 0.00009, Train Loss: 0.2868, Train MAE: 0.2868,
                            Val Loss: 0.5659, Val MAE: 0.5661
2023-01-26 00:35:19,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-26 00:46:37,112:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.41s, LR: 0.00009, Train Loss: 0.2862, Train MAE: 0.2862,
                            Val Loss: 0.8087, Val MAE: 0.8091
2023-01-26 00:46:37,113:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 00:57:55,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.50s, LR: 0.00009, Train Loss: 0.2843, Train MAE: 0.2843,
                            Val Loss: 0.3971, Val MAE: 0.3971
2023-01-26 00:57:55,620:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 01:09:13,329:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.71s, LR: 0.00009, Train Loss: 0.2817, Train MAE: 0.2817,
                            Val Loss: 0.3617, Val MAE: 0.3615
2023-01-26 01:09:13,330:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 01:20:30,611:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.28s, LR: 0.00009, Train Loss: 0.2867, Train MAE: 0.2867,
                            Val Loss: 0.4350, Val MAE: 0.4350
2023-01-26 01:20:30,612:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 01:31:48,271:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.66s, LR: 0.00009, Train Loss: 0.2823, Train MAE: 0.2823,
                            Val Loss: 0.5127, Val MAE: 0.5128
2023-01-26 01:31:48,272:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 01:43:04,698:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.43s, LR: 0.00009, Train Loss: 0.2900, Train MAE: 0.2900,
                            Val Loss: 0.6028, Val MAE: 0.6030
2023-01-26 01:43:04,699:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 01:54:22,123:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.42s, LR: 0.00009, Train Loss: 0.2853, Train MAE: 0.2853,
                            Val Loss: 0.5812, Val MAE: 0.5813
2023-01-26 01:54:22,124:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 02:05:39,055:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.93s, LR: 0.00009, Train Loss: 0.2834, Train MAE: 0.2834,
                            Val Loss: 0.5027, Val MAE: 0.5026
2023-01-26 02:05:39,056:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-26 02:16:56,340:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.28s, LR: 0.00009, Train Loss: 0.2807, Train MAE: 0.2807,
                            Val Loss: 0.3627, Val MAE: 0.3627
2023-01-26 02:16:56,341:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-26 02:28:13,171:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.83s, LR: 0.00009, Train Loss: 0.2794, Train MAE: 0.2794,
                            Val Loss: 0.5220, Val MAE: 0.5221
2023-01-26 02:28:13,172:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-26 02:39:28,479:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.31s, LR: 0.00004, Train Loss: 0.2732, Train MAE: 0.2732,
                            Val Loss: 0.5105, Val MAE: 0.5105
2023-01-26 02:39:28,480:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-26 02:50:43,125:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 674.64s, LR: 0.00004, Train Loss: 0.2724, Train MAE: 0.2724,
                            Val Loss: 0.3636, Val MAE: 0.3634
2023-01-26 02:50:43,126:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-26 03:02:58,177:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 735.05s, LR: 0.00004, Train Loss: 0.2709, Train MAE: 0.2709,
                            Val Loss: 0.7358, Val MAE: 0.7362
2023-01-26 03:02:58,178:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-26 03:14:13,573:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.39s, LR: 0.00004, Train Loss: 0.2707, Train MAE: 0.2707,
                            Val Loss: 0.5576, Val MAE: 0.5577
2023-01-26 03:14:13,574:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-26 03:25:31,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.54s, LR: 0.00004, Train Loss: 0.2701, Train MAE: 0.2701,
                            Val Loss: 0.4093, Val MAE: 0.4093
2023-01-26 03:25:31,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-26 03:36:47,765:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.65s, LR: 0.00004, Train Loss: 0.2688, Train MAE: 0.2688,
                            Val Loss: 0.7167, Val MAE: 0.7171
2023-01-26 03:36:47,767:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-26 03:48:04,107:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.34s, LR: 0.00004, Train Loss: 0.2676, Train MAE: 0.2676,
                            Val Loss: 0.5579, Val MAE: 0.5580
2023-01-26 03:48:04,108:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-26 03:59:21,617:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.51s, LR: 0.00004, Train Loss: 0.2672, Train MAE: 0.2672,
                            Val Loss: 0.5229, Val MAE: 0.5230
2023-01-26 03:59:21,618:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-26 04:10:37,830:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.21s, LR: 0.00004, Train Loss: 0.2671, Train MAE: 0.2671,
                            Val Loss: 0.6910, Val MAE: 0.6912
2023-01-26 04:10:37,831:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-26 04:21:54,564:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.73s, LR: 0.00004, Train Loss: 0.2656, Train MAE: 0.2656,
                            Val Loss: 0.6481, Val MAE: 0.6483
2023-01-26 04:21:54,566:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-26 04:33:10,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.75s, LR: 0.00004, Train Loss: 0.2655, Train MAE: 0.2655,
                            Val Loss: 0.5789, Val MAE: 0.5790
2023-01-26 04:33:10,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-26 04:44:27,049:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.73s, LR: 0.00004, Train Loss: 0.2650, Train MAE: 0.2650,
                            Val Loss: 0.6799, Val MAE: 0.6802
2023-01-26 04:44:27,050:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-26 04:55:44,127:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.08s, LR: 0.00004, Train Loss: 0.2682, Train MAE: 0.2682,
                            Val Loss: 0.4414, Val MAE: 0.4414
2023-01-26 04:55:44,128:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-26 05:07:00,283:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.15s, LR: 0.00004, Train Loss: 0.2669, Train MAE: 0.2669,
                            Val Loss: 0.4694, Val MAE: 0.4695
2023-01-26 05:07:00,284:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-26 05:18:16,986:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3493483364582062
2023-01-26 05:18:16,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 676.70s, LR: 0.00004, Train Loss: 0.2669, Train MAE: 0.2669,
                            Val Loss: 0.3494, Val MAE: 0.3493
2023-01-26 05:18:16,988:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-26 05:29:32,491:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.50s, LR: 0.00004, Train Loss: 0.2638, Train MAE: 0.2638,
                            Val Loss: 0.3793, Val MAE: 0.3793
2023-01-26 05:29:32,492:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:29:32,492:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-26 05:38:08,091:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.3793
2023-01-26 05:38:08,093:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.3414
2023-01-26 05:38:08,095:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-26 05:38:08,096:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 120.0000
2023-01-26 05:38:08,097:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87360.4893s
2023-01-26 05:38:08,097:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 682.6494s
2023-01-26 05:38:08,099:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-20initials-trials', 'job_num': 32}
2023-01-26 05:38:08,267:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.3414)]
2023-01-26 05:38:08,267:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.3793)]
