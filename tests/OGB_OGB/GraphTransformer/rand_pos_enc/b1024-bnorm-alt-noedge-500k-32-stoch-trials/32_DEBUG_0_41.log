2023-01-25 05:05:18,047:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-25 05:05:18,047:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:16:37,319:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:17:08,022:ogbdata.py:332 -             __init__(): Time taken: 709.9747s
2023-01-25 05:17:08,022:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:17:08,022:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:17:08,022:ogbdata.py:348 -             __init__(): [I] Data load time: 709.9753s
2023-01-25 05:17:08,023:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-trials/32_DEBUG_0_41.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [41]}
2023-01-25 05:17:08,023:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-25 05:17:08,037:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:17:15,167:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:17:15,167:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:17:15,167:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:17:15,199:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:17:15,211:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-25 05:17:15,212:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2023-01-25 05:17:15,212:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:17:15,213:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:17:15,213:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:17:15,213:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:17:15,264:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:26:22,979:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4147.766465425491
2023-01-25 06:26:22,985:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:26:22,985:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:26:23,188:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:39:58,012:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 2.7009735107421875
2023-01-25 06:39:58,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 814.83s, LR: 0.00070, Train Loss: 0.5372, Train MAE: 0.5372,
                            Val Loss: 2.7017, Val MAE: 2.7010
2023-01-25 06:39:58,014:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 06:52:09,147:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9288685917854309
2023-01-25 06:52:09,149:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 731.13s, LR: 0.00070, Train Loss: 0.3642, Train MAE: 0.3642,
                            Val Loss: 0.9292, Val MAE: 0.9289
2023-01-25 06:52:09,150:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:04:34,439:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 745.29s, LR: 0.00070, Train Loss: 0.3674, Train MAE: 0.3674,
                            Val Loss: 1.5461, Val MAE: 1.5463
2023-01-25 07:04:34,441:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:15:57,593:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.15s, LR: 0.00070, Train Loss: 0.4197, Train MAE: 0.4197,
                            Val Loss: 8.0175, Val MAE: 8.0169
2023-01-25 07:15:57,594:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:27:11,063:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.47s, LR: 0.00070, Train Loss: 0.3803, Train MAE: 0.3803,
                            Val Loss: 2.0361, Val MAE: 2.0361
2023-01-25 07:27:11,064:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:38:23,780:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.71s, LR: 0.00070, Train Loss: 0.3588, Train MAE: 0.3588,
                            Val Loss: 3.4269, Val MAE: 3.4267
2023-01-25 07:38:23,781:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 07:49:36,415:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.63s, LR: 0.00070, Train Loss: 0.3460, Train MAE: 0.3460,
                            Val Loss: 1.4738, Val MAE: 1.4733
2023-01-25 07:49:36,417:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 08:02:02,906:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 746.49s, LR: 0.00070, Train Loss: 0.3237, Train MAE: 0.3237,
                            Val Loss: 1.8715, Val MAE: 1.8713
2023-01-25 08:02:02,907:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:13:15,232:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.32s, LR: 0.00070, Train Loss: 0.3101, Train MAE: 0.3101,
                            Val Loss: 4.4710, Val MAE: 4.4706
2023-01-25 08:13:15,233:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:24:25,602:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.37s, LR: 0.00070, Train Loss: 0.2999, Train MAE: 0.2999,
                            Val Loss: 2.2404, Val MAE: 2.2399
2023-01-25 08:24:25,603:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:35:36,768:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.16s, LR: 0.00070, Train Loss: 0.2940, Train MAE: 0.2940,
                            Val Loss: 1.8203, Val MAE: 1.8199
2023-01-25 08:35:36,769:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 08:46:47,630:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.86s, LR: 0.00070, Train Loss: 0.2808, Train MAE: 0.2808,
                            Val Loss: 2.2457, Val MAE: 2.2457
2023-01-25 08:46:47,632:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 08:57:58,346:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.71s, LR: 0.00070, Train Loss: 0.2750, Train MAE: 0.2750,
                            Val Loss: 2.3789, Val MAE: 2.3787
2023-01-25 08:57:58,347:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:09:09,548:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.20s, LR: 0.00070, Train Loss: 0.2675, Train MAE: 0.2675,
                            Val Loss: 2.8936, Val MAE: 2.8930
2023-01-25 09:09:09,549:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:20:20,273:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.72s, LR: 0.00070, Train Loss: 0.2619, Train MAE: 0.2619,
                            Val Loss: 1.7608, Val MAE: 1.7605
2023-01-25 09:20:20,274:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:31:31,825:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.55s, LR: 0.00070, Train Loss: 0.2596, Train MAE: 0.2596,
                            Val Loss: 1.4347, Val MAE: 1.4348
2023-01-25 09:31:31,826:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 09:42:41,916:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.09s, LR: 0.00070, Train Loss: 0.2540, Train MAE: 0.2540,
                            Val Loss: 1.2306, Val MAE: 1.2302
2023-01-25 09:42:41,917:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 09:53:50,566:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.65s, LR: 0.00070, Train Loss: 0.2467, Train MAE: 0.2467,
                            Val Loss: 3.0326, Val MAE: 3.0320
2023-01-25 09:53:50,567:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 10:04:58,779:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.46100640296936035
2023-01-25 10:04:58,781:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.21s, LR: 0.00035, Train Loss: 0.2394, Train MAE: 0.2394,
                            Val Loss: 0.4611, Val MAE: 0.4610
2023-01-25 10:04:58,781:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:16:04,460:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.68s, LR: 0.00035, Train Loss: 0.2358, Train MAE: 0.2358,
                            Val Loss: 0.6404, Val MAE: 0.6401
2023-01-25 10:16:04,460:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 10:27:11,878:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.42s, LR: 0.00035, Train Loss: 0.2345, Train MAE: 0.2345,
                            Val Loss: 0.5256, Val MAE: 0.5254
2023-01-25 10:27:11,879:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 10:38:20,710:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.83s, LR: 0.00035, Train Loss: 0.2403, Train MAE: 0.2403,
                            Val Loss: 1.0490, Val MAE: 1.0491
2023-01-25 10:38:20,711:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 10:49:28,672:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.96s, LR: 0.00035, Train Loss: 0.2337, Train MAE: 0.2337,
                            Val Loss: 0.9324, Val MAE: 0.9320
2023-01-25 10:49:28,674:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 11:01:46,912:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.24s, LR: 0.00035, Train Loss: 0.2318, Train MAE: 0.2318,
                            Val Loss: 0.7253, Val MAE: 0.7254
2023-01-25 11:01:46,913:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:12:55,774:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.86s, LR: 0.00035, Train Loss: 0.2274, Train MAE: 0.2274,
                            Val Loss: 0.8495, Val MAE: 0.8496
2023-01-25 11:12:55,775:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 11:24:05,099:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.32s, LR: 0.00035, Train Loss: 0.2240, Train MAE: 0.2240,
                            Val Loss: 1.0713, Val MAE: 1.0711
2023-01-25 11:24:05,100:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 11:35:13,468:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.37s, LR: 0.00035, Train Loss: 0.2228, Train MAE: 0.2228,
                            Val Loss: 0.6586, Val MAE: 0.6587
2023-01-25 11:35:13,469:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 11:46:21,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.82s, LR: 0.00035, Train Loss: 0.2229, Train MAE: 0.2229,
                            Val Loss: 0.4678, Val MAE: 0.4677
2023-01-25 11:46:21,296:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 11:57:28,243:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.95s, LR: 0.00035, Train Loss: 0.2190, Train MAE: 0.2190,
                            Val Loss: 1.3217, Val MAE: 1.3221
2023-01-25 11:57:28,244:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 12:08:35,693:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.45s, LR: 0.00035, Train Loss: 0.2226, Train MAE: 0.2226,
                            Val Loss: 1.0225, Val MAE: 1.0226
2023-01-25 12:08:35,694:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 12:19:42,894:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.20s, LR: 0.00035, Train Loss: 0.2204, Train MAE: 0.2204,
                            Val Loss: 0.7028, Val MAE: 0.7025
2023-01-25 12:19:42,895:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 12:30:53,241:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.34s, LR: 0.00035, Train Loss: 0.2190, Train MAE: 0.2190,
                            Val Loss: 0.8381, Val MAE: 0.8383
2023-01-25 12:30:53,242:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 12:42:05,406:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.16s, LR: 0.00035, Train Loss: 0.2189, Train MAE: 0.2189,
                            Val Loss: 1.1413, Val MAE: 1.1415
2023-01-25 12:42:05,407:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 12:53:11,562:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.15s, LR: 0.00035, Train Loss: 0.2176, Train MAE: 0.2176,
                            Val Loss: 1.6375, Val MAE: 1.6375
2023-01-25 12:53:11,563:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 13:04:18,468:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.90s, LR: 0.00035, Train Loss: 0.2150, Train MAE: 0.2150,
                            Val Loss: 1.4947, Val MAE: 1.4951
2023-01-25 13:04:18,469:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 13:15:26,783:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.35826513171195984
2023-01-25 13:15:26,785:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.32s, LR: 0.00017, Train Loss: 0.2087, Train MAE: 0.2087,
                            Val Loss: 0.3584, Val MAE: 0.3583
2023-01-25 13:15:26,785:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 13:26:37,386:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.60s, LR: 0.00017, Train Loss: 0.2068, Train MAE: 0.2068,
                            Val Loss: 0.5281, Val MAE: 0.5283
2023-01-25 13:26:37,387:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 13:37:45,773:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.39s, LR: 0.00017, Train Loss: 0.2059, Train MAE: 0.2059,
                            Val Loss: 0.3737, Val MAE: 0.3737
2023-01-25 13:37:45,774:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 13:48:51,284:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.51s, LR: 0.00017, Train Loss: 0.2058, Train MAE: 0.2058,
                            Val Loss: 0.6614, Val MAE: 0.6617
2023-01-25 13:48:51,285:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 14:00:38,325:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3218473792076111
2023-01-25 14:00:38,326:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.04s, LR: 0.00017, Train Loss: 0.2042, Train MAE: 0.2042,
                            Val Loss: 0.3220, Val MAE: 0.3218
2023-01-25 14:00:38,328:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 14:13:00,422:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.09s, LR: 0.00017, Train Loss: 0.2050, Train MAE: 0.2050,
                            Val Loss: 0.4589, Val MAE: 0.4586
2023-01-25 14:13:00,423:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 14:24:02,643:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.22s, LR: 0.00017, Train Loss: 0.2030, Train MAE: 0.2030,
                            Val Loss: 0.4730, Val MAE: 0.4729
2023-01-25 14:24:02,644:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 14:35:25,716:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.07s, LR: 0.00017, Train Loss: 0.2014, Train MAE: 0.2014,
                            Val Loss: 0.3315, Val MAE: 0.3314
2023-01-25 14:35:25,718:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 14:47:30,277:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.56s, LR: 0.00017, Train Loss: 0.1962, Train MAE: 0.1962,
                            Val Loss: 0.6187, Val MAE: 0.6190
2023-01-25 14:47:30,278:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 14:59:03,830:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.55s, LR: 0.00017, Train Loss: 0.1933, Train MAE: 0.1933,
                            Val Loss: 0.3527, Val MAE: 0.3527
2023-01-25 14:59:03,831:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 15:10:49,030:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.27548378705978394
2023-01-25 15:10:49,031:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.20s, LR: 0.00017, Train Loss: 0.1909, Train MAE: 0.1909,
                            Val Loss: 0.2756, Val MAE: 0.2755
2023-01-25 15:10:49,032:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 15:21:42,608:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.25063246488571167
2023-01-25 15:21:42,610:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.58s, LR: 0.00017, Train Loss: 0.1880, Train MAE: 0.1880,
                            Val Loss: 0.2507, Val MAE: 0.2506
2023-01-25 15:21:42,610:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 15:32:36,087:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.48s, LR: 0.00017, Train Loss: 0.1886, Train MAE: 0.1886,
                            Val Loss: 0.2673, Val MAE: 0.2671
2023-01-25 15:32:36,089:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 15:43:49,408:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.32s, LR: 0.00017, Train Loss: 0.1877, Train MAE: 0.1877,
                            Val Loss: 0.2657, Val MAE: 0.2656
2023-01-25 15:43:49,410:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 15:55:53,329:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.24865446984767914
2023-01-25 15:55:53,331:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.92s, LR: 0.00017, Train Loss: 0.1879, Train MAE: 0.1879,
                            Val Loss: 0.2488, Val MAE: 0.2487
2023-01-25 15:55:53,331:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 16:07:40,210:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.88s, LR: 0.00017, Train Loss: 0.2017, Train MAE: 0.2017,
                            Val Loss: 0.2816, Val MAE: 0.2815
2023-01-25 16:07:40,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 16:19:38,867:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.66s, LR: 0.00017, Train Loss: 0.1988, Train MAE: 0.1988,
                            Val Loss: 0.2682, Val MAE: 0.2681
2023-01-25 16:19:38,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 16:31:00,654:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.79s, LR: 0.00017, Train Loss: 0.1908, Train MAE: 0.1908,
                            Val Loss: 0.2849, Val MAE: 0.2849
2023-01-25 16:31:00,655:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 16:41:53,742:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.09s, LR: 0.00017, Train Loss: 0.1868, Train MAE: 0.1868,
                            Val Loss: 0.2534, Val MAE: 0.2533
2023-01-25 16:41:53,743:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 16:52:56,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.19s, LR: 0.00017, Train Loss: 0.1864, Train MAE: 0.1864,
                            Val Loss: 0.2652, Val MAE: 0.2651
2023-01-25 16:52:56,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 17:04:06,440:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.24839209020137787
2023-01-25 17:04:06,442:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.51s, LR: 0.00017, Train Loss: 0.1856, Train MAE: 0.1856,
                            Val Loss: 0.2485, Val MAE: 0.2484
2023-01-25 17:04:06,442:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 17:15:45,518:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.08s, LR: 0.00017, Train Loss: 0.1823, Train MAE: 0.1823,
                            Val Loss: 0.3774, Val MAE: 0.3774
2023-01-25 17:15:45,519:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 17:27:45,631:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.11s, LR: 0.00017, Train Loss: 0.1811, Train MAE: 0.1811,
                            Val Loss: 0.4863, Val MAE: 0.4862
2023-01-25 17:27:45,632:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 17:38:42,781:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.15s, LR: 0.00017, Train Loss: 0.1806, Train MAE: 0.1806,
                            Val Loss: 0.3175, Val MAE: 0.3175
2023-01-25 17:38:42,782:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 17:49:35,151:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.37s, LR: 0.00017, Train Loss: 0.1796, Train MAE: 0.1796,
                            Val Loss: 0.2808, Val MAE: 0.2807
2023-01-25 17:49:35,152:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 18:00:27,316:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2395825833082199
2023-01-25 18:00:27,318:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.16s, LR: 0.00017, Train Loss: 0.1806, Train MAE: 0.1806,
                            Val Loss: 0.2397, Val MAE: 0.2396
2023-01-25 18:00:27,318:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 18:11:20,006:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.69s, LR: 0.00017, Train Loss: 0.1786, Train MAE: 0.1786,
                            Val Loss: 0.3812, Val MAE: 0.3812
2023-01-25 18:11:20,007:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 18:22:10,563:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.56s, LR: 0.00017, Train Loss: 0.1776, Train MAE: 0.1776,
                            Val Loss: 0.3019, Val MAE: 0.3018
2023-01-25 18:22:10,565:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 18:33:01,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.73s, LR: 0.00017, Train Loss: 0.1766, Train MAE: 0.1766,
                            Val Loss: 0.2805, Val MAE: 0.2804
2023-01-25 18:33:01,297:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 18:43:50,755:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.46s, LR: 0.00017, Train Loss: 0.1764, Train MAE: 0.1764,
                            Val Loss: 0.3681, Val MAE: 0.3681
2023-01-25 18:43:50,756:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 18:54:39,205:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2317502796649933
2023-01-25 18:54:39,208:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.45s, LR: 0.00017, Train Loss: 0.1757, Train MAE: 0.1757,
                            Val Loss: 0.2318, Val MAE: 0.2318
2023-01-25 18:54:39,208:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 19:05:24,454:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.25s, LR: 0.00017, Train Loss: 0.1741, Train MAE: 0.1741,
                            Val Loss: 0.2373, Val MAE: 0.2372
2023-01-25 19:05:24,456:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 19:16:12,298:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.84s, LR: 0.00017, Train Loss: 0.1736, Train MAE: 0.1736,
                            Val Loss: 0.4153, Val MAE: 0.4152
2023-01-25 19:16:12,298:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 19:27:00,899:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.60s, LR: 0.00017, Train Loss: 0.1763, Train MAE: 0.1763,
                            Val Loss: 0.3797, Val MAE: 0.3798
2023-01-25 19:27:00,901:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 19:37:48,290:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.39s, LR: 0.00017, Train Loss: 0.1800, Train MAE: 0.1800,
                            Val Loss: 0.3850, Val MAE: 0.3850
2023-01-25 19:37:48,291:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 19:48:35,888:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.60s, LR: 0.00017, Train Loss: 0.1760, Train MAE: 0.1760,
                            Val Loss: 0.3815, Val MAE: 0.3815
2023-01-25 19:48:35,889:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 19:59:47,987:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.220412015914917
2023-01-25 19:59:47,989:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.10s, LR: 0.00017, Train Loss: 0.1780, Train MAE: 0.1780,
                            Val Loss: 0.2206, Val MAE: 0.2204
2023-01-25 19:59:47,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 20:10:35,128:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.14s, LR: 0.00017, Train Loss: 0.1742, Train MAE: 0.1742,
                            Val Loss: 0.3545, Val MAE: 0.3543
2023-01-25 20:10:35,129:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 20:22:01,246:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 686.12s, LR: 0.00017, Train Loss: 0.1726, Train MAE: 0.1726,
                            Val Loss: 0.4421, Val MAE: 0.4419
2023-01-25 20:22:01,247:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 20:34:08,548:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.30s, LR: 0.00017, Train Loss: 0.1738, Train MAE: 0.1738,
                            Val Loss: 0.2636, Val MAE: 0.2635
2023-01-25 20:34:08,549:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 20:44:55,789:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.20783919095993042
2023-01-25 20:44:55,790:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.24s, LR: 0.00017, Train Loss: 0.1728, Train MAE: 0.1728,
                            Val Loss: 0.2080, Val MAE: 0.2078
2023-01-25 20:44:55,790:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 20:56:15,924:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.13s, LR: 0.00017, Train Loss: 0.1720, Train MAE: 0.1720,
                            Val Loss: 0.2365, Val MAE: 0.2364
2023-01-25 20:56:15,925:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 21:08:16,741:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.82s, LR: 0.00017, Train Loss: 0.1718, Train MAE: 0.1718,
                            Val Loss: 0.4191, Val MAE: 0.4191
2023-01-25 21:08:16,742:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-25 21:20:13,050:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.31s, LR: 0.00017, Train Loss: 0.1723, Train MAE: 0.1723,
                            Val Loss: 0.2294, Val MAE: 0.2292
2023-01-25 21:20:13,051:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-25 21:31:27,019:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.97s, LR: 0.00017, Train Loss: 0.1730, Train MAE: 0.1730,
                            Val Loss: 0.4487, Val MAE: 0.4487
2023-01-25 21:31:27,020:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-25 21:42:57,742:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.72s, LR: 0.00017, Train Loss: 0.1728, Train MAE: 0.1728,
                            Val Loss: 0.3601, Val MAE: 0.3601
2023-01-25 21:42:57,743:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-25 21:54:39,452:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.71s, LR: 0.00017, Train Loss: 0.1715, Train MAE: 0.1715,
                            Val Loss: 0.3990, Val MAE: 0.3989
2023-01-25 21:54:39,454:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-25 22:06:27,533:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.08s, LR: 0.00017, Train Loss: 0.1701, Train MAE: 0.1701,
                            Val Loss: 0.3627, Val MAE: 0.3627
2023-01-25 22:06:27,535:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-25 22:17:52,955:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.42s, LR: 0.00017, Train Loss: 0.1685, Train MAE: 0.1685,
                            Val Loss: 0.2083, Val MAE: 0.2081
2023-01-25 22:17:52,956:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-25 22:29:36,374:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.42s, LR: 0.00017, Train Loss: 0.1672, Train MAE: 0.1672,
                            Val Loss: 0.3040, Val MAE: 0.3039
2023-01-25 22:29:36,375:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-25 22:41:34,566:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.19s, LR: 0.00017, Train Loss: 0.1847, Train MAE: 0.1847,
                            Val Loss: 0.2622, Val MAE: 0.2621
2023-01-25 22:41:34,567:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-25 22:52:34,469:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.90s, LR: 0.00017, Train Loss: 0.1750, Train MAE: 0.1750,
                            Val Loss: 0.3648, Val MAE: 0.3648
2023-01-25 22:52:34,471:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-25 23:04:24,854:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.38s, LR: 0.00017, Train Loss: 0.1692, Train MAE: 0.1692,
                            Val Loss: 0.4835, Val MAE: 0.4834
2023-01-25 23:04:24,855:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-25 23:16:23,965:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.11s, LR: 0.00017, Train Loss: 0.1677, Train MAE: 0.1677,
                            Val Loss: 0.2448, Val MAE: 0.2446
2023-01-25 23:16:23,966:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-25 23:27:56,969:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.00s, LR: 0.00017, Train Loss: 0.1713, Train MAE: 0.1713,
                            Val Loss: 0.2664, Val MAE: 0.2663
2023-01-25 23:27:56,971:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-25 23:39:45,562:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.59s, LR: 0.00017, Train Loss: 0.2048, Train MAE: 0.2048,
                            Val Loss: 0.5159, Val MAE: 0.5157
2023-01-25 23:39:45,563:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-25 23:52:33,494:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.93s, LR: 0.00017, Train Loss: 0.2002, Train MAE: 0.2002,
                            Val Loss: 0.4461, Val MAE: 0.4459
2023-01-25 23:52:33,495:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-26 00:04:20,228:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.73s, LR: 0.00009, Train Loss: 0.1938, Train MAE: 0.1938,
                            Val Loss: 0.2579, Val MAE: 0.2577
2023-01-26 00:04:20,230:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-26 00:16:20,219:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.99s, LR: 0.00009, Train Loss: 0.1928, Train MAE: 0.1928,
                            Val Loss: 0.2499, Val MAE: 0.2497
2023-01-26 00:16:20,221:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-26 00:28:20,404:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.18s, LR: 0.00009, Train Loss: 0.1905, Train MAE: 0.1905,
                            Val Loss: 0.3129, Val MAE: 0.3129
2023-01-26 00:28:20,405:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-26 00:40:21,589:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.18s, LR: 0.00009, Train Loss: 0.1867, Train MAE: 0.1867,
                            Val Loss: 0.2990, Val MAE: 0.2989
2023-01-26 00:40:21,590:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 00:51:53,481:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.89s, LR: 0.00009, Train Loss: 0.1768, Train MAE: 0.1768,
                            Val Loss: 0.2338, Val MAE: 0.2336
2023-01-26 00:51:53,483:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 01:03:46,270:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.79s, LR: 0.00009, Train Loss: 0.1938, Train MAE: 0.1938,
                            Val Loss: 0.2543, Val MAE: 0.2542
2023-01-26 01:03:46,271:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 01:15:09,074:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.80s, LR: 0.00009, Train Loss: 0.1919, Train MAE: 0.1919,
                            Val Loss: 0.2449, Val MAE: 0.2447
2023-01-26 01:15:09,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 01:25:57,813:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.74s, LR: 0.00009, Train Loss: 0.1788, Train MAE: 0.1788,
                            Val Loss: 0.2095, Val MAE: 0.2094
2023-01-26 01:25:57,814:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 01:36:45,983:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.17s, LR: 0.00009, Train Loss: 0.1714, Train MAE: 0.1714,
                            Val Loss: 0.2631, Val MAE: 0.2630
2023-01-26 01:36:45,984:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 01:47:59,418:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.43s, LR: 0.00009, Train Loss: 0.1698, Train MAE: 0.1698,
                            Val Loss: 0.2182, Val MAE: 0.2181
2023-01-26 01:47:59,419:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 01:59:58,289:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.87s, LR: 0.00009, Train Loss: 0.1691, Train MAE: 0.1691,
                            Val Loss: 0.3135, Val MAE: 0.3133
2023-01-26 01:59:58,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-26 02:11:57,563:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.27s, LR: 0.00009, Train Loss: 0.1663, Train MAE: 0.1663,
                            Val Loss: 0.2603, Val MAE: 0.2601
2023-01-26 02:11:57,564:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-26 02:23:56,379:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.81s, LR: 0.00009, Train Loss: 0.1653, Train MAE: 0.1653,
                            Val Loss: 0.2800, Val MAE: 0.2798
2023-01-26 02:23:56,380:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-26 02:34:55,019:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.64s, LR: 0.00009, Train Loss: 0.1643, Train MAE: 0.1643,
                            Val Loss: 0.2885, Val MAE: 0.2883
2023-01-26 02:34:55,020:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-26 02:46:02,993:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.97s, LR: 0.00009, Train Loss: 0.1638, Train MAE: 0.1638,
                            Val Loss: 0.3824, Val MAE: 0.3824
2023-01-26 02:46:02,993:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-26 02:59:07,477:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2013377845287323
2023-01-26 02:59:07,479:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.49s, LR: 0.00009, Train Loss: 0.1627, Train MAE: 0.1627,
                            Val Loss: 0.2015, Val MAE: 0.2013
2023-01-26 02:59:07,480:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-26 03:10:02,553:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.07s, LR: 0.00009, Train Loss: 0.1621, Train MAE: 0.1621,
                            Val Loss: 0.3827, Val MAE: 0.3826
2023-01-26 03:10:02,554:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-26 03:20:48,526:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.97s, LR: 0.00009, Train Loss: 0.1614, Train MAE: 0.1614,
                            Val Loss: 0.3154, Val MAE: 0.3154
2023-01-26 03:20:48,528:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-26 03:31:34,150:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.62s, LR: 0.00009, Train Loss: 0.1610, Train MAE: 0.1610,
                            Val Loss: 0.2320, Val MAE: 0.2319
2023-01-26 03:31:34,151:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-26 03:42:21,530:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.38s, LR: 0.00009, Train Loss: 0.1606, Train MAE: 0.1606,
                            Val Loss: 0.2232, Val MAE: 0.2231
2023-01-26 03:42:21,531:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-26 03:53:08,645:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.18568675220012665
2023-01-26 03:53:08,646:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.11s, LR: 0.00009, Train Loss: 0.1599, Train MAE: 0.1599,
                            Val Loss: 0.1859, Val MAE: 0.1857
2023-01-26 03:53:08,647:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-26 04:03:54,766:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 646.12s, LR: 0.00009, Train Loss: 0.1623, Train MAE: 0.1623,
                            Val Loss: 0.2912, Val MAE: 0.2912
2023-01-26 04:03:54,768:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-26 04:14:41,500:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 646.73s, LR: 0.00009, Train Loss: 0.1629, Train MAE: 0.1629,
                            Val Loss: 0.2508, Val MAE: 0.2508
2023-01-26 04:14:41,501:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-26 04:25:28,607:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.11s, LR: 0.00009, Train Loss: 0.1602, Train MAE: 0.1602,
                            Val Loss: 0.2357, Val MAE: 0.2356
2023-01-26 04:25:28,608:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-26 04:36:15,946:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.34s, LR: 0.00009, Train Loss: 0.1589, Train MAE: 0.1589,
                            Val Loss: 0.3025, Val MAE: 0.3024
2023-01-26 04:36:15,948:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-26 04:47:17,848:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.90s, LR: 0.00009, Train Loss: 0.1588, Train MAE: 0.1588,
                            Val Loss: 0.2471, Val MAE: 0.2470
2023-01-26 04:47:17,849:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-26 04:59:15,270:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.42s, LR: 0.00009, Train Loss: 0.1582, Train MAE: 0.1582,
                            Val Loss: 0.2783, Val MAE: 0.2781
2023-01-26 04:59:15,272:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-26 05:11:12,551:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.28s, LR: 0.00009, Train Loss: 0.1585, Train MAE: 0.1585,
                            Val Loss: 0.2523, Val MAE: 0.2522
2023-01-26 05:11:12,553:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-26 05:23:09,556:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.00s, LR: 0.00009, Train Loss: 0.1576, Train MAE: 0.1576,
                            Val Loss: 0.2051, Val MAE: 0.2050
2023-01-26 05:23:09,557:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:23:09,558:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-26 05:31:57,049:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.2050
2023-01-26 05:31:57,051:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.1777
2023-01-26 05:31:57,052:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-26 05:31:57,054:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 120.0000
2023-01-26 05:31:57,054:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87281.8422s
2023-01-26 05:31:57,054:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 682.6967s
2023-01-26 05:31:57,057:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-26 05:31:57,145:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.1777)]
2023-01-26 05:31:57,146:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.2050)]
