2023-01-25 05:05:06,481:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2023-01-25 05:05:06,482:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:16:27,482:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:16:56,354:ogbdata.py:332 -             __init__(): Time taken: 709.8717s
2023-01-25 05:16:56,354:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:16:56,354:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:16:56,355:ogbdata.py:348 -             __init__(): [I] Data load time: 709.8730s
2023-01-25 05:16:56,355:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-trials/32_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-25 05:16:56,355:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-25 05:16:56,368:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:16:57,429:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:16:57,429:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:16:57,429:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:16:57,444:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:16:57,446:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-25 05:16:57,446:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-25 05:16:57,447:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:16:57,447:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:16:57,447:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:16:57,447:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:16:57,467:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:30:50,293:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4432.845794439316
2023-01-25 06:30:50,315:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:30:50,315:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:30:50,319:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:46:24,109:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 4.125677108764648
2023-01-25 06:46:24,111:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 933.79s, LR: 0.00070, Train Loss: 0.5544, Train MAE: 0.5544,
                            Val Loss: 4.1264, Val MAE: 4.1257
2023-01-25 06:46:24,111:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 06:59:13,054:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.94s, LR: 0.00070, Train Loss: 0.3822, Train MAE: 0.3822,
                            Val Loss: 28.4105, Val MAE: 28.4081
2023-01-25 06:59:13,055:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:12:00,774:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.72s, LR: 0.00070, Train Loss: 0.3527, Train MAE: 0.3527,
                            Val Loss: 6.9635, Val MAE: 6.9629
2023-01-25 07:12:00,776:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:24:49,179:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.9805856943130493
2023-01-25 07:24:49,181:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.40s, LR: 0.00070, Train Loss: 0.3585, Train MAE: 0.3585,
                            Val Loss: 1.9809, Val MAE: 1.9806
2023-01-25 07:24:49,182:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:37:37,347:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.2234697341918945
2023-01-25 07:37:37,349:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.17s, LR: 0.00070, Train Loss: 0.3462, Train MAE: 0.3462,
                            Val Loss: 1.2236, Val MAE: 1.2235
2023-01-25 07:37:37,350:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:50:26,685:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8376443386077881
2023-01-25 07:50:26,687:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.34s, LR: 0.00070, Train Loss: 0.3151, Train MAE: 0.3151,
                            Val Loss: 0.8376, Val MAE: 0.8376
2023-01-25 07:50:26,688:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 08:03:15,777:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.09s, LR: 0.00070, Train Loss: 0.3003, Train MAE: 0.3003,
                            Val Loss: 16.1494, Val MAE: 16.1479
2023-01-25 08:03:15,778:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 08:16:59,090:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 823.31s, LR: 0.00070, Train Loss: 0.2827, Train MAE: 0.2827,
                            Val Loss: 1.6204, Val MAE: 1.6201
2023-01-25 08:16:59,092:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:29:49,189:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.10s, LR: 0.00070, Train Loss: 0.2802, Train MAE: 0.2802,
                            Val Loss: 3.0748, Val MAE: 3.0744
2023-01-25 08:29:49,190:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:42:38,131:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.94s, LR: 0.00070, Train Loss: 0.2692, Train MAE: 0.2692,
                            Val Loss: 19.4205, Val MAE: 19.4186
2023-01-25 08:42:38,132:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:55:27,612:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.48s, LR: 0.00070, Train Loss: 0.2592, Train MAE: 0.2592,
                            Val Loss: 4.3887, Val MAE: 4.3882
2023-01-25 08:55:27,613:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 09:08:16,919:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.30s, LR: 0.00070, Train Loss: 0.2615, Train MAE: 0.2615,
                            Val Loss: 1.1075, Val MAE: 1.1075
2023-01-25 09:08:16,920:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 09:21:06,403:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.48s, LR: 0.00070, Train Loss: 0.2590, Train MAE: 0.2590,
                            Val Loss: 17.3004, Val MAE: 17.2984
2023-01-25 09:21:06,405:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:33:55,686:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.28s, LR: 0.00070, Train Loss: 0.2559, Train MAE: 0.2559,
                            Val Loss: 1.3827, Val MAE: 1.3824
2023-01-25 09:33:55,687:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:46:44,447:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.76s, LR: 0.00070, Train Loss: 0.2565, Train MAE: 0.2565,
                            Val Loss: 2.7892, Val MAE: 2.7890
2023-01-25 09:46:44,448:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:59:34,099:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.65s, LR: 0.00070, Train Loss: 0.2625, Train MAE: 0.2625,
                            Val Loss: 1.5276, Val MAE: 1.5277
2023-01-25 09:59:34,101:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 10:12:23,612:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.51s, LR: 0.00070, Train Loss: 0.2570, Train MAE: 0.2570,
                            Val Loss: 0.8934, Val MAE: 0.8933
2023-01-25 10:12:23,613:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 10:25:14,073:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.46s, LR: 0.00070, Train Loss: 0.2540, Train MAE: 0.2540,
                            Val Loss: 0.9987, Val MAE: 0.9979
2023-01-25 10:25:14,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 10:38:03,912:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.84s, LR: 0.00070, Train Loss: 0.2652, Train MAE: 0.2652,
                            Val Loss: 1.6604, Val MAE: 1.6602
2023-01-25 10:38:03,913:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:50:53,087:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.17s, LR: 0.00070, Train Loss: 0.3873, Train MAE: 0.3873,
                            Val Loss: 8.2123, Val MAE: 8.2116
2023-01-25 10:50:53,088:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 11:03:43,152:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.06s, LR: 0.00070, Train Loss: 0.3132, Train MAE: 0.3132,
                            Val Loss: 4.2701, Val MAE: 4.2698
2023-01-25 11:03:43,153:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 11:16:32,788:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.63s, LR: 0.00070, Train Loss: 0.2907, Train MAE: 0.2907,
                            Val Loss: 2.0025, Val MAE: 2.0028
2023-01-25 11:16:32,790:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 11:29:23,549:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.76s, LR: 0.00035, Train Loss: 0.2737, Train MAE: 0.2737,
                            Val Loss: 3.1831, Val MAE: 3.1827
2023-01-25 11:29:23,550:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 11:43:08,026:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 824.47s, LR: 0.00035, Train Loss: 0.2675, Train MAE: 0.2675,
                            Val Loss: 1.8570, Val MAE: 1.8563
2023-01-25 11:43:08,027:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:55:58,139:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.11s, LR: 0.00035, Train Loss: 0.2635, Train MAE: 0.2635,
                            Val Loss: 1.0823, Val MAE: 1.0825
2023-01-25 11:55:58,141:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 12:08:48,362:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.22s, LR: 0.00035, Train Loss: 0.2601, Train MAE: 0.2601,
                            Val Loss: 3.1687, Val MAE: 3.1677
2023-01-25 12:08:48,363:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 12:21:38,006:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.47708767652511597
2023-01-25 12:21:38,008:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.64s, LR: 0.00035, Train Loss: 0.2570, Train MAE: 0.2570,
                            Val Loss: 0.4773, Val MAE: 0.4771
2023-01-25 12:21:38,009:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 12:34:27,863:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.85s, LR: 0.00035, Train Loss: 0.2543, Train MAE: 0.2543,
                            Val Loss: 1.2800, Val MAE: 1.2801
2023-01-25 12:34:27,865:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 12:47:18,593:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.73s, LR: 0.00035, Train Loss: 0.2568, Train MAE: 0.2568,
                            Val Loss: 0.8388, Val MAE: 0.8388
2023-01-25 12:47:18,595:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 13:00:08,696:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.10s, LR: 0.00035, Train Loss: 0.2507, Train MAE: 0.2507,
                            Val Loss: 0.9416, Val MAE: 0.9417
2023-01-25 13:00:08,697:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 13:12:58,764:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.07s, LR: 0.00035, Train Loss: 0.2483, Train MAE: 0.2483,
                            Val Loss: 1.3111, Val MAE: 1.3110
2023-01-25 13:12:58,765:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 13:25:48,518:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.75s, LR: 0.00035, Train Loss: 0.2350, Train MAE: 0.2350,
                            Val Loss: 1.6659, Val MAE: 1.6659
2023-01-25 13:25:48,519:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 13:38:38,864:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.34s, LR: 0.00035, Train Loss: 0.2444, Train MAE: 0.2444,
                            Val Loss: 1.5448, Val MAE: 1.5450
2023-01-25 13:38:38,865:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 13:51:28,861:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.00s, LR: 0.00035, Train Loss: 0.2420, Train MAE: 0.2420,
                            Val Loss: 0.6635, Val MAE: 0.6634
2023-01-25 13:51:28,862:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 14:04:19,094:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.23s, LR: 0.00035, Train Loss: 0.2410, Train MAE: 0.2410,
                            Val Loss: 1.3035, Val MAE: 1.3035
2023-01-25 14:04:19,095:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 14:17:09,610:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.51s, LR: 0.00035, Train Loss: 0.2411, Train MAE: 0.2411,
                            Val Loss: 1.4856, Val MAE: 1.4858
2023-01-25 14:17:09,611:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 14:29:58,891:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.28s, LR: 0.00035, Train Loss: 0.2495, Train MAE: 0.2495,
                            Val Loss: 1.7669, Val MAE: 1.7663
2023-01-25 14:29:58,893:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 14:42:49,010:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.12s, LR: 0.00035, Train Loss: 0.2459, Train MAE: 0.2459,
                            Val Loss: 1.1956, Val MAE: 1.1960
2023-01-25 14:42:49,011:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 14:55:39,576:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.56s, LR: 0.00035, Train Loss: 0.2429, Train MAE: 0.2429,
                            Val Loss: 1.0189, Val MAE: 1.0190
2023-01-25 14:55:39,577:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 15:08:30,028:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.45s, LR: 0.00035, Train Loss: 0.2414, Train MAE: 0.2414,
                            Val Loss: 1.3423, Val MAE: 1.3424
2023-01-25 15:08:30,030:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 15:22:14,546:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 824.52s, LR: 0.00035, Train Loss: 0.2395, Train MAE: 0.2395,
                            Val Loss: 1.3517, Val MAE: 1.3518
2023-01-25 15:22:14,547:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 15:35:04,438:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.89s, LR: 0.00035, Train Loss: 0.2393, Train MAE: 0.2393,
                            Val Loss: 3.0395, Val MAE: 3.0388
2023-01-25 15:35:04,439:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 15:47:54,743:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.30s, LR: 0.00035, Train Loss: 0.2364, Train MAE: 0.2364,
                            Val Loss: 0.7052, Val MAE: 0.7051
2023-01-25 15:47:54,744:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 16:00:45,697:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.95s, LR: 0.00017, Train Loss: 0.2298, Train MAE: 0.2298,
                            Val Loss: 1.0458, Val MAE: 1.0460
2023-01-25 16:00:45,698:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 16:13:36,082:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.38s, LR: 0.00017, Train Loss: 0.2288, Train MAE: 0.2288,
                            Val Loss: 0.8405, Val MAE: 0.8406
2023-01-25 16:13:36,083:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 16:26:26,810:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.73s, LR: 0.00017, Train Loss: 0.2276, Train MAE: 0.2276,
                            Val Loss: 0.6760, Val MAE: 0.6761
2023-01-25 16:26:26,811:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 16:39:16,889:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.08s, LR: 0.00017, Train Loss: 0.2324, Train MAE: 0.2324,
                            Val Loss: 0.6797, Val MAE: 0.6797
2023-01-25 16:39:16,890:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 16:52:07,457:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.57s, LR: 0.00017, Train Loss: 0.2329, Train MAE: 0.2329,
                            Val Loss: 0.9597, Val MAE: 0.9600
2023-01-25 16:52:07,458:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 17:04:58,304:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.85s, LR: 0.00017, Train Loss: 0.2236, Train MAE: 0.2236,
                            Val Loss: 0.7207, Val MAE: 0.7209
2023-01-25 17:04:58,305:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 17:17:48,325:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.02s, LR: 0.00017, Train Loss: 0.2067, Train MAE: 0.2067,
                            Val Loss: 0.7454, Val MAE: 0.7455
2023-01-25 17:17:48,326:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 17:30:38,683:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.46132534742355347
2023-01-25 17:30:38,685:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.36s, LR: 0.00017, Train Loss: 0.2007, Train MAE: 0.2007,
                            Val Loss: 0.4613, Val MAE: 0.4613
2023-01-25 17:30:38,686:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 17:43:28,416:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.73s, LR: 0.00017, Train Loss: 0.1998, Train MAE: 0.1998,
                            Val Loss: 0.5840, Val MAE: 0.5842
2023-01-25 17:43:28,417:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 17:56:18,515:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3722938895225525
2023-01-25 17:56:18,516:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.10s, LR: 0.00017, Train Loss: 0.2097, Train MAE: 0.2097,
                            Val Loss: 0.3725, Val MAE: 0.3723
2023-01-25 17:56:18,517:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 18:09:09,867:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.35s, LR: 0.00017, Train Loss: 0.2024, Train MAE: 0.2024,
                            Val Loss: 0.6019, Val MAE: 0.6018
2023-01-25 18:09:09,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 18:22:00,065:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2447536140680313
2023-01-25 18:22:00,067:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.20s, LR: 0.00017, Train Loss: 0.2034, Train MAE: 0.2034,
                            Val Loss: 0.2449, Val MAE: 0.2448
2023-01-25 18:22:00,068:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 18:34:50,360:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.29s, LR: 0.00017, Train Loss: 0.1946, Train MAE: 0.1946,
                            Val Loss: 0.6742, Val MAE: 0.6741
2023-01-25 18:34:50,361:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 18:47:40,769:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.41s, LR: 0.00017, Train Loss: 0.1948, Train MAE: 0.1948,
                            Val Loss: 0.3670, Val MAE: 0.3668
2023-01-25 18:47:40,770:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 19:01:24,094:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 823.32s, LR: 0.00017, Train Loss: 0.2167, Train MAE: 0.2167,
                            Val Loss: 0.2909, Val MAE: 0.2908
2023-01-25 19:01:24,095:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 19:14:14,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.49s, LR: 0.00017, Train Loss: 0.1949, Train MAE: 0.1949,
                            Val Loss: 0.3093, Val MAE: 0.3093
2023-01-25 19:14:14,589:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 19:27:04,637:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.05s, LR: 0.00017, Train Loss: 0.1917, Train MAE: 0.1917,
                            Val Loss: 0.7040, Val MAE: 0.7040
2023-01-25 19:27:04,638:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 19:39:54,508:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.87s, LR: 0.00017, Train Loss: 0.1956, Train MAE: 0.1956,
                            Val Loss: 0.7648, Val MAE: 0.7649
2023-01-25 19:39:54,509:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 19:52:44,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.46s, LR: 0.00017, Train Loss: 0.1945, Train MAE: 0.1945,
                            Val Loss: 0.3879, Val MAE: 0.3878
2023-01-25 19:52:44,973:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 20:05:34,789:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.82s, LR: 0.00017, Train Loss: 0.1915, Train MAE: 0.1915,
                            Val Loss: 0.2811, Val MAE: 0.2810
2023-01-25 20:05:34,791:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 20:18:25,193:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.40s, LR: 0.00017, Train Loss: 0.2201, Train MAE: 0.2201,
                            Val Loss: 1.2081, Val MAE: 1.2086
2023-01-25 20:18:25,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 20:31:16,054:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.86s, LR: 0.00017, Train Loss: 0.1971, Train MAE: 0.1971,
                            Val Loss: 0.2541, Val MAE: 0.2539
2023-01-25 20:31:16,055:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 20:44:06,259:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.20s, LR: 0.00017, Train Loss: 0.1952, Train MAE: 0.1952,
                            Val Loss: 0.3592, Val MAE: 0.3590
2023-01-25 20:44:06,260:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 20:56:56,572:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.31s, LR: 0.00017, Train Loss: 0.1894, Train MAE: 0.1894,
                            Val Loss: 0.4344, Val MAE: 0.4342
2023-01-25 20:56:56,573:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 21:09:46,738:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.16s, LR: 0.00017, Train Loss: 0.1882, Train MAE: 0.1882,
                            Val Loss: 0.4870, Val MAE: 0.4869
2023-01-25 21:09:46,740:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 21:22:37,629:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.89s, LR: 0.00017, Train Loss: 0.1871, Train MAE: 0.1871,
                            Val Loss: 0.6253, Val MAE: 0.6252
2023-01-25 21:22:37,630:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 21:35:28,697:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.07s, LR: 0.00017, Train Loss: 0.1863, Train MAE: 0.1863,
                            Val Loss: 0.7971, Val MAE: 0.7970
2023-01-25 21:35:28,698:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 21:48:18,794:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.10s, LR: 0.00017, Train Loss: 0.1859, Train MAE: 0.1859,
                            Val Loss: 0.6476, Val MAE: 0.6475
2023-01-25 21:48:18,796:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 22:01:09,162:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.37s, LR: 0.00009, Train Loss: 0.1811, Train MAE: 0.1811,
                            Val Loss: 0.4410, Val MAE: 0.4410
2023-01-25 22:01:09,163:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 22:13:59,793:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.63s, LR: 0.00009, Train Loss: 0.1801, Train MAE: 0.1801,
                            Val Loss: 0.3610, Val MAE: 0.3611
2023-01-25 22:13:59,794:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 22:26:50,554:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.76s, LR: 0.00009, Train Loss: 0.1797, Train MAE: 0.1797,
                            Val Loss: 0.3599, Val MAE: 0.3598
2023-01-25 22:26:50,555:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 22:40:36,333:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 825.78s, LR: 0.00009, Train Loss: 0.1795, Train MAE: 0.1795,
                            Val Loss: 0.3120, Val MAE: 0.3119
2023-01-25 22:40:36,334:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 22:53:26,270:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.93s, LR: 0.00009, Train Loss: 0.1788, Train MAE: 0.1788,
                            Val Loss: 0.3811, Val MAE: 0.3810
2023-01-25 22:53:26,271:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 23:06:15,702:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.43s, LR: 0.00009, Train Loss: 0.1783, Train MAE: 0.1783,
                            Val Loss: 0.3063, Val MAE: 0.3062
2023-01-25 23:06:15,704:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 23:19:06,159:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.45s, LR: 0.00009, Train Loss: 0.1781, Train MAE: 0.1781,
                            Val Loss: 0.3555, Val MAE: 0.3555
2023-01-25 23:19:06,160:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-25 23:31:56,079:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.92s, LR: 0.00009, Train Loss: 0.1773, Train MAE: 0.1773,
                            Val Loss: 0.3811, Val MAE: 0.3811
2023-01-25 23:31:56,081:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-25 23:44:47,081:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.00s, LR: 0.00009, Train Loss: 0.1771, Train MAE: 0.1771,
                            Val Loss: 0.3469, Val MAE: 0.3468
2023-01-25 23:44:47,081:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-25 23:57:37,427:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.35s, LR: 0.00009, Train Loss: 0.1769, Train MAE: 0.1769,
                            Val Loss: 0.2761, Val MAE: 0.2760
2023-01-25 23:57:37,429:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-26 00:10:27,275:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.85s, LR: 0.00009, Train Loss: 0.1763, Train MAE: 0.1763,
                            Val Loss: 0.4261, Val MAE: 0.4260
2023-01-26 00:10:27,276:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-26 00:23:18,267:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.99s, LR: 0.00009, Train Loss: 0.1760, Train MAE: 0.1760,
                            Val Loss: 0.3447, Val MAE: 0.3446
2023-01-26 00:23:18,268:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-26 00:36:09,205:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.94s, LR: 0.00009, Train Loss: 0.1757, Train MAE: 0.1757,
                            Val Loss: 0.4034, Val MAE: 0.4033
2023-01-26 00:36:09,206:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-26 00:48:59,493:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.29s, LR: 0.00009, Train Loss: 0.1753, Train MAE: 0.1753,
                            Val Loss: 0.4041, Val MAE: 0.4041
2023-01-26 00:48:59,493:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-26 01:01:49,376:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.88s, LR: 0.00009, Train Loss: 0.1770, Train MAE: 0.1770,
                            Val Loss: 0.3130, Val MAE: 0.3129
2023-01-26 01:01:49,377:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-26 01:14:39,045:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.67s, LR: 0.00009, Train Loss: 0.1762, Train MAE: 0.1762,
                            Val Loss: 0.5403, Val MAE: 0.5403
2023-01-26 01:14:39,046:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-26 01:27:28,864:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.82s, LR: 0.00004, Train Loss: 0.1726, Train MAE: 0.1726,
                            Val Loss: 0.5071, Val MAE: 0.5070
2023-01-26 01:27:28,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-26 01:40:19,169:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.30s, LR: 0.00004, Train Loss: 0.1722, Train MAE: 0.1722,
                            Val Loss: 0.3897, Val MAE: 0.3897
2023-01-26 01:40:19,170:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-26 01:53:08,712:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.54s, LR: 0.00004, Train Loss: 0.1718, Train MAE: 0.1718,
                            Val Loss: 0.4982, Val MAE: 0.4980
2023-01-26 01:53:08,713:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-26 02:05:58,208:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.49s, LR: 0.00004, Train Loss: 0.1713, Train MAE: 0.1713,
                            Val Loss: 0.3962, Val MAE: 0.3961
2023-01-26 02:05:58,209:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-26 02:19:42,981:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 824.77s, LR: 0.00004, Train Loss: 0.1711, Train MAE: 0.1711,
                            Val Loss: 0.5972, Val MAE: 0.5972
2023-01-26 02:19:42,982:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-26 02:32:32,705:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.72s, LR: 0.00004, Train Loss: 0.1710, Train MAE: 0.1710,
                            Val Loss: 0.3912, Val MAE: 0.3912
2023-01-26 02:32:32,706:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-26 02:45:22,699:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.99s, LR: 0.00004, Train Loss: 0.1705, Train MAE: 0.1705,
                            Val Loss: 0.3124, Val MAE: 0.3123
2023-01-26 02:45:22,700:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-26 02:58:12,515:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.81s, LR: 0.00004, Train Loss: 0.1703, Train MAE: 0.1703,
                            Val Loss: 0.3852, Val MAE: 0.3851
2023-01-26 02:58:12,516:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-26 03:11:01,716:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.20s, LR: 0.00004, Train Loss: 0.1700, Train MAE: 0.1700,
                            Val Loss: 0.3975, Val MAE: 0.3973
2023-01-26 03:11:01,717:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 03:23:51,247:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.53s, LR: 0.00004, Train Loss: 0.1698, Train MAE: 0.1698,
                            Val Loss: 0.3911, Val MAE: 0.3911
2023-01-26 03:23:51,248:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 03:36:41,125:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.88s, LR: 0.00004, Train Loss: 0.1697, Train MAE: 0.1697,
                            Val Loss: 0.3161, Val MAE: 0.3160
2023-01-26 03:36:41,126:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 03:49:31,172:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.04s, LR: 0.00004, Train Loss: 0.1694, Train MAE: 0.1694,
                            Val Loss: 0.3259, Val MAE: 0.3258
2023-01-26 03:49:31,173:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 04:02:21,544:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.37s, LR: 0.00004, Train Loss: 0.1691, Train MAE: 0.1691,
                            Val Loss: 0.3692, Val MAE: 0.3693
2023-01-26 04:02:21,545:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 04:15:11,399:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.85s, LR: 0.00004, Train Loss: 0.1690, Train MAE: 0.1690,
                            Val Loss: 0.3738, Val MAE: 0.3738
2023-01-26 04:15:11,401:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 04:28:00,988:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.23696379363536835
2023-01-26 04:28:00,990:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.59s, LR: 0.00004, Train Loss: 0.1686, Train MAE: 0.1686,
                            Val Loss: 0.2371, Val MAE: 0.2370
2023-01-26 04:28:00,991:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 04:40:51,266:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.27s, LR: 0.00004, Train Loss: 0.1683, Train MAE: 0.1683,
                            Val Loss: 0.3411, Val MAE: 0.3411
2023-01-26 04:40:51,267:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-26 04:53:41,350:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.08s, LR: 0.00004, Train Loss: 0.1682, Train MAE: 0.1682,
                            Val Loss: 0.5032, Val MAE: 0.5031
2023-01-26 04:53:41,351:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-26 05:06:31,487:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.14s, LR: 0.00004, Train Loss: 0.1682, Train MAE: 0.1682,
                            Val Loss: 0.3710, Val MAE: 0.3710
2023-01-26 05:06:31,488:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-26 05:19:21,601:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.11s, LR: 0.00004, Train Loss: 0.1678, Train MAE: 0.1678,
                            Val Loss: 0.3878, Val MAE: 0.3878
2023-01-26 05:19:21,602:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:19:21,603:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-26 05:28:26,987:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.3878
2023-01-26 05:28:27,001:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.3969
2023-01-26 05:28:27,010:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-26 05:28:27,011:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 105.0000
2023-01-26 05:28:27,012:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87089.5653s
2023-01-26 05:28:27,076:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 774.6340s
2023-01-26 05:28:27,132:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-26 05:28:27,411:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.3969)]
2023-01-26 05:28:27,412:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.3878)]
