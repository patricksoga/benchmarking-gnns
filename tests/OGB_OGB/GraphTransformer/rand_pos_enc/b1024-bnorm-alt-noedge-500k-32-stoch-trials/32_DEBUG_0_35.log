2023-01-25 05:05:09,382:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2023-01-25 05:05:09,382:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:15:20,298:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:15:47,598:ogbdata.py:332 -             __init__(): Time taken: 638.2160s
2023-01-25 05:15:47,598:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:15:47,598:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:15:47,598:ogbdata.py:348 -             __init__(): [I] Data load time: 638.2163s
2023-01-25 05:15:47,598:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-trials/32_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-25 05:15:47,599:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-25 05:15:47,683:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:15:48,707:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:15:48,707:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:15:48,707:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:15:48,721:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:15:48,723:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-25 05:15:48,724:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-25 05:15:48,724:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:15:48,725:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:15:48,725:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:15:48,725:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:15:48,744:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:22:43,261:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4014.536838531494
2023-01-25 06:22:43,282:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:22:43,282:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:22:43,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:37:46,027:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 2.56881046295166
2023-01-25 06:37:46,028:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 902.74s, LR: 0.00070, Train Loss: 0.5966, Train MAE: 0.5966,
                            Val Loss: 2.5691, Val MAE: 2.5688
2023-01-25 06:37:46,029:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 06:50:49,792:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.76s, LR: 0.00070, Train Loss: 0.3907, Train MAE: 0.3907,
                            Val Loss: 3.5045, Val MAE: 3.5040
2023-01-25 06:50:49,794:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:03:54,791:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.0656002759933472
2023-01-25 07:03:54,793:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 785.00s, LR: 0.00070, Train Loss: 0.3568, Train MAE: 0.3568,
                            Val Loss: 1.0656, Val MAE: 1.0656
2023-01-25 07:03:54,794:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:17:00,005:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 785.21s, LR: 0.00070, Train Loss: 0.3304, Train MAE: 0.3304,
                            Val Loss: 1.4875, Val MAE: 1.4876
2023-01-25 07:17:00,007:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:30:05,789:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 785.78s, LR: 0.00070, Train Loss: 0.3005, Train MAE: 0.3005,
                            Val Loss: 4.0841, Val MAE: 4.0838
2023-01-25 07:30:05,790:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:43:10,285:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4329056739807129
2023-01-25 07:43:10,287:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.50s, LR: 0.00070, Train Loss: 0.2808, Train MAE: 0.2808,
                            Val Loss: 0.4329, Val MAE: 0.4329
2023-01-25 07:43:10,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 07:56:15,435:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 785.15s, LR: 0.00070, Train Loss: 0.2683, Train MAE: 0.2683,
                            Val Loss: 1.4794, Val MAE: 1.4793
2023-01-25 07:56:15,437:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 08:10:14,314:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 838.88s, LR: 0.00070, Train Loss: 0.2633, Train MAE: 0.2633,
                            Val Loss: 0.9352, Val MAE: 0.9352
2023-01-25 08:10:14,316:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:23:15,054:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.74s, LR: 0.00070, Train Loss: 0.3162, Train MAE: 0.3162,
                            Val Loss: 1.1378, Val MAE: 1.1379
2023-01-25 08:23:15,056:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:36:19,009:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.95s, LR: 0.00070, Train Loss: 0.4248, Train MAE: 0.4248,
                            Val Loss: 1.6869, Val MAE: 1.6868
2023-01-25 08:36:19,011:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:49:22,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.69s, LR: 0.00070, Train Loss: 0.3622, Train MAE: 0.3622,
                            Val Loss: 1.0185, Val MAE: 1.0185
2023-01-25 08:49:22,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 09:02:27,289:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.59s, LR: 0.00070, Train Loss: 0.3197, Train MAE: 0.3197,
                            Val Loss: 3.2364, Val MAE: 3.2360
2023-01-25 09:02:27,290:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 09:15:31,320:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.03s, LR: 0.00070, Train Loss: 0.2968, Train MAE: 0.2968,
                            Val Loss: 1.0736, Val MAE: 1.0732
2023-01-25 09:15:31,322:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:28:35,514:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.19s, LR: 0.00070, Train Loss: 0.2775, Train MAE: 0.2775,
                            Val Loss: 1.9530, Val MAE: 1.9529
2023-01-25 09:28:35,515:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:41:40,174:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.66s, LR: 0.00070, Train Loss: 0.2693, Train MAE: 0.2693,
                            Val Loss: 1.0877, Val MAE: 1.0878
2023-01-25 09:41:40,176:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:55:18,544:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 818.37s, LR: 0.00070, Train Loss: 0.2629, Train MAE: 0.2629,
                            Val Loss: 0.6955, Val MAE: 0.6956
2023-01-25 09:55:18,545:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 10:09:09,804:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 831.26s, LR: 0.00070, Train Loss: 0.2559, Train MAE: 0.2559,
                            Val Loss: 1.2130, Val MAE: 1.2131
2023-01-25 10:09:09,806:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 10:22:31,707:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 801.90s, LR: 0.00070, Train Loss: 0.2505, Train MAE: 0.2505,
                            Val Loss: 1.1063, Val MAE: 1.1065
2023-01-25 10:22:31,708:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 10:35:32,077:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.37s, LR: 0.00070, Train Loss: 0.2475, Train MAE: 0.2475,
                            Val Loss: 1.9927, Val MAE: 1.9927
2023-01-25 10:35:32,079:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:48:32,434:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.35s, LR: 0.00070, Train Loss: 0.2417, Train MAE: 0.2417,
                            Val Loss: 1.8660, Val MAE: 1.8661
2023-01-25 10:48:32,436:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 11:01:33,267:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.83s, LR: 0.00070, Train Loss: 0.3471, Train MAE: 0.3471,
                            Val Loss: 0.9879, Val MAE: 0.9879
2023-01-25 11:01:33,269:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 11:14:33,520:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.25s, LR: 0.00070, Train Loss: 0.5704, Train MAE: 0.5704,
                            Val Loss: 1.2254, Val MAE: 1.2253
2023-01-25 11:14:33,522:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 11:27:42,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 788.86s, LR: 0.00035, Train Loss: 0.3872, Train MAE: 0.3872,
                            Val Loss: 1.1300, Val MAE: 1.1300
2023-01-25 11:27:42,386:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 11:42:29,184:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 886.80s, LR: 0.00035, Train Loss: 0.3407, Train MAE: 0.3407,
                            Val Loss: 1.4999, Val MAE: 1.5003
2023-01-25 11:42:29,185:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:56:21,578:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 832.39s, LR: 0.00035, Train Loss: 0.3226, Train MAE: 0.3226,
                            Val Loss: 0.9584, Val MAE: 0.9584
2023-01-25 11:56:21,579:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 12:10:14,093:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 832.51s, LR: 0.00035, Train Loss: 0.3173, Train MAE: 0.3173,
                            Val Loss: 1.8990, Val MAE: 1.8988
2023-01-25 12:10:14,095:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 12:24:06,029:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 831.93s, LR: 0.00035, Train Loss: 0.3083, Train MAE: 0.3083,
                            Val Loss: 2.0478, Val MAE: 2.0478
2023-01-25 12:24:06,031:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 12:37:57,794:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 831.76s, LR: 0.00035, Train Loss: 0.3014, Train MAE: 0.3014,
                            Val Loss: 1.4902, Val MAE: 1.4905
2023-01-25 12:37:57,795:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 12:51:50,033:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 832.24s, LR: 0.00035, Train Loss: 0.2952, Train MAE: 0.2952,
                            Val Loss: 1.5912, Val MAE: 1.5914
2023-01-25 12:51:50,035:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 13:04:54,752:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.72s, LR: 0.00035, Train Loss: 0.2910, Train MAE: 0.2910,
                            Val Loss: 0.8348, Val MAE: 0.8344
2023-01-25 13:04:54,753:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 13:17:54,748:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.99s, LR: 0.00035, Train Loss: 0.2869, Train MAE: 0.2869,
                            Val Loss: 1.1119, Val MAE: 1.1120
2023-01-25 13:17:54,749:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 13:31:28,253:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 813.50s, LR: 0.00035, Train Loss: 0.2854, Train MAE: 0.2854,
                            Val Loss: 0.9684, Val MAE: 0.9686
2023-01-25 13:31:28,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 13:45:19,007:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 830.75s, LR: 0.00035, Train Loss: 0.2813, Train MAE: 0.2813,
                            Val Loss: 1.0269, Val MAE: 1.0269
2023-01-25 13:45:19,009:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 13:58:48,539:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 809.53s, LR: 0.00035, Train Loss: 0.2781, Train MAE: 0.2781,
                            Val Loss: 1.0521, Val MAE: 1.0522
2023-01-25 13:58:48,540:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 14:11:48,530:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.99s, LR: 0.00035, Train Loss: 0.2755, Train MAE: 0.2755,
                            Val Loss: 1.5167, Val MAE: 1.5167
2023-01-25 14:11:48,531:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 14:24:49,027:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.50s, LR: 0.00035, Train Loss: 0.2701, Train MAE: 0.2701,
                            Val Loss: 3.8439, Val MAE: 3.8437
2023-01-25 14:24:49,028:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 14:38:11,004:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 801.97s, LR: 0.00035, Train Loss: 0.2656, Train MAE: 0.2656,
                            Val Loss: 0.7511, Val MAE: 0.7509
2023-01-25 14:38:11,005:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 14:51:39,687:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 808.68s, LR: 0.00035, Train Loss: 0.2667, Train MAE: 0.2667,
                            Val Loss: 1.8524, Val MAE: 1.8523
2023-01-25 14:51:39,688:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 15:04:39,166:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.48s, LR: 0.00017, Train Loss: 0.2579, Train MAE: 0.2579,
                            Val Loss: 0.7775, Val MAE: 0.7777
2023-01-25 15:04:39,167:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 15:17:40,257:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 781.09s, LR: 0.00017, Train Loss: 0.2563, Train MAE: 0.2563,
                            Val Loss: 2.7799, Val MAE: 2.7797
2023-01-25 15:17:40,258:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 15:32:05,941:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 865.68s, LR: 0.00017, Train Loss: 0.2543, Train MAE: 0.2543,
                            Val Loss: 1.0579, Val MAE: 1.0581
2023-01-25 15:32:05,942:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 15:45:55,915:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.97s, LR: 0.00017, Train Loss: 0.2518, Train MAE: 0.2518,
                            Val Loss: 0.6604, Val MAE: 0.6605
2023-01-25 15:45:55,916:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 15:59:46,512:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 830.59s, LR: 0.00017, Train Loss: 0.2496, Train MAE: 0.2496,
                            Val Loss: 1.0435, Val MAE: 1.0436
2023-01-25 15:59:46,514:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 16:13:36,584:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 830.07s, LR: 0.00017, Train Loss: 0.2479, Train MAE: 0.2479,
                            Val Loss: 0.6001, Val MAE: 0.5999
2023-01-25 16:13:36,585:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 16:27:26,859:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 830.27s, LR: 0.00017, Train Loss: 0.2476, Train MAE: 0.2476,
                            Val Loss: 0.7053, Val MAE: 0.7054
2023-01-25 16:27:26,860:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 16:41:16,798:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.94s, LR: 0.00017, Train Loss: 0.2489, Train MAE: 0.2489,
                            Val Loss: 0.4822, Val MAE: 0.4821
2023-01-25 16:41:16,799:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 16:55:06,483:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.68s, LR: 0.00017, Train Loss: 0.2478, Train MAE: 0.2478,
                            Val Loss: 0.5595, Val MAE: 0.5594
2023-01-25 16:55:06,484:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 17:08:56,806:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3813786208629608
2023-01-25 17:08:56,808:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 830.32s, LR: 0.00017, Train Loss: 0.2464, Train MAE: 0.2464,
                            Val Loss: 0.3816, Val MAE: 0.3814
2023-01-25 17:08:56,809:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 17:22:46,747:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.94s, LR: 0.00017, Train Loss: 0.2451, Train MAE: 0.2451,
                            Val Loss: 0.6235, Val MAE: 0.6232
2023-01-25 17:22:46,749:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 17:36:36,594:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.84s, LR: 0.00017, Train Loss: 0.2442, Train MAE: 0.2442,
                            Val Loss: 1.2052, Val MAE: 1.2048
2023-01-25 17:36:36,595:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 17:50:26,668:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 830.07s, LR: 0.00017, Train Loss: 0.2445, Train MAE: 0.2445,
                            Val Loss: 0.8337, Val MAE: 0.8335
2023-01-25 17:50:26,670:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 18:03:48,418:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 801.75s, LR: 0.00017, Train Loss: 0.2436, Train MAE: 0.2436,
                            Val Loss: 0.6241, Val MAE: 0.6240
2023-01-25 18:03:48,420:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 18:16:48,241:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.82s, LR: 0.00017, Train Loss: 0.2424, Train MAE: 0.2424,
                            Val Loss: 0.8976, Val MAE: 0.8971
2023-01-25 18:16:48,242:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 18:29:47,850:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.32230329513549805
2023-01-25 18:29:47,852:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.61s, LR: 0.00017, Train Loss: 0.2418, Train MAE: 0.2418,
                            Val Loss: 0.3224, Val MAE: 0.3223
2023-01-25 18:29:47,852:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 18:42:47,048:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.20s, LR: 0.00017, Train Loss: 0.2406, Train MAE: 0.2406,
                            Val Loss: 1.4133, Val MAE: 1.4134
2023-01-25 18:42:47,050:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 18:55:46,845:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.79s, LR: 0.00017, Train Loss: 0.2401, Train MAE: 0.2401,
                            Val Loss: 0.5430, Val MAE: 0.5429
2023-01-25 18:55:46,846:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 19:08:46,069:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.22s, LR: 0.00017, Train Loss: 0.2384, Train MAE: 0.2384,
                            Val Loss: 0.9129, Val MAE: 0.9124
2023-01-25 19:08:46,070:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 19:22:41,137:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 835.07s, LR: 0.00017, Train Loss: 0.2383, Train MAE: 0.2383,
                            Val Loss: 1.3314, Val MAE: 1.3315
2023-01-25 19:22:41,138:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 19:35:40,282:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.14s, LR: 0.00017, Train Loss: 0.2382, Train MAE: 0.2382,
                            Val Loss: 1.1491, Val MAE: 1.1488
2023-01-25 19:35:40,284:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 19:48:42,253:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 781.97s, LR: 0.00017, Train Loss: 0.2374, Train MAE: 0.2374,
                            Val Loss: 1.1931, Val MAE: 1.1930
2023-01-25 19:48:42,255:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 20:02:25,612:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 823.36s, LR: 0.00017, Train Loss: 0.2366, Train MAE: 0.2366,
                            Val Loss: 0.4451, Val MAE: 0.4450
2023-01-25 20:02:25,614:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 20:15:23,771:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.16s, LR: 0.00017, Train Loss: 0.2356, Train MAE: 0.2356,
                            Val Loss: 0.7328, Val MAE: 0.7327
2023-01-25 20:15:23,773:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 20:29:05,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 822.20s, LR: 0.00017, Train Loss: 0.2349, Train MAE: 0.2349,
                            Val Loss: 1.3958, Val MAE: 1.3958
2023-01-25 20:29:05,973:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 20:42:54,452:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 828.48s, LR: 0.00017, Train Loss: 0.2343, Train MAE: 0.2343,
                            Val Loss: 1.3076, Val MAE: 1.3077
2023-01-25 20:42:54,453:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 20:56:43,624:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.17s, LR: 0.00017, Train Loss: 0.2335, Train MAE: 0.2335,
                            Val Loss: 1.3682, Val MAE: 1.3683
2023-01-25 20:56:43,625:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 21:10:32,497:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 828.87s, LR: 0.00017, Train Loss: 0.2328, Train MAE: 0.2328,
                            Val Loss: 0.6908, Val MAE: 0.6907
2023-01-25 21:10:32,498:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 21:24:21,550:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.05s, LR: 0.00017, Train Loss: 0.2326, Train MAE: 0.2326,
                            Val Loss: 0.7425, Val MAE: 0.7426
2023-01-25 21:24:21,551:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 21:37:47,263:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 805.71s, LR: 0.00017, Train Loss: 0.2320, Train MAE: 0.2320,
                            Val Loss: 0.4180, Val MAE: 0.4180
2023-01-25 21:37:47,264:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 21:50:57,314:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 790.05s, LR: 0.00017, Train Loss: 0.2305, Train MAE: 0.2305,
                            Val Loss: 0.8030, Val MAE: 0.8026
2023-01-25 21:50:57,315:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 22:04:19,623:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 802.31s, LR: 0.00017, Train Loss: 0.2289, Train MAE: 0.2289,
                            Val Loss: 0.8026, Val MAE: 0.8028
2023-01-25 22:04:19,625:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 22:18:06,776:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 827.15s, LR: 0.00009, Train Loss: 0.2215, Train MAE: 0.2215,
                            Val Loss: 0.4425, Val MAE: 0.4426
2023-01-25 22:18:06,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 22:31:04,247:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.47s, LR: 0.00009, Train Loss: 0.2179, Train MAE: 0.2179,
                            Val Loss: 0.3758, Val MAE: 0.3756
2023-01-25 22:31:04,249:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 22:44:02,686:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.44s, LR: 0.00009, Train Loss: 0.2158, Train MAE: 0.2158,
                            Val Loss: 0.3440, Val MAE: 0.3438
2023-01-25 22:44:02,687:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 22:57:00,421:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.73s, LR: 0.00009, Train Loss: 0.2144, Train MAE: 0.2144,
                            Val Loss: 0.3397, Val MAE: 0.3396
2023-01-25 22:57:00,422:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 23:10:54,162:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 833.74s, LR: 0.00009, Train Loss: 0.2132, Train MAE: 0.2132,
                            Val Loss: 0.3248, Val MAE: 0.3247
2023-01-25 23:10:54,163:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 23:23:51,208:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.04s, LR: 0.00009, Train Loss: 0.2118, Train MAE: 0.2118,
                            Val Loss: 0.3310, Val MAE: 0.3310
2023-01-25 23:23:51,209:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 23:37:04,555:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 793.34s, LR: 0.00009, Train Loss: 0.2108, Train MAE: 0.2108,
                            Val Loss: 0.3286, Val MAE: 0.3284
2023-01-25 23:37:04,556:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 23:50:52,520:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2946043908596039
2023-01-25 23:50:52,521:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 827.97s, LR: 0.00009, Train Loss: 0.2100, Train MAE: 0.2100,
                            Val Loss: 0.2947, Val MAE: 0.2946
2023-01-25 23:50:52,522:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-26 00:04:40,360:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 827.84s, LR: 0.00009, Train Loss: 0.2091, Train MAE: 0.2091,
                            Val Loss: 0.3364, Val MAE: 0.3362
2023-01-26 00:04:40,361:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-26 00:18:28,318:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 827.96s, LR: 0.00009, Train Loss: 0.2093, Train MAE: 0.2093,
                            Val Loss: 0.4187, Val MAE: 0.4186
2023-01-26 00:18:28,319:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-26 00:32:16,069:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.29014092683792114
2023-01-26 00:32:16,071:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 827.75s, LR: 0.00009, Train Loss: 0.2074, Train MAE: 0.2074,
                            Val Loss: 0.2903, Val MAE: 0.2901
2023-01-26 00:32:16,071:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-26 00:46:03,653:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 827.58s, LR: 0.00009, Train Loss: 0.2068, Train MAE: 0.2068,
                            Val Loss: 0.3841, Val MAE: 0.3839
2023-01-26 00:46:03,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-26 00:59:32,416:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 808.76s, LR: 0.00009, Train Loss: 0.2059, Train MAE: 0.2059,
                            Val Loss: 0.3931, Val MAE: 0.3931
2023-01-26 00:59:32,418:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-26 01:12:45,804:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 793.39s, LR: 0.00009, Train Loss: 0.2052, Train MAE: 0.2052,
                            Val Loss: 0.3418, Val MAE: 0.3418
2023-01-26 01:12:45,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-26 01:26:02,730:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 796.92s, LR: 0.00009, Train Loss: 0.2042, Train MAE: 0.2042,
                            Val Loss: 0.4044, Val MAE: 0.4043
2023-01-26 01:26:02,731:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-26 01:39:05,480:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.75s, LR: 0.00009, Train Loss: 0.2044, Train MAE: 0.2044,
                            Val Loss: 0.3520, Val MAE: 0.3520
2023-01-26 01:39:05,481:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-26 01:52:15,819:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2701394259929657
2023-01-26 01:52:15,821:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 790.34s, LR: 0.00009, Train Loss: 0.2055, Train MAE: 0.2055,
                            Val Loss: 0.2703, Val MAE: 0.2701
2023-01-26 01:52:15,821:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-26 02:05:44,062:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 808.24s, LR: 0.00009, Train Loss: 0.2033, Train MAE: 0.2033,
                            Val Loss: 0.3031, Val MAE: 0.3029
2023-01-26 02:05:44,063:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-26 02:18:40,666:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.60s, LR: 0.00009, Train Loss: 0.2024, Train MAE: 0.2024,
                            Val Loss: 0.3562, Val MAE: 0.3561
2023-01-26 02:18:40,668:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-26 02:31:36,915:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2524864673614502
2023-01-26 02:31:36,916:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.25s, LR: 0.00009, Train Loss: 0.2016, Train MAE: 0.2016,
                            Val Loss: 0.2527, Val MAE: 0.2525
2023-01-26 02:31:36,917:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-26 02:45:10,054:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 813.14s, LR: 0.00009, Train Loss: 0.2009, Train MAE: 0.2009,
                            Val Loss: 0.3174, Val MAE: 0.3173
2023-01-26 02:45:10,055:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-26 02:59:53,246:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 883.19s, LR: 0.00009, Train Loss: 0.2004, Train MAE: 0.2004,
                            Val Loss: 0.3129, Val MAE: 0.3128
2023-01-26 02:59:53,247:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-26 03:13:28,894:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 815.65s, LR: 0.00009, Train Loss: 0.1998, Train MAE: 0.1998,
                            Val Loss: 0.3887, Val MAE: 0.3885
2023-01-26 03:13:28,894:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-26 03:26:24,310:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 775.41s, LR: 0.00009, Train Loss: 0.2001, Train MAE: 0.2001,
                            Val Loss: 0.2881, Val MAE: 0.2879
2023-01-26 03:26:24,311:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-26 03:39:20,736:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.42s, LR: 0.00009, Train Loss: 0.1989, Train MAE: 0.1989,
                            Val Loss: 0.4537, Val MAE: 0.4537
2023-01-26 03:39:20,737:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-26 03:52:15,771:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 775.03s, LR: 0.00009, Train Loss: 0.1987, Train MAE: 0.1987,
                            Val Loss: 0.3266, Val MAE: 0.3266
2023-01-26 03:52:15,773:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 04:05:10,524:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.24321503937244415
2023-01-26 04:05:10,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.75s, LR: 0.00009, Train Loss: 0.1986, Train MAE: 0.1986,
                            Val Loss: 0.2434, Val MAE: 0.2432
2023-01-26 04:05:10,526:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 04:18:06,716:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.19s, LR: 0.00009, Train Loss: 0.1982, Train MAE: 0.1982,
                            Val Loss: 0.4023, Val MAE: 0.4021
2023-01-26 04:18:06,718:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 04:31:01,969:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 775.25s, LR: 0.00009, Train Loss: 0.1980, Train MAE: 0.1980,
                            Val Loss: 0.4128, Val MAE: 0.4129
2023-01-26 04:31:01,970:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 04:43:56,437:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.47s, LR: 0.00009, Train Loss: 0.1969, Train MAE: 0.1969,
                            Val Loss: 0.3842, Val MAE: 0.3843
2023-01-26 04:43:56,439:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 04:56:53,002:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.56s, LR: 0.00009, Train Loss: 0.1971, Train MAE: 0.1971,
                            Val Loss: 0.3656, Val MAE: 0.3654
2023-01-26 04:56:53,003:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 05:09:48,401:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 775.40s, LR: 0.00009, Train Loss: 0.1965, Train MAE: 0.1965,
                            Val Loss: 0.3014, Val MAE: 0.3013
2023-01-26 05:09:48,402:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 05:22:43,091:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.69s, LR: 0.00009, Train Loss: 0.1981, Train MAE: 0.1981,
                            Val Loss: 0.2942, Val MAE: 0.2941
2023-01-26 05:22:43,092:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:22:43,093:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-26 05:30:54,134:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.2941
2023-01-26 05:30:54,136:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.2631
2023-01-26 05:30:54,137:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-26 05:30:54,139:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 102.0000
2023-01-26 05:30:54,140:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87305.4162s
2023-01-26 05:30:54,142:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 803.8808s
2023-01-26 05:30:54,144:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-26 05:30:54,145:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.2631)]
2023-01-26 05:30:54,146:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.2941)]
