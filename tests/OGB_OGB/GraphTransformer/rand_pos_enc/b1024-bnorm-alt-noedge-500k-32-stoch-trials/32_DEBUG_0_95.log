2023-01-25 05:05:23,042:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-25 05:05:23,042:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-25 05:15:48,596:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-25 05:16:17,699:ogbdata.py:332 -             __init__(): Time taken: 654.6568s
2023-01-25 05:16:17,699:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-25 05:16:17,699:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-25 05:16:17,699:ogbdata.py:348 -             __init__(): [I] Data load time: 654.6571s
2023-01-25 05:16:17,699:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-trials/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-25 05:16:17,699:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-25 05:16:17,701:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:16:19,222:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:16:19,222:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:16:19,222:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:16:19,238:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-25 05:16:19,240:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-25 05:16:19,241:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-25 05:16:19,241:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-25 05:16:19,242:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-25 05:16:19,242:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-25 05:16:19,242:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-25 05:16:19,262:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-25 06:25:58,110:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4178.869329690933
2023-01-25 06:25:58,118:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-25 06:25:58,118:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-25 06:25:58,121:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-25 06:39:20,662:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 3.514805316925049
2023-01-25 06:39:20,664:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 802.54s, LR: 0.00070, Train Loss: 0.5609, Train MAE: 0.5609,
                            Val Loss: 3.5152, Val MAE: 3.5148
2023-01-25 06:39:20,664:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-25 06:50:27,166:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 2.2207441329956055
2023-01-25 06:50:27,168:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.50s, LR: 0.00070, Train Loss: 0.4935, Train MAE: 0.4935,
                            Val Loss: 2.2208, Val MAE: 2.2207
2023-01-25 06:50:27,169:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-25 07:01:32,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.87s, LR: 0.00070, Train Loss: 0.4067, Train MAE: 0.4067,
                            Val Loss: 3.4526, Val MAE: 3.4524
2023-01-25 07:01:32,039:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-25 07:12:38,244:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.409374475479126
2023-01-25 07:12:38,247:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.21s, LR: 0.00070, Train Loss: 0.4092, Train MAE: 0.4092,
                            Val Loss: 1.4095, Val MAE: 1.4094
2023-01-25 07:12:38,247:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-25 07:23:43,954:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.2897216081619263
2023-01-25 07:23:43,956:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.71s, LR: 0.00070, Train Loss: 0.4409, Train MAE: 0.4409,
                            Val Loss: 1.2898, Val MAE: 1.2897
2023-01-25 07:23:43,957:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-25 07:34:47,749:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.79s, LR: 0.00070, Train Loss: 0.4246, Train MAE: 0.4246,
                            Val Loss: 3.8673, Val MAE: 3.8672
2023-01-25 07:34:47,751:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-25 07:45:51,428:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5381642580032349
2023-01-25 07:45:51,431:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.68s, LR: 0.00070, Train Loss: 0.4071, Train MAE: 0.4071,
                            Val Loss: 0.5381, Val MAE: 0.5382
2023-01-25 07:45:51,431:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-25 07:57:56,358:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.93s, LR: 0.00070, Train Loss: 0.3996, Train MAE: 0.3996,
                            Val Loss: 1.8154, Val MAE: 1.8152
2023-01-25 07:57:56,360:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-25 08:08:58,157:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.80s, LR: 0.00070, Train Loss: 0.3794, Train MAE: 0.3794,
                            Val Loss: 3.1719, Val MAE: 3.1711
2023-01-25 08:08:58,158:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-25 08:19:56,676:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.52s, LR: 0.00070, Train Loss: 0.3544, Train MAE: 0.3544,
                            Val Loss: 1.3422, Val MAE: 1.3421
2023-01-25 08:19:56,678:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-25 08:30:54,869:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.19s, LR: 0.00070, Train Loss: 0.3328, Train MAE: 0.3328,
                            Val Loss: 2.6190, Val MAE: 2.6188
2023-01-25 08:30:54,870:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-25 08:41:52,866:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.99s, LR: 0.00070, Train Loss: 0.3202, Train MAE: 0.3202,
                            Val Loss: 1.4725, Val MAE: 1.4728
2023-01-25 08:41:52,867:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-25 08:52:48,265:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.40s, LR: 0.00070, Train Loss: 0.3171, Train MAE: 0.3171,
                            Val Loss: 0.9249, Val MAE: 0.9249
2023-01-25 08:52:48,266:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-25 09:03:44,435:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.17s, LR: 0.00070, Train Loss: 0.3222, Train MAE: 0.3222,
                            Val Loss: 0.5602, Val MAE: 0.5598
2023-01-25 09:03:44,437:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-25 09:14:40,799:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.36s, LR: 0.00070, Train Loss: 0.3069, Train MAE: 0.3069,
                            Val Loss: 4.1950, Val MAE: 4.1946
2023-01-25 09:14:40,800:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-25 09:25:39,876:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.07s, LR: 0.00070, Train Loss: 0.2947, Train MAE: 0.2947,
                            Val Loss: 1.1529, Val MAE: 1.1528
2023-01-25 09:25:39,877:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-25 09:36:37,592:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.71s, LR: 0.00070, Train Loss: 0.2968, Train MAE: 0.2968,
                            Val Loss: 4.6243, Val MAE: 4.6239
2023-01-25 09:36:37,593:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-25 09:47:35,585:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.99s, LR: 0.00070, Train Loss: 0.2884, Train MAE: 0.2884,
                            Val Loss: 1.4078, Val MAE: 1.4072
2023-01-25 09:47:35,586:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-25 09:58:32,758:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.17s, LR: 0.00070, Train Loss: 0.2833, Train MAE: 0.2833,
                            Val Loss: 1.5365, Val MAE: 1.5367
2023-01-25 09:58:32,759:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-25 10:09:28,633:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.87s, LR: 0.00070, Train Loss: 0.2812, Train MAE: 0.2812,
                            Val Loss: 1.9321, Val MAE: 1.9320
2023-01-25 10:09:28,634:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-25 10:20:24,152:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.52s, LR: 0.00070, Train Loss: 0.2927, Train MAE: 0.2927,
                            Val Loss: 2.6485, Val MAE: 2.6477
2023-01-25 10:20:24,153:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-25 10:31:19,156:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.00s, LR: 0.00070, Train Loss: 0.2870, Train MAE: 0.2870,
                            Val Loss: 5.2235, Val MAE: 5.2233
2023-01-25 10:31:19,157:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-25 10:42:13,763:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.61s, LR: 0.00070, Train Loss: 0.2791, Train MAE: 0.2791,
                            Val Loss: 0.7195, Val MAE: 0.7190
2023-01-25 10:42:13,764:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-25 10:54:07,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.21s, LR: 0.00035, Train Loss: 0.2673, Train MAE: 0.2673,
                            Val Loss: 1.8806, Val MAE: 1.8808
2023-01-25 10:54:07,973:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-25 11:05:02,766:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.79s, LR: 0.00035, Train Loss: 0.2638, Train MAE: 0.2638,
                            Val Loss: 1.3209, Val MAE: 1.3203
2023-01-25 11:05:02,767:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-25 11:15:56,723:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.96s, LR: 0.00035, Train Loss: 0.2666, Train MAE: 0.2666,
                            Val Loss: 0.9232, Val MAE: 0.9234
2023-01-25 11:15:56,725:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-25 11:26:50,360:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.63s, LR: 0.00035, Train Loss: 0.2584, Train MAE: 0.2584,
                            Val Loss: 2.5378, Val MAE: 2.5372
2023-01-25 11:26:50,360:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-25 11:37:41,744:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.33239832520484924
2023-01-25 11:37:41,746:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.38s, LR: 0.00035, Train Loss: 0.2551, Train MAE: 0.2551,
                            Val Loss: 0.3326, Val MAE: 0.3324
2023-01-25 11:37:41,746:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-25 11:48:32,768:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.02s, LR: 0.00035, Train Loss: 0.2512, Train MAE: 0.2512,
                            Val Loss: 0.6317, Val MAE: 0.6319
2023-01-25 11:48:32,768:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-25 11:59:23,661:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.89s, LR: 0.00035, Train Loss: 0.2494, Train MAE: 0.2494,
                            Val Loss: 0.7144, Val MAE: 0.7140
2023-01-25 11:59:23,663:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-25 12:10:14,164:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.50s, LR: 0.00035, Train Loss: 0.2464, Train MAE: 0.2464,
                            Val Loss: 1.1241, Val MAE: 1.1244
2023-01-25 12:10:14,166:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-25 12:21:06,496:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.33s, LR: 0.00035, Train Loss: 0.2483, Train MAE: 0.2483,
                            Val Loss: 1.8904, Val MAE: 1.8907
2023-01-25 12:21:06,497:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-25 12:32:00,172:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.67s, LR: 0.00035, Train Loss: 0.2526, Train MAE: 0.2526,
                            Val Loss: 1.4369, Val MAE: 1.4371
2023-01-25 12:32:00,173:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-25 12:42:53,376:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.20s, LR: 0.00035, Train Loss: 0.2470, Train MAE: 0.2470,
                            Val Loss: 0.9182, Val MAE: 0.9184
2023-01-25 12:42:53,376:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-25 12:53:48,098:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.72s, LR: 0.00035, Train Loss: 0.2484, Train MAE: 0.2484,
                            Val Loss: 1.0195, Val MAE: 1.0193
2023-01-25 12:53:48,098:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-25 13:04:41,108:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.01s, LR: 0.00035, Train Loss: 0.2477, Train MAE: 0.2477,
                            Val Loss: 0.6342, Val MAE: 0.6337
2023-01-25 13:04:41,109:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-25 13:15:35,093:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.98s, LR: 0.00035, Train Loss: 0.2501, Train MAE: 0.2501,
                            Val Loss: 1.1903, Val MAE: 1.1904
2023-01-25 13:15:35,094:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-25 13:26:28,769:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.67s, LR: 0.00035, Train Loss: 0.2522, Train MAE: 0.2522,
                            Val Loss: 0.7121, Val MAE: 0.7117
2023-01-25 13:26:28,770:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-25 13:37:21,291:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.52s, LR: 0.00035, Train Loss: 0.2376, Train MAE: 0.2376,
                            Val Loss: 0.3569, Val MAE: 0.3568
2023-01-25 13:37:21,292:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-25 13:48:12,705:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.41s, LR: 0.00035, Train Loss: 0.2301, Train MAE: 0.2301,
                            Val Loss: 0.3899, Val MAE: 0.3898
2023-01-25 13:48:12,706:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-25 14:00:00,362:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.66s, LR: 0.00035, Train Loss: 0.2281, Train MAE: 0.2281,
                            Val Loss: 0.4234, Val MAE: 0.4234
2023-01-25 14:00:00,364:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-25 14:10:51,831:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.47s, LR: 0.00035, Train Loss: 0.2401, Train MAE: 0.2401,
                            Val Loss: 0.9116, Val MAE: 0.9118
2023-01-25 14:10:51,832:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-25 14:21:43,068:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.24s, LR: 0.00035, Train Loss: 0.2450, Train MAE: 0.2450,
                            Val Loss: 0.9450, Val MAE: 0.9452
2023-01-25 14:21:43,069:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-25 14:32:34,186:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.12s, LR: 0.00035, Train Loss: 0.2374, Train MAE: 0.2374,
                            Val Loss: 0.4841, Val MAE: 0.4837
2023-01-25 14:32:34,187:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-25 14:43:24,980:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.79s, LR: 0.00017, Train Loss: 0.2200, Train MAE: 0.2200,
                            Val Loss: 0.5183, Val MAE: 0.5184
2023-01-25 14:43:24,981:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-25 14:54:15,256:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2466452568769455
2023-01-25 14:54:15,257:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.28s, LR: 0.00017, Train Loss: 0.2163, Train MAE: 0.2163,
                            Val Loss: 0.2468, Val MAE: 0.2466
2023-01-25 14:54:15,258:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-25 15:05:05,303:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.04s, LR: 0.00017, Train Loss: 0.2135, Train MAE: 0.2135,
                            Val Loss: 0.4525, Val MAE: 0.4522
2023-01-25 15:05:05,304:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-25 15:15:56,042:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.74s, LR: 0.00017, Train Loss: 0.2122, Train MAE: 0.2122,
                            Val Loss: 0.5357, Val MAE: 0.5358
2023-01-25 15:15:56,042:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-25 15:26:47,033:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.99s, LR: 0.00017, Train Loss: 0.2138, Train MAE: 0.2138,
                            Val Loss: 0.4211, Val MAE: 0.4211
2023-01-25 15:26:47,034:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-25 15:37:36,791:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.76s, LR: 0.00017, Train Loss: 0.2105, Train MAE: 0.2105,
                            Val Loss: 0.2566, Val MAE: 0.2564
2023-01-25 15:37:36,792:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-25 15:48:26,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.51s, LR: 0.00017, Train Loss: 0.2116, Train MAE: 0.2116,
                            Val Loss: 0.3291, Val MAE: 0.3290
2023-01-25 15:48:26,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-25 15:59:16,774:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.47s, LR: 0.00017, Train Loss: 0.2101, Train MAE: 0.2101,
                            Val Loss: 0.2800, Val MAE: 0.2799
2023-01-25 15:59:16,775:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-25 16:10:07,370:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.59s, LR: 0.00017, Train Loss: 0.2094, Train MAE: 0.2094,
                            Val Loss: 0.2687, Val MAE: 0.2685
2023-01-25 16:10:07,371:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-25 16:20:57,185:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.81s, LR: 0.00017, Train Loss: 0.2093, Train MAE: 0.2093,
                            Val Loss: 0.3700, Val MAE: 0.3700
2023-01-25 16:20:57,186:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-25 16:31:46,568:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.38s, LR: 0.00017, Train Loss: 0.2092, Train MAE: 0.2092,
                            Val Loss: 0.2541, Val MAE: 0.2540
2023-01-25 16:31:46,569:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-25 16:42:36,622:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.05s, LR: 0.00017, Train Loss: 0.2070, Train MAE: 0.2070,
                            Val Loss: 0.3467, Val MAE: 0.3466
2023-01-25 16:42:36,622:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-25 16:53:27,573:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.24191340804100037
2023-01-25 16:53:27,574:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.95s, LR: 0.00017, Train Loss: 0.2064, Train MAE: 0.2064,
                            Val Loss: 0.2421, Val MAE: 0.2419
2023-01-25 16:53:27,575:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-25 17:05:12,702:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.13s, LR: 0.00017, Train Loss: 0.2054, Train MAE: 0.2054,
                            Val Loss: 0.3855, Val MAE: 0.3855
2023-01-25 17:05:12,703:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-25 17:17:28,717:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 736.01s, LR: 0.00017, Train Loss: 0.2044, Train MAE: 0.2044,
                            Val Loss: 0.2928, Val MAE: 0.2928
2023-01-25 17:17:28,718:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-25 17:28:49,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.76s, LR: 0.00017, Train Loss: 0.2048, Train MAE: 0.2048,
                            Val Loss: 0.3717, Val MAE: 0.3717
2023-01-25 17:28:49,512:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-25 17:40:04,094:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 674.58s, LR: 0.00017, Train Loss: 0.2042, Train MAE: 0.2042,
                            Val Loss: 0.2502, Val MAE: 0.2500
2023-01-25 17:40:04,110:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-25 17:50:55,963:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.85s, LR: 0.00017, Train Loss: 0.2039, Train MAE: 0.2039,
                            Val Loss: 0.3220, Val MAE: 0.3219
2023-01-25 17:50:55,964:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-25 18:01:48,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.02s, LR: 0.00017, Train Loss: 0.2032, Train MAE: 0.2032,
                            Val Loss: 0.2905, Val MAE: 0.2904
2023-01-25 18:01:48,988:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-25 18:12:40,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.32s, LR: 0.00017, Train Loss: 0.2025, Train MAE: 0.2025,
                            Val Loss: 0.3236, Val MAE: 0.3234
2023-01-25 18:12:40,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-25 18:23:31,445:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.13s, LR: 0.00017, Train Loss: 0.2020, Train MAE: 0.2020,
                            Val Loss: 0.2558, Val MAE: 0.2557
2023-01-25 18:23:31,446:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-25 18:34:23,258:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.81s, LR: 0.00017, Train Loss: 0.2018, Train MAE: 0.2018,
                            Val Loss: 0.2707, Val MAE: 0.2705
2023-01-25 18:34:23,259:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-25 18:45:15,580:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.32s, LR: 0.00017, Train Loss: 0.2017, Train MAE: 0.2017,
                            Val Loss: 0.3681, Val MAE: 0.3680
2023-01-25 18:45:15,581:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-25 18:56:06,694:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2328716218471527
2023-01-25 18:56:06,695:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.11s, LR: 0.00017, Train Loss: 0.2008, Train MAE: 0.2008,
                            Val Loss: 0.2331, Val MAE: 0.2329
2023-01-25 18:56:06,696:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-25 19:06:57,662:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.97s, LR: 0.00017, Train Loss: 0.2002, Train MAE: 0.2002,
                            Val Loss: 0.3423, Val MAE: 0.3422
2023-01-25 19:06:57,663:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-25 19:18:19,789:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.13s, LR: 0.00017, Train Loss: 0.2052, Train MAE: 0.2052,
                            Val Loss: 0.2740, Val MAE: 0.2739
2023-01-25 19:18:19,790:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-25 19:30:21,532:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.74s, LR: 0.00017, Train Loss: 0.2068, Train MAE: 0.2068,
                            Val Loss: 0.3306, Val MAE: 0.3304
2023-01-25 19:30:21,533:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-25 19:42:23,884:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.35s, LR: 0.00017, Train Loss: 0.2019, Train MAE: 0.2019,
                            Val Loss: 0.2810, Val MAE: 0.2809
2023-01-25 19:42:23,885:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-25 19:54:25,661:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.77s, LR: 0.00017, Train Loss: 0.2035, Train MAE: 0.2035,
                            Val Loss: 0.3356, Val MAE: 0.3355
2023-01-25 19:54:25,662:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-25 20:05:58,294:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.63s, LR: 0.00017, Train Loss: 0.1988, Train MAE: 0.1988,
                            Val Loss: 0.3433, Val MAE: 0.3432
2023-01-25 20:05:58,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-25 20:17:43,299:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.00s, LR: 0.00017, Train Loss: 0.1979, Train MAE: 0.1979,
                            Val Loss: 0.3688, Val MAE: 0.3686
2023-01-25 20:17:43,299:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-25 20:28:33,969:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.67s, LR: 0.00017, Train Loss: 0.1978, Train MAE: 0.1978,
                            Val Loss: 0.2480, Val MAE: 0.2478
2023-01-25 20:28:33,970:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-25 20:39:25,438:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.47s, LR: 0.00017, Train Loss: 0.1974, Train MAE: 0.1974,
                            Val Loss: 0.3796, Val MAE: 0.3795
2023-01-25 20:39:25,438:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-25 20:50:17,699:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.26s, LR: 0.00017, Train Loss: 0.2075, Train MAE: 0.2075,
                            Val Loss: 0.2835, Val MAE: 0.2834
2023-01-25 20:50:17,700:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-25 21:01:09,089:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.39s, LR: 0.00017, Train Loss: 0.1968, Train MAE: 0.1968,
                            Val Loss: 0.3403, Val MAE: 0.3402
2023-01-25 21:01:09,089:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-25 21:12:00,297:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.21s, LR: 0.00017, Train Loss: 0.1963, Train MAE: 0.1963,
                            Val Loss: 0.2554, Val MAE: 0.2552
2023-01-25 21:12:00,298:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-25 21:22:52,340:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.04s, LR: 0.00017, Train Loss: 0.1956, Train MAE: 0.1956,
                            Val Loss: 0.3431, Val MAE: 0.3430
2023-01-25 21:22:52,341:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-25 21:33:44,552:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.21s, LR: 0.00017, Train Loss: 0.1953, Train MAE: 0.1953,
                            Val Loss: 0.3441, Val MAE: 0.3440
2023-01-25 21:33:44,552:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-25 21:44:35,708:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.15s, LR: 0.00017, Train Loss: 0.1956, Train MAE: 0.1956,
                            Val Loss: 0.2626, Val MAE: 0.2624
2023-01-25 21:44:35,709:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-25 21:55:26,710:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.00s, LR: 0.00017, Train Loss: 0.1942, Train MAE: 0.1942,
                            Val Loss: 0.2841, Val MAE: 0.2839
2023-01-25 21:55:26,711:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-25 22:06:18,431:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.72s, LR: 0.00009, Train Loss: 0.1901, Train MAE: 0.1901,
                            Val Loss: 0.2626, Val MAE: 0.2625
2023-01-25 22:06:18,432:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-25 22:17:10,367:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.93s, LR: 0.00009, Train Loss: 0.2035, Train MAE: 0.2035,
                            Val Loss: 0.2940, Val MAE: 0.2940
2023-01-25 22:17:10,368:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-25 22:28:01,550:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.18s, LR: 0.00009, Train Loss: 0.1897, Train MAE: 0.1897,
                            Val Loss: 0.2521, Val MAE: 0.2520
2023-01-25 22:28:01,551:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-25 22:38:52,657:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.22445011138916016
2023-01-25 22:38:52,659:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.11s, LR: 0.00009, Train Loss: 0.1896, Train MAE: 0.1896,
                            Val Loss: 0.2246, Val MAE: 0.2245
2023-01-25 22:38:52,660:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-25 22:49:44,168:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.51s, LR: 0.00009, Train Loss: 0.1889, Train MAE: 0.1889,
                            Val Loss: 0.3375, Val MAE: 0.3375
2023-01-25 22:49:44,169:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-25 23:00:36,015:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2228623330593109
2023-01-25 23:00:36,016:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.85s, LR: 0.00009, Train Loss: 0.1886, Train MAE: 0.1886,
                            Val Loss: 0.2230, Val MAE: 0.2229
2023-01-25 23:00:36,017:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-25 23:11:26,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.85s, LR: 0.00009, Train Loss: 0.1887, Train MAE: 0.1887,
                            Val Loss: 0.3204, Val MAE: 0.3203
2023-01-25 23:11:26,871:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-25 23:23:12,461:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.59s, LR: 0.00009, Train Loss: 0.1884, Train MAE: 0.1884,
                            Val Loss: 0.2503, Val MAE: 0.2501
2023-01-25 23:23:12,462:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-25 23:34:04,275:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.81s, LR: 0.00009, Train Loss: 0.1880, Train MAE: 0.1880,
                            Val Loss: 0.2614, Val MAE: 0.2613
2023-01-25 23:34:04,276:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-25 23:44:55,660:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.38s, LR: 0.00009, Train Loss: 0.1885, Train MAE: 0.1885,
                            Val Loss: 0.2350, Val MAE: 0.2348
2023-01-25 23:44:55,661:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-25 23:55:47,464:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.80s, LR: 0.00009, Train Loss: 0.1874, Train MAE: 0.1874,
                            Val Loss: 0.2303, Val MAE: 0.2300
2023-01-25 23:55:47,465:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-26 00:06:39,520:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.05s, LR: 0.00009, Train Loss: 0.1872, Train MAE: 0.1872,
                            Val Loss: 0.3407, Val MAE: 0.3407
2023-01-26 00:06:39,521:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-26 00:17:30,573:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.05s, LR: 0.00009, Train Loss: 0.1869, Train MAE: 0.1869,
                            Val Loss: 0.2392, Val MAE: 0.2391
2023-01-26 00:17:30,574:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-26 00:28:21,998:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.42s, LR: 0.00009, Train Loss: 0.1870, Train MAE: 0.1870,
                            Val Loss: 0.2252, Val MAE: 0.2249
2023-01-26 00:28:21,999:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-26 00:39:14,380:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.38s, LR: 0.00009, Train Loss: 0.1868, Train MAE: 0.1868,
                            Val Loss: 0.2834, Val MAE: 0.2833
2023-01-26 00:39:14,381:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-26 00:50:06,144:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.76s, LR: 0.00009, Train Loss: 0.1875, Train MAE: 0.1875,
                            Val Loss: 0.3420, Val MAE: 0.3419
2023-01-26 00:50:06,145:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-26 01:00:57,274:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.13s, LR: 0.00009, Train Loss: 0.1866, Train MAE: 0.1866,
                            Val Loss: 0.3449, Val MAE: 0.3448
2023-01-26 01:00:57,275:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-26 01:11:48,720:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.44s, LR: 0.00009, Train Loss: 0.1860, Train MAE: 0.1860,
                            Val Loss: 0.2569, Val MAE: 0.2568
2023-01-26 01:11:48,721:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-26 01:22:40,640:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.92s, LR: 0.00009, Train Loss: 0.1861, Train MAE: 0.1861,
                            Val Loss: 0.2813, Val MAE: 0.2812
2023-01-26 01:22:40,641:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-26 01:33:32,706:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.06s, LR: 0.00009, Train Loss: 0.1856, Train MAE: 0.1856,
                            Val Loss: 0.2911, Val MAE: 0.2911
2023-01-26 01:33:32,707:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-26 01:44:23,653:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.95s, LR: 0.00009, Train Loss: 0.1855, Train MAE: 0.1855,
                            Val Loss: 0.2554, Val MAE: 0.2552
2023-01-26 01:44:23,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-26 01:55:15,514:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.86s, LR: 0.00009, Train Loss: 0.1856, Train MAE: 0.1856,
                            Val Loss: 0.2357, Val MAE: 0.2355
2023-01-26 01:55:15,515:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-26 02:06:07,603:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.09s, LR: 0.00004, Train Loss: 0.1830, Train MAE: 0.1830,
                            Val Loss: 0.2327, Val MAE: 0.2325
2023-01-26 02:06:07,603:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-26 02:16:59,617:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.01s, LR: 0.00004, Train Loss: 0.1828, Train MAE: 0.1828,
                            Val Loss: 0.2602, Val MAE: 0.2602
2023-01-26 02:16:59,618:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-26 02:28:44,782:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.16s, LR: 0.00004, Train Loss: 0.1826, Train MAE: 0.1826,
                            Val Loss: 0.3391, Val MAE: 0.3390
2023-01-26 02:28:44,783:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-26 02:39:35,495:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.71s, LR: 0.00004, Train Loss: 0.1827, Train MAE: 0.1827,
                            Val Loss: 0.2272, Val MAE: 0.2271
2023-01-26 02:39:35,496:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-26 02:50:27,464:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.97s, LR: 0.00004, Train Loss: 0.1826, Train MAE: 0.1826,
                            Val Loss: 0.3355, Val MAE: 0.3354
2023-01-26 02:50:27,465:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-26 03:01:19,267:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.80s, LR: 0.00004, Train Loss: 0.1823, Train MAE: 0.1823,
                            Val Loss: 0.2424, Val MAE: 0.2423
2023-01-26 03:01:19,268:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-26 03:12:09,730:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.46s, LR: 0.00004, Train Loss: 0.1822, Train MAE: 0.1822,
                            Val Loss: 0.3219, Val MAE: 0.3218
2023-01-26 03:12:09,731:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-26 03:23:00,706:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.97s, LR: 0.00004, Train Loss: 0.1819, Train MAE: 0.1819,
                            Val Loss: 0.2302, Val MAE: 0.2300
2023-01-26 03:23:00,707:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-26 03:33:52,150:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2144685536623001
2023-01-26 03:33:52,152:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.44s, LR: 0.00004, Train Loss: 0.1821, Train MAE: 0.1821,
                            Val Loss: 0.2147, Val MAE: 0.2145
2023-01-26 03:33:52,153:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-26 03:44:44,412:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.26s, LR: 0.00004, Train Loss: 0.1823, Train MAE: 0.1823,
                            Val Loss: 0.3424, Val MAE: 0.3423
2023-01-26 03:44:44,413:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-26 03:55:35,562:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.15s, LR: 0.00004, Train Loss: 0.1819, Train MAE: 0.1819,
                            Val Loss: 0.2881, Val MAE: 0.2880
2023-01-26 03:55:35,563:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-26 04:06:26,283:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.72s, LR: 0.00004, Train Loss: 0.1817, Train MAE: 0.1817,
                            Val Loss: 0.2668, Val MAE: 0.2667
2023-01-26 04:06:26,284:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-26 04:17:18,227:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.94s, LR: 0.00004, Train Loss: 0.1815, Train MAE: 0.1815,
                            Val Loss: 0.2992, Val MAE: 0.2991
2023-01-26 04:17:18,228:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-26 04:28:10,003:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.77s, LR: 0.00004, Train Loss: 0.1813, Train MAE: 0.1813,
                            Val Loss: 0.2997, Val MAE: 0.2996
2023-01-26 04:28:10,004:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-26 04:39:00,669:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.66s, LR: 0.00004, Train Loss: 0.1824, Train MAE: 0.1824,
                            Val Loss: 0.3344, Val MAE: 0.3344
2023-01-26 04:39:00,670:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-26 04:49:51,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.05s, LR: 0.00004, Train Loss: 0.1819, Train MAE: 0.1819,
                            Val Loss: 0.2221, Val MAE: 0.2219
2023-01-26 04:49:51,724:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-26 05:00:43,741:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.02s, LR: 0.00004, Train Loss: 0.1815, Train MAE: 0.1815,
                            Val Loss: 0.2938, Val MAE: 0.2937
2023-01-26 05:00:43,742:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-26 05:11:35,501:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.76s, LR: 0.00004, Train Loss: 0.1816, Train MAE: 0.1816,
                            Val Loss: 0.2396, Val MAE: 0.2394
2023-01-26 05:11:35,502:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-26 05:23:20,905:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.40s, LR: 0.00004, Train Loss: 0.1813, Train MAE: 0.1813,
                            Val Loss: 0.2430, Val MAE: 0.2429
2023-01-26 05:23:20,906:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-26 05:23:20,907:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-26 05:30:39,051:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.2429
2023-01-26 05:30:39,059:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.2113
2023-01-26 05:30:39,060:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-26 05:30:39,061:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 124.0000
2023-01-26 05:30:39,062:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87259.8214s
2023-01-26 05:30:39,062:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 661.1418s
2023-01-26 05:30:39,104:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-trials', 'job_num': 32}
2023-01-26 05:30:39,288:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.2113)]
2023-01-26 05:30:39,288:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.2429)]
