2023-01-26 05:38:45,153:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2023-01-26 05:38:45,153:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-26 05:48:36,795:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-26 05:49:13,939:ogbdata.py:332 -             __init__(): Time taken: 628.7855s
2023-01-26 05:49:13,939:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-26 05:49:13,939:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-26 05:49:13,939:ogbdata.py:348 -             __init__(): [I] Data load time: 628.7860s
2023-01-26 05:49:13,939:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials/32_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-26 05:49:13,940:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-26 05:49:13,942:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:49:22,482:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:49:22,483:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:49:22,483:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:49:22,511:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-26 05:49:22,518:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-26 05:49:22,519:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-26 05:49:22,519:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:49:22,521:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:49:22,521:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:49:22,521:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:49:22,544:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-26 06:56:53,172:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4050.6533765792847
2023-01-26 06:56:53,215:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-26 06:56:53,215:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-26 06:56:53,231:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-26 07:12:49,152:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8580265641212463
2023-01-26 07:12:49,154:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 955.92s, LR: 0.00070, Train Loss: 0.5336, Train MAE: 0.5336,
                            Val Loss: 0.8586, Val MAE: 0.8580
2023-01-26 07:12:49,155:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-26 07:25:40,387:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4894825220108032
2023-01-26 07:25:40,388:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.23s, LR: 0.00070, Train Loss: 0.3741, Train MAE: 0.3741,
                            Val Loss: 0.4898, Val MAE: 0.4895
2023-01-26 07:25:40,389:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-26 07:38:25,849:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.46s, LR: 0.00070, Train Loss: 0.3163, Train MAE: 0.3163,
                            Val Loss: 0.6136, Val MAE: 0.6130
2023-01-26 07:38:25,850:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-26 07:51:11,367:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4810541570186615
2023-01-26 07:51:11,369:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.52s, LR: 0.00070, Train Loss: 0.2689, Train MAE: 0.2689,
                            Val Loss: 0.4812, Val MAE: 0.4811
2023-01-26 07:51:11,370:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-26 08:03:57,878:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.51s, LR: 0.00070, Train Loss: 0.2413, Train MAE: 0.2413,
                            Val Loss: 0.5384, Val MAE: 0.5382
2023-01-26 08:03:57,879:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-26 08:16:43,649:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.77s, LR: 0.00070, Train Loss: 0.2244, Train MAE: 0.2244,
                            Val Loss: 0.5709, Val MAE: 0.5708
2023-01-26 08:16:43,650:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-26 08:29:30,398:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.75s, LR: 0.00070, Train Loss: 0.2157, Train MAE: 0.2157,
                            Val Loss: 0.6187, Val MAE: 0.6187
2023-01-26 08:29:30,400:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-26 08:43:11,088:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3440135419368744
2023-01-26 08:43:11,090:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 820.69s, LR: 0.00070, Train Loss: 0.2026, Train MAE: 0.2026,
                            Val Loss: 0.3442, Val MAE: 0.3440
2023-01-26 08:43:11,091:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-26 08:55:58,178:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.09s, LR: 0.00070, Train Loss: 0.1980, Train MAE: 0.1980,
                            Val Loss: 0.5954, Val MAE: 0.5954
2023-01-26 08:55:58,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-26 09:08:45,686:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3216329514980316
2023-01-26 09:08:45,687:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.51s, LR: 0.00070, Train Loss: 0.1904, Train MAE: 0.1904,
                            Val Loss: 0.3218, Val MAE: 0.3216
2023-01-26 09:08:45,688:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-26 09:21:32,602:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2542755603790283
2023-01-26 09:21:32,604:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.92s, LR: 0.00070, Train Loss: 0.1964, Train MAE: 0.1964,
                            Val Loss: 0.2545, Val MAE: 0.2543
2023-01-26 09:21:32,605:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-26 09:34:19,241:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.63s, LR: 0.00070, Train Loss: 0.1826, Train MAE: 0.1826,
                            Val Loss: 0.2968, Val MAE: 0.2966
2023-01-26 09:34:19,242:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-26 09:47:05,953:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.71s, LR: 0.00070, Train Loss: 0.1765, Train MAE: 0.1765,
                            Val Loss: 0.4303, Val MAE: 0.4300
2023-01-26 09:47:05,954:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-26 09:59:52,370:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.42s, LR: 0.00070, Train Loss: 0.1770, Train MAE: 0.1770,
                            Val Loss: 0.4336, Val MAE: 0.4334
2023-01-26 09:59:52,371:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-26 10:12:39,354:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.98s, LR: 0.00070, Train Loss: 0.1698, Train MAE: 0.1698,
                            Val Loss: 0.2993, Val MAE: 0.2992
2023-01-26 10:12:39,355:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-26 10:25:26,157:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.80s, LR: 0.00070, Train Loss: 0.1671, Train MAE: 0.1671,
                            Val Loss: 0.3069, Val MAE: 0.3068
2023-01-26 10:25:26,159:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-26 10:38:13,404:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.24s, LR: 0.00070, Train Loss: 0.1627, Train MAE: 0.1627,
                            Val Loss: 0.2726, Val MAE: 0.2725
2023-01-26 10:38:13,405:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-26 10:51:00,884:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.48s, LR: 0.00070, Train Loss: 0.1596, Train MAE: 0.1596,
                            Val Loss: 0.4433, Val MAE: 0.4432
2023-01-26 10:51:00,885:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-26 11:03:47,715:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.83s, LR: 0.00070, Train Loss: 0.1585, Train MAE: 0.1585,
                            Val Loss: 0.5244, Val MAE: 0.5243
2023-01-26 11:03:47,716:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-26 11:16:34,196:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.48s, LR: 0.00070, Train Loss: 0.1549, Train MAE: 0.1549,
                            Val Loss: 0.2741, Val MAE: 0.2740
2023-01-26 11:16:34,197:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-26 11:29:21,497:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2190493792295456
2023-01-26 11:29:21,499:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.30s, LR: 0.00070, Train Loss: 0.1527, Train MAE: 0.1527,
                            Val Loss: 0.2192, Val MAE: 0.2190
2023-01-26 11:29:21,499:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-26 11:42:07,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.23s, LR: 0.00070, Train Loss: 0.1507, Train MAE: 0.1507,
                            Val Loss: 0.4597, Val MAE: 0.4597
2023-01-26 11:42:07,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-26 11:54:54,123:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.39s, LR: 0.00070, Train Loss: 0.1498, Train MAE: 0.1498,
                            Val Loss: 0.2906, Val MAE: 0.2904
2023-01-26 11:54:54,124:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-26 12:08:35,911:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.20960254967212677
2023-01-26 12:08:35,912:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 821.79s, LR: 0.00070, Train Loss: 0.1473, Train MAE: 0.1473,
                            Val Loss: 0.2099, Val MAE: 0.2096
2023-01-26 12:08:35,913:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-26 12:21:22,293:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.38s, LR: 0.00070, Train Loss: 0.1529, Train MAE: 0.1529,
                            Val Loss: 0.4015, Val MAE: 0.4015
2023-01-26 12:21:22,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-26 12:34:09,191:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.90s, LR: 0.00070, Train Loss: 0.1447, Train MAE: 0.1447,
                            Val Loss: 0.2321, Val MAE: 0.2319
2023-01-26 12:34:09,192:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-26 12:46:56,694:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.50s, LR: 0.00070, Train Loss: 0.1434, Train MAE: 0.1434,
                            Val Loss: 0.4711, Val MAE: 0.4713
2023-01-26 12:46:56,695:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-26 12:59:43,578:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.88s, LR: 0.00070, Train Loss: 0.1430, Train MAE: 0.1430,
                            Val Loss: 0.2752, Val MAE: 0.2752
2023-01-26 12:59:43,579:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-26 13:12:30,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.15s, LR: 0.00070, Train Loss: 0.1410, Train MAE: 0.1410,
                            Val Loss: 0.2706, Val MAE: 0.2705
2023-01-26 13:12:30,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-26 13:25:17,626:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.90s, LR: 0.00070, Train Loss: 0.1406, Train MAE: 0.1406,
                            Val Loss: 0.3665, Val MAE: 0.3665
2023-01-26 13:25:17,627:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-26 13:38:04,034:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.41s, LR: 0.00070, Train Loss: 0.1380, Train MAE: 0.1380,
                            Val Loss: 0.2414, Val MAE: 0.2413
2023-01-26 13:38:04,035:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-26 13:50:51,035:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.00s, LR: 0.00070, Train Loss: 0.1370, Train MAE: 0.1370,
                            Val Loss: 0.3527, Val MAE: 0.3527
2023-01-26 13:50:51,036:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-26 14:03:37,946:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.91s, LR: 0.00070, Train Loss: 0.1365, Train MAE: 0.1365,
                            Val Loss: 0.3983, Val MAE: 0.3985
2023-01-26 14:03:37,947:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-26 14:16:24,567:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.62s, LR: 0.00070, Train Loss: 0.1347, Train MAE: 0.1347,
                            Val Loss: 0.2752, Val MAE: 0.2752
2023-01-26 14:16:24,568:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-26 14:29:12,053:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.48s, LR: 0.00070, Train Loss: 0.1343, Train MAE: 0.1343,
                            Val Loss: 0.2553, Val MAE: 0.2552
2023-01-26 14:29:12,054:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-26 14:41:59,672:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.62s, LR: 0.00070, Train Loss: 0.1328, Train MAE: 0.1328,
                            Val Loss: 0.3793, Val MAE: 0.3794
2023-01-26 14:41:59,674:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-26 14:54:46,132:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.46s, LR: 0.00070, Train Loss: 0.1688, Train MAE: 0.1688,
                            Val Loss: 0.3356, Val MAE: 0.3354
2023-01-26 14:54:46,133:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-26 15:07:33,454:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2045280784368515
2023-01-26 15:07:33,455:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.32s, LR: 0.00070, Train Loss: 0.1761, Train MAE: 0.1761,
                            Val Loss: 0.2047, Val MAE: 0.2045
2023-01-26 15:07:33,456:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-26 15:20:20,336:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.88s, LR: 0.00070, Train Loss: 0.1340, Train MAE: 0.1340,
                            Val Loss: 0.3905, Val MAE: 0.3905
2023-01-26 15:20:20,337:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-26 15:33:06,735:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1691490262746811
2023-01-26 15:33:06,736:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.40s, LR: 0.00070, Train Loss: 0.1319, Train MAE: 0.1319,
                            Val Loss: 0.1693, Val MAE: 0.1691
2023-01-26 15:33:06,736:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-26 15:46:48,908:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 822.17s, LR: 0.00070, Train Loss: 0.1307, Train MAE: 0.1307,
                            Val Loss: 0.3460, Val MAE: 0.3460
2023-01-26 15:46:48,909:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-26 15:59:35,733:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.82s, LR: 0.00070, Train Loss: 0.1294, Train MAE: 0.1294,
                            Val Loss: 0.3900, Val MAE: 0.3900
2023-01-26 15:59:35,734:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-26 16:12:22,432:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.70s, LR: 0.00070, Train Loss: 0.1286, Train MAE: 0.1286,
                            Val Loss: 0.4345, Val MAE: 0.4346
2023-01-26 16:12:22,433:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-26 16:25:10,362:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.93s, LR: 0.00070, Train Loss: 0.1278, Train MAE: 0.1278,
                            Val Loss: 0.3690, Val MAE: 0.3689
2023-01-26 16:25:10,363:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-26 16:37:57,134:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.77s, LR: 0.00070, Train Loss: 0.1270, Train MAE: 0.1270,
                            Val Loss: 0.2033, Val MAE: 0.2031
2023-01-26 16:37:57,135:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-26 16:50:43,394:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1534687727689743
2023-01-26 16:50:43,396:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.26s, LR: 0.00070, Train Loss: 0.1375, Train MAE: 0.1375,
                            Val Loss: 0.1537, Val MAE: 0.1535
2023-01-26 16:50:43,396:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-26 17:03:30,918:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.52s, LR: 0.00070, Train Loss: 0.1257, Train MAE: 0.1257,
                            Val Loss: 0.2907, Val MAE: 0.2907
2023-01-26 17:03:30,918:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-26 17:16:17,429:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.51s, LR: 0.00070, Train Loss: 0.1253, Train MAE: 0.1253,
                            Val Loss: 0.4356, Val MAE: 0.4358
2023-01-26 17:16:17,429:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-26 17:29:03,238:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.81s, LR: 0.00070, Train Loss: 0.1246, Train MAE: 0.1246,
                            Val Loss: 0.2976, Val MAE: 0.2975
2023-01-26 17:29:03,239:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-26 17:41:50,044:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.80s, LR: 0.00070, Train Loss: 0.1242, Train MAE: 0.1242,
                            Val Loss: 0.4458, Val MAE: 0.4459
2023-01-26 17:41:50,044:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-26 17:54:36,760:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.72s, LR: 0.00070, Train Loss: 0.1231, Train MAE: 0.1231,
                            Val Loss: 0.3028, Val MAE: 0.3028
2023-01-26 17:54:36,761:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-26 18:07:22,916:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.15s, LR: 0.00070, Train Loss: 0.1233, Train MAE: 0.1233,
                            Val Loss: 0.1625, Val MAE: 0.1623
2023-01-26 18:07:22,917:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-26 18:20:10,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.68s, LR: 0.00070, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.3363, Val MAE: 0.3362
2023-01-26 18:20:10,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-26 18:32:57,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.71s, LR: 0.00070, Train Loss: 0.1211, Train MAE: 0.1211,
                            Val Loss: 0.3841, Val MAE: 0.3841
2023-01-26 18:32:57,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-26 18:45:43,991:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.68s, LR: 0.00070, Train Loss: 0.1211, Train MAE: 0.1211,
                            Val Loss: 0.3746, Val MAE: 0.3747
2023-01-26 18:45:43,992:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-26 18:58:31,317:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.32s, LR: 0.00070, Train Loss: 0.1207, Train MAE: 0.1207,
                            Val Loss: 0.2219, Val MAE: 0.2218
2023-01-26 18:58:31,318:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-26 19:11:17,602:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1463548243045807
2023-01-26 19:11:17,604:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.29s, LR: 0.00070, Train Loss: 0.1205, Train MAE: 0.1205,
                            Val Loss: 0.1465, Val MAE: 0.1464
2023-01-26 19:11:17,604:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-26 19:24:58,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 820.51s, LR: 0.00070, Train Loss: 0.1195, Train MAE: 0.1195,
                            Val Loss: 0.2027, Val MAE: 0.2026
2023-01-26 19:24:58,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-26 19:37:45,064:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.94s, LR: 0.00070, Train Loss: 0.1198, Train MAE: 0.1198,
                            Val Loss: 0.1685, Val MAE: 0.1683
2023-01-26 19:37:45,064:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-26 19:50:31,145:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.08s, LR: 0.00070, Train Loss: 0.1184, Train MAE: 0.1184,
                            Val Loss: 0.2407, Val MAE: 0.2406
2023-01-26 19:50:31,146:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-26 20:03:17,502:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.36s, LR: 0.00070, Train Loss: 0.1180, Train MAE: 0.1180,
                            Val Loss: 0.4488, Val MAE: 0.4489
2023-01-26 20:03:17,503:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-26 20:16:05,268:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.76s, LR: 0.00070, Train Loss: 0.1182, Train MAE: 0.1182,
                            Val Loss: 0.4717, Val MAE: 0.4719
2023-01-26 20:16:05,269:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-26 20:28:52,084:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.81s, LR: 0.00070, Train Loss: 0.1175, Train MAE: 0.1175,
                            Val Loss: 0.2208, Val MAE: 0.2207
2023-01-26 20:28:52,084:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-26 20:41:38,026:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.94s, LR: 0.00070, Train Loss: 0.1174, Train MAE: 0.1174,
                            Val Loss: 0.3296, Val MAE: 0.3296
2023-01-26 20:41:38,027:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-26 20:54:25,333:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.31s, LR: 0.00070, Train Loss: 0.1168, Train MAE: 0.1168,
                            Val Loss: 0.3967, Val MAE: 0.3968
2023-01-26 20:54:25,334:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-26 21:07:11,527:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.19s, LR: 0.00070, Train Loss: 0.1164, Train MAE: 0.1164,
                            Val Loss: 0.2722, Val MAE: 0.2721
2023-01-26 21:07:11,528:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-26 21:19:57,507:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.98s, LR: 0.00070, Train Loss: 0.1162, Train MAE: 0.1162,
                            Val Loss: 0.2980, Val MAE: 0.2979
2023-01-26 21:19:57,507:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-26 21:32:44,179:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.67s, LR: 0.00070, Train Loss: 0.1160, Train MAE: 0.1160,
                            Val Loss: 0.3433, Val MAE: 0.3433
2023-01-26 21:32:44,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-26 21:45:30,424:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.24s, LR: 0.00070, Train Loss: 0.1154, Train MAE: 0.1154,
                            Val Loss: 0.3552, Val MAE: 0.3553
2023-01-26 21:45:30,425:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-26 21:58:16,831:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.41s, LR: 0.00070, Train Loss: 0.1153, Train MAE: 0.1153,
                            Val Loss: 0.4938, Val MAE: 0.4940
2023-01-26 21:58:16,832:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-26 22:11:03,553:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.72s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.3701, Val MAE: 0.3701
2023-01-26 22:11:03,554:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-26 22:23:49,636:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.08s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1593, Val MAE: 0.1591
2023-01-26 22:23:49,637:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-26 22:36:35,051:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.41s, LR: 0.00070, Train Loss: 0.1143, Train MAE: 0.1143,
                            Val Loss: 0.3162, Val MAE: 0.3162
2023-01-26 22:36:35,052:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-26 22:49:21,127:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.07s, LR: 0.00035, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.1590, Val MAE: 0.1589
2023-01-26 22:49:21,127:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-26 23:03:02,876:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 821.75s, LR: 0.00035, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.4673, Val MAE: 0.4674
2023-01-26 23:03:02,877:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-26 23:15:48,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.51s, LR: 0.00035, Train Loss: 0.1059, Train MAE: 0.1059,
                            Val Loss: 0.3204, Val MAE: 0.3204
2023-01-26 23:15:48,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-26 23:28:34,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.95s, LR: 0.00035, Train Loss: 0.1054, Train MAE: 0.1054,
                            Val Loss: 0.3827, Val MAE: 0.3827
2023-01-26 23:28:34,337:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-26 23:41:20,653:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.32s, LR: 0.00035, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.3324, Val MAE: 0.3324
2023-01-26 23:41:20,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-26 23:54:06,669:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.01s, LR: 0.00035, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.3301, Val MAE: 0.3302
2023-01-26 23:54:06,670:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-27 00:06:52,452:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.78s, LR: 0.00035, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.4376, Val MAE: 0.4377
2023-01-27 00:06:52,453:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-27 00:19:38,259:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.81s, LR: 0.00035, Train Loss: 0.1045, Train MAE: 0.1045,
                            Val Loss: 0.2984, Val MAE: 0.2984
2023-01-27 00:19:38,260:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-27 00:32:23,832:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.57s, LR: 0.00035, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.3619, Val MAE: 0.3620
2023-01-27 00:32:23,833:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-27 00:45:09,173:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.34s, LR: 0.00035, Train Loss: 0.1040, Train MAE: 0.1040,
                            Val Loss: 0.4206, Val MAE: 0.4207
2023-01-27 00:45:09,174:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-27 00:57:55,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.12s, LR: 0.00035, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.2157, Val MAE: 0.2156
2023-01-27 00:57:55,293:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-27 01:10:40,964:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.67s, LR: 0.00035, Train Loss: 0.1038, Train MAE: 0.1038,
                            Val Loss: 0.1923, Val MAE: 0.1922
2023-01-27 01:10:40,966:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-27 01:23:26,892:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.93s, LR: 0.00035, Train Loss: 0.1037, Train MAE: 0.1037,
                            Val Loss: 0.2524, Val MAE: 0.2524
2023-01-27 01:23:26,893:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-27 01:36:13,330:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.44s, LR: 0.00035, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.3763, Val MAE: 0.3763
2023-01-27 01:36:13,331:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-27 01:48:58,383:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.05s, LR: 0.00035, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.2621, Val MAE: 0.2620
2023-01-27 01:48:58,384:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-27 02:01:43,603:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.22s, LR: 0.00035, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1973, Val MAE: 0.1972
2023-01-27 02:01:43,604:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-27 02:14:29,477:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14010249078273773
2023-01-27 02:14:29,479:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.87s, LR: 0.00017, Train Loss: 0.0993, Train MAE: 0.0993,
                            Val Loss: 0.1403, Val MAE: 0.1401
2023-01-27 02:14:29,479:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-27 02:27:14,718:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13382655382156372
2023-01-27 02:27:14,720:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.24s, LR: 0.00017, Train Loss: 0.0988, Train MAE: 0.0988,
                            Val Loss: 0.1340, Val MAE: 0.1338
2023-01-27 02:27:14,721:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-27 02:40:55,534:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 820.81s, LR: 0.00017, Train Loss: 0.0986, Train MAE: 0.0986,
                            Val Loss: 0.2183, Val MAE: 0.2182
2023-01-27 02:40:55,535:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-27 02:53:41,425:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.89s, LR: 0.00017, Train Loss: 0.0984, Train MAE: 0.0984,
                            Val Loss: 0.1514, Val MAE: 0.1513
2023-01-27 02:53:41,426:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-27 03:06:26,628:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.20s, LR: 0.00017, Train Loss: 0.0983, Train MAE: 0.0983,
                            Val Loss: 0.3943, Val MAE: 0.3944
2023-01-27 03:06:26,629:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-27 03:19:11,805:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.18s, LR: 0.00017, Train Loss: 0.0981, Train MAE: 0.0981,
                            Val Loss: 0.2337, Val MAE: 0.2336
2023-01-27 03:19:11,806:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-27 03:31:57,327:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.52s, LR: 0.00017, Train Loss: 0.0980, Train MAE: 0.0980,
                            Val Loss: 0.2310, Val MAE: 0.2309
2023-01-27 03:31:57,328:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-27 03:44:42,656:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.33s, LR: 0.00017, Train Loss: 0.0979, Train MAE: 0.0979,
                            Val Loss: 0.2579, Val MAE: 0.2578
2023-01-27 03:44:42,656:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-27 03:57:28,083:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.131454735994339
2023-01-27 03:57:28,084:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.43s, LR: 0.00017, Train Loss: 0.0978, Train MAE: 0.0978,
                            Val Loss: 0.1316, Val MAE: 0.1315
2023-01-27 03:57:28,085:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-27 04:10:13,657:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12741945683956146
2023-01-27 04:10:13,659:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.57s, LR: 0.00017, Train Loss: 0.0977, Train MAE: 0.0977,
                            Val Loss: 0.1276, Val MAE: 0.1274
2023-01-27 04:10:13,660:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-27 04:22:59,187:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.53s, LR: 0.00017, Train Loss: 0.0975, Train MAE: 0.0975,
                            Val Loss: 0.2268, Val MAE: 0.2267
2023-01-27 04:22:59,188:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-27 04:35:44,744:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.55s, LR: 0.00017, Train Loss: 0.0974, Train MAE: 0.0974,
                            Val Loss: 0.2703, Val MAE: 0.2703
2023-01-27 04:35:44,745:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-27 04:48:30,627:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.88s, LR: 0.00017, Train Loss: 0.0973, Train MAE: 0.0973,
                            Val Loss: 0.2199, Val MAE: 0.2198
2023-01-27 04:48:30,628:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-27 05:01:16,738:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.11s, LR: 0.00017, Train Loss: 0.0973, Train MAE: 0.0973,
                            Val Loss: 0.2940, Val MAE: 0.2939
2023-01-27 05:01:16,738:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-27 05:14:01,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.86s, LR: 0.00017, Train Loss: 0.0971, Train MAE: 0.0971,
                            Val Loss: 0.1869, Val MAE: 0.1868
2023-01-27 05:14:01,600:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-27 05:26:46,646:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.05s, LR: 0.00017, Train Loss: 0.0971, Train MAE: 0.0971,
                            Val Loss: 0.1490, Val MAE: 0.1488
2023-01-27 05:26:46,647:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-27 05:39:31,287:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.64s, LR: 0.00017, Train Loss: 0.0970, Train MAE: 0.0970,
                            Val Loss: 0.1387, Val MAE: 0.1385
2023-01-27 05:39:31,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-27 05:52:15,979:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.69s, LR: 0.00017, Train Loss: 0.0969, Train MAE: 0.0969,
                            Val Loss: 0.1826, Val MAE: 0.1825
2023-01-27 05:52:15,980:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-27 05:52:15,980:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-27 06:01:16,339:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1825
2023-01-27 06:01:16,340:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.1590
2023-01-27 06:01:16,341:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-27 06:01:16,342:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 106.0000
2023-01-27 06:01:16,342:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87113.8236s
2023-01-27 06:01:16,343:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 771.2401s
2023-01-27 06:01:16,344:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-27 06:01:16,460:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.1590)]
2023-01-27 06:01:16,460:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1825)]
