2023-01-26 05:40:01,241:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-26 05:40:01,241:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-26 05:54:48,274:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-26 05:55:34,919:ogbdata.py:332 -             __init__(): Time taken: 933.6781s
2023-01-26 05:55:34,919:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-26 05:55:34,919:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-26 05:55:34,919:ogbdata.py:348 -             __init__(): [I] Data load time: 933.6786s
2023-01-26 05:55:34,920:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-26 05:55:34,920:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-26 05:55:34,922:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:55:42,581:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:55:42,582:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:55:42,582:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:55:42,599:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-26 05:55:42,602:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-26 05:55:42,602:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-26 05:55:42,603:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:55:42,604:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:55:42,605:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:55:42,605:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:55:42,627:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-26 07:17:59,337:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4936.7337901592255
2023-01-26 07:17:59,378:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-26 07:17:59,378:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-26 07:17:59,548:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-26 07:32:22,867:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 6.3127241134643555
2023-01-26 07:32:22,887:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 863.34s, LR: 0.00070, Train Loss: 0.6028, Train MAE: 0.6028,
                            Val Loss: 6.3144, Val MAE: 6.3127
2023-01-26 07:32:22,887:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-26 07:43:58,462:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.843798041343689
2023-01-26 07:43:58,480:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.59s, LR: 0.00070, Train Loss: 0.4994, Train MAE: 0.4994,
                            Val Loss: 0.8440, Val MAE: 0.8438
2023-01-26 07:43:58,481:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-26 07:55:45,988:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.51s, LR: 0.00070, Train Loss: 0.4641, Train MAE: 0.4641,
                            Val Loss: 1.6604, Val MAE: 1.6600
2023-01-26 07:55:45,990:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-26 08:07:41,715:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.72s, LR: 0.00070, Train Loss: 0.4898, Train MAE: 0.4898,
                            Val Loss: 1.5206, Val MAE: 1.5207
2023-01-26 08:07:41,717:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-26 08:19:31,339:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.62s, LR: 0.00070, Train Loss: 0.4367, Train MAE: 0.4367,
                            Val Loss: 1.1671, Val MAE: 1.1667
2023-01-26 08:19:31,340:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-26 08:31:20,419:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.08s, LR: 0.00070, Train Loss: 0.5249, Train MAE: 0.5249,
                            Val Loss: 2.3830, Val MAE: 2.3828
2023-01-26 08:31:20,421:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-26 08:42:57,163:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.74s, LR: 0.00070, Train Loss: 0.4338, Train MAE: 0.4338,
                            Val Loss: 3.2261, Val MAE: 3.2251
2023-01-26 08:42:57,165:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-26 08:55:37,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.13s, LR: 0.00070, Train Loss: 0.4218, Train MAE: 0.4218,
                            Val Loss: 1.1799, Val MAE: 1.1796
2023-01-26 08:55:37,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-26 09:07:28,250:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.95s, LR: 0.00070, Train Loss: 0.3959, Train MAE: 0.3959,
                            Val Loss: 1.2335, Val MAE: 1.2333
2023-01-26 09:07:28,252:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-26 09:19:19,246:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.99s, LR: 0.00070, Train Loss: 0.4092, Train MAE: 0.4092,
                            Val Loss: 1.1187, Val MAE: 1.1189
2023-01-26 09:19:19,247:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-26 09:30:59,764:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.52s, LR: 0.00070, Train Loss: 0.4071, Train MAE: 0.4071,
                            Val Loss: 1.5229, Val MAE: 1.5226
2023-01-26 09:30:59,765:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-26 09:43:04,474:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8420151472091675
2023-01-26 09:43:04,493:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.73s, LR: 0.00070, Train Loss: 0.3861, Train MAE: 0.3861,
                            Val Loss: 0.8422, Val MAE: 0.8420
2023-01-26 09:43:04,494:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-26 09:54:55,197:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.70s, LR: 0.00070, Train Loss: 0.4386, Train MAE: 0.4386,
                            Val Loss: 1.0015, Val MAE: 1.0013
2023-01-26 09:54:55,236:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-26 10:06:37,294:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.6553500890731812
2023-01-26 10:06:37,312:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.08s, LR: 0.00070, Train Loss: 0.4491, Train MAE: 0.4491,
                            Val Loss: 0.6554, Val MAE: 0.6554
2023-01-26 10:06:37,313:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-26 10:18:32,779:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.46s, LR: 0.00070, Train Loss: 0.4381, Train MAE: 0.4381,
                            Val Loss: 1.2868, Val MAE: 1.2865
2023-01-26 10:18:32,794:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-26 10:30:15,336:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.54s, LR: 0.00070, Train Loss: 0.4081, Train MAE: 0.4081,
                            Val Loss: 1.6421, Val MAE: 1.6417
2023-01-26 10:30:15,337:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-26 10:41:36,881:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.54s, LR: 0.00070, Train Loss: 0.4510, Train MAE: 0.4510,
                            Val Loss: 1.5110, Val MAE: 1.5107
2023-01-26 10:41:36,882:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-26 10:53:41,892:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.01s, LR: 0.00070, Train Loss: 0.4429, Train MAE: 0.4429,
                            Val Loss: 1.1270, Val MAE: 1.1267
2023-01-26 10:53:41,893:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-26 11:05:18,690:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.80s, LR: 0.00070, Train Loss: 0.4575, Train MAE: 0.4575,
                            Val Loss: 0.9816, Val MAE: 0.9813
2023-01-26 11:05:18,692:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-26 11:16:24,321:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.63s, LR: 0.00070, Train Loss: 0.5164, Train MAE: 0.5164,
                            Val Loss: 1.3712, Val MAE: 1.3708
2023-01-26 11:16:24,322:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-26 11:28:03,815:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.49s, LR: 0.00070, Train Loss: 0.4849, Train MAE: 0.4849,
                            Val Loss: 1.3093, Val MAE: 1.3091
2023-01-26 11:28:03,847:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-26 11:39:51,499:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.65s, LR: 0.00070, Train Loss: 0.4598, Train MAE: 0.4598,
                            Val Loss: 0.9338, Val MAE: 0.9336
2023-01-26 11:39:51,530:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-26 11:51:47,830:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 716.30s, LR: 0.00070, Train Loss: 0.4648, Train MAE: 0.4648,
                            Val Loss: 0.8799, Val MAE: 0.8797
2023-01-26 11:51:47,855:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-26 12:04:35,960:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.10s, LR: 0.00070, Train Loss: 0.4568, Train MAE: 0.4568,
                            Val Loss: 1.1081, Val MAE: 1.1078
2023-01-26 12:04:35,986:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-26 12:16:13,228:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.24s, LR: 0.00070, Train Loss: 0.4315, Train MAE: 0.4315,
                            Val Loss: 1.1861, Val MAE: 1.1857
2023-01-26 12:16:13,253:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-26 12:27:57,439:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 704.18s, LR: 0.00070, Train Loss: 0.4390, Train MAE: 0.4390,
                            Val Loss: 1.4209, Val MAE: 1.4205
2023-01-26 12:27:57,461:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-26 12:39:35,834:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.37s, LR: 0.00070, Train Loss: 0.4307, Train MAE: 0.4307,
                            Val Loss: 1.3443, Val MAE: 1.3438
2023-01-26 12:39:35,853:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-26 12:51:14,299:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.44s, LR: 0.00070, Train Loss: 0.4136, Train MAE: 0.4136,
                            Val Loss: 1.1145, Val MAE: 1.1141
2023-01-26 12:51:14,301:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-26 13:02:50,868:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.57s, LR: 0.00070, Train Loss: 0.4065, Train MAE: 0.4065,
                            Val Loss: 0.9326, Val MAE: 0.9324
2023-01-26 13:02:50,869:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-26 13:14:30,111:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.24s, LR: 0.00070, Train Loss: 0.4014, Train MAE: 0.4014,
                            Val Loss: 1.8285, Val MAE: 1.8281
2023-01-26 13:14:30,112:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-26 13:26:08,269:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.16s, LR: 0.00035, Train Loss: 0.3851, Train MAE: 0.3851,
                            Val Loss: 0.9812, Val MAE: 0.9813
2023-01-26 13:26:08,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-26 13:37:49,534:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.25s, LR: 0.00035, Train Loss: 0.3800, Train MAE: 0.3800,
                            Val Loss: 0.9306, Val MAE: 0.9302
2023-01-26 13:37:49,555:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-26 13:49:37,936:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5677080154418945
2023-01-26 13:49:37,938:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.38s, LR: 0.00035, Train Loss: 0.3730, Train MAE: 0.3730,
                            Val Loss: 0.5678, Val MAE: 0.5677
2023-01-26 13:49:37,939:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-26 14:01:15,735:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.80s, LR: 0.00035, Train Loss: 0.3649, Train MAE: 0.3649,
                            Val Loss: 1.0573, Val MAE: 1.0573
2023-01-26 14:01:15,737:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-26 14:12:54,809:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.07s, LR: 0.00035, Train Loss: 0.3711, Train MAE: 0.3711,
                            Val Loss: 1.5700, Val MAE: 1.5699
2023-01-26 14:12:54,810:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-26 14:24:26,765:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.95s, LR: 0.00035, Train Loss: 0.3783, Train MAE: 0.3783,
                            Val Loss: 1.0777, Val MAE: 1.0773
2023-01-26 14:24:26,766:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-26 14:36:04,428:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.66s, LR: 0.00035, Train Loss: 0.3718, Train MAE: 0.3718,
                            Val Loss: 1.5565, Val MAE: 1.5561
2023-01-26 14:36:04,429:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-26 14:47:47,923:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.49s, LR: 0.00035, Train Loss: 0.3603, Train MAE: 0.3603,
                            Val Loss: 1.4881, Val MAE: 1.4877
2023-01-26 14:47:47,924:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-26 14:59:22,394:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.47s, LR: 0.00035, Train Loss: 0.3555, Train MAE: 0.3555,
                            Val Loss: 1.1716, Val MAE: 1.1711
2023-01-26 14:59:22,395:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-26 15:11:04,262:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.87s, LR: 0.00035, Train Loss: 0.3547, Train MAE: 0.3547,
                            Val Loss: 0.9199, Val MAE: 0.9199
2023-01-26 15:11:04,263:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-26 15:23:45,574:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.31s, LR: 0.00035, Train Loss: 0.3458, Train MAE: 0.3458,
                            Val Loss: 1.3782, Val MAE: 1.3778
2023-01-26 15:23:45,575:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-26 15:35:21,673:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.10s, LR: 0.00035, Train Loss: 0.3471, Train MAE: 0.3471,
                            Val Loss: 0.8003, Val MAE: 0.8001
2023-01-26 15:35:21,675:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-26 15:47:05,452:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.78s, LR: 0.00035, Train Loss: 0.3424, Train MAE: 0.3424,
                            Val Loss: 0.8862, Val MAE: 0.8860
2023-01-26 15:47:05,453:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-26 15:58:52,974:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.52s, LR: 0.00035, Train Loss: 0.3438, Train MAE: 0.3438,
                            Val Loss: 0.8658, Val MAE: 0.8656
2023-01-26 15:58:52,975:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-26 16:10:52,256:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.28s, LR: 0.00035, Train Loss: 0.3412, Train MAE: 0.3412,
                            Val Loss: 1.3202, Val MAE: 1.3198
2023-01-26 16:10:52,257:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-26 16:22:43,034:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.78s, LR: 0.00035, Train Loss: 0.3348, Train MAE: 0.3348,
                            Val Loss: 1.6773, Val MAE: 1.6769
2023-01-26 16:22:43,035:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-26 16:34:18,479:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.44s, LR: 0.00035, Train Loss: 0.3302, Train MAE: 0.3302,
                            Val Loss: 1.1890, Val MAE: 1.1886
2023-01-26 16:34:18,480:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-26 16:45:58,623:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.14s, LR: 0.00035, Train Loss: 0.3306, Train MAE: 0.3306,
                            Val Loss: 2.8217, Val MAE: 2.8210
2023-01-26 16:45:58,625:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-26 16:57:36,882:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.46811461448669434
2023-01-26 16:57:36,884:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.26s, LR: 0.00035, Train Loss: 0.3334, Train MAE: 0.3334,
                            Val Loss: 0.4682, Val MAE: 0.4681
2023-01-26 16:57:36,885:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-26 17:09:10,156:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.27s, LR: 0.00035, Train Loss: 0.3289, Train MAE: 0.3289,
                            Val Loss: 1.1384, Val MAE: 1.1382
2023-01-26 17:09:10,157:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-26 17:20:47,387:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.23s, LR: 0.00035, Train Loss: 0.3271, Train MAE: 0.3271,
                            Val Loss: 0.6578, Val MAE: 0.6575
2023-01-26 17:20:47,389:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-26 17:32:26,081:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.45591241121292114
2023-01-26 17:32:26,083:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.69s, LR: 0.00035, Train Loss: 0.3241, Train MAE: 0.3241,
                            Val Loss: 0.4560, Val MAE: 0.4559
2023-01-26 17:32:26,084:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-26 17:44:13,918:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.83s, LR: 0.00035, Train Loss: 0.3185, Train MAE: 0.3185,
                            Val Loss: 0.5595, Val MAE: 0.5593
2023-01-26 17:44:13,919:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-26 17:56:03,200:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.28s, LR: 0.00035, Train Loss: 0.3189, Train MAE: 0.3189,
                            Val Loss: 0.7103, Val MAE: 0.7099
2023-01-26 17:56:03,201:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-26 18:07:36,933:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.73s, LR: 0.00035, Train Loss: 0.3229, Train MAE: 0.3229,
                            Val Loss: 0.8251, Val MAE: 0.8250
2023-01-26 18:07:36,944:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-26 18:19:27,726:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 710.78s, LR: 0.00035, Train Loss: 0.3218, Train MAE: 0.3218,
                            Val Loss: 0.9660, Val MAE: 0.9659
2023-01-26 18:19:27,727:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-26 18:31:00,160:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.43s, LR: 0.00035, Train Loss: 0.3136, Train MAE: 0.3136,
                            Val Loss: 0.8687, Val MAE: 0.8682
2023-01-26 18:31:00,162:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-26 18:43:32,484:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 752.32s, LR: 0.00035, Train Loss: 0.3179, Train MAE: 0.3179,
                            Val Loss: 1.5751, Val MAE: 1.5747
2023-01-26 18:43:32,485:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-26 18:55:08,187:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.70s, LR: 0.00035, Train Loss: 0.3155, Train MAE: 0.3155,
                            Val Loss: 1.0420, Val MAE: 1.0415
2023-01-26 18:55:08,188:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-26 19:06:47,989:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.80s, LR: 0.00035, Train Loss: 0.3084, Train MAE: 0.3084,
                            Val Loss: 1.2548, Val MAE: 1.2547
2023-01-26 19:06:47,991:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-26 19:18:33,721:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.73s, LR: 0.00035, Train Loss: 0.3063, Train MAE: 0.3063,
                            Val Loss: 1.0942, Val MAE: 1.0938
2023-01-26 19:18:33,752:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-26 19:30:05,648:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.89s, LR: 0.00035, Train Loss: 0.3054, Train MAE: 0.3054,
                            Val Loss: 1.1052, Val MAE: 1.1048
2023-01-26 19:30:05,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-26 19:41:45,501:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 699.85s, LR: 0.00035, Train Loss: 0.3032, Train MAE: 0.3032,
                            Val Loss: 2.9127, Val MAE: 2.9117
2023-01-26 19:41:45,511:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-26 19:53:23,985:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.47s, LR: 0.00035, Train Loss: 0.3011, Train MAE: 0.3011,
                            Val Loss: 1.7497, Val MAE: 1.7494
2023-01-26 19:53:23,987:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-26 20:04:59,956:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.97s, LR: 0.00035, Train Loss: 0.3024, Train MAE: 0.3024,
                            Val Loss: 0.6390, Val MAE: 0.6391
2023-01-26 20:04:59,978:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-26 20:16:27,615:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.64s, LR: 0.00035, Train Loss: 0.3020, Train MAE: 0.3020,
                            Val Loss: 1.7552, Val MAE: 1.7545
2023-01-26 20:16:27,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-26 20:27:57,532:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.88s, LR: 0.00035, Train Loss: 0.3043, Train MAE: 0.3043,
                            Val Loss: 1.6509, Val MAE: 1.6505
2023-01-26 20:27:57,555:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-26 20:39:21,625:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.07s, LR: 0.00035, Train Loss: 0.3038, Train MAE: 0.3038,
                            Val Loss: 1.2688, Val MAE: 1.2685
2023-01-26 20:39:21,681:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-26 20:50:46,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.94s, LR: 0.00017, Train Loss: 0.2933, Train MAE: 0.2933,
                            Val Loss: 1.0372, Val MAE: 1.0370
2023-01-26 20:50:46,632:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-26 21:02:13,228:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 686.60s, LR: 0.00017, Train Loss: 0.2932, Train MAE: 0.2932,
                            Val Loss: 0.6403, Val MAE: 0.6400
2023-01-26 21:02:13,241:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-26 21:13:41,294:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.05s, LR: 0.00017, Train Loss: 0.2907, Train MAE: 0.2907,
                            Val Loss: 0.5462, Val MAE: 0.5461
2023-01-26 21:13:41,308:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-26 21:25:13,896:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.59s, LR: 0.00017, Train Loss: 0.2890, Train MAE: 0.2890,
                            Val Loss: 0.4588, Val MAE: 0.4588
2023-01-26 21:25:13,925:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-26 21:36:45,146:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.22s, LR: 0.00017, Train Loss: 0.2880, Train MAE: 0.2880,
                            Val Loss: 0.4709, Val MAE: 0.4707
2023-01-26 21:36:45,147:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-26 21:48:17,806:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.66s, LR: 0.00017, Train Loss: 0.2876, Train MAE: 0.2876,
                            Val Loss: 0.6419, Val MAE: 0.6419
2023-01-26 21:48:17,807:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-26 22:00:39,338:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 741.53s, LR: 0.00017, Train Loss: 0.2870, Train MAE: 0.2870,
                            Val Loss: 1.0321, Val MAE: 1.0320
2023-01-26 22:00:39,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-26 22:12:20,880:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.54s, LR: 0.00017, Train Loss: 0.2883, Train MAE: 0.2883,
                            Val Loss: 0.5901, Val MAE: 0.5902
2023-01-26 22:12:20,881:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-26 22:23:19,287:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.41s, LR: 0.00017, Train Loss: 0.2878, Train MAE: 0.2878,
                            Val Loss: 0.7083, Val MAE: 0.7079
2023-01-26 22:23:19,289:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-26 22:34:17,837:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.55s, LR: 0.00017, Train Loss: 0.2861, Train MAE: 0.2861,
                            Val Loss: 1.1200, Val MAE: 1.1196
2023-01-26 22:34:17,838:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-26 22:45:13,624:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.78s, LR: 0.00017, Train Loss: 0.2850, Train MAE: 0.2850,
                            Val Loss: 0.8595, Val MAE: 0.8593
2023-01-26 22:45:13,626:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-26 22:56:08,158:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.53s, LR: 0.00017, Train Loss: 0.2843, Train MAE: 0.2843,
                            Val Loss: 1.0008, Val MAE: 1.0008
2023-01-26 22:56:08,159:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-26 23:07:12,140:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.98s, LR: 0.00017, Train Loss: 0.2830, Train MAE: 0.2830,
                            Val Loss: 0.9746, Val MAE: 0.9746
2023-01-26 23:07:12,142:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-26 23:18:18,481:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.34s, LR: 0.00017, Train Loss: 0.2835, Train MAE: 0.2835,
                            Val Loss: 0.5201, Val MAE: 0.5201
2023-01-26 23:18:18,483:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-26 23:29:22,555:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.07s, LR: 0.00017, Train Loss: 0.2831, Train MAE: 0.2831,
                            Val Loss: 0.5276, Val MAE: 0.5274
2023-01-26 23:29:22,555:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-26 23:40:26,366:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.81s, LR: 0.00017, Train Loss: 0.2835, Train MAE: 0.2835,
                            Val Loss: 0.8208, Val MAE: 0.8209
2023-01-26 23:40:26,367:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-26 23:51:26,396:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.03s, LR: 0.00009, Train Loss: 0.2801, Train MAE: 0.2801,
                            Val Loss: 0.8055, Val MAE: 0.8055
2023-01-26 23:51:26,397:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-27 00:02:23,710:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4082436263561249
2023-01-27 00:02:23,713:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.31s, LR: 0.00009, Train Loss: 0.2786, Train MAE: 0.2786,
                            Val Loss: 0.4083, Val MAE: 0.4082
2023-01-27 00:02:23,714:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-27 00:13:25,873:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.16s, LR: 0.00009, Train Loss: 0.2779, Train MAE: 0.2779,
                            Val Loss: 0.8869, Val MAE: 0.8866
2023-01-27 00:13:25,902:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-27 00:24:26,858:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.95s, LR: 0.00009, Train Loss: 0.2777, Train MAE: 0.2777,
                            Val Loss: 0.4827, Val MAE: 0.4826
2023-01-27 00:24:26,862:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-27 00:35:35,594:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.73s, LR: 0.00009, Train Loss: 0.2767, Train MAE: 0.2767,
                            Val Loss: 0.9207, Val MAE: 0.9204
2023-01-27 00:35:35,605:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-27 00:46:36,002:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.40s, LR: 0.00009, Train Loss: 0.2754, Train MAE: 0.2754,
                            Val Loss: 1.0370, Val MAE: 1.0370
2023-01-27 00:46:36,003:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-27 00:57:48,370:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.37s, LR: 0.00009, Train Loss: 0.2748, Train MAE: 0.2748,
                            Val Loss: 0.7392, Val MAE: 0.7389
2023-01-27 00:57:48,371:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-27 01:10:20,607:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 752.23s, LR: 0.00009, Train Loss: 0.2737, Train MAE: 0.2737,
                            Val Loss: 0.6815, Val MAE: 0.6816
2023-01-27 01:10:20,608:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-27 01:21:25,218:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.61s, LR: 0.00009, Train Loss: 0.2732, Train MAE: 0.2732,
                            Val Loss: 0.5757, Val MAE: 0.5758
2023-01-27 01:21:25,219:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-27 01:32:31,319:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.10s, LR: 0.00009, Train Loss: 0.2742, Train MAE: 0.2742,
                            Val Loss: 0.5510, Val MAE: 0.5510
2023-01-27 01:32:31,320:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-27 01:43:39,121:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.80s, LR: 0.00009, Train Loss: 0.2739, Train MAE: 0.2739,
                            Val Loss: 0.4643, Val MAE: 0.4641
2023-01-27 01:43:39,123:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-27 01:54:49,064:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.94s, LR: 0.00009, Train Loss: 0.2735, Train MAE: 0.2735,
                            Val Loss: 0.6579, Val MAE: 0.6580
2023-01-27 01:54:49,065:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-27 02:05:52,365:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.30s, LR: 0.00009, Train Loss: 0.2733, Train MAE: 0.2733,
                            Val Loss: 0.6289, Val MAE: 0.6290
2023-01-27 02:05:52,366:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-27 02:16:57,397:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.03s, LR: 0.00009, Train Loss: 0.2728, Train MAE: 0.2728,
                            Val Loss: 0.7380, Val MAE: 0.7377
2023-01-27 02:16:57,398:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-27 02:28:37,993:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.37866348028182983
2023-01-27 02:28:37,995:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.60s, LR: 0.00009, Train Loss: 0.2723, Train MAE: 0.2723,
                            Val Loss: 0.3787, Val MAE: 0.3787
2023-01-27 02:28:37,996:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-27 02:40:45,530:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.53s, LR: 0.00009, Train Loss: 0.2715, Train MAE: 0.2715,
                            Val Loss: 0.6591, Val MAE: 0.6592
2023-01-27 02:40:45,531:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-27 02:52:04,803:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.27s, LR: 0.00009, Train Loss: 0.2720, Train MAE: 0.2720,
                            Val Loss: 0.7362, Val MAE: 0.7360
2023-01-27 02:52:04,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-27 03:03:54,713:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.91s, LR: 0.00009, Train Loss: 0.2716, Train MAE: 0.2716,
                            Val Loss: 0.4920, Val MAE: 0.4919
2023-01-27 03:03:54,714:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-27 03:15:32,309:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.59s, LR: 0.00009, Train Loss: 0.2704, Train MAE: 0.2704,
                            Val Loss: 1.3766, Val MAE: 1.3762
2023-01-27 03:15:32,309:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-27 03:27:40,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.29s, LR: 0.00009, Train Loss: 0.2700, Train MAE: 0.2700,
                            Val Loss: 0.6017, Val MAE: 0.6015
2023-01-27 03:27:40,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-27 03:39:21,939:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.34s, LR: 0.00009, Train Loss: 0.2719, Train MAE: 0.2719,
                            Val Loss: 0.7508, Val MAE: 0.7506
2023-01-27 03:39:21,940:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-27 03:50:17,235:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.29s, LR: 0.00009, Train Loss: 0.2727, Train MAE: 0.2727,
                            Val Loss: 0.8090, Val MAE: 0.8088
2023-01-27 03:50:17,237:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-27 04:01:14,203:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.97s, LR: 0.00009, Train Loss: 0.2710, Train MAE: 0.2710,
                            Val Loss: 0.5464, Val MAE: 0.5465
2023-01-27 04:01:14,204:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-27 04:12:11,370:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.34186363220214844
2023-01-27 04:12:11,373:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.17s, LR: 0.00009, Train Loss: 0.2699, Train MAE: 0.2699,
                            Val Loss: 0.3419, Val MAE: 0.3419
2023-01-27 04:12:11,374:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-27 04:24:00,204:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.32395803928375244
2023-01-27 04:24:00,206:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.83s, LR: 0.00009, Train Loss: 0.2698, Train MAE: 0.2698,
                            Val Loss: 0.3240, Val MAE: 0.3240
2023-01-27 04:24:00,207:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-27 04:34:56,985:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.78s, LR: 0.00009, Train Loss: 0.2699, Train MAE: 0.2699,
                            Val Loss: 0.7440, Val MAE: 0.7439
2023-01-27 04:34:56,986:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-27 04:45:59,885:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.90s, LR: 0.00009, Train Loss: 0.2692, Train MAE: 0.2692,
                            Val Loss: 0.7692, Val MAE: 0.7692
2023-01-27 04:45:59,887:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-27 04:57:59,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.43s, LR: 0.00009, Train Loss: 0.2692, Train MAE: 0.2692,
                            Val Loss: 0.4522, Val MAE: 0.4520
2023-01-27 04:57:59,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-27 05:10:06,004:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.69s, LR: 0.00009, Train Loss: 0.2678, Train MAE: 0.2678,
                            Val Loss: 0.4729, Val MAE: 0.4729
2023-01-27 05:10:06,005:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-27 05:22:07,274:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 721.27s, LR: 0.00009, Train Loss: 0.2676, Train MAE: 0.2676,
                            Val Loss: 0.5745, Val MAE: 0.5746
2023-01-27 05:22:07,275:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-27 05:33:11,892:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.61s, LR: 0.00009, Train Loss: 0.2666, Train MAE: 0.2666,
                            Val Loss: 0.6463, Val MAE: 0.6463
2023-01-27 05:33:11,893:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-27 05:44:34,537:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 682.64s, LR: 0.00009, Train Loss: 0.2708, Train MAE: 0.2708,
                            Val Loss: 0.5078, Val MAE: 0.5078
2023-01-27 05:44:34,538:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-27 05:56:17,069:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.53s, LR: 0.00009, Train Loss: 0.2686, Train MAE: 0.2686,
                            Val Loss: 1.1107, Val MAE: 1.1104
2023-01-27 05:56:17,070:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-27 05:56:17,071:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-27 06:04:07,723:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 1.1104
2023-01-27 06:04:07,744:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 1.1224
2023-01-27 06:04:07,765:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-27 06:04:07,767:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 116.0000
2023-01-27 06:04:07,768:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 86905.1651s
2023-01-27 06:04:07,783:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 696.5593s
2023-01-27 06:04:07,833:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-27 06:04:08,307:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(1.1224)]
2023-01-27 06:04:08,308:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(1.1104)]
