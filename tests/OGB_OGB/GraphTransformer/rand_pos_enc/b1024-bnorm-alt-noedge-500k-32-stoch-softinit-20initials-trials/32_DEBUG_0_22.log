2023-01-26 05:38:41,311:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-26 05:38:41,311:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-26 05:49:53,026:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-26 05:50:25,796:ogbdata.py:332 -             __init__(): Time taken: 704.4847s
2023-01-26 05:50:25,796:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-26 05:50:25,796:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-26 05:50:25,796:ogbdata.py:348 -             __init__(): [I] Data load time: 704.4850s
2023-01-26 05:50:25,796:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials/32_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-26 05:50:25,797:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-26 05:50:25,801:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:50:27,192:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:50:27,192:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:50:27,192:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:50:27,208:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-26 05:50:27,210:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-26 05:50:27,211:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-26 05:50:27,211:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:50:27,213:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:50:27,213:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:50:27,213:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:50:27,234:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-26 07:02:11,996:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4304.7851486206055
2023-01-26 07:02:12,003:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-26 07:02:12,003:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-26 07:02:12,007:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-26 07:15:15,108:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.6645864248275757
2023-01-26 07:15:15,110:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.10s, LR: 0.00070, Train Loss: 0.5652, Train MAE: 0.5652,
                            Val Loss: 0.6647, Val MAE: 0.6646
2023-01-26 07:15:15,110:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-26 07:26:04,545:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5741743445396423
2023-01-26 07:26:04,547:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.44s, LR: 0.00070, Train Loss: 0.3878, Train MAE: 0.3878,
                            Val Loss: 0.5745, Val MAE: 0.5742
2023-01-26 07:26:04,548:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-26 07:36:52,696:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.4932229518890381
2023-01-26 07:36:52,699:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.15s, LR: 0.00070, Train Loss: 0.3332, Train MAE: 0.3332,
                            Val Loss: 0.4937, Val MAE: 0.4932
2023-01-26 07:36:52,699:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-26 07:47:40,393:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 647.69s, LR: 0.00070, Train Loss: 0.4214, Train MAE: 0.4214,
                            Val Loss: 0.6925, Val MAE: 0.6922
2023-01-26 07:47:40,395:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-26 07:58:29,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.32s, LR: 0.00070, Train Loss: 0.3575, Train MAE: 0.3575,
                            Val Loss: 0.5455, Val MAE: 0.5452
2023-01-26 07:58:29,716:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-26 08:09:18,164:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.45s, LR: 0.00070, Train Loss: 0.3204, Train MAE: 0.3204,
                            Val Loss: 0.6764, Val MAE: 0.6762
2023-01-26 08:09:18,165:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-26 08:20:06,256:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.09s, LR: 0.00070, Train Loss: 0.3016, Train MAE: 0.3016,
                            Val Loss: 0.7158, Val MAE: 0.7154
2023-01-26 08:20:06,257:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-26 08:31:49,035:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.41692325472831726
2023-01-26 08:31:49,037:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 702.78s, LR: 0.00070, Train Loss: 0.2813, Train MAE: 0.2813,
                            Val Loss: 0.4171, Val MAE: 0.4169
2023-01-26 08:31:49,038:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-26 08:42:38,265:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3917049765586853
2023-01-26 08:42:38,267:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.23s, LR: 0.00070, Train Loss: 0.2857, Train MAE: 0.2857,
                            Val Loss: 0.3921, Val MAE: 0.3917
2023-01-26 08:42:38,268:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-26 08:53:24,301:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.33916175365448
2023-01-26 08:53:24,303:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 646.03s, LR: 0.00070, Train Loss: 0.2814, Train MAE: 0.2814,
                            Val Loss: 0.3394, Val MAE: 0.3392
2023-01-26 08:53:24,304:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-26 09:04:08,505:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.20s, LR: 0.00070, Train Loss: 0.2551, Train MAE: 0.2551,
                            Val Loss: 0.3587, Val MAE: 0.3585
2023-01-26 09:04:08,506:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-26 09:14:54,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.80s, LR: 0.00070, Train Loss: 0.2552, Train MAE: 0.2552,
                            Val Loss: 0.6185, Val MAE: 0.6178
2023-01-26 09:14:54,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-26 09:25:40,706:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 646.40s, LR: 0.00070, Train Loss: 0.2351, Train MAE: 0.2351,
                            Val Loss: 0.4263, Val MAE: 0.4262
2023-01-26 09:25:40,708:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-26 09:36:25,741:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.03s, LR: 0.00070, Train Loss: 0.2262, Train MAE: 0.2262,
                            Val Loss: 0.3680, Val MAE: 0.3679
2023-01-26 09:36:25,743:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-26 09:47:14,661:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.3089017868041992
2023-01-26 09:47:14,663:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 648.92s, LR: 0.00070, Train Loss: 0.2514, Train MAE: 0.2514,
                            Val Loss: 0.3091, Val MAE: 0.3089
2023-01-26 09:47:14,664:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-26 09:58:05,806:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.14s, LR: 0.00070, Train Loss: 0.2293, Train MAE: 0.2293,
                            Val Loss: 0.7775, Val MAE: 0.7777
2023-01-26 09:58:05,808:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-26 10:08:55,914:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.11s, LR: 0.00070, Train Loss: 0.2141, Train MAE: 0.2141,
                            Val Loss: 0.3377, Val MAE: 0.3376
2023-01-26 10:08:55,915:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-26 10:19:39,593:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 643.68s, LR: 0.00070, Train Loss: 0.2031, Train MAE: 0.2031,
                            Val Loss: 0.5101, Val MAE: 0.5101
2023-01-26 10:19:39,594:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-26 10:30:20,228:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.63s, LR: 0.00070, Train Loss: 0.2053, Train MAE: 0.2053,
                            Val Loss: 0.3571, Val MAE: 0.3569
2023-01-26 10:30:20,229:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-26 10:41:00,971:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.74s, LR: 0.00070, Train Loss: 0.1918, Train MAE: 0.1918,
                            Val Loss: 0.4572, Val MAE: 0.4572
2023-01-26 10:41:00,972:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-26 10:51:39,938:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.23625193536281586
2023-01-26 10:51:39,940:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.97s, LR: 0.00070, Train Loss: 0.1933, Train MAE: 0.1933,
                            Val Loss: 0.2364, Val MAE: 0.2363
2023-01-26 10:51:39,941:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-26 11:02:20,926:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.98s, LR: 0.00070, Train Loss: 0.1846, Train MAE: 0.1846,
                            Val Loss: 0.3206, Val MAE: 0.3206
2023-01-26 11:02:20,927:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-26 11:13:01,680:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.75s, LR: 0.00070, Train Loss: 0.1804, Train MAE: 0.1804,
                            Val Loss: 0.3924, Val MAE: 0.3925
2023-01-26 11:13:01,682:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-26 11:24:38,677:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.99s, LR: 0.00070, Train Loss: 0.1774, Train MAE: 0.1774,
                            Val Loss: 0.3578, Val MAE: 0.3578
2023-01-26 11:24:38,678:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-26 11:35:20,284:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.61s, LR: 0.00070, Train Loss: 0.1801, Train MAE: 0.1801,
                            Val Loss: 0.3764, Val MAE: 0.3763
2023-01-26 11:35:20,286:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-26 11:46:01,887:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.60s, LR: 0.00070, Train Loss: 0.1733, Train MAE: 0.1733,
                            Val Loss: 0.4913, Val MAE: 0.4913
2023-01-26 11:46:01,888:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-26 11:56:43,486:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.60s, LR: 0.00070, Train Loss: 0.1758, Train MAE: 0.1758,
                            Val Loss: 0.3224, Val MAE: 0.3223
2023-01-26 11:56:43,487:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-26 12:07:27,808:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.32s, LR: 0.00070, Train Loss: 0.1740, Train MAE: 0.1740,
                            Val Loss: 0.4987, Val MAE: 0.4987
2023-01-26 12:07:27,809:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-26 12:18:08,958:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.15s, LR: 0.00070, Train Loss: 0.1710, Train MAE: 0.1710,
                            Val Loss: 0.3360, Val MAE: 0.3360
2023-01-26 12:18:08,959:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-26 12:28:51,316:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 642.36s, LR: 0.00070, Train Loss: 0.1651, Train MAE: 0.1651,
                            Val Loss: 0.3479, Val MAE: 0.3478
2023-01-26 12:28:51,317:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-26 12:39:37,312:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 645.99s, LR: 0.00070, Train Loss: 0.1748, Train MAE: 0.1748,
                            Val Loss: 0.2779, Val MAE: 0.2779
2023-01-26 12:39:37,313:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-26 12:50:18,317:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.00s, LR: 0.00070, Train Loss: 0.1652, Train MAE: 0.1652,
                            Val Loss: 0.5747, Val MAE: 0.5746
2023-01-26 12:50:18,319:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-26 13:00:56,666:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.35s, LR: 0.00070, Train Loss: 0.2051, Train MAE: 0.2051,
                            Val Loss: 0.4363, Val MAE: 0.4365
2023-01-26 13:00:56,667:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-26 13:11:35,291:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.62s, LR: 0.00070, Train Loss: 0.1758, Train MAE: 0.1758,
                            Val Loss: 0.3573, Val MAE: 0.3572
2023-01-26 13:11:35,292:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-26 13:22:19,993:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 644.70s, LR: 0.00070, Train Loss: 0.1626, Train MAE: 0.1626,
                            Val Loss: 0.3002, Val MAE: 0.3002
2023-01-26 13:22:19,995:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-26 13:33:02,033:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 642.04s, LR: 0.00070, Train Loss: 0.1597, Train MAE: 0.1597,
                            Val Loss: 0.4519, Val MAE: 0.4520
2023-01-26 13:33:02,034:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-26 13:43:41,769:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.73s, LR: 0.00070, Train Loss: 0.1575, Train MAE: 0.1575,
                            Val Loss: 0.2483, Val MAE: 0.2481
2023-01-26 13:43:41,770:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-26 13:54:21,343:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.57s, LR: 0.00035, Train Loss: 0.1457, Train MAE: 0.1457,
                            Val Loss: 0.3134, Val MAE: 0.3134
2023-01-26 13:54:21,344:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-26 14:05:00,765:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.42s, LR: 0.00035, Train Loss: 0.1454, Train MAE: 0.1454,
                            Val Loss: 0.3190, Val MAE: 0.3190
2023-01-26 14:05:00,766:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-26 14:15:39,357:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.59s, LR: 0.00035, Train Loss: 0.1429, Train MAE: 0.1429,
                            Val Loss: 0.2415, Val MAE: 0.2414
2023-01-26 14:15:39,358:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-26 14:27:11,749:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.39s, LR: 0.00035, Train Loss: 0.1418, Train MAE: 0.1418,
                            Val Loss: 0.4646, Val MAE: 0.4648
2023-01-26 14:27:11,750:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-26 14:37:51,303:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.21569675207138062
2023-01-26 14:37:51,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.55s, LR: 0.00035, Train Loss: 0.1411, Train MAE: 0.1411,
                            Val Loss: 0.2159, Val MAE: 0.2157
2023-01-26 14:37:51,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-26 14:48:31,607:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.30s, LR: 0.00035, Train Loss: 0.1399, Train MAE: 0.1399,
                            Val Loss: 0.3538, Val MAE: 0.3537
2023-01-26 14:48:31,608:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-26 14:59:11,387:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.78s, LR: 0.00035, Train Loss: 0.1396, Train MAE: 0.1396,
                            Val Loss: 0.2859, Val MAE: 0.2858
2023-01-26 14:59:11,388:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-26 15:09:51,190:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.19114309549331665
2023-01-26 15:09:51,192:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.80s, LR: 0.00035, Train Loss: 0.1390, Train MAE: 0.1390,
                            Val Loss: 0.1913, Val MAE: 0.1911
2023-01-26 15:09:51,192:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-26 15:20:31,304:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.11s, LR: 0.00035, Train Loss: 0.1385, Train MAE: 0.1385,
                            Val Loss: 0.1966, Val MAE: 0.1964
2023-01-26 15:20:31,305:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-26 15:31:10,875:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.57s, LR: 0.00035, Train Loss: 0.1373, Train MAE: 0.1373,
                            Val Loss: 0.3225, Val MAE: 0.3225
2023-01-26 15:31:10,876:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-26 15:41:51,052:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.18s, LR: 0.00035, Train Loss: 0.1367, Train MAE: 0.1367,
                            Val Loss: 0.3901, Val MAE: 0.3902
2023-01-26 15:41:51,053:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-26 15:52:31,478:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.42s, LR: 0.00035, Train Loss: 0.1363, Train MAE: 0.1363,
                            Val Loss: 0.3401, Val MAE: 0.3401
2023-01-26 15:52:31,479:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-26 16:03:11,302:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.82s, LR: 0.00035, Train Loss: 0.1356, Train MAE: 0.1356,
                            Val Loss: 0.3396, Val MAE: 0.3396
2023-01-26 16:03:11,303:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-26 16:13:50,266:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.17668767273426056
2023-01-26 16:13:50,267:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.96s, LR: 0.00035, Train Loss: 0.1355, Train MAE: 0.1355,
                            Val Loss: 0.1769, Val MAE: 0.1767
2023-01-26 16:13:50,267:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-26 16:24:28,702:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.43s, LR: 0.00035, Train Loss: 0.1348, Train MAE: 0.1348,
                            Val Loss: 0.3397, Val MAE: 0.3396
2023-01-26 16:24:28,703:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-26 16:35:08,302:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.60s, LR: 0.00035, Train Loss: 0.1343, Train MAE: 0.1343,
                            Val Loss: 0.3438, Val MAE: 0.3437
2023-01-26 16:35:08,302:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-26 16:45:46,307:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.00s, LR: 0.00035, Train Loss: 0.1339, Train MAE: 0.1339,
                            Val Loss: 0.3620, Val MAE: 0.3618
2023-01-26 16:45:46,308:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-26 16:56:24,674:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.36s, LR: 0.00035, Train Loss: 0.1336, Train MAE: 0.1336,
                            Val Loss: 0.3076, Val MAE: 0.3076
2023-01-26 16:56:24,675:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-26 17:07:04,453:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.78s, LR: 0.00035, Train Loss: 0.1333, Train MAE: 0.1333,
                            Val Loss: 0.2276, Val MAE: 0.2275
2023-01-26 17:07:04,454:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-26 17:17:44,942:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.49s, LR: 0.00035, Train Loss: 0.1329, Train MAE: 0.1329,
                            Val Loss: 0.2668, Val MAE: 0.2667
2023-01-26 17:17:44,944:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-26 17:29:17,690:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.75s, LR: 0.00035, Train Loss: 0.1325, Train MAE: 0.1325,
                            Val Loss: 0.4061, Val MAE: 0.4060
2023-01-26 17:29:17,691:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-26 17:39:57,001:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.31s, LR: 0.00035, Train Loss: 0.1319, Train MAE: 0.1319,
                            Val Loss: 0.2167, Val MAE: 0.2166
2023-01-26 17:39:57,002:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-26 17:50:35,518:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.52s, LR: 0.00035, Train Loss: 0.1316, Train MAE: 0.1316,
                            Val Loss: 0.1822, Val MAE: 0.1821
2023-01-26 17:50:35,519:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-26 18:01:14,462:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.94s, LR: 0.00035, Train Loss: 0.1313, Train MAE: 0.1313,
                            Val Loss: 0.1845, Val MAE: 0.1843
2023-01-26 18:01:14,464:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-26 18:11:52,328:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.86s, LR: 0.00035, Train Loss: 0.1313, Train MAE: 0.1313,
                            Val Loss: 0.2016, Val MAE: 0.2014
2023-01-26 18:11:52,328:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-26 18:22:30,627:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.30s, LR: 0.00035, Train Loss: 0.1320, Train MAE: 0.1320,
                            Val Loss: 0.1779, Val MAE: 0.1777
2023-01-26 18:22:30,628:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-26 18:33:08,189:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.56s, LR: 0.00035, Train Loss: 0.1308, Train MAE: 0.1308,
                            Val Loss: 0.3945, Val MAE: 0.3943
2023-01-26 18:33:08,190:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-26 18:43:45,621:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.43s, LR: 0.00035, Train Loss: 0.1322, Train MAE: 0.1322,
                            Val Loss: 0.2351, Val MAE: 0.2350
2023-01-26 18:43:45,622:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-26 18:54:22,643:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.02s, LR: 0.00035, Train Loss: 0.1298, Train MAE: 0.1298,
                            Val Loss: 0.5492, Val MAE: 0.5492
2023-01-26 18:54:22,644:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-26 19:04:58,422:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.78s, LR: 0.00035, Train Loss: 0.1299, Train MAE: 0.1299,
                            Val Loss: 0.2326, Val MAE: 0.2325
2023-01-26 19:04:58,423:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-26 19:15:35,974:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.55s, LR: 0.00017, Train Loss: 0.1242, Train MAE: 0.1242,
                            Val Loss: 0.2280, Val MAE: 0.2279
2023-01-26 19:15:35,975:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-26 19:26:12,979:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16893860697746277
2023-01-26 19:26:12,981:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.01s, LR: 0.00017, Train Loss: 0.1237, Train MAE: 0.1237,
                            Val Loss: 0.1691, Val MAE: 0.1689
2023-01-26 19:26:12,982:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-26 19:36:50,500:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.52s, LR: 0.00017, Train Loss: 0.1233, Train MAE: 0.1233,
                            Val Loss: 0.2047, Val MAE: 0.2045
2023-01-26 19:36:50,501:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-26 19:47:27,923:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.42s, LR: 0.00017, Train Loss: 0.1229, Train MAE: 0.1229,
                            Val Loss: 0.3603, Val MAE: 0.3603
2023-01-26 19:47:27,924:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-26 19:58:05,923:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.00s, LR: 0.00017, Train Loss: 0.1227, Train MAE: 0.1227,
                            Val Loss: 0.1849, Val MAE: 0.1848
2023-01-26 19:58:05,924:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-26 20:08:41,619:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.69s, LR: 0.00017, Train Loss: 0.1225, Train MAE: 0.1225,
                            Val Loss: 0.4057, Val MAE: 0.4058
2023-01-26 20:08:41,620:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-26 20:19:18,101:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.48s, LR: 0.00017, Train Loss: 0.1222, Train MAE: 0.1222,
                            Val Loss: 0.3893, Val MAE: 0.3892
2023-01-26 20:19:18,102:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-26 20:30:48,026:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.92s, LR: 0.00017, Train Loss: 0.1219, Train MAE: 0.1219,
                            Val Loss: 0.1730, Val MAE: 0.1729
2023-01-26 20:30:48,027:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-26 20:41:25,609:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.58s, LR: 0.00017, Train Loss: 0.1218, Train MAE: 0.1218,
                            Val Loss: 0.2378, Val MAE: 0.2377
2023-01-26 20:41:25,611:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-26 20:52:01,317:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16683997213840485
2023-01-26 20:52:01,320:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.71s, LR: 0.00017, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.1670, Val MAE: 0.1668
2023-01-26 20:52:01,321:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-26 21:02:37,314:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 635.99s, LR: 0.00017, Train Loss: 0.1214, Train MAE: 0.1214,
                            Val Loss: 0.3366, Val MAE: 0.3366
2023-01-26 21:02:37,315:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-26 21:13:15,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.80s, LR: 0.00017, Train Loss: 0.1213, Train MAE: 0.1213,
                            Val Loss: 0.2234, Val MAE: 0.2233
2023-01-26 21:13:15,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-26 21:23:52,059:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.94s, LR: 0.00017, Train Loss: 0.1211, Train MAE: 0.1211,
                            Val Loss: 0.2812, Val MAE: 0.2812
2023-01-26 21:23:52,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-26 21:34:28,861:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.80s, LR: 0.00017, Train Loss: 0.1210, Train MAE: 0.1210,
                            Val Loss: 0.2819, Val MAE: 0.2819
2023-01-26 21:34:28,863:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-26 21:45:05,345:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.48s, LR: 0.00017, Train Loss: 0.1207, Train MAE: 0.1207,
                            Val Loss: 0.2894, Val MAE: 0.2893
2023-01-26 21:45:05,346:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-26 21:55:41,941:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.59s, LR: 0.00017, Train Loss: 0.1205, Train MAE: 0.1205,
                            Val Loss: 0.4086, Val MAE: 0.4086
2023-01-26 21:55:41,942:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-26 22:06:17,944:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.00s, LR: 0.00017, Train Loss: 0.1205, Train MAE: 0.1205,
                            Val Loss: 0.3991, Val MAE: 0.3990
2023-01-26 22:06:17,946:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-26 22:16:54,287:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.34s, LR: 0.00017, Train Loss: 0.1203, Train MAE: 0.1203,
                            Val Loss: 0.2020, Val MAE: 0.2019
2023-01-26 22:16:54,288:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-26 22:27:30,964:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.68s, LR: 0.00017, Train Loss: 0.1201, Train MAE: 0.1201,
                            Val Loss: 0.2076, Val MAE: 0.2075
2023-01-26 22:27:30,965:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-26 22:38:08,625:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.66s, LR: 0.00017, Train Loss: 0.1200, Train MAE: 0.1200,
                            Val Loss: 0.2453, Val MAE: 0.2453
2023-01-26 22:38:08,626:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-26 22:48:45,395:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.77s, LR: 0.00017, Train Loss: 0.1199, Train MAE: 0.1199,
                            Val Loss: 0.2939, Val MAE: 0.2939
2023-01-26 22:48:45,396:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-26 22:59:21,448:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.05s, LR: 0.00017, Train Loss: 0.1197, Train MAE: 0.1197,
                            Val Loss: 0.2293, Val MAE: 0.2292
2023-01-26 22:59:21,449:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-26 23:09:57,696:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.25s, LR: 0.00017, Train Loss: 0.1202, Train MAE: 0.1202,
                            Val Loss: 0.1912, Val MAE: 0.1911
2023-01-26 23:09:57,697:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-26 23:20:34,076:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.38s, LR: 0.00017, Train Loss: 0.1194, Train MAE: 0.1194,
                            Val Loss: 0.2183, Val MAE: 0.2182
2023-01-26 23:20:34,077:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-26 23:32:03,838:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.76s, LR: 0.00017, Train Loss: 0.1194, Train MAE: 0.1194,
                            Val Loss: 0.1949, Val MAE: 0.1947
2023-01-26 23:32:03,839:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-26 23:42:40,182:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.34s, LR: 0.00017, Train Loss: 0.1212, Train MAE: 0.1212,
                            Val Loss: 0.2238, Val MAE: 0.2237
2023-01-26 23:42:40,183:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-26 23:53:16,897:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15612949430942535
2023-01-26 23:53:16,898:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.71s, LR: 0.00009, Train Loss: 0.1166, Train MAE: 0.1166,
                            Val Loss: 0.1563, Val MAE: 0.1561
2023-01-26 23:53:16,899:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-27 00:03:53,977:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.08s, LR: 0.00009, Train Loss: 0.1160, Train MAE: 0.1160,
                            Val Loss: 0.2073, Val MAE: 0.2072
2023-01-27 00:03:53,979:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-27 00:14:31,608:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.63s, LR: 0.00009, Train Loss: 0.1159, Train MAE: 0.1159,
                            Val Loss: 0.2509, Val MAE: 0.2508
2023-01-27 00:14:31,609:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-27 00:25:08,925:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.32s, LR: 0.00009, Train Loss: 0.1157, Train MAE: 0.1157,
                            Val Loss: 0.3019, Val MAE: 0.3019
2023-01-27 00:25:08,926:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-27 00:35:47,195:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.27s, LR: 0.00009, Train Loss: 0.1156, Train MAE: 0.1156,
                            Val Loss: 0.3119, Val MAE: 0.3118
2023-01-27 00:35:47,196:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-27 00:46:24,145:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.95s, LR: 0.00009, Train Loss: 0.1154, Train MAE: 0.1154,
                            Val Loss: 0.2455, Val MAE: 0.2454
2023-01-27 00:46:24,147:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-27 00:57:00,648:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.50s, LR: 0.00009, Train Loss: 0.1152, Train MAE: 0.1152,
                            Val Loss: 0.2337, Val MAE: 0.2336
2023-01-27 00:57:00,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-27 01:07:37,545:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.89s, LR: 0.00009, Train Loss: 0.1153, Train MAE: 0.1153,
                            Val Loss: 0.1575, Val MAE: 0.1573
2023-01-27 01:07:37,546:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-27 01:18:16,145:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.60s, LR: 0.00009, Train Loss: 0.1151, Train MAE: 0.1151,
                            Val Loss: 0.1722, Val MAE: 0.1720
2023-01-27 01:18:16,146:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-27 01:28:53,998:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.85s, LR: 0.00009, Train Loss: 0.1151, Train MAE: 0.1151,
                            Val Loss: 0.1884, Val MAE: 0.1883
2023-01-27 01:28:53,999:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-27 01:39:30,557:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14400489628314972
2023-01-27 01:39:30,559:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.56s, LR: 0.00009, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1442, Val MAE: 0.1440
2023-01-27 01:39:30,559:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-27 01:50:07,645:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.08s, LR: 0.00009, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1494, Val MAE: 0.1492
2023-01-27 01:50:07,646:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-27 02:00:45,035:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.39s, LR: 0.00009, Train Loss: 0.1148, Train MAE: 0.1148,
                            Val Loss: 0.1485, Val MAE: 0.1483
2023-01-27 02:00:45,036:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-27 02:11:21,628:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.59s, LR: 0.00009, Train Loss: 0.1147, Train MAE: 0.1147,
                            Val Loss: 0.3424, Val MAE: 0.3423
2023-01-27 02:11:21,629:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-27 02:22:52,666:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.04s, LR: 0.00009, Train Loss: 0.1146, Train MAE: 0.1146,
                            Val Loss: 0.1623, Val MAE: 0.1621
2023-01-27 02:22:52,667:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-27 02:33:29,235:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.57s, LR: 0.00009, Train Loss: 0.1146, Train MAE: 0.1146,
                            Val Loss: 0.2364, Val MAE: 0.2363
2023-01-27 02:33:29,236:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-27 02:44:07,396:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.16s, LR: 0.00009, Train Loss: 0.1145, Train MAE: 0.1145,
                            Val Loss: 0.1673, Val MAE: 0.1672
2023-01-27 02:44:07,397:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-27 02:54:45,070:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.67s, LR: 0.00009, Train Loss: 0.1144, Train MAE: 0.1144,
                            Val Loss: 0.2073, Val MAE: 0.2072
2023-01-27 02:54:45,071:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-27 03:05:21,670:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.60s, LR: 0.00009, Train Loss: 0.1144, Train MAE: 0.1144,
                            Val Loss: 0.2309, Val MAE: 0.2308
2023-01-27 03:05:21,671:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-27 03:15:58,360:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.69s, LR: 0.00009, Train Loss: 0.1143, Train MAE: 0.1143,
                            Val Loss: 0.2329, Val MAE: 0.2328
2023-01-27 03:15:58,361:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-27 03:26:35,667:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.31s, LR: 0.00009, Train Loss: 0.1142, Train MAE: 0.1142,
                            Val Loss: 0.3148, Val MAE: 0.3148
2023-01-27 03:26:35,669:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-27 03:37:11,834:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 636.16s, LR: 0.00009, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.2930, Val MAE: 0.2929
2023-01-27 03:37:11,835:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-27 03:47:49,941:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.11s, LR: 0.00009, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.1688, Val MAE: 0.1687
2023-01-27 03:47:49,942:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-27 03:58:27,770:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.83s, LR: 0.00009, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.1478, Val MAE: 0.1476
2023-01-27 03:58:27,771:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-27 04:09:06,190:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14270788431167603
2023-01-27 04:09:06,192:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 638.42s, LR: 0.00009, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.1429, Val MAE: 0.1427
2023-01-27 04:09:06,192:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-27 04:19:43,857:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.66s, LR: 0.00009, Train Loss: 0.1140, Train MAE: 0.1140,
                            Val Loss: 0.2025, Val MAE: 0.2024
2023-01-27 04:19:43,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-27 04:30:21,555:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.70s, LR: 0.00009, Train Loss: 0.1138, Train MAE: 0.1138,
                            Val Loss: 0.1611, Val MAE: 0.1609
2023-01-27 04:30:21,556:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-27 04:40:59,354:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 637.80s, LR: 0.00009, Train Loss: 0.1138, Train MAE: 0.1138,
                            Val Loss: 0.1621, Val MAE: 0.1619
2023-01-27 04:40:59,356:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-27 04:51:38,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.09s, LR: 0.00009, Train Loss: 0.1136, Train MAE: 0.1136,
                            Val Loss: 0.2340, Val MAE: 0.2339
2023-01-27 04:51:38,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-27 05:02:17,886:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 639.44s, LR: 0.00009, Train Loss: 0.1136, Train MAE: 0.1136,
                            Val Loss: 0.3996, Val MAE: 0.3997
2023-01-27 05:02:17,887:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-27 05:12:57,924:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.04s, LR: 0.00009, Train Loss: 0.1135, Train MAE: 0.1135,
                            Val Loss: 0.2710, Val MAE: 0.2710
2023-01-27 05:12:57,925:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-27 05:24:30,010:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.08s, LR: 0.00009, Train Loss: 0.1135, Train MAE: 0.1135,
                            Val Loss: 0.1585, Val MAE: 0.1584
2023-01-27 05:24:30,011:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 126/1000
2023-01-27 05:35:10,953:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.94s, LR: 0.00009, Train Loss: 0.1134, Train MAE: 0.1134,
                            Val Loss: 0.2173, Val MAE: 0.2172
2023-01-27 05:35:10,954:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 127/1000
2023-01-27 05:45:52,101:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 641.15s, LR: 0.00009, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.1747, Val MAE: 0.1745
2023-01-27 05:45:52,102:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 128/1000
2023-01-27 05:56:32,827:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 640.72s, LR: 0.00009, Train Loss: 0.1134, Train MAE: 0.1134,
                            Val Loss: 0.1569, Val MAE: 0.1567
2023-01-27 05:56:32,828:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-27 05:56:32,828:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-27 06:03:44,447:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1567
2023-01-27 06:03:44,449:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.1277
2023-01-27 06:03:44,450:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-27 06:03:44,451:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 127.0000
2023-01-27 06:03:44,452:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87197.2413s
2023-01-27 06:03:44,453:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 644.2246s
2023-01-27 06:03:44,455:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-27 06:03:44,456:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.1277)]
2023-01-27 06:03:44,456:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1567)]
