2023-01-26 05:38:49,054:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2023-01-26 05:38:49,054:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-26 05:48:22,335:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-26 05:48:47,887:ogbdata.py:332 -             __init__(): Time taken: 598.8325s
2023-01-26 05:48:47,887:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-26 05:48:47,887:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-26 05:48:47,887:ogbdata.py:348 -             __init__(): [I] Data load time: 598.8328s
2023-01-26 05:48:47,887:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials/32_DEBUG_0_41.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [41]}
2023-01-26 05:48:47,887:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-26 05:48:47,890:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:48:48,901:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:48:48,901:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:48:48,901:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:48:48,916:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-26 05:48:48,919:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541681
2023-01-26 05:48:48,919:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2023-01-26 05:48:48,919:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-26 05:48:48,920:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-26 05:48:48,920:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-26 05:48:48,920:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-26 05:48:48,939:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-26 06:56:37,169:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4068.249673604965
2023-01-26 06:56:37,175:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-26 06:56:37,175:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-26 06:56:37,178:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-26 07:11:29,484:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.6524970531463623
2023-01-26 07:11:29,486:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 892.31s, LR: 0.00070, Train Loss: 0.5894, Train MAE: 0.5894,
                            Val Loss: 0.6526, Val MAE: 0.6525
2023-01-26 07:11:29,486:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-26 07:24:21,934:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.6204002499580383
2023-01-26 07:24:21,936:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.45s, LR: 0.00070, Train Loss: 0.3921, Train MAE: 0.3921,
                            Val Loss: 0.6209, Val MAE: 0.6204
2023-01-26 07:24:21,937:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-26 07:38:00,522:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 818.58s, LR: 0.00070, Train Loss: 0.3417, Train MAE: 0.3417,
                            Val Loss: 0.7218, Val MAE: 0.7216
2023-01-26 07:38:00,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-26 07:51:42,004:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 821.48s, LR: 0.00070, Train Loss: 0.3056, Train MAE: 0.3056,
                            Val Loss: 0.6456, Val MAE: 0.6456
2023-01-26 07:51:42,006:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-26 08:05:12,400:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 810.39s, LR: 0.00070, Train Loss: 0.3395, Train MAE: 0.3395,
                            Val Loss: 0.9355, Val MAE: 0.9354
2023-01-26 08:05:12,402:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-26 08:18:03,032:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.63s, LR: 0.00070, Train Loss: 0.3771, Train MAE: 0.3771,
                            Val Loss: 0.9864, Val MAE: 0.9860
2023-01-26 08:18:03,033:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-26 08:31:12,790:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5147497057914734
2023-01-26 08:31:12,792:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 789.76s, LR: 0.00070, Train Loss: 0.3491, Train MAE: 0.3491,
                            Val Loss: 0.5150, Val MAE: 0.5147
2023-01-26 08:31:12,793:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-26 08:45:31,466:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.43198585510253906
2023-01-26 08:45:31,468:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 858.67s, LR: 0.00070, Train Loss: 0.3407, Train MAE: 0.3407,
                            Val Loss: 0.4322, Val MAE: 0.4320
2023-01-26 08:45:31,469:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-26 08:58:25,341:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 773.87s, LR: 0.00070, Train Loss: 0.3124, Train MAE: 0.3124,
                            Val Loss: 0.5039, Val MAE: 0.5038
2023-01-26 08:58:25,343:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-26 09:12:04,967:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 819.62s, LR: 0.00070, Train Loss: 0.2841, Train MAE: 0.2841,
                            Val Loss: 0.5014, Val MAE: 0.5012
2023-01-26 09:12:04,969:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-26 09:25:36,522:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 811.54s, LR: 0.00070, Train Loss: 0.2630, Train MAE: 0.2630,
                            Val Loss: 0.8793, Val MAE: 0.8792
2023-01-26 09:25:36,523:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-26 09:39:02,857:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 806.33s, LR: 0.00070, Train Loss: 0.2623, Train MAE: 0.2623,
                            Val Loss: 0.4947, Val MAE: 0.4946
2023-01-26 09:39:02,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-26 09:51:53,898:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.04s, LR: 0.00070, Train Loss: 0.2445, Train MAE: 0.2445,
                            Val Loss: 0.6952, Val MAE: 0.6954
2023-01-26 09:51:53,900:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-26 10:04:45,313:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.28958651423454285
2023-01-26 10:04:45,315:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.41s, LR: 0.00070, Train Loss: 0.2634, Train MAE: 0.2634,
                            Val Loss: 0.2898, Val MAE: 0.2896
2023-01-26 10:04:45,316:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-26 10:17:35,197:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.88s, LR: 0.00070, Train Loss: 0.2974, Train MAE: 0.2974,
                            Val Loss: 0.5517, Val MAE: 0.5518
2023-01-26 10:17:35,198:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-26 10:30:25,446:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.25s, LR: 0.00070, Train Loss: 0.2616, Train MAE: 0.2616,
                            Val Loss: 0.5738, Val MAE: 0.5738
2023-01-26 10:30:25,447:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-26 10:43:12,567:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.12s, LR: 0.00070, Train Loss: 0.2434, Train MAE: 0.2434,
                            Val Loss: 0.4095, Val MAE: 0.4094
2023-01-26 10:43:12,569:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-26 10:56:03,939:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.37s, LR: 0.00070, Train Loss: 0.2403, Train MAE: 0.2403,
                            Val Loss: 0.4792, Val MAE: 0.4791
2023-01-26 10:56:03,940:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-26 11:08:51,815:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.87s, LR: 0.00070, Train Loss: 0.2249, Train MAE: 0.2249,
                            Val Loss: 0.4069, Val MAE: 0.4069
2023-01-26 11:08:51,816:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-26 11:21:43,334:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.52s, LR: 0.00070, Train Loss: 0.2275, Train MAE: 0.2275,
                            Val Loss: 0.3406, Val MAE: 0.3403
2023-01-26 11:21:43,335:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-26 11:34:33,585:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.25s, LR: 0.00070, Train Loss: 0.2191, Train MAE: 0.2191,
                            Val Loss: 0.4278, Val MAE: 0.4279
2023-01-26 11:34:33,586:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-26 11:47:19,759:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.17s, LR: 0.00070, Train Loss: 0.2099, Train MAE: 0.2099,
                            Val Loss: 0.4975, Val MAE: 0.4974
2023-01-26 11:47:19,760:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-26 12:00:07,172:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.41s, LR: 0.00070, Train Loss: 0.2040, Train MAE: 0.2040,
                            Val Loss: 0.4375, Val MAE: 0.4373
2023-01-26 12:00:07,173:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-26 12:13:50,000:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 822.83s, LR: 0.00070, Train Loss: 0.1938, Train MAE: 0.1938,
                            Val Loss: 0.4070, Val MAE: 0.4068
2023-01-26 12:13:50,001:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-26 12:26:34,647:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.64s, LR: 0.00070, Train Loss: 0.2051, Train MAE: 0.2051,
                            Val Loss: 0.4296, Val MAE: 0.4295
2023-01-26 12:26:34,647:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-26 12:39:19,851:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.20s, LR: 0.00070, Train Loss: 0.1961, Train MAE: 0.1961,
                            Val Loss: 0.4547, Val MAE: 0.4547
2023-01-26 12:39:19,851:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-26 12:52:04,351:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.50s, LR: 0.00070, Train Loss: 0.1848, Train MAE: 0.1848,
                            Val Loss: 0.3346, Val MAE: 0.3345
2023-01-26 12:52:04,353:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-26 13:04:47,943:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.59s, LR: 0.00070, Train Loss: 0.1810, Train MAE: 0.1810,
                            Val Loss: 0.3107, Val MAE: 0.3106
2023-01-26 13:04:47,945:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-26 13:17:32,535:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.59s, LR: 0.00070, Train Loss: 0.1815, Train MAE: 0.1815,
                            Val Loss: 0.3215, Val MAE: 0.3215
2023-01-26 13:17:32,536:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-26 13:30:15,776:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.24s, LR: 0.00070, Train Loss: 0.1773, Train MAE: 0.1773,
                            Val Loss: 0.3772, Val MAE: 0.3771
2023-01-26 13:30:15,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-26 13:42:58,750:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.97s, LR: 0.00035, Train Loss: 0.1639, Train MAE: 0.1639,
                            Val Loss: 0.3622, Val MAE: 0.3621
2023-01-26 13:42:58,751:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-26 13:55:42,109:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2605578303337097
2023-01-26 13:55:42,110:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.36s, LR: 0.00035, Train Loss: 0.1647, Train MAE: 0.1647,
                            Val Loss: 0.2606, Val MAE: 0.2606
2023-01-26 13:55:42,110:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-26 14:08:24,619:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.51s, LR: 0.00035, Train Loss: 0.1586, Train MAE: 0.1586,
                            Val Loss: 0.3978, Val MAE: 0.3979
2023-01-26 14:08:24,620:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-26 14:21:07,139:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.52s, LR: 0.00035, Train Loss: 0.1568, Train MAE: 0.1568,
                            Val Loss: 0.2678, Val MAE: 0.2677
2023-01-26 14:21:07,140:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-26 14:33:50,353:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.21s, LR: 0.00035, Train Loss: 0.1572, Train MAE: 0.1572,
                            Val Loss: 0.2786, Val MAE: 0.2786
2023-01-26 14:33:50,354:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-26 14:46:33,410:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.05s, LR: 0.00035, Train Loss: 0.1575, Train MAE: 0.1575,
                            Val Loss: 0.3312, Val MAE: 0.3312
2023-01-26 14:46:33,411:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-26 14:59:16,508:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.10s, LR: 0.00035, Train Loss: 0.1537, Train MAE: 0.1537,
                            Val Loss: 0.4146, Val MAE: 0.4148
2023-01-26 14:59:16,510:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-26 15:11:59,625:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.11s, LR: 0.00035, Train Loss: 0.1529, Train MAE: 0.1529,
                            Val Loss: 0.2718, Val MAE: 0.2717
2023-01-26 15:11:59,626:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-26 15:24:42,582:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.20874924957752228
2023-01-26 15:24:42,583:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.96s, LR: 0.00035, Train Loss: 0.1554, Train MAE: 0.1554,
                            Val Loss: 0.2089, Val MAE: 0.2087
2023-01-26 15:24:42,584:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-26 15:37:27,260:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.68s, LR: 0.00035, Train Loss: 0.1540, Train MAE: 0.1540,
                            Val Loss: 0.3169, Val MAE: 0.3169
2023-01-26 15:37:27,262:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-26 15:51:05,319:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 818.06s, LR: 0.00035, Train Loss: 0.1535, Train MAE: 0.1535,
                            Val Loss: 0.2524, Val MAE: 0.2523
2023-01-26 15:51:05,320:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-26 16:03:48,412:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.09s, LR: 0.00035, Train Loss: 0.1523, Train MAE: 0.1523,
                            Val Loss: 0.2997, Val MAE: 0.2998
2023-01-26 16:03:48,412:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-26 16:16:30,743:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.33s, LR: 0.00035, Train Loss: 0.1511, Train MAE: 0.1511,
                            Val Loss: 0.2618, Val MAE: 0.2617
2023-01-26 16:16:30,744:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-26 16:29:14,150:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.41s, LR: 0.00035, Train Loss: 0.1508, Train MAE: 0.1508,
                            Val Loss: 0.2621, Val MAE: 0.2620
2023-01-26 16:29:14,151:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-26 16:41:57,248:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.10s, LR: 0.00035, Train Loss: 0.1496, Train MAE: 0.1496,
                            Val Loss: 0.2783, Val MAE: 0.2783
2023-01-26 16:41:57,249:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-26 16:54:40,074:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.82s, LR: 0.00035, Train Loss: 0.1486, Train MAE: 0.1486,
                            Val Loss: 0.2411, Val MAE: 0.2410
2023-01-26 16:54:40,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-26 17:07:23,425:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.35s, LR: 0.00035, Train Loss: 0.1479, Train MAE: 0.1479,
                            Val Loss: 0.2113, Val MAE: 0.2111
2023-01-26 17:07:23,426:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-26 17:20:05,601:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.17s, LR: 0.00035, Train Loss: 0.1470, Train MAE: 0.1470,
                            Val Loss: 0.2742, Val MAE: 0.2742
2023-01-26 17:20:05,601:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-26 17:32:48,270:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.67s, LR: 0.00035, Train Loss: 0.1467, Train MAE: 0.1467,
                            Val Loss: 0.2440, Val MAE: 0.2439
2023-01-26 17:32:48,270:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-26 17:45:31,174:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.90s, LR: 0.00035, Train Loss: 0.1450, Train MAE: 0.1450,
                            Val Loss: 0.2554, Val MAE: 0.2553
2023-01-26 17:45:31,175:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-26 17:58:16,627:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.45s, LR: 0.00035, Train Loss: 0.1443, Train MAE: 0.1443,
                            Val Loss: 0.3812, Val MAE: 0.3813
2023-01-26 17:58:16,628:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-26 18:10:58,954:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.32s, LR: 0.00035, Train Loss: 0.1430, Train MAE: 0.1430,
                            Val Loss: 0.2504, Val MAE: 0.2502
2023-01-26 18:10:58,955:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-26 18:23:40,838:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.88s, LR: 0.00035, Train Loss: 0.1425, Train MAE: 0.1425,
                            Val Loss: 0.4437, Val MAE: 0.4438
2023-01-26 18:23:40,839:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-26 18:36:22,423:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.58s, LR: 0.00035, Train Loss: 0.1419, Train MAE: 0.1419,
                            Val Loss: 0.2731, Val MAE: 0.2730
2023-01-26 18:36:22,425:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-26 18:49:05,056:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.63s, LR: 0.00035, Train Loss: 0.1412, Train MAE: 0.1412,
                            Val Loss: 0.2788, Val MAE: 0.2788
2023-01-26 18:49:05,057:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-26 19:01:46,294:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.24s, LR: 0.00017, Train Loss: 0.1350, Train MAE: 0.1350,
                            Val Loss: 0.3201, Val MAE: 0.3201
2023-01-26 19:01:46,295:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-26 19:14:30,547:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1903311014175415
2023-01-26 19:14:30,549:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.25s, LR: 0.00017, Train Loss: 0.1341, Train MAE: 0.1341,
                            Val Loss: 0.1905, Val MAE: 0.1903
2023-01-26 19:14:30,549:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-26 19:28:09,731:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 819.18s, LR: 0.00017, Train Loss: 0.1337, Train MAE: 0.1337,
                            Val Loss: 0.3245, Val MAE: 0.3245
2023-01-26 19:28:09,732:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-26 19:40:52,262:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.53s, LR: 0.00017, Train Loss: 0.1332, Train MAE: 0.1332,
                            Val Loss: 0.3254, Val MAE: 0.3254
2023-01-26 19:40:52,263:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-26 19:53:37,361:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.10s, LR: 0.00017, Train Loss: 0.1328, Train MAE: 0.1328,
                            Val Loss: 0.3447, Val MAE: 0.3447
2023-01-26 19:53:37,361:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-26 20:06:20,513:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.15s, LR: 0.00017, Train Loss: 0.1324, Train MAE: 0.1324,
                            Val Loss: 0.3054, Val MAE: 0.3054
2023-01-26 20:06:20,514:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-26 20:19:01,958:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1623462438583374
2023-01-26 20:19:01,959:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.44s, LR: 0.00017, Train Loss: 0.1322, Train MAE: 0.1322,
                            Val Loss: 0.1626, Val MAE: 0.1623
2023-01-26 20:19:01,960:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-26 20:31:43,854:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.89s, LR: 0.00017, Train Loss: 0.1368, Train MAE: 0.1368,
                            Val Loss: 0.2235, Val MAE: 0.2234
2023-01-26 20:31:43,855:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-26 20:44:28,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.87s, LR: 0.00017, Train Loss: 0.1366, Train MAE: 0.1366,
                            Val Loss: 0.2063, Val MAE: 0.2061
2023-01-26 20:44:28,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-26 20:57:10,267:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.54s, LR: 0.00017, Train Loss: 0.1341, Train MAE: 0.1341,
                            Val Loss: 0.2019, Val MAE: 0.2017
2023-01-26 20:57:10,268:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-26 21:09:52,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.77s, LR: 0.00017, Train Loss: 0.1317, Train MAE: 0.1317,
                            Val Loss: 0.2721, Val MAE: 0.2721
2023-01-26 21:09:52,039:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-26 21:22:35,004:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.96s, LR: 0.00017, Train Loss: 0.1336, Train MAE: 0.1336,
                            Val Loss: 0.2339, Val MAE: 0.2338
2023-01-26 21:22:35,005:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-26 21:35:20,144:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.14s, LR: 0.00017, Train Loss: 0.1326, Train MAE: 0.1326,
                            Val Loss: 0.3160, Val MAE: 0.3160
2023-01-26 21:35:20,145:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-26 21:48:05,610:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.46s, LR: 0.00017, Train Loss: 0.1310, Train MAE: 0.1310,
                            Val Loss: 0.2331, Val MAE: 0.2330
2023-01-26 21:48:05,611:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-26 22:00:48,643:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.03s, LR: 0.00017, Train Loss: 0.1304, Train MAE: 0.1304,
                            Val Loss: 0.2530, Val MAE: 0.2529
2023-01-26 22:00:48,644:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-26 22:13:34,397:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.75s, LR: 0.00017, Train Loss: 0.1301, Train MAE: 0.1301,
                            Val Loss: 0.2369, Val MAE: 0.2368
2023-01-26 22:13:34,398:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-26 22:26:20,580:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.18s, LR: 0.00017, Train Loss: 0.1298, Train MAE: 0.1298,
                            Val Loss: 0.2799, Val MAE: 0.2798
2023-01-26 22:26:20,581:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-26 22:39:02,867:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.29s, LR: 0.00017, Train Loss: 0.1296, Train MAE: 0.1296,
                            Val Loss: 0.2369, Val MAE: 0.2368
2023-01-26 22:39:02,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-26 22:51:44,641:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.77s, LR: 0.00017, Train Loss: 0.1295, Train MAE: 0.1295,
                            Val Loss: 0.2602, Val MAE: 0.2601
2023-01-26 22:51:44,642:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-26 23:05:24,765:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 820.12s, LR: 0.00017, Train Loss: 0.1291, Train MAE: 0.1291,
                            Val Loss: 0.2032, Val MAE: 0.2031
2023-01-26 23:05:24,766:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-26 23:18:10,456:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.69s, LR: 0.00017, Train Loss: 0.1289, Train MAE: 0.1289,
                            Val Loss: 0.2022, Val MAE: 0.2020
2023-01-26 23:18:10,457:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-26 23:30:55,484:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.03s, LR: 0.00017, Train Loss: 0.1313, Train MAE: 0.1313,
                            Val Loss: 0.4334, Val MAE: 0.4335
2023-01-26 23:30:55,485:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-26 23:43:41,431:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 765.94s, LR: 0.00017, Train Loss: 0.1305, Train MAE: 0.1305,
                            Val Loss: 0.2235, Val MAE: 0.2234
2023-01-26 23:43:41,432:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-26 23:56:25,593:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.16s, LR: 0.00009, Train Loss: 0.1263, Train MAE: 0.1263,
                            Val Loss: 0.1785, Val MAE: 0.1783
2023-01-26 23:56:25,594:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-27 00:09:07,073:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.48s, LR: 0.00009, Train Loss: 0.1258, Train MAE: 0.1258,
                            Val Loss: 0.2129, Val MAE: 0.2128
2023-01-27 00:09:07,074:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-27 00:21:51,996:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.92s, LR: 0.00009, Train Loss: 0.1255, Train MAE: 0.1255,
                            Val Loss: 0.2862, Val MAE: 0.2862
2023-01-27 00:21:51,998:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-27 00:34:35,210:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.21s, LR: 0.00009, Train Loss: 0.1254, Train MAE: 0.1254,
                            Val Loss: 0.2881, Val MAE: 0.2881
2023-01-27 00:34:35,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-27 00:47:16,202:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16146551072597504
2023-01-27 00:47:16,204:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.99s, LR: 0.00009, Train Loss: 0.1251, Train MAE: 0.1251,
                            Val Loss: 0.1617, Val MAE: 0.1615
2023-01-27 00:47:16,205:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-27 00:59:57,512:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.31s, LR: 0.00009, Train Loss: 0.1248, Train MAE: 0.1248,
                            Val Loss: 0.2592, Val MAE: 0.2592
2023-01-27 00:59:57,513:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-27 01:12:38,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.42s, LR: 0.00009, Train Loss: 0.1247, Train MAE: 0.1247,
                            Val Loss: 0.2526, Val MAE: 0.2525
2023-01-27 01:12:38,931:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-27 01:25:20,809:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.88s, LR: 0.00009, Train Loss: 0.1246, Train MAE: 0.1246,
                            Val Loss: 0.2390, Val MAE: 0.2389
2023-01-27 01:25:20,810:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-27 01:38:04,152:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.34s, LR: 0.00009, Train Loss: 0.1243, Train MAE: 0.1243,
                            Val Loss: 0.2777, Val MAE: 0.2776
2023-01-27 01:38:04,153:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-27 01:50:46,213:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.06s, LR: 0.00009, Train Loss: 0.1242, Train MAE: 0.1242,
                            Val Loss: 0.1737, Val MAE: 0.1735
2023-01-27 01:50:46,215:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-27 02:03:28,795:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.58s, LR: 0.00009, Train Loss: 0.1239, Train MAE: 0.1239,
                            Val Loss: 0.2426, Val MAE: 0.2425
2023-01-27 02:03:28,796:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-27 02:16:09,773:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.98s, LR: 0.00009, Train Loss: 0.1239, Train MAE: 0.1239,
                            Val Loss: 0.1715, Val MAE: 0.1713
2023-01-27 02:16:09,774:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-27 02:28:53,749:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 763.97s, LR: 0.00009, Train Loss: 0.1237, Train MAE: 0.1237,
                            Val Loss: 0.3568, Val MAE: 0.3568
2023-01-27 02:28:53,749:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-27 02:42:32,204:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 818.45s, LR: 0.00009, Train Loss: 0.1236, Train MAE: 0.1236,
                            Val Loss: 0.4489, Val MAE: 0.4489
2023-01-27 02:42:32,205:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-27 02:55:14,927:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.72s, LR: 0.00009, Train Loss: 0.1235, Train MAE: 0.1235,
                            Val Loss: 0.2558, Val MAE: 0.2558
2023-01-27 02:55:14,929:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-27 03:07:56,962:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.03s, LR: 0.00009, Train Loss: 0.1234, Train MAE: 0.1234,
                            Val Loss: 0.1979, Val MAE: 0.1978
2023-01-27 03:07:56,964:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-27 03:20:38,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.74s, LR: 0.00009, Train Loss: 0.1231, Train MAE: 0.1231,
                            Val Loss: 0.1749, Val MAE: 0.1747
2023-01-27 03:20:38,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-27 03:33:19,552:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.85s, LR: 0.00009, Train Loss: 0.1231, Train MAE: 0.1231,
                            Val Loss: 0.3243, Val MAE: 0.3243
2023-01-27 03:33:19,553:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-27 03:46:01,355:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.80s, LR: 0.00009, Train Loss: 0.1231, Train MAE: 0.1231,
                            Val Loss: 0.2321, Val MAE: 0.2320
2023-01-27 03:46:01,356:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-27 03:58:42,647:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.29s, LR: 0.00009, Train Loss: 0.1228, Train MAE: 0.1228,
                            Val Loss: 0.2302, Val MAE: 0.2301
2023-01-27 03:58:42,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-27 04:11:23,459:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.81s, LR: 0.00009, Train Loss: 0.1227, Train MAE: 0.1227,
                            Val Loss: 0.1904, Val MAE: 0.1902
2023-01-27 04:11:23,460:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-27 04:24:05,201:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.74s, LR: 0.00004, Train Loss: 0.1208, Train MAE: 0.1208,
                            Val Loss: 0.2028, Val MAE: 0.2027
2023-01-27 04:24:05,203:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-27 04:36:46,158:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.95s, LR: 0.00004, Train Loss: 0.1206, Train MAE: 0.1206,
                            Val Loss: 0.2175, Val MAE: 0.2174
2023-01-27 04:36:46,159:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-27 04:49:26,876:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.72s, LR: 0.00004, Train Loss: 0.1205, Train MAE: 0.1205,
                            Val Loss: 0.1746, Val MAE: 0.1744
2023-01-27 04:49:26,878:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-27 05:02:08,301:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 761.42s, LR: 0.00004, Train Loss: 0.1204, Train MAE: 0.1204,
                            Val Loss: 0.2431, Val MAE: 0.2431
2023-01-27 05:02:08,302:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-27 05:14:48,750:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.45s, LR: 0.00004, Train Loss: 0.1203, Train MAE: 0.1203,
                            Val Loss: 0.1984, Val MAE: 0.1983
2023-01-27 05:14:48,751:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-27 05:27:29,043:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.29s, LR: 0.00004, Train Loss: 0.1202, Train MAE: 0.1202,
                            Val Loss: 0.1924, Val MAE: 0.1923
2023-01-27 05:27:29,044:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-27 05:40:11,437:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 762.39s, LR: 0.00004, Train Loss: 0.1202, Train MAE: 0.1202,
                            Val Loss: 0.1824, Val MAE: 0.1822
2023-01-27 05:40:11,438:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-27 05:52:52,355:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.92s, LR: 0.00004, Train Loss: 0.1201, Train MAE: 0.1201,
                            Val Loss: 0.2017, Val MAE: 0.2015
2023-01-27 05:52:52,357:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-27 05:52:52,358:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-27 06:01:48,989:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.2015
2023-01-27 06:01:48,991:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.1724
2023-01-27 06:01:48,992:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-27 06:01:48,993:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 106.0000
2023-01-27 06:01:48,994:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87180.0755s
2023-01-27 06:01:48,996:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 771.7299s
2023-01-27 06:01:49,015:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-20initials-trials', 'job_num': 32}
2023-01-27 06:01:49,016:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.1724)]
2023-01-27 06:01:49,016:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.2015)]
