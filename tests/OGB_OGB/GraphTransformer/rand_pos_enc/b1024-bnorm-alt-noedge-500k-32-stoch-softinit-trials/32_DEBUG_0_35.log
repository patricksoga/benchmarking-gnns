2023-01-23 19:38:33,789:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2023-01-23 19:38:33,790:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 19:49:52,560:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 19:50:30,856:ogbdata.py:332 -             __init__(): Time taken: 717.0664s
2023-01-23 19:50:30,857:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 19:50:30,857:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 19:50:30,857:ogbdata.py:348 -             __init__(): [I] Data load time: 717.0670s
2023-01-23 19:50:30,857:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials/32_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-23 19:50:30,857:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials', 'job_num': 32}
2023-01-23 19:50:30,864:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 19:50:32,394:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 19:50:32,394:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 19:50:32,394:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 19:50:32,410:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 19:50:32,413:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-23 19:50:32,413:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-23 19:50:32,414:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 19:50:32,414:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 19:50:32,414:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 19:50:32,414:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 19:50:32,438:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-23 21:04:47,678:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4455.264283895493
2023-01-23 21:04:47,697:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-23 21:04:47,697:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-23 21:04:47,704:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-23 21:20:34,193:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.7527095675468445
2023-01-23 21:20:34,195:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 946.49s, LR: 0.00070, Train Loss: 0.5848, Train MAE: 0.5848,
                            Val Loss: 0.7525, Val MAE: 0.7527
2023-01-23 21:20:34,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-23 21:33:47,666:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 793.47s, LR: 0.00070, Train Loss: 0.4038, Train MAE: 0.4038,
                            Val Loss: 1.5177, Val MAE: 1.5176
2023-01-23 21:33:47,667:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-23 21:47:28,520:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 820.85s, LR: 0.00070, Train Loss: 0.3480, Train MAE: 0.3480,
                            Val Loss: 1.1287, Val MAE: 1.1286
2023-01-23 21:47:28,522:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-23 22:01:00,266:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 811.74s, LR: 0.00070, Train Loss: 0.3416, Train MAE: 0.3416,
                            Val Loss: 0.9669, Val MAE: 0.9668
2023-01-23 22:01:00,267:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-23 22:14:12,649:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 792.38s, LR: 0.00070, Train Loss: 0.3725, Train MAE: 0.3725,
                            Val Loss: 2.0413, Val MAE: 2.0407
2023-01-23 22:14:12,651:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-23 22:27:13,256:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.60s, LR: 0.00070, Train Loss: 0.3638, Train MAE: 0.3638,
                            Val Loss: 2.0550, Val MAE: 2.0549
2023-01-23 22:27:13,257:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-23 22:40:15,975:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.72s, LR: 0.00070, Train Loss: 0.3488, Train MAE: 0.3488,
                            Val Loss: 2.4290, Val MAE: 2.4290
2023-01-23 22:40:15,976:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-23 22:54:40,481:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 864.50s, LR: 0.00070, Train Loss: 0.3261, Train MAE: 0.3261,
                            Val Loss: 2.5542, Val MAE: 2.5541
2023-01-23 22:54:40,483:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-23 23:08:09,912:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 809.43s, LR: 0.00070, Train Loss: 0.3079, Train MAE: 0.3079,
                            Val Loss: 1.1635, Val MAE: 1.1634
2023-01-23 23:08:09,913:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-23 23:21:18,092:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 788.18s, LR: 0.00070, Train Loss: 0.2940, Train MAE: 0.2940,
                            Val Loss: 1.6818, Val MAE: 1.6815
2023-01-23 23:21:18,094:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-23 23:34:19,555:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 781.46s, LR: 0.00070, Train Loss: 0.2888, Train MAE: 0.2888,
                            Val Loss: 1.1641, Val MAE: 1.1638
2023-01-23 23:34:19,557:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-23 23:47:23,170:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.61s, LR: 0.00070, Train Loss: 0.2878, Train MAE: 0.2878,
                            Val Loss: 2.0257, Val MAE: 2.0257
2023-01-23 23:47:23,172:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-24 00:00:25,446:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.27s, LR: 0.00070, Train Loss: 0.2915, Train MAE: 0.2915,
                            Val Loss: 2.5193, Val MAE: 2.5189
2023-01-24 00:00:25,448:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-24 00:13:27,534:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.08s, LR: 0.00070, Train Loss: 0.2836, Train MAE: 0.2836,
                            Val Loss: 1.5328, Val MAE: 1.5328
2023-01-24 00:13:27,536:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-24 00:26:30,371:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.83s, LR: 0.00070, Train Loss: 0.2757, Train MAE: 0.2757,
                            Val Loss: 1.8593, Val MAE: 1.8594
2023-01-24 00:26:30,372:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-24 00:39:33,278:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.90s, LR: 0.00070, Train Loss: 0.2690, Train MAE: 0.2690,
                            Val Loss: 2.3414, Val MAE: 2.3409
2023-01-24 00:39:33,280:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-24 00:52:35,815:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.53s, LR: 0.00070, Train Loss: 0.2678, Train MAE: 0.2678,
                            Val Loss: 2.8832, Val MAE: 2.8827
2023-01-24 00:52:35,817:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-24 01:05:47,228:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 791.41s, LR: 0.00035, Train Loss: 0.2509, Train MAE: 0.2509,
                            Val Loss: 1.0124, Val MAE: 1.0125
2023-01-24 01:05:47,230:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-24 01:19:41,186:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 833.95s, LR: 0.00035, Train Loss: 0.2470, Train MAE: 0.2470,
                            Val Loss: 1.5217, Val MAE: 1.5218
2023-01-24 01:19:41,188:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-24 01:33:11,134:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 809.94s, LR: 0.00035, Train Loss: 0.2435, Train MAE: 0.2435,
                            Val Loss: 2.1237, Val MAE: 2.1235
2023-01-24 01:33:11,135:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-24 01:46:26,498:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 795.36s, LR: 0.00035, Train Loss: 0.2403, Train MAE: 0.2403,
                            Val Loss: 1.7030, Val MAE: 1.7032
2023-01-24 01:46:26,500:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-24 01:59:46,982:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.413834810256958
2023-01-24 01:59:46,984:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 800.48s, LR: 0.00035, Train Loss: 0.2370, Train MAE: 0.2370,
                            Val Loss: 0.4138, Val MAE: 0.4138
2023-01-24 01:59:46,985:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-24 02:13:12,822:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 805.83s, LR: 0.00035, Train Loss: 0.2350, Train MAE: 0.2350,
                            Val Loss: 1.6328, Val MAE: 1.6324
2023-01-24 02:13:12,823:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-24 02:27:44,505:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 871.68s, LR: 0.00035, Train Loss: 0.2320, Train MAE: 0.2320,
                            Val Loss: 0.7022, Val MAE: 0.7023
2023-01-24 02:27:44,507:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-24 02:40:55,997:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 791.49s, LR: 0.00035, Train Loss: 0.2329, Train MAE: 0.2329,
                            Val Loss: 2.0161, Val MAE: 2.0162
2023-01-24 02:40:55,998:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-24 02:54:07,073:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 791.07s, LR: 0.00035, Train Loss: 0.2320, Train MAE: 0.2320,
                            Val Loss: 0.6623, Val MAE: 0.6620
2023-01-24 02:54:07,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-24 03:07:11,015:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.94s, LR: 0.00035, Train Loss: 0.2322, Train MAE: 0.2322,
                            Val Loss: 1.2442, Val MAE: 1.2442
2023-01-24 03:07:11,016:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-24 03:20:14,345:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.33s, LR: 0.00035, Train Loss: 0.2274, Train MAE: 0.2274,
                            Val Loss: 0.4613, Val MAE: 0.4612
2023-01-24 03:20:14,346:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-24 03:33:41,062:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 806.71s, LR: 0.00035, Train Loss: 0.2275, Train MAE: 0.2275,
                            Val Loss: 1.7069, Val MAE: 1.7068
2023-01-24 03:33:41,064:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-24 03:47:11,800:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 810.74s, LR: 0.00035, Train Loss: 0.2277, Train MAE: 0.2277,
                            Val Loss: 2.0659, Val MAE: 2.0660
2023-01-24 03:47:11,802:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-24 04:00:35,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 803.72s, LR: 0.00035, Train Loss: 0.2258, Train MAE: 0.2258,
                            Val Loss: 1.4891, Val MAE: 1.4891
2023-01-24 04:00:35,526:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-24 04:14:24,954:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 829.43s, LR: 0.00035, Train Loss: 0.2242, Train MAE: 0.2242,
                            Val Loss: 1.5342, Val MAE: 1.5344
2023-01-24 04:14:24,956:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-24 04:27:27,176:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 782.22s, LR: 0.00035, Train Loss: 0.2235, Train MAE: 0.2235,
                            Val Loss: 0.4636, Val MAE: 0.4635
2023-01-24 04:27:27,176:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-24 04:40:40,632:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 793.46s, LR: 0.00035, Train Loss: 0.2213, Train MAE: 0.2213,
                            Val Loss: 2.1823, Val MAE: 2.1821
2023-01-24 04:40:40,634:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-24 04:53:39,807:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.17s, LR: 0.00035, Train Loss: 0.3337, Train MAE: 0.3337,
                            Val Loss: 0.9818, Val MAE: 0.9820
2023-01-24 04:53:39,808:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-24 05:06:39,691:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.88s, LR: 0.00035, Train Loss: 0.3686, Train MAE: 0.3686,
                            Val Loss: 1.9894, Val MAE: 1.9893
2023-01-24 05:06:39,693:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-24 05:19:39,398:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.70s, LR: 0.00035, Train Loss: 0.3652, Train MAE: 0.3652,
                            Val Loss: 1.9463, Val MAE: 1.9459
2023-01-24 05:19:39,400:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-24 05:32:39,322:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.92s, LR: 0.00035, Train Loss: 0.3409, Train MAE: 0.3409,
                            Val Loss: 1.8850, Val MAE: 1.8849
2023-01-24 05:32:39,323:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-24 05:45:38,593:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.27s, LR: 0.00017, Train Loss: 0.3173, Train MAE: 0.3173,
                            Val Loss: 1.7378, Val MAE: 1.7378
2023-01-24 05:45:38,594:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-24 05:58:37,841:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.25s, LR: 0.00017, Train Loss: 0.3069, Train MAE: 0.3069,
                            Val Loss: 4.3997, Val MAE: 4.3994
2023-01-24 05:58:37,842:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-24 06:12:39,099:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 841.25s, LR: 0.00017, Train Loss: 0.2968, Train MAE: 0.2968,
                            Val Loss: 3.9739, Val MAE: 3.9735
2023-01-24 06:12:39,100:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-24 06:25:39,348:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 780.25s, LR: 0.00017, Train Loss: 0.2900, Train MAE: 0.2900,
                            Val Loss: 2.0791, Val MAE: 2.0787
2023-01-24 06:25:39,350:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-24 06:38:37,952:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.60s, LR: 0.00017, Train Loss: 0.2843, Train MAE: 0.2843,
                            Val Loss: 2.3108, Val MAE: 2.3102
2023-01-24 06:38:37,954:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-24 06:51:37,277:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.32s, LR: 0.00017, Train Loss: 0.2767, Train MAE: 0.2767,
                            Val Loss: 2.0139, Val MAE: 2.0134
2023-01-24 06:51:37,278:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-24 07:04:35,776:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.50s, LR: 0.00017, Train Loss: 0.2697, Train MAE: 0.2697,
                            Val Loss: 1.9870, Val MAE: 1.9864
2023-01-24 07:04:35,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-24 07:17:34,358:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.58s, LR: 0.00017, Train Loss: 0.2638, Train MAE: 0.2638,
                            Val Loss: 2.1218, Val MAE: 2.1216
2023-01-24 07:17:34,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-24 07:30:33,213:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.85s, LR: 0.00017, Train Loss: 0.2589, Train MAE: 0.2589,
                            Val Loss: 0.7078, Val MAE: 0.7079
2023-01-24 07:30:33,214:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-24 07:43:31,311:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.10s, LR: 0.00017, Train Loss: 0.2549, Train MAE: 0.2549,
                            Val Loss: 0.9965, Val MAE: 0.9962
2023-01-24 07:43:31,312:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-24 07:56:27,953:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.64s, LR: 0.00017, Train Loss: 0.2533, Train MAE: 0.2533,
                            Val Loss: 1.4129, Val MAE: 1.4131
2023-01-24 07:56:27,954:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-24 08:09:26,970:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.01s, LR: 0.00017, Train Loss: 0.2526, Train MAE: 0.2526,
                            Val Loss: 2.1061, Val MAE: 2.1063
2023-01-24 08:09:26,971:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-24 08:22:24,592:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.62s, LR: 0.00017, Train Loss: 0.2513, Train MAE: 0.2513,
                            Val Loss: 1.5904, Val MAE: 1.5905
2023-01-24 08:22:24,593:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-24 08:35:21,373:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.78s, LR: 0.00017, Train Loss: 0.2475, Train MAE: 0.2475,
                            Val Loss: 2.1746, Val MAE: 2.1745
2023-01-24 08:35:21,374:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-24 08:48:19,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.74s, LR: 0.00017, Train Loss: 0.2447, Train MAE: 0.2447,
                            Val Loss: 1.0091, Val MAE: 1.0089
2023-01-24 08:48:19,117:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-24 09:01:16,522:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.40s, LR: 0.00017, Train Loss: 0.2462, Train MAE: 0.2462,
                            Val Loss: 1.5861, Val MAE: 1.5862
2023-01-24 09:01:16,523:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-24 09:14:12,801:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.28s, LR: 0.00009, Train Loss: 0.2403, Train MAE: 0.2403,
                            Val Loss: 1.4392, Val MAE: 1.4394
2023-01-24 09:14:12,803:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-24 09:27:10,005:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.20s, LR: 0.00009, Train Loss: 0.2373, Train MAE: 0.2373,
                            Val Loss: 1.6548, Val MAE: 1.6548
2023-01-24 09:27:10,006:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-24 09:40:07,155:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.15s, LR: 0.00009, Train Loss: 0.2370, Train MAE: 0.2370,
                            Val Loss: 2.7478, Val MAE: 2.7476
2023-01-24 09:40:07,156:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-24 09:54:06,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 839.23s, LR: 0.00009, Train Loss: 0.2362, Train MAE: 0.2362,
                            Val Loss: 0.8501, Val MAE: 0.8500
2023-01-24 09:54:06,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-24 10:07:04,701:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.31s, LR: 0.00009, Train Loss: 0.2345, Train MAE: 0.2345,
                            Val Loss: 1.4583, Val MAE: 1.4584
2023-01-24 10:07:04,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-24 10:20:02,947:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.24s, LR: 0.00009, Train Loss: 0.2343, Train MAE: 0.2343,
                            Val Loss: 0.6907, Val MAE: 0.6906
2023-01-24 10:20:02,949:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-24 10:33:01,872:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.92s, LR: 0.00009, Train Loss: 0.2330, Train MAE: 0.2330,
                            Val Loss: 0.8165, Val MAE: 0.8164
2023-01-24 10:33:01,873:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-24 10:45:59,876:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.00s, LR: 0.00009, Train Loss: 0.2313, Train MAE: 0.2313,
                            Val Loss: 0.8313, Val MAE: 0.8316
2023-01-24 10:45:59,877:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-24 10:58:57,465:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.59s, LR: 0.00009, Train Loss: 0.2308, Train MAE: 0.2308,
                            Val Loss: 1.8232, Val MAE: 1.8234
2023-01-24 10:58:57,466:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-24 11:11:56,775:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.31s, LR: 0.00009, Train Loss: 0.2289, Train MAE: 0.2289,
                            Val Loss: 0.5256, Val MAE: 0.5255
2023-01-24 11:11:56,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-24 11:24:54,682:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.26750168204307556
2023-01-24 11:24:54,684:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.91s, LR: 0.00009, Train Loss: 0.2284, Train MAE: 0.2284,
                            Val Loss: 0.2677, Val MAE: 0.2675
2023-01-24 11:24:54,684:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-24 11:37:51,941:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.26s, LR: 0.00009, Train Loss: 0.2275, Train MAE: 0.2275,
                            Val Loss: 1.1751, Val MAE: 1.1749
2023-01-24 11:37:51,942:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-24 11:50:50,340:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.40s, LR: 0.00009, Train Loss: 0.2275, Train MAE: 0.2275,
                            Val Loss: 0.4256, Val MAE: 0.4256
2023-01-24 11:50:50,341:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-24 12:03:47,251:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.91s, LR: 0.00009, Train Loss: 0.2273, Train MAE: 0.2273,
                            Val Loss: 0.9052, Val MAE: 0.9051
2023-01-24 12:03:47,252:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-24 12:16:43,583:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.33s, LR: 0.00009, Train Loss: 0.2272, Train MAE: 0.2272,
                            Val Loss: 1.2359, Val MAE: 1.2361
2023-01-24 12:16:43,584:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-24 12:29:40,447:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.86s, LR: 0.00009, Train Loss: 0.2249, Train MAE: 0.2249,
                            Val Loss: 0.7040, Val MAE: 0.7041
2023-01-24 12:29:40,448:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-24 12:42:37,072:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.62s, LR: 0.00009, Train Loss: 0.2247, Train MAE: 0.2247,
                            Val Loss: 1.0317, Val MAE: 1.0318
2023-01-24 12:42:37,073:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-24 12:55:35,111:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.04s, LR: 0.00009, Train Loss: 0.2255, Train MAE: 0.2255,
                            Val Loss: 0.7971, Val MAE: 0.7972
2023-01-24 12:55:35,112:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-24 13:08:39,358:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 784.24s, LR: 0.00009, Train Loss: 0.2240, Train MAE: 0.2240,
                            Val Loss: 1.1028, Val MAE: 1.1030
2023-01-24 13:08:39,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-24 13:21:36,543:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.18s, LR: 0.00009, Train Loss: 0.2249, Train MAE: 0.2249,
                            Val Loss: 1.5085, Val MAE: 1.5081
2023-01-24 13:21:36,545:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-24 13:35:36,064:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 839.52s, LR: 0.00009, Train Loss: 0.2231, Train MAE: 0.2231,
                            Val Loss: 0.9407, Val MAE: 0.9404
2023-01-24 13:35:36,065:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-24 13:49:22,641:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 826.58s, LR: 0.00009, Train Loss: 0.2223, Train MAE: 0.2223,
                            Val Loss: 1.0817, Val MAE: 1.0815
2023-01-24 13:49:22,643:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-24 14:03:02,498:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 819.85s, LR: 0.00009, Train Loss: 0.2217, Train MAE: 0.2217,
                            Val Loss: 1.1725, Val MAE: 1.1727
2023-01-24 14:03:02,499:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-24 14:15:58,740:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.24s, LR: 0.00009, Train Loss: 0.2225, Train MAE: 0.2225,
                            Val Loss: 1.8359, Val MAE: 1.8362
2023-01-24 14:15:58,741:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-24 14:28:58,239:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.50s, LR: 0.00009, Train Loss: 0.2225, Train MAE: 0.2225,
                            Val Loss: 0.5954, Val MAE: 0.5955
2023-01-24 14:28:58,239:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-24 14:42:21,454:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 803.21s, LR: 0.00009, Train Loss: 0.2218, Train MAE: 0.2218,
                            Val Loss: 1.6692, Val MAE: 1.6694
2023-01-24 14:42:21,455:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-24 14:55:17,829:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.37s, LR: 0.00009, Train Loss: 0.2203, Train MAE: 0.2203,
                            Val Loss: 0.5266, Val MAE: 0.5264
2023-01-24 14:55:17,830:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-24 15:08:35,426:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 797.60s, LR: 0.00004, Train Loss: 0.2176, Train MAE: 0.2176,
                            Val Loss: 1.3252, Val MAE: 1.3254
2023-01-24 15:08:35,428:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-24 15:21:44,542:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 789.11s, LR: 0.00004, Train Loss: 0.2170, Train MAE: 0.2170,
                            Val Loss: 1.4011, Val MAE: 1.4014
2023-01-24 15:21:44,544:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-24 15:34:47,987:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 783.44s, LR: 0.00004, Train Loss: 0.2166, Train MAE: 0.2166,
                            Val Loss: 0.3758, Val MAE: 0.3757
2023-01-24 15:34:47,988:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-24 15:48:09,721:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 801.73s, LR: 0.00004, Train Loss: 0.2162, Train MAE: 0.2162,
                            Val Loss: 1.5038, Val MAE: 1.5040
2023-01-24 15:48:09,722:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-24 16:01:34,302:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 804.58s, LR: 0.00004, Train Loss: 0.2156, Train MAE: 0.2156,
                            Val Loss: 0.3883, Val MAE: 0.3883
2023-01-24 16:01:34,304:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-24 16:14:55,417:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 801.11s, LR: 0.00004, Train Loss: 0.2169, Train MAE: 0.2169,
                            Val Loss: 0.4372, Val MAE: 0.4372
2023-01-24 16:14:55,418:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-24 16:28:19,420:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 804.00s, LR: 0.00004, Train Loss: 0.2168, Train MAE: 0.2168,
                            Val Loss: 1.2278, Val MAE: 1.2280
2023-01-24 16:28:19,421:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-24 16:41:27,147:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 787.73s, LR: 0.00004, Train Loss: 0.2164, Train MAE: 0.2164,
                            Val Loss: 0.9428, Val MAE: 0.9429
2023-01-24 16:41:27,149:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-24 16:54:26,777:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.63s, LR: 0.00004, Train Loss: 0.2155, Train MAE: 0.2155,
                            Val Loss: 0.9279, Val MAE: 0.9277
2023-01-24 16:54:26,778:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-24 17:07:50,199:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 803.42s, LR: 0.00004, Train Loss: 0.2153, Train MAE: 0.2153,
                            Val Loss: 0.5445, Val MAE: 0.5443
2023-01-24 17:07:50,200:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-24 17:21:46,460:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 836.26s, LR: 0.00004, Train Loss: 0.2153, Train MAE: 0.2153,
                            Val Loss: 0.7784, Val MAE: 0.7785
2023-01-24 17:21:46,462:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-24 17:34:45,985:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 779.52s, LR: 0.00004, Train Loss: 0.2154, Train MAE: 0.2154,
                            Val Loss: 1.2347, Val MAE: 1.2350
2023-01-24 17:34:45,986:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-24 17:47:43,157:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 777.17s, LR: 0.00004, Train Loss: 0.2148, Train MAE: 0.2148,
                            Val Loss: 0.2792, Val MAE: 0.2791
2023-01-24 17:47:43,158:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-24 18:00:38,382:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 775.22s, LR: 0.00004, Train Loss: 0.2141, Train MAE: 0.2141,
                            Val Loss: 0.9981, Val MAE: 0.9982
2023-01-24 18:00:38,384:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-24 18:13:34,430:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.04s, LR: 0.00004, Train Loss: 0.2137, Train MAE: 0.2137,
                            Val Loss: 0.3834, Val MAE: 0.3834
2023-01-24 18:13:34,431:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-24 18:26:31,000:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 776.57s, LR: 0.00004, Train Loss: 0.2161, Train MAE: 0.2161,
                            Val Loss: 2.1283, Val MAE: 2.1282
2023-01-24 18:26:31,001:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-24 18:39:24,842:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2570367753505707
2023-01-24 18:39:24,844:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 773.84s, LR: 0.00002, Train Loss: 0.2133, Train MAE: 0.2133,
                            Val Loss: 0.2572, Val MAE: 0.2570
2023-01-24 18:39:24,845:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-24 18:52:18,399:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 773.55s, LR: 0.00002, Train Loss: 0.2126, Train MAE: 0.2126,
                            Val Loss: 0.8799, Val MAE: 0.8800
2023-01-24 18:52:18,400:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-24 19:05:12,966:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.239177867770195
2023-01-24 19:05:12,968:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.57s, LR: 0.00002, Train Loss: 0.2122, Train MAE: 0.2122,
                            Val Loss: 0.2393, Val MAE: 0.2392
2023-01-24 19:05:12,969:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-24 19:18:06,976:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.01s, LR: 0.00002, Train Loss: 0.2119, Train MAE: 0.2119,
                            Val Loss: 1.1487, Val MAE: 1.1488
2023-01-24 19:18:06,977:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-24 19:31:00,205:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 773.23s, LR: 0.00002, Train Loss: 0.2117, Train MAE: 0.2117,
                            Val Loss: 1.5960, Val MAE: 1.5962
2023-01-24 19:31:00,206:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-24 19:43:53,585:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 773.38s, LR: 0.00002, Train Loss: 0.2113, Train MAE: 0.2113,
                            Val Loss: 1.1859, Val MAE: 1.1861
2023-01-24 19:43:53,587:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-24 19:56:47,109:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 773.52s, LR: 0.00002, Train Loss: 0.2115, Train MAE: 0.2115,
                            Val Loss: 0.9296, Val MAE: 0.9297
2023-01-24 19:56:47,110:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-24 19:56:47,112:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-24 20:06:05,214:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.9297
2023-01-24 20:06:05,215:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.9325
2023-01-24 20:06:05,216:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-24 20:06:05,218:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 103.0000
2023-01-24 20:06:05,219:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87332.8055s
2023-01-24 20:06:05,220:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 791.5319s
2023-01-24 20:06:05,224:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials', 'job_num': 32}
2023-01-24 20:06:05,225:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.9325)]
2023-01-24 20:06:05,225:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.9297)]
