2023-01-23 22:37:37,352:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-23 22:37:37,352:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 22:52:56,970:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 22:53:33,038:ogbdata.py:332 -             __init__(): Time taken: 955.6863s
2023-01-23 22:53:33,039:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 22:53:33,039:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 22:53:33,039:ogbdata.py:348 -             __init__(): [I] Data load time: 955.6870s
2023-01-23 22:53:33,039:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials/32_DEBUG_0_41.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [41]}
2023-01-23 22:53:33,039:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials', 'job_num': 32}
2023-01-23 22:53:33,044:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 22:53:47,924:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 22:53:47,924:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 22:53:47,925:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 22:53:47,966:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 22:53:47,981:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-23 22:53:47,981:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2023-01-23 22:53:47,981:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 22:53:47,982:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 22:53:47,982:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 22:53:47,982:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 22:53:48,036:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-24 00:06:54,023:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4386.041262149811
2023-01-24 00:06:54,201:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-24 00:06:54,201:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-24 00:06:54,214:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-24 00:22:29,921:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.0665720701217651
2023-01-24 00:22:29,942:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 935.73s, LR: 0.00070, Train Loss: 0.5575, Train MAE: 0.5575,
                            Val Loss: 1.0667, Val MAE: 1.0666
2023-01-24 00:22:29,942:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-24 00:35:01,134:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 751.19s, LR: 0.00070, Train Loss: 0.3853, Train MAE: 0.3853,
                            Val Loss: 14.3134, Val MAE: 14.3122
2023-01-24 00:35:01,136:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-24 00:46:52,463:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 711.33s, LR: 0.00070, Train Loss: 0.4353, Train MAE: 0.4353,
                            Val Loss: 1.1380, Val MAE: 1.1378
2023-01-24 00:46:52,465:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-24 00:58:36,442:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.0597842931747437
2023-01-24 00:58:36,445:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.98s, LR: 0.00070, Train Loss: 0.5430, Train MAE: 0.5430,
                            Val Loss: 1.0598, Val MAE: 1.0598
2023-01-24 00:58:36,446:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-24 01:10:24,639:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.19s, LR: 0.00070, Train Loss: 0.3793, Train MAE: 0.3793,
                            Val Loss: 1.8268, Val MAE: 1.8267
2023-01-24 01:10:24,641:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-24 01:22:03,204:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.56s, LR: 0.00070, Train Loss: 0.3743, Train MAE: 0.3743,
                            Val Loss: 3.4565, Val MAE: 3.4563
2023-01-24 01:22:03,205:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-24 01:33:39,847:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.64s, LR: 0.00070, Train Loss: 0.3614, Train MAE: 0.3614,
                            Val Loss: 2.2417, Val MAE: 2.2415
2023-01-24 01:33:39,848:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-24 01:46:26,742:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 766.89s, LR: 0.00070, Train Loss: 0.3461, Train MAE: 0.3461,
                            Val Loss: 3.6382, Val MAE: 3.6379
2023-01-24 01:46:26,743:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-24 01:57:54,291:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9080945253372192
2023-01-24 01:57:54,293:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.55s, LR: 0.00070, Train Loss: 0.3365, Train MAE: 0.3365,
                            Val Loss: 0.9081, Val MAE: 0.9081
2023-01-24 01:57:54,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-24 02:09:31,987:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.69s, LR: 0.00070, Train Loss: 0.3218, Train MAE: 0.3218,
                            Val Loss: 1.6715, Val MAE: 1.6713
2023-01-24 02:09:31,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-24 02:21:03,523:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.53s, LR: 0.00070, Train Loss: 0.3329, Train MAE: 0.3329,
                            Val Loss: 0.9491, Val MAE: 0.9490
2023-01-24 02:21:03,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-24 02:32:36,869:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.34s, LR: 0.00070, Train Loss: 0.3260, Train MAE: 0.3260,
                            Val Loss: 1.4344, Val MAE: 1.4340
2023-01-24 02:32:36,870:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-24 02:44:16,938:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.07s, LR: 0.00070, Train Loss: 0.3143, Train MAE: 0.3143,
                            Val Loss: 2.8342, Val MAE: 2.8339
2023-01-24 02:44:16,949:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-24 02:56:57,193:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 760.24s, LR: 0.00070, Train Loss: 0.2997, Train MAE: 0.2997,
                            Val Loss: 2.6849, Val MAE: 2.6846
2023-01-24 02:56:57,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-24 03:09:18,328:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 741.13s, LR: 0.00070, Train Loss: 0.2968, Train MAE: 0.2968,
                            Val Loss: 3.3701, Val MAE: 3.3698
2023-01-24 03:09:18,330:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-24 03:21:38,928:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.60s, LR: 0.00070, Train Loss: 0.3052, Train MAE: 0.3052,
                            Val Loss: 1.5522, Val MAE: 1.5521
2023-01-24 03:21:38,929:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-24 03:33:49,472:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.54s, LR: 0.00070, Train Loss: 0.2863, Train MAE: 0.2863,
                            Val Loss: 1.2924, Val MAE: 1.2923
2023-01-24 03:33:49,473:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-24 03:45:35,166:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.69s, LR: 0.00070, Train Loss: 0.2821, Train MAE: 0.2821,
                            Val Loss: 1.3212, Val MAE: 1.3211
2023-01-24 03:45:35,167:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-24 03:57:07,300:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.13s, LR: 0.00070, Train Loss: 0.2780, Train MAE: 0.2780,
                            Val Loss: 1.5282, Val MAE: 1.5281
2023-01-24 03:57:07,301:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-24 04:08:48,552:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.25s, LR: 0.00070, Train Loss: 0.2739, Train MAE: 0.2739,
                            Val Loss: 2.0596, Val MAE: 2.0595
2023-01-24 04:08:48,554:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-24 04:20:20,895:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.8318854570388794
2023-01-24 04:20:20,898:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.34s, LR: 0.00070, Train Loss: 0.2707, Train MAE: 0.2707,
                            Val Loss: 0.8319, Val MAE: 0.8319
2023-01-24 04:20:20,898:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-24 04:31:54,376:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.48s, LR: 0.00070, Train Loss: 0.2618, Train MAE: 0.2618,
                            Val Loss: 1.8623, Val MAE: 1.8621
2023-01-24 04:31:54,377:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-24 04:43:23,846:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.47s, LR: 0.00070, Train Loss: 0.2608, Train MAE: 0.2608,
                            Val Loss: 2.3448, Val MAE: 2.3448
2023-01-24 04:43:23,847:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-24 04:56:07,965:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.12s, LR: 0.00070, Train Loss: 0.2582, Train MAE: 0.2582,
                            Val Loss: 1.3065, Val MAE: 1.3065
2023-01-24 04:56:07,967:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-24 05:07:37,769:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.80s, LR: 0.00070, Train Loss: 0.2560, Train MAE: 0.2560,
                            Val Loss: 2.5328, Val MAE: 2.5328
2023-01-24 05:07:37,770:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-24 05:19:11,260:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.49s, LR: 0.00070, Train Loss: 0.2527, Train MAE: 0.2527,
                            Val Loss: 5.0187, Val MAE: 5.0184
2023-01-24 05:19:11,261:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-24 05:30:43,760:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.50s, LR: 0.00070, Train Loss: 0.2522, Train MAE: 0.2522,
                            Val Loss: 1.7406, Val MAE: 1.7405
2023-01-24 05:30:43,772:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-24 05:42:13,667:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.89s, LR: 0.00070, Train Loss: 0.2514, Train MAE: 0.2514,
                            Val Loss: 0.9564, Val MAE: 0.9564
2023-01-24 05:42:13,668:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-24 05:53:48,080:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.41s, LR: 0.00070, Train Loss: 0.2513, Train MAE: 0.2513,
                            Val Loss: 1.3544, Val MAE: 1.3545
2023-01-24 05:53:48,081:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-24 06:05:20,724:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.64s, LR: 0.00070, Train Loss: 0.2474, Train MAE: 0.2474,
                            Val Loss: 0.9924, Val MAE: 0.9922
2023-01-24 06:05:20,726:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-24 06:16:52,109:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.38s, LR: 0.00070, Train Loss: 0.2486, Train MAE: 0.2486,
                            Val Loss: 1.9015, Val MAE: 1.9013
2023-01-24 06:16:52,110:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-24 06:28:24,560:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.45s, LR: 0.00070, Train Loss: 0.2462, Train MAE: 0.2462,
                            Val Loss: 2.6890, Val MAE: 2.6884
2023-01-24 06:28:24,561:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-24 06:40:01,933:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.37s, LR: 0.00070, Train Loss: 0.2449, Train MAE: 0.2449,
                            Val Loss: 1.9846, Val MAE: 1.9841
2023-01-24 06:40:01,934:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-24 06:51:40,283:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.35s, LR: 0.00070, Train Loss: 0.2462, Train MAE: 0.2462,
                            Val Loss: 1.7141, Val MAE: 1.7137
2023-01-24 06:51:40,284:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-24 07:03:11,927:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.64s, LR: 0.00070, Train Loss: 0.2475, Train MAE: 0.2475,
                            Val Loss: 1.3315, Val MAE: 1.3318
2023-01-24 07:03:11,928:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-24 07:14:55,356:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.43s, LR: 0.00070, Train Loss: 0.4190, Train MAE: 0.4190,
                            Val Loss: 2.1053, Val MAE: 2.1051
2023-01-24 07:14:55,357:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-24 07:27:02,398:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.04s, LR: 0.00070, Train Loss: 0.4022, Train MAE: 0.4022,
                            Val Loss: 0.9414, Val MAE: 0.9414
2023-01-24 07:27:02,549:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-24 07:39:12,358:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 729.81s, LR: 0.00035, Train Loss: 0.3648, Train MAE: 0.3648,
                            Val Loss: 1.1815, Val MAE: 1.1815
2023-01-24 07:39:12,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-24 07:51:19,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.57s, LR: 0.00035, Train Loss: 0.3515, Train MAE: 0.3515,
                            Val Loss: 0.9243, Val MAE: 0.9242
2023-01-24 07:51:19,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-24 08:03:17,876:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.94s, LR: 0.00035, Train Loss: 0.3428, Train MAE: 0.3428,
                            Val Loss: 1.1267, Val MAE: 1.1267
2023-01-24 08:03:17,877:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-24 08:16:28,045:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 790.17s, LR: 0.00035, Train Loss: 0.3367, Train MAE: 0.3367,
                            Val Loss: 0.9070, Val MAE: 0.9069
2023-01-24 08:16:28,045:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-24 08:28:30,972:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.93s, LR: 0.00035, Train Loss: 0.3294, Train MAE: 0.3294,
                            Val Loss: 1.1855, Val MAE: 1.1856
2023-01-24 08:28:30,972:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-24 08:40:03,257:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.28s, LR: 0.00035, Train Loss: 0.3319, Train MAE: 0.3319,
                            Val Loss: 0.9605, Val MAE: 0.9604
2023-01-24 08:40:03,258:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-24 08:51:39,413:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.15s, LR: 0.00035, Train Loss: 0.3209, Train MAE: 0.3209,
                            Val Loss: 1.7849, Val MAE: 1.7848
2023-01-24 08:51:39,415:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-24 09:03:14,019:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.60s, LR: 0.00035, Train Loss: 0.3105, Train MAE: 0.3105,
                            Val Loss: 2.2730, Val MAE: 2.2729
2023-01-24 09:03:14,021:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-24 09:14:49,739:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.72s, LR: 0.00035, Train Loss: 0.3012, Train MAE: 0.3012,
                            Val Loss: 1.6532, Val MAE: 1.6530
2023-01-24 09:14:49,740:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-24 09:26:24,799:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.06s, LR: 0.00035, Train Loss: 0.2936, Train MAE: 0.2936,
                            Val Loss: 2.0874, Val MAE: 2.0874
2023-01-24 09:26:24,800:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-24 09:37:58,785:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.98s, LR: 0.00035, Train Loss: 0.2901, Train MAE: 0.2901,
                            Val Loss: 2.1442, Val MAE: 2.1440
2023-01-24 09:37:58,786:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-24 09:49:35,448:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.66s, LR: 0.00035, Train Loss: 0.2845, Train MAE: 0.2845,
                            Val Loss: 1.6845, Val MAE: 1.6843
2023-01-24 09:49:35,449:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-24 10:01:11,817:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.37s, LR: 0.00035, Train Loss: 0.2800, Train MAE: 0.2800,
                            Val Loss: 4.3846, Val MAE: 4.3843
2023-01-24 10:01:11,818:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-24 10:12:49,497:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.68s, LR: 0.00035, Train Loss: 0.2825, Train MAE: 0.2825,
                            Val Loss: 4.2904, Val MAE: 4.2901
2023-01-24 10:12:49,498:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-24 10:24:26,196:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.70s, LR: 0.00035, Train Loss: 0.4497, Train MAE: 0.4497,
                            Val Loss: 1.1880, Val MAE: 1.1879
2023-01-24 10:24:26,197:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-24 10:35:56,727:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.5128480792045593
2023-01-24 10:35:56,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.53s, LR: 0.00035, Train Loss: 0.4361, Train MAE: 0.4361,
                            Val Loss: 0.5134, Val MAE: 0.5128
2023-01-24 10:35:56,729:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-24 10:47:34,611:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.88s, LR: 0.00035, Train Loss: 0.3756, Train MAE: 0.3756,
                            Val Loss: 1.9737, Val MAE: 1.9737
2023-01-24 10:47:34,613:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-24 10:59:07,186:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.57s, LR: 0.00035, Train Loss: 0.3906, Train MAE: 0.3906,
                            Val Loss: 1.5802, Val MAE: 1.5803
2023-01-24 10:59:07,187:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-24 11:10:39,176:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.99s, LR: 0.00035, Train Loss: 0.4065, Train MAE: 0.4065,
                            Val Loss: 2.0136, Val MAE: 2.0136
2023-01-24 11:10:39,178:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-24 11:22:08,258:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.08s, LR: 0.00035, Train Loss: 0.3653, Train MAE: 0.3653,
                            Val Loss: 1.5266, Val MAE: 1.5266
2023-01-24 11:22:08,259:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-24 11:34:47,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 758.76s, LR: 0.00035, Train Loss: 0.3338, Train MAE: 0.3338,
                            Val Loss: 2.0164, Val MAE: 2.0163
2023-01-24 11:34:47,015:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-24 11:46:23,333:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.32s, LR: 0.00035, Train Loss: 0.3166, Train MAE: 0.3166,
                            Val Loss: 1.7894, Val MAE: 1.7893
2023-01-24 11:46:23,334:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-24 11:57:53,908:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.57s, LR: 0.00035, Train Loss: 0.3093, Train MAE: 0.3093,
                            Val Loss: 1.0571, Val MAE: 1.0569
2023-01-24 11:57:53,909:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-24 12:09:27,023:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.11s, LR: 0.00035, Train Loss: 0.3053, Train MAE: 0.3053,
                            Val Loss: 1.7227, Val MAE: 1.7226
2023-01-24 12:09:27,024:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-24 12:21:34,601:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.58s, LR: 0.00035, Train Loss: 0.2992, Train MAE: 0.2992,
                            Val Loss: 2.4285, Val MAE: 2.4287
2023-01-24 12:21:34,603:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-24 12:33:43,143:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.54s, LR: 0.00035, Train Loss: 0.2906, Train MAE: 0.2906,
                            Val Loss: 3.0035, Val MAE: 3.0027
2023-01-24 12:33:43,145:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-24 12:45:48,250:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.10s, LR: 0.00035, Train Loss: 0.2846, Train MAE: 0.2846,
                            Val Loss: 1.4321, Val MAE: 1.4319
2023-01-24 12:45:48,251:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-24 12:57:54,102:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.85s, LR: 0.00035, Train Loss: 0.2849, Train MAE: 0.2849,
                            Val Loss: 1.9146, Val MAE: 1.9145
2023-01-24 12:57:54,103:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-24 13:09:51,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.61s, LR: 0.00035, Train Loss: 0.2841, Train MAE: 0.2841,
                            Val Loss: 4.9190, Val MAE: 4.9185
2023-01-24 13:09:51,715:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-24 13:21:54,874:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.16s, LR: 0.00035, Train Loss: 0.2772, Train MAE: 0.2772,
                            Val Loss: 3.9369, Val MAE: 3.9366
2023-01-24 13:21:54,876:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-24 13:33:40,557:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.68s, LR: 0.00035, Train Loss: 0.3004, Train MAE: 0.3004,
                            Val Loss: 0.9968, Val MAE: 0.9968
2023-01-24 13:33:40,558:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-24 13:45:17,151:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.59s, LR: 0.00035, Train Loss: 0.2944, Train MAE: 0.2944,
                            Val Loss: 3.0306, Val MAE: 3.0306
2023-01-24 13:45:17,152:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-24 13:56:47,218:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 690.07s, LR: 0.00017, Train Loss: 0.2781, Train MAE: 0.2781,
                            Val Loss: 2.1259, Val MAE: 2.1258
2023-01-24 13:56:47,219:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-24 14:08:22,264:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.04s, LR: 0.00017, Train Loss: 0.2748, Train MAE: 0.2748,
                            Val Loss: 0.9620, Val MAE: 0.9620
2023-01-24 14:08:22,265:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-24 14:19:55,222:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.96s, LR: 0.00017, Train Loss: 0.2736, Train MAE: 0.2736,
                            Val Loss: 2.1777, Val MAE: 2.1770
2023-01-24 14:19:55,223:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-24 14:31:29,334:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.11s, LR: 0.00017, Train Loss: 0.2713, Train MAE: 0.2713,
                            Val Loss: 0.6855, Val MAE: 0.6852
2023-01-24 14:31:29,336:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-24 14:43:05,194:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 695.86s, LR: 0.00017, Train Loss: 0.2661, Train MAE: 0.2661,
                            Val Loss: 1.9093, Val MAE: 1.9093
2023-01-24 14:43:05,195:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-24 14:55:37,576:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 752.38s, LR: 0.00017, Train Loss: 0.2642, Train MAE: 0.2642,
                            Val Loss: 1.0593, Val MAE: 1.0592
2023-01-24 14:55:37,577:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-24 15:07:11,762:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.18s, LR: 0.00017, Train Loss: 0.2640, Train MAE: 0.2640,
                            Val Loss: 1.8049, Val MAE: 1.8047
2023-01-24 15:07:11,763:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-24 15:18:48,474:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.71s, LR: 0.00017, Train Loss: 0.2615, Train MAE: 0.2615,
                            Val Loss: 3.3137, Val MAE: 3.3136
2023-01-24 15:18:48,474:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-24 15:30:18,230:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.75s, LR: 0.00017, Train Loss: 0.2593, Train MAE: 0.2593,
                            Val Loss: 2.1219, Val MAE: 2.1218
2023-01-24 15:30:18,231:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-24 15:41:51,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 693.21s, LR: 0.00017, Train Loss: 0.2603, Train MAE: 0.2603,
                            Val Loss: 1.9081, Val MAE: 1.9080
2023-01-24 15:41:51,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-24 15:53:28,022:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 696.58s, LR: 0.00017, Train Loss: 0.2590, Train MAE: 0.2590,
                            Val Loss: 1.4916, Val MAE: 1.4914
2023-01-24 15:53:28,023:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-24 16:05:02,878:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.85s, LR: 0.00017, Train Loss: 0.2563, Train MAE: 0.2563,
                            Val Loss: 1.2055, Val MAE: 1.2052
2023-01-24 16:05:02,879:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-24 16:16:37,062:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.18s, LR: 0.00017, Train Loss: 0.2549, Train MAE: 0.2549,
                            Val Loss: 0.9593, Val MAE: 0.9591
2023-01-24 16:16:37,064:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-24 16:28:06,542:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.48s, LR: 0.00017, Train Loss: 0.2524, Train MAE: 0.2524,
                            Val Loss: 1.3082, Val MAE: 1.3081
2023-01-24 16:28:06,543:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-24 16:39:26,482:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.94s, LR: 0.00017, Train Loss: 0.2526, Train MAE: 0.2526,
                            Val Loss: 0.6106, Val MAE: 0.6105
2023-01-24 16:39:26,484:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-24 16:50:54,421:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.94s, LR: 0.00017, Train Loss: 0.2507, Train MAE: 0.2507,
                            Val Loss: 0.7192, Val MAE: 0.7190
2023-01-24 16:50:54,422:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-24 17:02:36,372:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 701.95s, LR: 0.00009, Train Loss: 0.2456, Train MAE: 0.2456,
                            Val Loss: 4.1739, Val MAE: 4.1736
2023-01-24 17:02:36,373:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-24 17:14:40,062:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.69s, LR: 0.00009, Train Loss: 0.2461, Train MAE: 0.2461,
                            Val Loss: 4.7440, Val MAE: 4.7436
2023-01-24 17:14:40,064:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-24 17:26:43,495:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.43s, LR: 0.00009, Train Loss: 0.2473, Train MAE: 0.2473,
                            Val Loss: 2.0849, Val MAE: 2.0851
2023-01-24 17:26:43,496:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-24 17:38:45,880:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.38s, LR: 0.00009, Train Loss: 0.2443, Train MAE: 0.2443,
                            Val Loss: 1.9612, Val MAE: 1.9613
2023-01-24 17:38:45,881:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-24 17:50:44,435:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.29888588190078735
2023-01-24 17:50:44,436:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 718.55s, LR: 0.00009, Train Loss: 0.2429, Train MAE: 0.2429,
                            Val Loss: 0.2990, Val MAE: 0.2989
2023-01-24 17:50:44,437:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-24 18:02:09,749:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.31s, LR: 0.00009, Train Loss: 0.2439, Train MAE: 0.2439,
                            Val Loss: 1.8938, Val MAE: 1.8941
2023-01-24 18:02:09,750:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-24 18:14:34,170:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.42s, LR: 0.00009, Train Loss: 0.2440, Train MAE: 0.2440,
                            Val Loss: 2.1164, Val MAE: 2.1159
2023-01-24 18:14:34,171:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-24 18:25:58,700:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.53s, LR: 0.00009, Train Loss: 0.2434, Train MAE: 0.2434,
                            Val Loss: 1.6173, Val MAE: 1.6171
2023-01-24 18:25:58,701:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-24 18:37:20,101:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.40s, LR: 0.00009, Train Loss: 0.2437, Train MAE: 0.2437,
                            Val Loss: 1.7208, Val MAE: 1.7209
2023-01-24 18:37:20,102:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-24 18:48:41,704:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 681.60s, LR: 0.00009, Train Loss: 0.2415, Train MAE: 0.2415,
                            Val Loss: 3.2641, Val MAE: 3.2635
2023-01-24 18:48:41,706:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-24 19:00:05,109:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.40s, LR: 0.00009, Train Loss: 0.2409, Train MAE: 0.2409,
                            Val Loss: 1.8791, Val MAE: 1.8794
2023-01-24 19:00:05,110:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
