2023-01-23 19:38:31,998:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2023-01-23 19:38:31,998:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 19:48:44,134:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 19:49:15,035:ogbdata.py:332 -             __init__(): Time taken: 643.0369s
2023-01-23 19:49:15,035:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 19:49:15,035:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 19:49:15,035:ogbdata.py:348 -             __init__(): [I] Data load time: 643.0373s
2023-01-23 19:49:15,035:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials/32_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-23 19:49:15,035:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials', 'job_num': 32}
2023-01-23 19:49:15,052:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 19:49:16,609:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 19:49:16,609:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 19:49:16,609:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 19:49:16,623:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 19:49:16,625:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-23 19:49:16,625:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-23 19:49:16,626:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 19:49:16,626:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 19:49:16,626:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 19:49:16,626:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 19:49:16,646:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-23 20:57:23,282:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4086.656152486801
2023-01-23 20:57:23,316:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-23 20:57:23,316:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-23 20:57:23,324:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-23 21:12:22,197:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.820725440979004
2023-01-23 21:12:22,198:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 898.87s, LR: 0.00070, Train Loss: 0.5377, Train MAE: 0.5377,
                            Val Loss: 1.8207, Val MAE: 1.8207
2023-01-23 21:12:22,199:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-23 21:25:13,254:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.9908961057662964
2023-01-23 21:25:13,256:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.06s, LR: 0.00070, Train Loss: 0.3539, Train MAE: 0.3539,
                            Val Loss: 0.9907, Val MAE: 0.9909
2023-01-23 21:25:13,257:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-23 21:38:03,110:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.85s, LR: 0.00070, Train Loss: 0.3282, Train MAE: 0.3282,
                            Val Loss: 1.0358, Val MAE: 1.0356
2023-01-23 21:38:03,112:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-23 21:50:53,933:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.538391649723053
2023-01-23 21:50:53,935:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.82s, LR: 0.00070, Train Loss: 0.2960, Train MAE: 0.2960,
                            Val Loss: 0.5386, Val MAE: 0.5384
2023-01-23 21:50:53,936:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-23 22:03:45,085:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.15s, LR: 0.00070, Train Loss: 0.2879, Train MAE: 0.2879,
                            Val Loss: 2.5718, Val MAE: 2.5718
2023-01-23 22:03:45,086:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-23 22:16:35,545:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.46s, LR: 0.00070, Train Loss: 0.2691, Train MAE: 0.2691,
                            Val Loss: 0.7278, Val MAE: 0.7275
2023-01-23 22:16:35,546:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-23 22:29:27,231:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.68s, LR: 0.00070, Train Loss: 0.2652, Train MAE: 0.2652,
                            Val Loss: 1.2593, Val MAE: 1.2588
2023-01-23 22:29:27,233:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-23 22:43:12,817:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 825.58s, LR: 0.00070, Train Loss: 0.2616, Train MAE: 0.2616,
                            Val Loss: 1.4782, Val MAE: 1.4786
2023-01-23 22:43:12,818:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-23 22:56:04,415:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.60s, LR: 0.00070, Train Loss: 0.2538, Train MAE: 0.2538,
                            Val Loss: 0.7395, Val MAE: 0.7395
2023-01-23 22:56:04,416:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-23 23:08:55,532:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.11s, LR: 0.00070, Train Loss: 0.2472, Train MAE: 0.2472,
                            Val Loss: 1.0232, Val MAE: 1.0235
2023-01-23 23:08:55,534:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-23 23:21:47,318:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.78s, LR: 0.00070, Train Loss: 0.2425, Train MAE: 0.2425,
                            Val Loss: 0.9666, Val MAE: 0.9668
2023-01-23 23:21:47,320:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-23 23:34:39,709:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.39s, LR: 0.00070, Train Loss: 0.2374, Train MAE: 0.2374,
                            Val Loss: 1.5508, Val MAE: 1.5504
2023-01-23 23:34:39,710:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-23 23:47:30,704:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.99s, LR: 0.00070, Train Loss: 0.2350, Train MAE: 0.2350,
                            Val Loss: 0.5665, Val MAE: 0.5665
2023-01-23 23:47:30,705:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-24 00:00:22,422:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.72s, LR: 0.00070, Train Loss: 0.2319, Train MAE: 0.2319,
                            Val Loss: 1.5120, Val MAE: 1.5123
2023-01-24 00:00:22,423:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-24 00:13:14,649:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.22s, LR: 0.00070, Train Loss: 0.2314, Train MAE: 0.2314,
                            Val Loss: 1.1078, Val MAE: 1.1079
2023-01-24 00:13:14,650:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-24 00:26:05,664:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.01s, LR: 0.00070, Train Loss: 0.2268, Train MAE: 0.2268,
                            Val Loss: 0.8901, Val MAE: 0.8902
2023-01-24 00:26:05,666:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-24 00:38:58,321:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.523834228515625
2023-01-24 00:38:58,323:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.66s, LR: 0.00070, Train Loss: 0.2220, Train MAE: 0.2220,
                            Val Loss: 0.5241, Val MAE: 0.5238
2023-01-24 00:38:58,324:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-24 00:51:50,431:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.11s, LR: 0.00070, Train Loss: 0.2187, Train MAE: 0.2187,
                            Val Loss: 1.2402, Val MAE: 1.2402
2023-01-24 00:51:50,432:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-24 01:04:41,651:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.22s, LR: 0.00070, Train Loss: 0.2181, Train MAE: 0.2181,
                            Val Loss: 1.6438, Val MAE: 1.6438
2023-01-24 01:04:41,652:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-24 01:17:33,551:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.46232175827026367
2023-01-24 01:17:33,553:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.90s, LR: 0.00070, Train Loss: 0.2182, Train MAE: 0.2182,
                            Val Loss: 0.4624, Val MAE: 0.4623
2023-01-24 01:17:33,553:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-24 01:30:25,367:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.81s, LR: 0.00070, Train Loss: 0.2144, Train MAE: 0.2144,
                            Val Loss: 1.2261, Val MAE: 1.2262
2023-01-24 01:30:25,369:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-24 01:43:16,859:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.49s, LR: 0.00070, Train Loss: 0.2154, Train MAE: 0.2154,
                            Val Loss: 1.4912, Val MAE: 1.4913
2023-01-24 01:43:16,860:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-24 01:56:08,276:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.41s, LR: 0.00070, Train Loss: 0.2146, Train MAE: 0.2146,
                            Val Loss: 1.9539, Val MAE: 1.9542
2023-01-24 01:56:08,277:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-24 02:09:53,195:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 824.92s, LR: 0.00070, Train Loss: 0.2108, Train MAE: 0.2108,
                            Val Loss: 0.6031, Val MAE: 0.6031
2023-01-24 02:09:53,196:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-24 02:22:45,873:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 772.68s, LR: 0.00070, Train Loss: 0.2113, Train MAE: 0.2113,
                            Val Loss: 0.6093, Val MAE: 0.6092
2023-01-24 02:22:45,874:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-24 02:35:36,784:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.91s, LR: 0.00070, Train Loss: 0.2125, Train MAE: 0.2125,
                            Val Loss: 1.6448, Val MAE: 1.6449
2023-01-24 02:35:36,786:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-24 02:48:27,938:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.15s, LR: 0.00070, Train Loss: 0.2086, Train MAE: 0.2086,
                            Val Loss: 0.9759, Val MAE: 0.9759
2023-01-24 02:48:27,940:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-24 03:01:19,503:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.56s, LR: 0.00070, Train Loss: 0.2075, Train MAE: 0.2075,
                            Val Loss: 0.7932, Val MAE: 0.7933
2023-01-24 03:01:19,504:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-24 03:14:09,809:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.30s, LR: 0.00070, Train Loss: 0.2051, Train MAE: 0.2051,
                            Val Loss: 1.2570, Val MAE: 1.2567
2023-01-24 03:14:09,810:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-24 03:27:01,032:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.22s, LR: 0.00070, Train Loss: 0.2052, Train MAE: 0.2052,
                            Val Loss: 0.4890, Val MAE: 0.4889
2023-01-24 03:27:01,033:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-24 03:39:51,485:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.45s, LR: 0.00070, Train Loss: 0.2023, Train MAE: 0.2023,
                            Val Loss: 0.6839, Val MAE: 0.6838
2023-01-24 03:39:51,486:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-24 03:52:42,206:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.72s, LR: 0.00070, Train Loss: 0.2302, Train MAE: 0.2302,
                            Val Loss: 0.5953, Val MAE: 0.5956
2023-01-24 03:52:42,207:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-24 04:05:32,879:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.67s, LR: 0.00070, Train Loss: 0.2143, Train MAE: 0.2143,
                            Val Loss: 1.5984, Val MAE: 1.5986
2023-01-24 04:05:32,880:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-24 04:18:23,786:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.91s, LR: 0.00070, Train Loss: 0.2058, Train MAE: 0.2058,
                            Val Loss: 1.5400, Val MAE: 1.5402
2023-01-24 04:18:23,787:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-24 04:31:14,839:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.05s, LR: 0.00070, Train Loss: 0.2055, Train MAE: 0.2055,
                            Val Loss: 1.0778, Val MAE: 1.0776
2023-01-24 04:31:14,839:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-24 04:44:05,147:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.31s, LR: 0.00070, Train Loss: 0.2036, Train MAE: 0.2036,
                            Val Loss: 0.7855, Val MAE: 0.7852
2023-01-24 04:44:05,149:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-24 04:56:55,427:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.40660300850868225
2023-01-24 04:56:55,429:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.28s, LR: 0.00035, Train Loss: 0.1929, Train MAE: 0.1929,
                            Val Loss: 0.4066, Val MAE: 0.4066
2023-01-24 04:56:55,430:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-24 05:09:46,655:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.22s, LR: 0.00035, Train Loss: 0.1925, Train MAE: 0.1925,
                            Val Loss: 1.2070, Val MAE: 1.2070
2023-01-24 05:09:46,656:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-24 05:22:36,963:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.31s, LR: 0.00035, Train Loss: 0.1898, Train MAE: 0.1898,
                            Val Loss: 1.5078, Val MAE: 1.5080
2023-01-24 05:22:36,964:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-24 05:35:27,168:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.20s, LR: 0.00035, Train Loss: 0.1888, Train MAE: 0.1888,
                            Val Loss: 1.8007, Val MAE: 1.8006
2023-01-24 05:35:27,169:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-24 05:49:11,150:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 823.98s, LR: 0.00035, Train Loss: 0.1894, Train MAE: 0.1894,
                            Val Loss: 1.0014, Val MAE: 1.0015
2023-01-24 05:49:11,152:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-24 06:02:02,087:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.93s, LR: 0.00035, Train Loss: 0.1868, Train MAE: 0.1868,
                            Val Loss: 1.5626, Val MAE: 1.5627
2023-01-24 06:02:02,088:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-24 06:14:52,802:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.71s, LR: 0.00035, Train Loss: 0.1851, Train MAE: 0.1851,
                            Val Loss: 0.6112, Val MAE: 0.6112
2023-01-24 06:14:52,804:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-24 06:27:43,344:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.54s, LR: 0.00035, Train Loss: 0.1850, Train MAE: 0.1850,
                            Val Loss: 0.5667, Val MAE: 0.5667
2023-01-24 06:27:43,345:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-24 06:40:34,030:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.68s, LR: 0.00035, Train Loss: 0.1843, Train MAE: 0.1843,
                            Val Loss: 1.1605, Val MAE: 1.1598
2023-01-24 06:40:34,032:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-24 06:53:25,113:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.35672101378440857
2023-01-24 06:53:25,115:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.08s, LR: 0.00035, Train Loss: 0.1835, Train MAE: 0.1835,
                            Val Loss: 0.3567, Val MAE: 0.3567
2023-01-24 06:53:25,116:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-24 07:06:15,509:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.39s, LR: 0.00035, Train Loss: 0.1841, Train MAE: 0.1841,
                            Val Loss: 0.5793, Val MAE: 0.5794
2023-01-24 07:06:15,510:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-24 07:19:05,966:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.46s, LR: 0.00035, Train Loss: 0.1832, Train MAE: 0.1832,
                            Val Loss: 1.2156, Val MAE: 1.2156
2023-01-24 07:19:05,967:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-24 07:31:56,544:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.58s, LR: 0.00035, Train Loss: 0.1825, Train MAE: 0.1825,
                            Val Loss: 0.7451, Val MAE: 0.7452
2023-01-24 07:31:56,545:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-24 07:44:46,096:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.55s, LR: 0.00035, Train Loss: 0.1816, Train MAE: 0.1816,
                            Val Loss: 0.8652, Val MAE: 0.8649
2023-01-24 07:44:46,098:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-24 07:57:36,359:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.26s, LR: 0.00035, Train Loss: 0.1810, Train MAE: 0.1810,
                            Val Loss: 1.0881, Val MAE: 1.0883
2023-01-24 07:57:36,360:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-24 08:10:26,865:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.50s, LR: 0.00035, Train Loss: 0.1812, Train MAE: 0.1812,
                            Val Loss: 2.0068, Val MAE: 2.0066
2023-01-24 08:10:26,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-24 08:23:16,707:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.84s, LR: 0.00035, Train Loss: 0.1807, Train MAE: 0.1807,
                            Val Loss: 1.5511, Val MAE: 1.5516
2023-01-24 08:23:16,707:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-24 08:36:06,769:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.06s, LR: 0.00035, Train Loss: 0.1797, Train MAE: 0.1797,
                            Val Loss: 1.0803, Val MAE: 1.0803
2023-01-24 08:36:06,770:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-24 08:48:57,730:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.96s, LR: 0.00035, Train Loss: 0.1797, Train MAE: 0.1797,
                            Val Loss: 0.5044, Val MAE: 0.5044
2023-01-24 08:48:57,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-24 09:01:47,644:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.91s, LR: 0.00035, Train Loss: 0.1794, Train MAE: 0.1794,
                            Val Loss: 0.8358, Val MAE: 0.8358
2023-01-24 09:01:47,645:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-24 09:14:38,319:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.67s, LR: 0.00035, Train Loss: 0.1805, Train MAE: 0.1805,
                            Val Loss: 1.8885, Val MAE: 1.8889
2023-01-24 09:14:38,320:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-24 09:28:21,206:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 822.88s, LR: 0.00035, Train Loss: 0.1811, Train MAE: 0.1811,
                            Val Loss: 0.8211, Val MAE: 0.8212
2023-01-24 09:28:21,207:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-24 09:41:11,948:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.74s, LR: 0.00035, Train Loss: 0.1799, Train MAE: 0.1799,
                            Val Loss: 0.6649, Val MAE: 0.6648
2023-01-24 09:41:11,948:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-24 09:54:02,653:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.70s, LR: 0.00035, Train Loss: 0.1804, Train MAE: 0.1804,
                            Val Loss: 1.6431, Val MAE: 1.6432
2023-01-24 09:54:02,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-24 10:06:52,932:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.28s, LR: 0.00035, Train Loss: 0.1799, Train MAE: 0.1799,
                            Val Loss: 1.0961, Val MAE: 1.0962
2023-01-24 10:06:52,933:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-24 10:19:44,006:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.07s, LR: 0.00035, Train Loss: 0.1831, Train MAE: 0.1831,
                            Val Loss: 0.5292, Val MAE: 0.5290
2023-01-24 10:19:44,007:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-24 10:32:35,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 771.33s, LR: 0.00017, Train Loss: 0.1793, Train MAE: 0.1793,
                            Val Loss: 0.9593, Val MAE: 0.9595
2023-01-24 10:32:35,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-24 10:45:25,549:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.21s, LR: 0.00017, Train Loss: 0.1779, Train MAE: 0.1779,
                            Val Loss: 0.5526, Val MAE: 0.5527
2023-01-24 10:45:25,550:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-24 10:58:16,312:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.76s, LR: 0.00017, Train Loss: 0.1768, Train MAE: 0.1768,
                            Val Loss: 1.0394, Val MAE: 1.0394
2023-01-24 10:58:16,313:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-24 11:11:07,068:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.75s, LR: 0.00017, Train Loss: 0.1760, Train MAE: 0.1760,
                            Val Loss: 0.3951, Val MAE: 0.3949
2023-01-24 11:11:07,069:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-24 11:23:56,939:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.87s, LR: 0.00017, Train Loss: 0.1737, Train MAE: 0.1737,
                            Val Loss: 0.3801, Val MAE: 0.3801
2023-01-24 11:23:56,940:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-24 11:36:47,558:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.62s, LR: 0.00017, Train Loss: 0.1735, Train MAE: 0.1735,
                            Val Loss: 0.6712, Val MAE: 0.6715
2023-01-24 11:36:47,559:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-24 11:49:38,317:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.76s, LR: 0.00017, Train Loss: 0.1740, Train MAE: 0.1740,
                            Val Loss: 0.6902, Val MAE: 0.6902
2023-01-24 11:49:38,318:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-24 12:02:27,865:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.55s, LR: 0.00017, Train Loss: 0.1726, Train MAE: 0.1726,
                            Val Loss: 0.4461, Val MAE: 0.4460
2023-01-24 12:02:27,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-24 12:15:17,655:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.79s, LR: 0.00017, Train Loss: 0.1721, Train MAE: 0.1721,
                            Val Loss: 0.6104, Val MAE: 0.6106
2023-01-24 12:15:17,656:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-24 12:28:08,616:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.96s, LR: 0.00017, Train Loss: 0.1746, Train MAE: 0.1746,
                            Val Loss: 0.5298, Val MAE: 0.5299
2023-01-24 12:28:08,618:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-24 12:40:57,657:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.04s, LR: 0.00017, Train Loss: 0.1733, Train MAE: 0.1733,
                            Val Loss: 1.1011, Val MAE: 1.1016
2023-01-24 12:40:57,658:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-24 12:53:48,309:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.65s, LR: 0.00017, Train Loss: 0.1731, Train MAE: 0.1731,
                            Val Loss: 1.0618, Val MAE: 1.0624
2023-01-24 12:53:48,310:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-24 13:07:38,313:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 830.00s, LR: 0.00017, Train Loss: 0.1713, Train MAE: 0.1713,
                            Val Loss: 0.6872, Val MAE: 0.6873
2023-01-24 13:07:38,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-24 13:20:28,314:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.00s, LR: 0.00017, Train Loss: 0.1707, Train MAE: 0.1707,
                            Val Loss: 0.6580, Val MAE: 0.6581
2023-01-24 13:20:28,316:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-24 13:33:18,229:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.91s, LR: 0.00017, Train Loss: 0.1706, Train MAE: 0.1706,
                            Val Loss: 1.0030, Val MAE: 1.0029
2023-01-24 13:33:18,230:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-24 13:46:08,416:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.18s, LR: 0.00017, Train Loss: 0.1700, Train MAE: 0.1700,
                            Val Loss: 1.3976, Val MAE: 1.3982
2023-01-24 13:46:08,417:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-24 13:58:58,648:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.23s, LR: 0.00009, Train Loss: 0.1671, Train MAE: 0.1671,
                            Val Loss: 1.3823, Val MAE: 1.3829
2023-01-24 13:58:58,649:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-24 14:11:52,847:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.20s, LR: 0.00009, Train Loss: 0.1666, Train MAE: 0.1666,
                            Val Loss: 0.7094, Val MAE: 0.7097
2023-01-24 14:11:52,849:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-24 14:24:43,756:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.21142710745334625
2023-01-24 14:24:43,758:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.91s, LR: 0.00009, Train Loss: 0.1662, Train MAE: 0.1662,
                            Val Loss: 0.2116, Val MAE: 0.2114
2023-01-24 14:24:43,759:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-24 14:37:34,431:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 770.67s, LR: 0.00009, Train Loss: 0.1649, Train MAE: 0.1649,
                            Val Loss: 0.2861, Val MAE: 0.2859
2023-01-24 14:37:34,432:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-24 14:50:32,809:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 778.38s, LR: 0.00009, Train Loss: 0.1638, Train MAE: 0.1638,
                            Val Loss: 1.1920, Val MAE: 1.1926
2023-01-24 14:50:32,810:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-24 15:03:27,481:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 774.67s, LR: 0.00009, Train Loss: 0.1623, Train MAE: 0.1623,
                            Val Loss: 1.5155, Val MAE: 1.5161
2023-01-24 15:03:27,483:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-24 15:16:16,624:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.14s, LR: 0.00009, Train Loss: 0.1614, Train MAE: 0.1614,
                            Val Loss: 0.7513, Val MAE: 0.7515
2023-01-24 15:16:16,625:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-24 15:29:06,144:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.52s, LR: 0.00009, Train Loss: 0.1605, Train MAE: 0.1605,
                            Val Loss: 0.2804, Val MAE: 0.2802
2023-01-24 15:29:06,144:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-24 15:41:55,053:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.91s, LR: 0.00009, Train Loss: 0.1596, Train MAE: 0.1596,
                            Val Loss: 0.3258, Val MAE: 0.3259
2023-01-24 15:41:55,054:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-24 15:54:43,960:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1968623399734497
2023-01-24 15:54:43,962:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.91s, LR: 0.00009, Train Loss: 0.1586, Train MAE: 0.1586,
                            Val Loss: 0.1970, Val MAE: 0.1969
2023-01-24 15:54:43,963:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-24 16:07:32,940:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.98s, LR: 0.00009, Train Loss: 0.1576, Train MAE: 0.1576,
                            Val Loss: 0.4633, Val MAE: 0.4634
2023-01-24 16:07:32,941:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-24 16:20:21,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.17s, LR: 0.00009, Train Loss: 0.1562, Train MAE: 0.1562,
                            Val Loss: 0.3208, Val MAE: 0.3206
2023-01-24 16:20:21,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-24 16:33:09,543:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.42s, LR: 0.00009, Train Loss: 0.1554, Train MAE: 0.1554,
                            Val Loss: 0.5159, Val MAE: 0.5160
2023-01-24 16:33:09,544:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-24 16:46:50,888:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 821.34s, LR: 0.00009, Train Loss: 0.1544, Train MAE: 0.1544,
                            Val Loss: 0.2744, Val MAE: 0.2743
2023-01-24 16:46:50,889:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-24 16:59:39,685:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.79s, LR: 0.00009, Train Loss: 0.1535, Train MAE: 0.1535,
                            Val Loss: 1.3444, Val MAE: 1.3447
2023-01-24 16:59:39,686:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-24 17:12:27,737:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1950911581516266
2023-01-24 17:12:27,739:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.05s, LR: 0.00009, Train Loss: 0.1528, Train MAE: 0.1528,
                            Val Loss: 0.1952, Val MAE: 0.1951
2023-01-24 17:12:27,740:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-24 17:25:16,185:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.44s, LR: 0.00009, Train Loss: 0.1522, Train MAE: 0.1522,
                            Val Loss: 0.2505, Val MAE: 0.2504
2023-01-24 17:25:16,186:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-24 17:38:04,391:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.20s, LR: 0.00009, Train Loss: 0.1515, Train MAE: 0.1515,
                            Val Loss: 0.2023, Val MAE: 0.2022
2023-01-24 17:38:04,393:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-24 17:50:52,695:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.30s, LR: 0.00009, Train Loss: 0.1510, Train MAE: 0.1510,
                            Val Loss: 1.6829, Val MAE: 1.6833
2023-01-24 17:50:52,696:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-24 18:03:41,787:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.09s, LR: 0.00009, Train Loss: 0.1506, Train MAE: 0.1506,
                            Val Loss: 1.1826, Val MAE: 1.1828
2023-01-24 18:03:41,788:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-24 18:16:30,198:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.41s, LR: 0.00009, Train Loss: 0.1525, Train MAE: 0.1525,
                            Val Loss: 0.2450, Val MAE: 0.2450
2023-01-24 18:16:30,199:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-24 18:29:18,420:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.22s, LR: 0.00009, Train Loss: 0.1500, Train MAE: 0.1500,
                            Val Loss: 0.3792, Val MAE: 0.3793
2023-01-24 18:29:18,421:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-24 18:42:08,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 769.96s, LR: 0.00009, Train Loss: 0.1494, Train MAE: 0.1494,
                            Val Loss: 1.6004, Val MAE: 1.6008
2023-01-24 18:42:08,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-24 18:54:57,164:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 768.78s, LR: 0.00009, Train Loss: 0.1490, Train MAE: 0.1490,
                            Val Loss: 0.2644, Val MAE: 0.2643
2023-01-24 18:54:57,165:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-24 19:07:45,042:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 767.88s, LR: 0.00009, Train Loss: 0.1487, Train MAE: 0.1487,
                            Val Loss: 1.7072, Val MAE: 1.7077
2023-01-24 19:07:45,043:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
