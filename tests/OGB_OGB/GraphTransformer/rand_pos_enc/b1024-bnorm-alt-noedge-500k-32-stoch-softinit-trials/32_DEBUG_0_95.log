2023-01-23 22:26:09,086:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-23 22:26:09,086:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-23 22:41:11,434:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-23 22:41:49,572:ogbdata.py:332 -             __init__(): Time taken: 940.4721s
2023-01-23 22:41:49,572:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-23 22:41:49,572:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-23 22:41:49,572:ogbdata.py:348 -             __init__(): [I] Data load time: 940.4858s
2023-01-23 22:41:49,572:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'partial_rw_pos_enc': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': True, 'gape_softmax_init': True, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-23 22:41:49,572:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b1024-bnorm-alt-noedge-500k-32-stoch-softinit-trials', 'job_num': 32}
2023-01-23 22:41:49,574:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 22:42:01,637:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 22:42:01,637:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 22:42:01,637:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 22:42:01,955:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-23 22:42:02,017:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-23 22:42:02,018:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-23 22:42:02,018:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-23 22:42:02,019:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-23 22:42:02,019:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-23 22:42:02,019:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-23 22:42:02,120:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-24 00:00:14,073:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4692.055459260941
2023-01-24 00:00:14,109:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-24 00:00:14,109:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-24 00:00:14,164:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-24 00:14:34,971:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.383054494857788
2023-01-24 00:14:34,973:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 860.81s, LR: 0.00070, Train Loss: 0.5113, Train MAE: 0.5113,
                            Val Loss: 1.3835, Val MAE: 1.3831
2023-01-24 00:14:34,973:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-24 00:26:29,316:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.34s, LR: 0.00070, Train Loss: 0.3560, Train MAE: 0.3560,
                            Val Loss: 2.3416, Val MAE: 2.3410
2023-01-24 00:26:29,318:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-24 00:37:47,522:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.2535104751586914
2023-01-24 00:37:47,676:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 678.34s, LR: 0.00070, Train Loss: 0.3320, Train MAE: 0.3320,
                            Val Loss: 1.2535, Val MAE: 1.2535
2023-01-24 00:37:47,677:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-24 00:48:57,476:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.80s, LR: 0.00070, Train Loss: 0.3404, Train MAE: 0.3404,
                            Val Loss: 1.7005, Val MAE: 1.7000
2023-01-24 00:48:57,477:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-24 01:00:23,783:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 686.27s, LR: 0.00070, Train Loss: 0.4053, Train MAE: 0.4053,
                            Val Loss: 3.4331, Val MAE: 3.4328
2023-01-24 01:00:23,818:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-24 01:12:09,356:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.52s, LR: 0.00070, Train Loss: 0.3634, Train MAE: 0.3634,
                            Val Loss: 3.6888, Val MAE: 3.6885
2023-01-24 01:12:09,358:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-24 01:23:55,796:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.44s, LR: 0.00070, Train Loss: 0.3399, Train MAE: 0.3399,
                            Val Loss: 2.2168, Val MAE: 2.2163
2023-01-24 01:23:55,798:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-24 01:36:06,256:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 1.1366844177246094
2023-01-24 01:36:06,258:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.46s, LR: 0.00070, Train Loss: 0.3232, Train MAE: 0.3232,
                            Val Loss: 1.1368, Val MAE: 1.1367
2023-01-24 01:36:06,259:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-24 01:47:11,850:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 665.59s, LR: 0.00070, Train Loss: 0.3168, Train MAE: 0.3168,
                            Val Loss: 3.6323, Val MAE: 3.6320
2023-01-24 01:47:11,851:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-24 01:58:27,424:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.57s, LR: 0.00070, Train Loss: 0.3039, Train MAE: 0.3039,
                            Val Loss: 1.9088, Val MAE: 1.9088
2023-01-24 01:58:27,426:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-24 02:09:33,686:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.6609921455383301
2023-01-24 02:09:33,688:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.26s, LR: 0.00070, Train Loss: 0.3010, Train MAE: 0.3010,
                            Val Loss: 0.6609, Val MAE: 0.6610
2023-01-24 02:09:33,690:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-24 02:21:05,543:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.85s, LR: 0.00070, Train Loss: 0.2907, Train MAE: 0.2907,
                            Val Loss: 2.1304, Val MAE: 2.1299
2023-01-24 02:21:05,544:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-24 02:33:12,428:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.88s, LR: 0.00070, Train Loss: 0.2872, Train MAE: 0.2872,
                            Val Loss: 3.9373, Val MAE: 3.9367
2023-01-24 02:33:12,485:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-24 02:44:20,027:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 667.54s, LR: 0.00070, Train Loss: 0.2888, Train MAE: 0.2888,
                            Val Loss: 2.4439, Val MAE: 2.4434
2023-01-24 02:44:20,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-24 02:55:26,294:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.23s, LR: 0.00070, Train Loss: 0.2879, Train MAE: 0.2879,
                            Val Loss: 2.6055, Val MAE: 2.6053
2023-01-24 02:55:26,485:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-24 03:06:35,300:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.81s, LR: 0.00070, Train Loss: 0.2864, Train MAE: 0.2864,
                            Val Loss: 1.6830, Val MAE: 1.6826
2023-01-24 03:06:35,484:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-24 03:17:41,736:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.25s, LR: 0.00070, Train Loss: 0.2935, Train MAE: 0.2935,
                            Val Loss: 1.9091, Val MAE: 1.9089
2023-01-24 03:17:41,758:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-24 03:28:45,773:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.01s, LR: 0.00070, Train Loss: 0.2849, Train MAE: 0.2849,
                            Val Loss: 4.0523, Val MAE: 4.0521
2023-01-24 03:28:45,816:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-24 03:39:55,203:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 669.39s, LR: 0.00070, Train Loss: 0.2756, Train MAE: 0.2756,
                            Val Loss: 1.8227, Val MAE: 1.8228
2023-01-24 03:39:55,224:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-24 03:50:58,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.50s, LR: 0.00070, Train Loss: 0.2698, Train MAE: 0.2698,
                            Val Loss: 1.9533, Val MAE: 1.9533
2023-01-24 03:50:58,773:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-24 04:02:00,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.67s, LR: 0.00070, Train Loss: 0.2714, Train MAE: 0.2714,
                            Val Loss: 0.8662, Val MAE: 0.8663
2023-01-24 04:02:00,881:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-24 04:13:05,096:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.21s, LR: 0.00070, Train Loss: 0.2655, Train MAE: 0.2655,
                            Val Loss: 1.1750, Val MAE: 1.1752
2023-01-24 04:13:05,130:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-24 04:24:08,359:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.23s, LR: 0.00070, Train Loss: 0.2609, Train MAE: 0.2609,
                            Val Loss: 1.4847, Val MAE: 1.4845
2023-01-24 04:24:08,371:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-24 04:36:15,367:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.99s, LR: 0.00070, Train Loss: 0.2572, Train MAE: 0.2572,
                            Val Loss: 3.5067, Val MAE: 3.5061
2023-01-24 04:36:15,388:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-24 04:47:19,133:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.74s, LR: 0.00070, Train Loss: 0.2562, Train MAE: 0.2562,
                            Val Loss: 1.2994, Val MAE: 1.2990
2023-01-24 04:47:19,154:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-24 04:58:27,602:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 668.45s, LR: 0.00070, Train Loss: 0.2526, Train MAE: 0.2526,
                            Val Loss: 1.5948, Val MAE: 1.5948
2023-01-24 04:58:27,645:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-24 05:09:38,357:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 670.71s, LR: 0.00070, Train Loss: 0.2564, Train MAE: 0.2564,
                            Val Loss: 1.8693, Val MAE: 1.8691
2023-01-24 05:09:38,378:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-24 05:20:51,102:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.48395243287086487
2023-01-24 05:20:51,128:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 672.75s, LR: 0.00035, Train Loss: 0.2432, Train MAE: 0.2432,
                            Val Loss: 0.4842, Val MAE: 0.4840
2023-01-24 05:20:51,129:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-24 05:31:55,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.16s, LR: 0.00035, Train Loss: 0.2385, Train MAE: 0.2385,
                            Val Loss: 2.0404, Val MAE: 2.0406
2023-01-24 05:31:55,326:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-24 05:42:52,726:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.40s, LR: 0.00035, Train Loss: 0.2422, Train MAE: 0.2422,
                            Val Loss: 1.0578, Val MAE: 1.0571
2023-01-24 05:42:52,727:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-24 05:53:44,643:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.91s, LR: 0.00035, Train Loss: 0.2407, Train MAE: 0.2407,
                            Val Loss: 1.3177, Val MAE: 1.3179
2023-01-24 05:53:44,644:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-24 06:04:33,904:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.42696675658226013
2023-01-24 06:04:33,906:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 649.26s, LR: 0.00035, Train Loss: 0.2372, Train MAE: 0.2372,
                            Val Loss: 0.4272, Val MAE: 0.4270
2023-01-24 06:04:33,906:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-24 06:15:31,927:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.02s, LR: 0.00035, Train Loss: 0.2381, Train MAE: 0.2381,
                            Val Loss: 1.6181, Val MAE: 1.6183
2023-01-24 06:15:31,940:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-24 06:26:28,146:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.42557910084724426
2023-01-24 06:26:28,156:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.22s, LR: 0.00035, Train Loss: 0.2377, Train MAE: 0.2377,
                            Val Loss: 0.4255, Val MAE: 0.4256
2023-01-24 06:26:28,157:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-24 06:38:19,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 711.56s, LR: 0.00035, Train Loss: 0.2324, Train MAE: 0.2324,
                            Val Loss: 1.2419, Val MAE: 1.2411
2023-01-24 06:38:19,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-24 06:50:38,959:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.23s, LR: 0.00035, Train Loss: 0.2333, Train MAE: 0.2333,
                            Val Loss: 0.5071, Val MAE: 0.5068
2023-01-24 06:50:38,972:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-24 07:02:56,592:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 737.62s, LR: 0.00035, Train Loss: 0.2345, Train MAE: 0.2345,
                            Val Loss: 1.0138, Val MAE: 1.0140
2023-01-24 07:02:56,605:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-24 07:15:19,268:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 742.66s, LR: 0.00035, Train Loss: 0.2356, Train MAE: 0.2356,
                            Val Loss: 0.5869, Val MAE: 0.5865
2023-01-24 07:15:19,280:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-24 07:27:47,600:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 748.32s, LR: 0.00035, Train Loss: 0.2316, Train MAE: 0.2316,
                            Val Loss: 1.9906, Val MAE: 1.9907
2023-01-24 07:27:47,613:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-24 07:40:07,617:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 740.00s, LR: 0.00035, Train Loss: 0.2344, Train MAE: 0.2344,
                            Val Loss: 1.6319, Val MAE: 1.6313
2023-01-24 07:40:07,630:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-24 07:53:35,969:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 808.34s, LR: 0.00035, Train Loss: 0.2333, Train MAE: 0.2333,
                            Val Loss: 0.8343, Val MAE: 0.8337
2023-01-24 07:53:35,981:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-24 08:06:00,226:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 744.24s, LR: 0.00035, Train Loss: 0.2340, Train MAE: 0.2340,
                            Val Loss: 0.6705, Val MAE: 0.6707
2023-01-24 08:06:00,239:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-24 08:18:17,034:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 736.79s, LR: 0.00035, Train Loss: 0.2351, Train MAE: 0.2351,
                            Val Loss: 0.6900, Val MAE: 0.6901
2023-01-24 08:18:17,047:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-24 08:30:35,793:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 738.74s, LR: 0.00035, Train Loss: 0.2345, Train MAE: 0.2345,
                            Val Loss: 1.1674, Val MAE: 1.1678
2023-01-24 08:30:35,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-24 08:42:55,253:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 739.45s, LR: 0.00035, Train Loss: 0.2287, Train MAE: 0.2287,
                            Val Loss: 1.7035, Val MAE: 1.7035
2023-01-24 08:42:55,264:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-24 08:54:55,068:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.80s, LR: 0.00035, Train Loss: 0.2280, Train MAE: 0.2280,
                            Val Loss: 0.5768, Val MAE: 0.5766
2023-01-24 08:54:55,080:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-24 09:05:53,308:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.23s, LR: 0.00035, Train Loss: 0.2283, Train MAE: 0.2283,
                            Val Loss: 1.9524, Val MAE: 1.9525
2023-01-24 09:05:53,309:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-24 09:16:56,771:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.46s, LR: 0.00035, Train Loss: 0.2273, Train MAE: 0.2273,
                            Val Loss: 0.7388, Val MAE: 0.7390
2023-01-24 09:16:56,795:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-24 09:27:58,573:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.78s, LR: 0.00035, Train Loss: 0.2259, Train MAE: 0.2259,
                            Val Loss: 2.3006, Val MAE: 2.3007
2023-01-24 09:27:58,594:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-24 09:39:04,889:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.29s, LR: 0.00035, Train Loss: 0.2357, Train MAE: 0.2357,
                            Val Loss: 1.2493, Val MAE: 1.2496
2023-01-24 09:39:04,902:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-24 09:50:07,738:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.84s, LR: 0.00017, Train Loss: 0.2244, Train MAE: 0.2244,
                            Val Loss: 1.2951, Val MAE: 1.2943
2023-01-24 09:50:07,751:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-24 10:01:09,406:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.65s, LR: 0.00017, Train Loss: 0.2222, Train MAE: 0.2222,
                            Val Loss: 0.4977, Val MAE: 0.4974
2023-01-24 10:01:09,434:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-24 10:12:10,120:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.69s, LR: 0.00017, Train Loss: 0.2226, Train MAE: 0.2226,
                            Val Loss: 0.5054, Val MAE: 0.5053
2023-01-24 10:12:10,133:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-24 10:23:08,966:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.83s, LR: 0.00017, Train Loss: 0.2200, Train MAE: 0.2200,
                            Val Loss: 0.5187, Val MAE: 0.5188
2023-01-24 10:23:08,990:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-24 10:34:15,910:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 666.92s, LR: 0.00017, Train Loss: 0.2192, Train MAE: 0.2192,
                            Val Loss: 1.0995, Val MAE: 1.0997
2023-01-24 10:34:15,923:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-24 10:45:41,604:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 685.68s, LR: 0.00017, Train Loss: 0.2184, Train MAE: 0.2184,
                            Val Loss: 0.5481, Val MAE: 0.5482
2023-01-24 10:45:41,606:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-24 10:57:29,256:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.39095601439476013
2023-01-24 10:57:29,281:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 707.67s, LR: 0.00017, Train Loss: 0.2180, Train MAE: 0.2180,
                            Val Loss: 0.3909, Val MAE: 0.3910
2023-01-24 10:57:29,281:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-24 11:10:13,327:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 764.05s, LR: 0.00017, Train Loss: 0.2167, Train MAE: 0.2167,
                            Val Loss: 0.9088, Val MAE: 0.9083
2023-01-24 11:10:13,355:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-24 11:21:31,167:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 677.81s, LR: 0.00017, Train Loss: 0.2165, Train MAE: 0.2165,
                            Val Loss: 0.5170, Val MAE: 0.5169
2023-01-24 11:21:31,169:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-24 11:32:44,738:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 673.57s, LR: 0.00017, Train Loss: 0.2146, Train MAE: 0.2146,
                            Val Loss: 0.8226, Val MAE: 0.8222
2023-01-24 11:32:44,754:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-24 11:44:04,857:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.10s, LR: 0.00017, Train Loss: 0.2149, Train MAE: 0.2149,
                            Val Loss: 1.0374, Val MAE: 1.0369
2023-01-24 11:44:04,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-24 11:55:35,963:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 691.10s, LR: 0.00017, Train Loss: 0.2138, Train MAE: 0.2138,
                            Val Loss: 0.5958, Val MAE: 0.5959
2023-01-24 11:55:35,965:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-24 12:07:24,132:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.17s, LR: 0.00017, Train Loss: 0.2136, Train MAE: 0.2136,
                            Val Loss: 0.6859, Val MAE: 0.6860
2023-01-24 12:07:24,133:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-24 12:18:48,167:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.03s, LR: 0.00017, Train Loss: 0.2125, Train MAE: 0.2125,
                            Val Loss: 1.4691, Val MAE: 1.4694
2023-01-24 12:18:48,169:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-24 12:30:25,654:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.48s, LR: 0.00017, Train Loss: 0.2114, Train MAE: 0.2114,
                            Val Loss: 0.4539, Val MAE: 0.4538
2023-01-24 12:30:25,679:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-24 12:42:24,863:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.18s, LR: 0.00017, Train Loss: 0.2142, Train MAE: 0.2142,
                            Val Loss: 0.4727, Val MAE: 0.4728
2023-01-24 12:42:24,864:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-24 12:53:52,754:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.36479321122169495
2023-01-24 12:53:52,757:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 687.89s, LR: 0.00017, Train Loss: 0.2253, Train MAE: 0.2253,
                            Val Loss: 0.3649, Val MAE: 0.3648
2023-01-24 12:53:52,757:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-24 13:05:31,236:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 698.48s, LR: 0.00017, Train Loss: 0.2199, Train MAE: 0.2199,
                            Val Loss: 1.1590, Val MAE: 1.1592
2023-01-24 13:05:31,237:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-24 13:17:05,728:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 694.49s, LR: 0.00017, Train Loss: 0.2162, Train MAE: 0.2162,
                            Val Loss: 0.4356, Val MAE: 0.4353
2023-01-24 13:17:05,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-24 13:28:33,833:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 688.10s, LR: 0.00017, Train Loss: 0.2166, Train MAE: 0.2166,
                            Val Loss: 1.2270, Val MAE: 1.2273
2023-01-24 13:28:33,835:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-24 13:39:53,710:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 679.87s, LR: 0.00017, Train Loss: 0.2174, Train MAE: 0.2174,
                            Val Loss: 0.5634, Val MAE: 0.5632
2023-01-24 13:39:53,711:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-24 13:51:14,189:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 680.48s, LR: 0.00017, Train Loss: 0.2148, Train MAE: 0.2148,
                            Val Loss: 0.6580, Val MAE: 0.6581
2023-01-24 13:51:14,191:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-24 14:02:37,572:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.38s, LR: 0.00017, Train Loss: 0.2126, Train MAE: 0.2126,
                            Val Loss: 0.7032, Val MAE: 0.7032
2023-01-24 14:02:37,574:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-24 14:13:52,863:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 675.29s, LR: 0.00017, Train Loss: 0.2124, Train MAE: 0.2124,
                            Val Loss: 0.8746, Val MAE: 0.8742
2023-01-24 14:13:52,864:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-24 14:25:59,774:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.91s, LR: 0.00017, Train Loss: 0.2121, Train MAE: 0.2121,
                            Val Loss: 0.8814, Val MAE: 0.8816
2023-01-24 14:25:59,799:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-24 14:38:03,368:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.57s, LR: 0.00017, Train Loss: 0.2110, Train MAE: 0.2110,
                            Val Loss: 1.8535, Val MAE: 1.8538
2023-01-24 14:38:03,382:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-24 14:50:10,725:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.34s, LR: 0.00017, Train Loss: 0.2090, Train MAE: 0.2090,
                            Val Loss: 0.5529, Val MAE: 0.5528
2023-01-24 14:50:10,752:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-24 15:01:36,750:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 686.00s, LR: 0.00017, Train Loss: 0.2104, Train MAE: 0.2104,
                            Val Loss: 0.4229, Val MAE: 0.4227
2023-01-24 15:01:36,776:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-24 15:13:22,734:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 705.96s, LR: 0.00017, Train Loss: 0.2098, Train MAE: 0.2098,
                            Val Loss: 0.4378, Val MAE: 0.4379
2023-01-24 15:13:22,742:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-24 15:24:33,801:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.06s, LR: 0.00017, Train Loss: 0.2082, Train MAE: 0.2082,
                            Val Loss: 0.6613, Val MAE: 0.6614
2023-01-24 15:24:33,825:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-24 15:35:34,702:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.28346556425094604
2023-01-24 15:35:34,741:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.91s, LR: 0.00017, Train Loss: 0.2088, Train MAE: 0.2088,
                            Val Loss: 0.2836, Val MAE: 0.2835
2023-01-24 15:35:34,741:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-24 15:46:29,371:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.63s, LR: 0.00017, Train Loss: 0.2082, Train MAE: 0.2082,
                            Val Loss: 0.9755, Val MAE: 0.9758
2023-01-24 15:46:29,399:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-24 15:57:23,328:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.26260170340538025
2023-01-24 15:57:23,355:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.96s, LR: 0.00017, Train Loss: 0.2082, Train MAE: 0.2082,
                            Val Loss: 0.2628, Val MAE: 0.2626
2023-01-24 15:57:23,356:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-24 16:08:47,293:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 683.94s, LR: 0.00017, Train Loss: 0.2068, Train MAE: 0.2068,
                            Val Loss: 0.6410, Val MAE: 0.6411
2023-01-24 16:08:47,314:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-24 16:20:33,396:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 706.08s, LR: 0.00017, Train Loss: 0.2059, Train MAE: 0.2059,
                            Val Loss: 0.3692, Val MAE: 0.3692
2023-01-24 16:20:33,405:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-24 16:31:27,547:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.14s, LR: 0.00017, Train Loss: 0.2053, Train MAE: 0.2053,
                            Val Loss: 0.8193, Val MAE: 0.8195
2023-01-24 16:31:27,548:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-24 16:42:56,554:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 689.01s, LR: 0.00017, Train Loss: 0.2053, Train MAE: 0.2053,
                            Val Loss: 0.5553, Val MAE: 0.5553
2023-01-24 16:42:56,555:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-24 16:54:28,960:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 692.40s, LR: 0.00017, Train Loss: 0.2047, Train MAE: 0.2047,
                            Val Loss: 1.4081, Val MAE: 1.4081
2023-01-24 16:54:28,961:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-24 17:05:22,087:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.13s, LR: 0.00017, Train Loss: 0.2054, Train MAE: 0.2054,
                            Val Loss: 0.7113, Val MAE: 0.7114
2023-01-24 17:05:22,103:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-24 17:16:15,870:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.77s, LR: 0.00017, Train Loss: 0.2085, Train MAE: 0.2085,
                            Val Loss: 0.3299, Val MAE: 0.3299
2023-01-24 17:16:15,885:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-24 17:27:10,300:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.41s, LR: 0.00017, Train Loss: 0.2083, Train MAE: 0.2083,
                            Val Loss: 1.7249, Val MAE: 1.7252
2023-01-24 17:27:10,309:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-24 17:39:14,150:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.84s, LR: 0.00017, Train Loss: 0.2077, Train MAE: 0.2077,
                            Val Loss: 0.2732, Val MAE: 0.2731
2023-01-24 17:39:14,151:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-24 17:50:10,862:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.71s, LR: 0.00017, Train Loss: 0.2092, Train MAE: 0.2092,
                            Val Loss: 0.3335, Val MAE: 0.3334
2023-01-24 17:50:10,875:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-24 18:01:10,482:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.61s, LR: 0.00017, Train Loss: 0.2066, Train MAE: 0.2066,
                            Val Loss: 0.9085, Val MAE: 0.9086
2023-01-24 18:01:10,491:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-24 18:12:47,599:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 697.11s, LR: 0.00017, Train Loss: 0.2061, Train MAE: 0.2061,
                            Val Loss: 0.7524, Val MAE: 0.7525
2023-01-24 18:12:47,600:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-24 18:24:11,640:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 684.04s, LR: 0.00017, Train Loss: 0.2045, Train MAE: 0.2045,
                            Val Loss: 0.5356, Val MAE: 0.5357
2023-01-24 18:24:11,648:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-24 18:36:23,798:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.15s, LR: 0.00017, Train Loss: 0.2059, Train MAE: 0.2059,
                            Val Loss: 0.6166, Val MAE: 0.6166
2023-01-24 18:36:23,806:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-24 18:48:27,606:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.80s, LR: 0.00017, Train Loss: 0.2054, Train MAE: 0.2054,
                            Val Loss: 0.3629, Val MAE: 0.3627
2023-01-24 18:48:27,615:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-24 19:00:21,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.00s, LR: 0.00017, Train Loss: 0.2040, Train MAE: 0.2040,
                            Val Loss: 0.3068, Val MAE: 0.3066
2023-01-24 19:00:21,652:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
