2023-01-22 02:28:36,593:main_utils.py:62 -            gpu_setup(): cuda available with GPU: Quadro RTX 6000
2023-01-22 02:28:36,593:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-22 02:38:31,067:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-22 02:38:57,207:ogbdata.py:332 -             __init__(): Time taken: 620.6139s
2023-01-22 02:38:57,207:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-22 02:38:57,207:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-22 02:38:57,207:ogbdata.py:348 -             __init__(): [I] Data load time: 620.6143s
2023-01-22 02:38:57,207:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0.02', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/gt_ogb_b1024-rand-32-scale002-noedge-scale002/32_DEBUG_0_35.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [35]}
2023-01-22 02:38:57,207:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'save_name': 'b128-prwpe', 'job_num': 32}
2023-01-22 02:38:57,210:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:38:58,650:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:38:58,650:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:38:58,650:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:38:58,668:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-22 02:38:58,669:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-22 02:38:58,670:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2023-01-22 02:38:58,670:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:38:58,670:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:38:58,670:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:38:58,670:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:38:58,685:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-22 03:32:09,115:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:3190.445686817169
2023-01-22 03:32:09,225:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-22 03:32:09,225:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-22 03:32:09,478:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-22 03:42:27,439:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.22730256617069244
2023-01-22 03:42:27,442:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 617.96s, LR: 0.00070, Train Loss: 0.3389, Train MAE: 0.3389,
                            Val Loss: 0.2276, Val MAE: 0.2273
2023-01-22 03:42:27,442:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-22 03:50:33,736:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.19490545988082886
2023-01-22 03:50:33,738:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.29s, LR: 0.00070, Train Loss: 0.1872, Train MAE: 0.1872,
                            Val Loss: 0.1953, Val MAE: 0.1949
2023-01-22 03:50:33,739:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-22 03:58:41,332:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1794147938489914
2023-01-22 03:58:41,334:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 487.59s, LR: 0.00070, Train Loss: 0.1721, Train MAE: 0.1721,
                            Val Loss: 0.1798, Val MAE: 0.1794
2023-01-22 03:58:41,335:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-22 04:06:46,494:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.17527545988559723
2023-01-22 04:06:46,495:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.16s, LR: 0.00070, Train Loss: 0.1645, Train MAE: 0.1645,
                            Val Loss: 0.1756, Val MAE: 0.1753
2023-01-22 04:06:46,497:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-22 04:14:52,464:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1659352034330368
2023-01-22 04:14:52,465:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.97s, LR: 0.00070, Train Loss: 0.1578, Train MAE: 0.1578,
                            Val Loss: 0.1663, Val MAE: 0.1659
2023-01-22 04:14:52,466:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-22 04:22:59,368:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.90s, LR: 0.00070, Train Loss: 0.1534, Train MAE: 0.1534,
                            Val Loss: 0.1742, Val MAE: 0.1738
2023-01-22 04:22:59,370:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-22 04:31:04,961:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15521802008152008
2023-01-22 04:31:04,963:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.59s, LR: 0.00070, Train Loss: 0.1505, Train MAE: 0.1505,
                            Val Loss: 0.1555, Val MAE: 0.1552
2023-01-22 04:31:04,964:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-22 04:40:28,818:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 563.85s, LR: 0.00070, Train Loss: 0.1471, Train MAE: 0.1471,
                            Val Loss: 0.2018, Val MAE: 0.2017
2023-01-22 04:40:28,819:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-22 04:48:37,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 488.19s, LR: 0.00070, Train Loss: 0.1450, Train MAE: 0.1450,
                            Val Loss: 0.1832, Val MAE: 0.1828
2023-01-22 04:48:37,016:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-22 04:56:44,209:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 487.19s, LR: 0.00070, Train Loss: 0.1429, Train MAE: 0.1429,
                            Val Loss: 0.1561, Val MAE: 0.1558
2023-01-22 04:56:44,211:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-22 05:04:51,925:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14488844573497772
2023-01-22 05:04:51,926:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 487.71s, LR: 0.00070, Train Loss: 0.1412, Train MAE: 0.1412,
                            Val Loss: 0.1452, Val MAE: 0.1449
2023-01-22 05:04:51,927:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-22 05:13:00,048:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 488.12s, LR: 0.00070, Train Loss: 0.1418, Train MAE: 0.1418,
                            Val Loss: 0.1917, Val MAE: 0.1914
2023-01-22 05:13:00,050:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-22 05:21:06,071:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.02s, LR: 0.00070, Train Loss: 0.1388, Train MAE: 0.1388,
                            Val Loss: 0.2267, Val MAE: 0.2264
2023-01-22 05:21:06,072:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-22 05:29:13,036:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.96s, LR: 0.00070, Train Loss: 0.1380, Train MAE: 0.1380,
                            Val Loss: 0.1545, Val MAE: 0.1543
2023-01-22 05:29:13,037:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-22 05:37:19,667:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.63s, LR: 0.00070, Train Loss: 0.1380, Train MAE: 0.1380,
                            Val Loss: 0.1455, Val MAE: 0.1453
2023-01-22 05:37:19,668:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-22 05:45:25,211:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.54s, LR: 0.00070, Train Loss: 0.1361, Train MAE: 0.1361,
                            Val Loss: 0.1546, Val MAE: 0.1544
2023-01-22 05:45:25,212:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-22 05:53:32,381:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 487.17s, LR: 0.00070, Train Loss: 0.1352, Train MAE: 0.1352,
                            Val Loss: 0.1584, Val MAE: 0.1582
2023-01-22 05:53:32,382:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-22 06:01:39,201:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.82s, LR: 0.00070, Train Loss: 0.1331, Train MAE: 0.1331,
                            Val Loss: 0.1876, Val MAE: 0.1874
2023-01-22 06:01:39,203:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-22 06:09:44,966:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.76s, LR: 0.00070, Train Loss: 0.1328, Train MAE: 0.1328,
                            Val Loss: 0.1482, Val MAE: 0.1480
2023-01-22 06:09:44,967:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-22 06:17:49,616:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13469813764095306
2023-01-22 06:17:49,617:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 484.65s, LR: 0.00070, Train Loss: 0.1320, Train MAE: 0.1320,
                            Val Loss: 0.1349, Val MAE: 0.1347
2023-01-22 06:17:49,619:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-22 06:25:54,643:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.02s, LR: 0.00070, Train Loss: 0.1318, Train MAE: 0.1318,
                            Val Loss: 0.1552, Val MAE: 0.1549
2023-01-22 06:25:54,644:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-22 06:33:59,340:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 484.69s, LR: 0.00070, Train Loss: 0.1304, Train MAE: 0.1304,
                            Val Loss: 0.1583, Val MAE: 0.1581
2023-01-22 06:33:59,342:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-22 06:42:05,698:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.35s, LR: 0.00070, Train Loss: 0.1303, Train MAE: 0.1303,
                            Val Loss: 0.1408, Val MAE: 0.1406
2023-01-22 06:42:05,699:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-22 06:51:28,572:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 562.87s, LR: 0.00070, Train Loss: 0.1287, Train MAE: 0.1287,
                            Val Loss: 0.1617, Val MAE: 0.1616
2023-01-22 06:51:28,574:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-22 06:59:34,559:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 485.98s, LR: 0.00070, Train Loss: 0.1277, Train MAE: 0.1277,
                            Val Loss: 0.1600, Val MAE: 0.1597
2023-01-22 06:59:34,560:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-22 07:07:40,837:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.28s, LR: 0.00070, Train Loss: 0.1270, Train MAE: 0.1270,
                            Val Loss: 0.1871, Val MAE: 0.1869
2023-01-22 07:07:40,839:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-22 07:15:48,635:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 487.80s, LR: 0.00070, Train Loss: 0.1264, Train MAE: 0.1264,
                            Val Loss: 0.1394, Val MAE: 0.1392
2023-01-22 07:15:48,637:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-22 07:23:55,622:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.98s, LR: 0.00070, Train Loss: 0.1252, Train MAE: 0.1252,
                            Val Loss: 0.1534, Val MAE: 0.1532
2023-01-22 07:23:55,623:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-22 07:32:02,995:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 487.37s, LR: 0.00070, Train Loss: 0.1253, Train MAE: 0.1253,
                            Val Loss: 0.1600, Val MAE: 0.1598
2023-01-22 07:32:02,996:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-22 07:40:07,564:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 484.57s, LR: 0.00070, Train Loss: 0.1256, Train MAE: 0.1256,
                            Val Loss: 0.1413, Val MAE: 0.1411
2023-01-22 07:40:07,566:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-22 07:48:14,006:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 486.44s, LR: 0.00070, Train Loss: 0.1229, Train MAE: 0.1229,
                            Val Loss: 0.1542, Val MAE: 0.1540
2023-01-22 07:48:14,008:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-22 07:56:15,751:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 481.74s, LR: 0.00070, Train Loss: 0.1222, Train MAE: 0.1222,
                            Val Loss: 0.1386, Val MAE: 0.1384
2023-01-22 07:56:15,753:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-22 08:04:15,909:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.16s, LR: 0.00070, Train Loss: 0.1223, Train MAE: 0.1223,
                            Val Loss: 0.1734, Val MAE: 0.1730
2023-01-22 08:04:15,911:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-22 08:12:15,951:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13435237109661102
2023-01-22 08:12:15,954:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.04s, LR: 0.00070, Train Loss: 0.1216, Train MAE: 0.1216,
                            Val Loss: 0.1346, Val MAE: 0.1344
2023-01-22 08:12:15,955:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-22 08:20:19,295:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13140612840652466
2023-01-22 08:20:19,296:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 483.34s, LR: 0.00070, Train Loss: 0.1253, Train MAE: 0.1253,
                            Val Loss: 0.1316, Val MAE: 0.1314
2023-01-22 08:20:19,297:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-22 08:28:18,961:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 479.66s, LR: 0.00070, Train Loss: 0.1233, Train MAE: 0.1233,
                            Val Loss: 0.1413, Val MAE: 0.1411
2023-01-22 08:28:18,963:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-22 08:36:19,056:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12876330316066742
2023-01-22 08:36:19,057:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.09s, LR: 0.00070, Train Loss: 0.1204, Train MAE: 0.1204,
                            Val Loss: 0.1290, Val MAE: 0.1288
2023-01-22 08:36:19,058:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-22 08:44:20,558:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 481.50s, LR: 0.00070, Train Loss: 0.1208, Train MAE: 0.1208,
                            Val Loss: 0.1326, Val MAE: 0.1324
2023-01-22 08:44:20,559:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-22 08:52:22,865:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 482.30s, LR: 0.00070, Train Loss: 0.1215, Train MAE: 0.1215,
                            Val Loss: 0.1363, Val MAE: 0.1361
2023-01-22 08:52:22,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-22 09:00:22,923:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 480.06s, LR: 0.00070, Train Loss: 0.1191, Train MAE: 0.1191,
                            Val Loss: 0.1350, Val MAE: 0.1347
2023-01-22 09:00:22,925:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-22 09:09:38,243:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12670888006687164
2023-01-22 09:09:38,244:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 555.32s, LR: 0.00070, Train Loss: 0.1188, Train MAE: 0.1188,
                            Val Loss: 0.1269, Val MAE: 0.1267
2023-01-22 09:09:38,246:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-22 09:17:37,436:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12563976645469666
2023-01-22 09:17:37,437:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 479.19s, LR: 0.00070, Train Loss: 0.1174, Train MAE: 0.1174,
                            Val Loss: 0.1258, Val MAE: 0.1256
2023-01-22 09:17:37,438:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-22 09:25:33,011:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.57s, LR: 0.00070, Train Loss: 0.1241, Train MAE: 0.1241,
                            Val Loss: 0.1295, Val MAE: 0.1293
2023-01-22 09:25:33,013:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-22 09:33:26,864:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.85s, LR: 0.00070, Train Loss: 0.1199, Train MAE: 0.1199,
                            Val Loss: 0.1384, Val MAE: 0.1382
2023-01-22 09:33:26,865:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-22 09:41:22,721:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.86s, LR: 0.00070, Train Loss: 0.1175, Train MAE: 0.1175,
                            Val Loss: 0.1283, Val MAE: 0.1281
2023-01-22 09:41:22,722:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-22 09:49:18,945:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 476.22s, LR: 0.00070, Train Loss: 0.1203, Train MAE: 0.1203,
                            Val Loss: 0.1345, Val MAE: 0.1343
2023-01-22 09:49:18,946:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-22 09:57:13,308:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.36s, LR: 0.00070, Train Loss: 0.1193, Train MAE: 0.1193,
                            Val Loss: 0.1296, Val MAE: 0.1294
2023-01-22 09:57:13,310:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-22 10:05:09,252:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.94s, LR: 0.00070, Train Loss: 0.1171, Train MAE: 0.1171,
                            Val Loss: 0.1376, Val MAE: 0.1374
2023-01-22 10:05:09,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-22 10:13:05,373:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 476.12s, LR: 0.00070, Train Loss: 0.1182, Train MAE: 0.1182,
                            Val Loss: 0.1543, Val MAE: 0.1542
2023-01-22 10:13:05,374:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-22 10:21:01,056:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.68s, LR: 0.00070, Train Loss: 0.1206, Train MAE: 0.1206,
                            Val Loss: 0.1344, Val MAE: 0.1342
2023-01-22 10:21:01,057:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-22 10:28:56,781:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.72s, LR: 0.00070, Train Loss: 0.1189, Train MAE: 0.1189,
                            Val Loss: 0.1269, Val MAE: 0.1267
2023-01-22 10:28:56,782:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-22 10:36:52,635:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.85s, LR: 0.00070, Train Loss: 0.1175, Train MAE: 0.1175,
                            Val Loss: 0.1439, Val MAE: 0.1437
2023-01-22 10:36:52,637:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-22 10:44:47,523:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.88s, LR: 0.00070, Train Loss: 0.1159, Train MAE: 0.1159,
                            Val Loss: 0.1277, Val MAE: 0.1275
2023-01-22 10:44:47,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-22 10:52:41,774:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.25s, LR: 0.00070, Train Loss: 0.1153, Train MAE: 0.1153,
                            Val Loss: 0.1386, Val MAE: 0.1385
2023-01-22 10:52:41,775:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-22 11:00:37,096:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12457618862390518
2023-01-22 11:00:37,098:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 475.32s, LR: 0.00070, Train Loss: 0.1145, Train MAE: 0.1145,
                            Val Loss: 0.1248, Val MAE: 0.1246
2023-01-22 11:00:37,099:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-22 11:08:31,938:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.84s, LR: 0.00070, Train Loss: 0.1139, Train MAE: 0.1139,
                            Val Loss: 0.1436, Val MAE: 0.1435
2023-01-22 11:08:31,939:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-22 11:16:26,532:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.59s, LR: 0.00070, Train Loss: 0.1171, Train MAE: 0.1171,
                            Val Loss: 0.1480, Val MAE: 0.1478
2023-01-22 11:16:26,533:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-22 11:25:31,840:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 545.31s, LR: 0.00070, Train Loss: 0.1149, Train MAE: 0.1149,
                            Val Loss: 0.1391, Val MAE: 0.1389
2023-01-22 11:25:31,841:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-22 11:33:25,603:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12275201082229614
2023-01-22 11:33:25,604:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.76s, LR: 0.00070, Train Loss: 0.1136, Train MAE: 0.1136,
                            Val Loss: 0.1229, Val MAE: 0.1228
2023-01-22 11:33:25,606:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-22 11:41:19,987:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.38s, LR: 0.00070, Train Loss: 0.1130, Train MAE: 0.1130,
                            Val Loss: 0.1261, Val MAE: 0.1259
2023-01-22 11:41:19,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-22 11:49:17,209:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 477.22s, LR: 0.00070, Train Loss: 0.1124, Train MAE: 0.1124,
                            Val Loss: 0.1270, Val MAE: 0.1268
2023-01-22 11:49:17,210:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-22 11:57:14,457:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 477.25s, LR: 0.00070, Train Loss: 0.1118, Train MAE: 0.1118,
                            Val Loss: 0.1284, Val MAE: 0.1282
2023-01-22 11:57:14,458:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-22 12:05:10,795:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 476.34s, LR: 0.00070, Train Loss: 0.1105, Train MAE: 0.1105,
                            Val Loss: 0.1247, Val MAE: 0.1245
2023-01-22 12:05:10,795:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-22 12:13:05,530:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.73s, LR: 0.00070, Train Loss: 0.1103, Train MAE: 0.1103,
                            Val Loss: 0.1310, Val MAE: 0.1308
2023-01-22 12:13:05,531:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-22 12:21:00,072:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.54s, LR: 0.00070, Train Loss: 0.1092, Train MAE: 0.1092,
                            Val Loss: 0.1334, Val MAE: 0.1332
2023-01-22 12:21:00,073:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-22 12:28:54,872:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.80s, LR: 0.00070, Train Loss: 0.1094, Train MAE: 0.1094,
                            Val Loss: 0.1969, Val MAE: 0.1967
2023-01-22 12:28:54,873:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-22 12:36:49,093:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 474.22s, LR: 0.00070, Train Loss: 0.1087, Train MAE: 0.1087,
                            Val Loss: 0.1394, Val MAE: 0.1393
2023-01-22 12:36:49,094:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-22 12:44:42,962:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12095405906438828
2023-01-22 12:44:42,964:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.87s, LR: 0.00070, Train Loss: 0.1082, Train MAE: 0.1082,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-22 12:44:42,965:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-22 12:52:36,870:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1204681470990181
2023-01-22 12:52:36,872:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.90s, LR: 0.00070, Train Loss: 0.1075, Train MAE: 0.1075,
                            Val Loss: 0.1207, Val MAE: 0.1205
2023-01-22 12:52:36,873:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-22 13:00:30,563:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.69s, LR: 0.00070, Train Loss: 0.1076, Train MAE: 0.1076,
                            Val Loss: 0.1249, Val MAE: 0.1247
2023-01-22 13:00:30,564:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-22 13:08:24,017:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 473.45s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1372, Val MAE: 0.1370
2023-01-22 13:08:24,019:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-22 13:16:16,888:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 472.87s, LR: 0.00070, Train Loss: 0.1066, Train MAE: 0.1066,
                            Val Loss: 0.1329, Val MAE: 0.1327
2023-01-22 13:16:16,890:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-22 13:24:07,929:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1184382364153862
2023-01-22 13:24:07,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 471.04s, LR: 0.00070, Train Loss: 0.1059, Train MAE: 0.1059,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-22 13:24:07,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-22 13:31:59,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 471.08s, LR: 0.00070, Train Loss: 0.1058, Train MAE: 0.1058,
                            Val Loss: 0.1251, Val MAE: 0.1249
2023-01-22 13:31:59,016:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-22 13:40:55,701:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 536.68s, LR: 0.00070, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.1217, Val MAE: 0.1215
2023-01-22 13:40:55,702:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-22 13:48:46,586:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11733041703701019
2023-01-22 13:48:46,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 470.88s, LR: 0.00070, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-22 13:48:46,589:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-22 13:56:35,113:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 468.52s, LR: 0.00070, Train Loss: 0.1045, Train MAE: 0.1045,
                            Val Loss: 0.1270, Val MAE: 0.1268
2023-01-22 13:56:35,113:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-22 14:04:24,171:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11650460213422775
2023-01-22 14:04:24,173:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 469.06s, LR: 0.00070, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1167, Val MAE: 0.1165
2023-01-22 14:04:24,174:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-22 14:12:13,132:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11524537205696106
2023-01-22 14:12:13,134:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 468.96s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1154, Val MAE: 0.1152
2023-01-22 14:12:13,135:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-22 14:19:59,767:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 466.63s, LR: 0.00070, Train Loss: 0.1043, Train MAE: 0.1043,
                            Val Loss: 0.1299, Val MAE: 0.1298
2023-01-22 14:19:59,768:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-22 14:27:45,512:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 465.74s, LR: 0.00070, Train Loss: 0.1037, Train MAE: 0.1037,
                            Val Loss: 0.1157, Val MAE: 0.1155
2023-01-22 14:27:45,514:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-22 14:35:29,363:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 463.85s, LR: 0.00070, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1301, Val MAE: 0.1299
2023-01-22 14:35:29,364:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-22 14:43:15,857:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11522962152957916
2023-01-22 14:43:15,859:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 466.49s, LR: 0.00070, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.1154, Val MAE: 0.1152
2023-01-22 14:43:15,860:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-22 14:51:00,717:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 464.86s, LR: 0.00070, Train Loss: 0.1028, Train MAE: 0.1028,
                            Val Loss: 0.1204, Val MAE: 0.1202
2023-01-22 14:51:00,718:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-22 14:58:46,166:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 465.45s, LR: 0.00070, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1182, Val MAE: 0.1180
2023-01-22 14:58:46,168:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-22 15:06:31,480:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 465.31s, LR: 0.00070, Train Loss: 0.1028, Train MAE: 0.1028,
                            Val Loss: 0.1181, Val MAE: 0.1180
2023-01-22 15:06:31,481:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-22 15:14:14,228:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 462.75s, LR: 0.00070, Train Loss: 0.1027, Train MAE: 0.1027,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-22 15:14:14,230:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-22 15:21:56,201:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 461.97s, LR: 0.00070, Train Loss: 0.1026, Train MAE: 0.1026,
                            Val Loss: 0.1158, Val MAE: 0.1156
2023-01-22 15:21:56,203:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-22 15:29:38,367:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 462.16s, LR: 0.00070, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.1156, Val MAE: 0.1154
2023-01-22 15:29:38,368:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-22 15:37:19,088:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 460.72s, LR: 0.00070, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.1167, Val MAE: 0.1165
2023-01-22 15:37:19,089:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-22 15:44:58,884:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 459.79s, LR: 0.00070, Train Loss: 0.1021, Train MAE: 0.1021,
                            Val Loss: 0.1158, Val MAE: 0.1156
2023-01-22 15:44:58,886:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-22 15:53:47,179:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 528.29s, LR: 0.00070, Train Loss: 0.1019, Train MAE: 0.1019,
                            Val Loss: 0.1406, Val MAE: 0.1404
2023-01-22 15:53:47,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-22 16:01:28,192:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 461.01s, LR: 0.00070, Train Loss: 0.1017, Train MAE: 0.1017,
                            Val Loss: 0.1173, Val MAE: 0.1172
2023-01-22 16:01:28,193:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-22 16:09:08,104:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 459.91s, LR: 0.00070, Train Loss: 0.1016, Train MAE: 0.1016,
                            Val Loss: 0.1234, Val MAE: 0.1232
2023-01-22 16:09:08,105:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-22 16:16:47,827:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11438564211130142
2023-01-22 16:16:47,828:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 459.72s, LR: 0.00070, Train Loss: 0.1013, Train MAE: 0.1013,
                            Val Loss: 0.1146, Val MAE: 0.1144
2023-01-22 16:16:47,829:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-22 16:24:29,109:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 461.28s, LR: 0.00070, Train Loss: 0.1013, Train MAE: 0.1013,
                            Val Loss: 0.1147, Val MAE: 0.1145
2023-01-22 16:24:29,110:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-22 16:32:07,819:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 458.71s, LR: 0.00070, Train Loss: 0.1012, Train MAE: 0.1012,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-22 16:32:07,821:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-22 16:39:45,524:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 457.70s, LR: 0.00070, Train Loss: 0.1010, Train MAE: 0.1010,
                            Val Loss: 0.1187, Val MAE: 0.1185
2023-01-22 16:39:45,525:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-22 16:47:24,151:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 458.62s, LR: 0.00070, Train Loss: 0.1009, Train MAE: 0.1009,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-22 16:47:24,153:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-22 16:55:07,993:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 463.84s, LR: 0.00070, Train Loss: 0.1007, Train MAE: 0.1007,
                            Val Loss: 0.1225, Val MAE: 0.1224
2023-01-22 16:55:07,995:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-22 17:02:45,126:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11385370790958405
2023-01-22 17:02:45,127:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 457.13s, LR: 0.00070, Train Loss: 0.1007, Train MAE: 0.1007,
                            Val Loss: 0.1140, Val MAE: 0.1139
2023-01-22 17:02:45,128:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-22 17:10:22,173:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 457.04s, LR: 0.00070, Train Loss: 0.1004, Train MAE: 0.1004,
                            Val Loss: 0.1149, Val MAE: 0.1147
2023-01-22 17:10:22,174:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-22 17:17:58,789:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 456.61s, LR: 0.00070, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1161, Val MAE: 0.1158
2023-01-22 17:17:58,790:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-22 17:25:34,742:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 455.95s, LR: 0.00070, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.1161, Val MAE: 0.1159
2023-01-22 17:25:34,743:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-22 17:33:10,975:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 456.23s, LR: 0.00070, Train Loss: 0.1001, Train MAE: 0.1001,
                            Val Loss: 0.1173, Val MAE: 0.1171
2023-01-22 17:33:10,977:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-22 17:40:48,947:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 457.97s, LR: 0.00070, Train Loss: 0.1004, Train MAE: 0.1004,
                            Val Loss: 0.1153, Val MAE: 0.1151
2023-01-22 17:40:48,948:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-22 17:48:25,252:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 456.30s, LR: 0.00070, Train Loss: 0.1000, Train MAE: 0.1000,
                            Val Loss: 0.1141, Val MAE: 0.1139
2023-01-22 17:48:25,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-22 17:57:08,450:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11327482014894485
2023-01-22 17:57:08,451:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 523.20s, LR: 0.00070, Train Loss: 0.1007, Train MAE: 0.1007,
                            Val Loss: 0.1135, Val MAE: 0.1133
2023-01-22 17:57:08,451:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-22 18:04:44,202:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 455.75s, LR: 0.00070, Train Loss: 0.1001, Train MAE: 0.1001,
                            Val Loss: 0.1158, Val MAE: 0.1156
2023-01-22 18:04:44,202:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-22 18:12:18,276:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 454.07s, LR: 0.00070, Train Loss: 0.1000, Train MAE: 0.1000,
                            Val Loss: 0.1144, Val MAE: 0.1142
2023-01-22 18:12:18,277:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-22 18:19:52,074:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 453.80s, LR: 0.00070, Train Loss: 0.0999, Train MAE: 0.0999,
                            Val Loss: 0.1176, Val MAE: 0.1173
2023-01-22 18:19:52,075:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-22 18:27:25,418:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 453.34s, LR: 0.00070, Train Loss: 0.0996, Train MAE: 0.0996,
                            Val Loss: 0.1152, Val MAE: 0.1150
2023-01-22 18:27:25,419:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-22 18:34:58,076:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 452.66s, LR: 0.00070, Train Loss: 0.0995, Train MAE: 0.0995,
                            Val Loss: 0.1199, Val MAE: 0.1198
2023-01-22 18:34:58,078:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-22 18:42:29,049:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 450.97s, LR: 0.00070, Train Loss: 0.0993, Train MAE: 0.0993,
                            Val Loss: 0.1176, Val MAE: 0.1173
2023-01-22 18:42:29,051:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-22 18:50:00,472:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 451.42s, LR: 0.00070, Train Loss: 0.0993, Train MAE: 0.0993,
                            Val Loss: 0.1154, Val MAE: 0.1152
2023-01-22 18:50:00,473:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-22 18:57:32,750:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11317568272352219
2023-01-22 18:57:32,751:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 452.28s, LR: 0.00070, Train Loss: 0.0993, Train MAE: 0.0993,
                            Val Loss: 0.1134, Val MAE: 0.1132
2023-01-22 18:57:32,753:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-22 19:05:03,899:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 451.15s, LR: 0.00070, Train Loss: 0.0995, Train MAE: 0.0995,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-22 19:05:03,901:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-22 19:12:36,613:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 452.71s, LR: 0.00070, Train Loss: 0.0990, Train MAE: 0.0990,
                            Val Loss: 0.1159, Val MAE: 0.1157
2023-01-22 19:12:36,615:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-22 19:20:08,811:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 452.19s, LR: 0.00070, Train Loss: 0.0990, Train MAE: 0.0990,
                            Val Loss: 0.1156, Val MAE: 0.1154
2023-01-22 19:20:08,812:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-22 19:27:40,039:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 451.23s, LR: 0.00070, Train Loss: 0.0990, Train MAE: 0.0990,
                            Val Loss: 0.1153, Val MAE: 0.1151
2023-01-22 19:27:40,041:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-22 19:35:10,051:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 450.01s, LR: 0.00070, Train Loss: 0.0991, Train MAE: 0.0991,
                            Val Loss: 0.1136, Val MAE: 0.1134
2023-01-22 19:35:10,052:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-22 19:42:40,821:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 450.77s, LR: 0.00070, Train Loss: 0.0986, Train MAE: 0.0986,
                            Val Loss: 0.1150, Val MAE: 0.1148
2023-01-22 19:42:40,822:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-22 19:50:10,156:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 449.33s, LR: 0.00070, Train Loss: 0.0987, Train MAE: 0.0987,
                            Val Loss: 0.1215, Val MAE: 0.1214
2023-01-22 19:50:10,157:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-22 19:57:39,531:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 449.37s, LR: 0.00070, Train Loss: 0.0987, Train MAE: 0.0987,
                            Val Loss: 0.1146, Val MAE: 0.1144
2023-01-22 19:57:39,532:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-22 20:06:23,067:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11294011026620865
2023-01-22 20:06:23,068:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 523.53s, LR: 0.00070, Train Loss: 0.0987, Train MAE: 0.0987,
                            Val Loss: 0.1131, Val MAE: 0.1129
2023-01-22 20:06:23,070:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 126/1000
2023-01-22 20:13:50,298:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 447.23s, LR: 0.00070, Train Loss: 0.0985, Train MAE: 0.0985,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-22 20:13:50,300:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 127/1000
2023-01-22 20:21:16,979:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 446.68s, LR: 0.00070, Train Loss: 0.0986, Train MAE: 0.0986,
                            Val Loss: 0.1163, Val MAE: 0.1161
2023-01-22 20:21:16,980:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 128/1000
2023-01-22 20:28:42,096:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 445.11s, LR: 0.00070, Train Loss: 0.0986, Train MAE: 0.0986,
                            Val Loss: 0.1134, Val MAE: 0.1131
2023-01-22 20:28:42,097:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 129/1000
2023-01-22 20:36:09,282:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 447.18s, LR: 0.00070, Train Loss: 0.0984, Train MAE: 0.0984,
                            Val Loss: 0.1226, Val MAE: 0.1224
2023-01-22 20:36:09,284:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 130/1000
2023-01-22 20:43:35,345:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 446.06s, LR: 0.00070, Train Loss: 0.0985, Train MAE: 0.0985,
                            Val Loss: 0.1155, Val MAE: 0.1153
2023-01-22 20:43:35,346:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 131/1000
2023-01-22 20:51:02,152:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 446.80s, LR: 0.00070, Train Loss: 0.0985, Train MAE: 0.0985,
                            Val Loss: 0.1136, Val MAE: 0.1134
2023-01-22 20:51:02,153:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 132/1000
2023-01-22 20:58:26,655:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 444.50s, LR: 0.00070, Train Loss: 0.0983, Train MAE: 0.0983,
                            Val Loss: 0.1133, Val MAE: 0.1131
2023-01-22 20:58:26,656:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 133/1000
2023-01-22 21:05:51,370:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 444.71s, LR: 0.00070, Train Loss: 0.0983, Train MAE: 0.0983,
                            Val Loss: 0.1134, Val MAE: 0.1132
2023-01-22 21:05:51,372:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 134/1000
2023-01-22 21:13:15,596:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11186043173074722
2023-01-22 21:13:15,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 444.22s, LR: 0.00070, Train Loss: 0.0982, Train MAE: 0.0982,
                            Val Loss: 0.1121, Val MAE: 0.1119
2023-01-22 21:13:15,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 135/1000
2023-01-22 21:20:41,059:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 445.46s, LR: 0.00070, Train Loss: 0.0980, Train MAE: 0.0980,
                            Val Loss: 0.1143, Val MAE: 0.1141
2023-01-22 21:20:41,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 136/1000
2023-01-22 21:28:02,765:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 441.70s, LR: 0.00070, Train Loss: 0.0980, Train MAE: 0.0980,
                            Val Loss: 0.1166, Val MAE: 0.1164
2023-01-22 21:28:02,766:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 137/1000
2023-01-22 21:35:25,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 442.25s, LR: 0.00070, Train Loss: 0.0979, Train MAE: 0.0979,
                            Val Loss: 0.1155, Val MAE: 0.1153
2023-01-22 21:35:25,015:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 138/1000
2023-01-22 21:42:47,091:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 442.07s, LR: 0.00070, Train Loss: 0.0979, Train MAE: 0.0979,
                            Val Loss: 0.1142, Val MAE: 0.1140
2023-01-22 21:42:47,092:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 139/1000
2023-01-22 21:50:13,347:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 446.25s, LR: 0.00070, Train Loss: 0.0976, Train MAE: 0.0976,
                            Val Loss: 0.1156, Val MAE: 0.1154
2023-01-22 21:50:13,348:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 140/1000
2023-01-22 21:57:38,823:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 445.47s, LR: 0.00070, Train Loss: 0.0977, Train MAE: 0.0977,
                            Val Loss: 0.1141, Val MAE: 0.1139
2023-01-22 21:57:38,825:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 141/1000
2023-01-22 22:05:04,263:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 445.44s, LR: 0.00070, Train Loss: 0.0977, Train MAE: 0.0977,
                            Val Loss: 0.1137, Val MAE: 0.1135
2023-01-22 22:05:04,264:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 142/1000
2023-01-22 22:13:36,207:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 511.94s, LR: 0.00070, Train Loss: 0.0980, Train MAE: 0.0980,
                            Val Loss: 0.1128, Val MAE: 0.1126
2023-01-22 22:13:36,208:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 143/1000
2023-01-22 22:21:03,345:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 447.14s, LR: 0.00070, Train Loss: 0.0975, Train MAE: 0.0975,
                            Val Loss: 0.1165, Val MAE: 0.1163
2023-01-22 22:21:03,346:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 144/1000
2023-01-22 22:28:29,427:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 446.08s, LR: 0.00070, Train Loss: 0.0975, Train MAE: 0.0975,
                            Val Loss: 0.1152, Val MAE: 0.1150
2023-01-22 22:28:29,429:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 145/1000
2023-01-22 22:35:54,276:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 444.85s, LR: 0.00070, Train Loss: 0.0974, Train MAE: 0.0974,
                            Val Loss: 0.1156, Val MAE: 0.1154
2023-01-22 22:35:54,277:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 146/1000
2023-01-22 22:43:17,668:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 443.39s, LR: 0.00070, Train Loss: 0.0975, Train MAE: 0.0975,
                            Val Loss: 0.1129, Val MAE: 0.1127
2023-01-22 22:43:17,669:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 147/1000
2023-01-22 22:50:39,044:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 441.37s, LR: 0.00070, Train Loss: 0.0974, Train MAE: 0.0974,
                            Val Loss: 0.1126, Val MAE: 0.1124
2023-01-22 22:50:39,046:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 148/1000
2023-01-22 22:58:01,336:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 442.29s, LR: 0.00070, Train Loss: 0.1144, Train MAE: 0.1144,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-22 22:58:01,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 149/1000
2023-01-22 23:05:21,491:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 440.15s, LR: 0.00070, Train Loss: 0.1015, Train MAE: 0.1015,
                            Val Loss: 0.1129, Val MAE: 0.1127
2023-01-22 23:05:21,492:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 150/1000
2023-01-22 23:12:43,131:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 441.64s, LR: 0.00070, Train Loss: 0.0982, Train MAE: 0.0982,
                            Val Loss: 0.1226, Val MAE: 0.1224
2023-01-22 23:12:43,132:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 151/1000
2023-01-22 23:20:02,712:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10881451517343521
2023-01-22 23:20:02,713:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 439.58s, LR: 0.00035, Train Loss: 0.0926, Train MAE: 0.0926,
                            Val Loss: 0.1090, Val MAE: 0.1088
2023-01-22 23:20:02,715:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 152/1000
2023-01-22 23:27:23,494:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10808519273996353
2023-01-22 23:27:23,496:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 440.78s, LR: 0.00035, Train Loss: 0.0917, Train MAE: 0.0917,
                            Val Loss: 0.1083, Val MAE: 0.1081
2023-01-22 23:27:23,497:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 153/1000
2023-01-22 23:34:44,776:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 441.28s, LR: 0.00035, Train Loss: 0.0910, Train MAE: 0.0910,
                            Val Loss: 0.1093, Val MAE: 0.1091
2023-01-22 23:34:44,777:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 154/1000
2023-01-22 23:41:59,276:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10792116820812225
2023-01-22 23:41:59,277:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 434.50s, LR: 0.00035, Train Loss: 0.0907, Train MAE: 0.0907,
                            Val Loss: 0.1081, Val MAE: 0.1079
2023-01-22 23:41:59,278:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 155/1000
2023-01-22 23:49:12,865:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 433.59s, LR: 0.00035, Train Loss: 0.0905, Train MAE: 0.0905,
                            Val Loss: 0.1095, Val MAE: 0.1093
2023-01-22 23:49:12,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 156/1000
2023-01-22 23:56:27,882:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 435.01s, LR: 0.00035, Train Loss: 0.0905, Train MAE: 0.0905,
                            Val Loss: 0.1086, Val MAE: 0.1084
2023-01-22 23:56:27,883:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 157/1000
2023-01-23 00:03:43,650:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 435.77s, LR: 0.00035, Train Loss: 0.0902, Train MAE: 0.0902,
                            Val Loss: 0.1104, Val MAE: 0.1102
2023-01-23 00:03:43,652:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 158/1000
2023-01-23 00:10:59,446:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 435.79s, LR: 0.00035, Train Loss: 0.0901, Train MAE: 0.0901,
                            Val Loss: 0.1089, Val MAE: 0.1087
2023-01-23 00:10:59,448:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 159/1000
