2023-01-22 02:30:08,120:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-22 02:30:08,121:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-22 02:41:16,159:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-22 02:41:45,431:ogbdata.py:332 -             __init__(): Time taken: 697.3108s
2023-01-22 02:41:45,432:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-22 02:41:45,432:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-22 02:41:45,432:ogbdata.py:348 -             __init__(): [I] Data load time: 697.3113s
2023-01-22 02:41:45,432:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0.02', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/gt_ogb_b1024-rand-32-scale002-noedge-scale002/32_DEBUG_0_95.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [95]}
2023-01-22 02:41:45,432:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [95], 'save_name': 'b128-prwpe', 'job_num': 32}
2023-01-22 02:41:45,448:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:41:53,153:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:41:53,153:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:41:53,153:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:41:53,188:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-22 02:41:53,196:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-22 02:41:53,196:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 95 in [95]...
2023-01-22 02:41:53,196:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:41:53,197:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:41:53,197:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:41:53,197:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:41:53,226:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-22 03:49:30,853:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4057.657356739044
2023-01-22 03:49:30,903:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-22 03:49:30,903:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-22 03:49:30,941:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-22 04:02:56,647:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.24125036597251892
2023-01-22 04:02:56,649:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 805.71s, LR: 0.00070, Train Loss: 0.3440, Train MAE: 0.3440,
                            Val Loss: 0.2416, Val MAE: 0.2413
2023-01-22 04:02:56,650:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-22 04:13:57,619:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1985878050327301
2023-01-22 04:13:57,621:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.97s, LR: 0.00070, Train Loss: 0.1924, Train MAE: 0.1924,
                            Val Loss: 0.1989, Val MAE: 0.1986
2023-01-22 04:13:57,622:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-22 04:24:57,454:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.18910403549671173
2023-01-22 04:24:57,456:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.83s, LR: 0.00070, Train Loss: 0.1714, Train MAE: 0.1714,
                            Val Loss: 0.1894, Val MAE: 0.1891
2023-01-22 04:24:57,457:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-22 04:35:57,416:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.17923881113529205
2023-01-22 04:35:57,418:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.96s, LR: 0.00070, Train Loss: 0.1617, Train MAE: 0.1617,
                            Val Loss: 0.1795, Val MAE: 0.1792
2023-01-22 04:35:57,419:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-22 04:46:58,356:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1619022786617279
2023-01-22 04:46:58,358:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.94s, LR: 0.00070, Train Loss: 0.1553, Train MAE: 0.1553,
                            Val Loss: 0.1622, Val MAE: 0.1619
2023-01-22 04:46:58,359:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-22 04:58:00,006:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.65s, LR: 0.00070, Train Loss: 0.1507, Train MAE: 0.1507,
                            Val Loss: 0.1718, Val MAE: 0.1714
2023-01-22 04:58:00,008:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-22 05:09:02,116:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.11s, LR: 0.00070, Train Loss: 0.1467, Train MAE: 0.1467,
                            Val Loss: 0.1629, Val MAE: 0.1626
2023-01-22 05:09:02,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-22 05:21:07,394:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15688006579875946
2023-01-22 05:21:07,396:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.28s, LR: 0.00070, Train Loss: 0.1428, Train MAE: 0.1428,
                            Val Loss: 0.1572, Val MAE: 0.1569
2023-01-22 05:21:07,397:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-22 05:32:11,123:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14459344744682312
2023-01-22 05:32:11,126:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.73s, LR: 0.00070, Train Loss: 0.1405, Train MAE: 0.1405,
                            Val Loss: 0.1449, Val MAE: 0.1446
2023-01-22 05:32:11,126:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-22 05:43:13,931:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.80s, LR: 0.00070, Train Loss: 0.1386, Train MAE: 0.1386,
                            Val Loss: 0.1915, Val MAE: 0.1912
2023-01-22 05:43:13,932:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-22 05:54:17,581:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14386196434497833
2023-01-22 05:54:17,583:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.65s, LR: 0.00070, Train Loss: 0.1359, Train MAE: 0.1359,
                            Val Loss: 0.1441, Val MAE: 0.1439
2023-01-22 05:54:17,584:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-22 06:05:21,426:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.84s, LR: 0.00070, Train Loss: 0.1343, Train MAE: 0.1343,
                            Val Loss: 0.1722, Val MAE: 0.1720
2023-01-22 06:05:21,428:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-22 06:16:24,581:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.15s, LR: 0.00070, Train Loss: 0.1333, Train MAE: 0.1333,
                            Val Loss: 0.1454, Val MAE: 0.1451
2023-01-22 06:16:24,582:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-22 06:27:27,766:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.18s, LR: 0.00070, Train Loss: 0.1316, Train MAE: 0.1316,
                            Val Loss: 0.1497, Val MAE: 0.1495
2023-01-22 06:27:27,767:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-22 06:38:30,706:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13893336057662964
2023-01-22 06:38:30,708:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.94s, LR: 0.00070, Train Loss: 0.1299, Train MAE: 0.1299,
                            Val Loss: 0.1392, Val MAE: 0.1389
2023-01-22 06:38:30,709:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-22 06:49:33,629:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.92s, LR: 0.00070, Train Loss: 0.1290, Train MAE: 0.1290,
                            Val Loss: 0.1498, Val MAE: 0.1496
2023-01-22 06:49:33,630:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-22 07:00:35,763:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.13s, LR: 0.00070, Train Loss: 0.1281, Train MAE: 0.1281,
                            Val Loss: 0.1400, Val MAE: 0.1398
2023-01-22 07:00:35,764:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-22 07:11:37,509:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.75s, LR: 0.00070, Train Loss: 0.1267, Train MAE: 0.1267,
                            Val Loss: 0.1484, Val MAE: 0.1482
2023-01-22 07:11:37,511:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-22 07:22:39,765:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13839736580848694
2023-01-22 07:22:39,768:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.26s, LR: 0.00070, Train Loss: 0.1256, Train MAE: 0.1256,
                            Val Loss: 0.1386, Val MAE: 0.1384
2023-01-22 07:22:39,769:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-22 07:33:40,027:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.26s, LR: 0.00070, Train Loss: 0.1245, Train MAE: 0.1245,
                            Val Loss: 0.1469, Val MAE: 0.1468
2023-01-22 07:33:40,028:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-22 07:44:40,612:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.58s, LR: 0.00070, Train Loss: 0.1238, Train MAE: 0.1238,
                            Val Loss: 0.1552, Val MAE: 0.1550
2023-01-22 07:44:40,614:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-22 07:55:42,848:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13683541119098663
2023-01-22 07:55:42,850:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.24s, LR: 0.00070, Train Loss: 0.1230, Train MAE: 0.1230,
                            Val Loss: 0.1370, Val MAE: 0.1368
2023-01-22 07:55:42,851:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-22 08:06:44,644:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.79s, LR: 0.00070, Train Loss: 0.1222, Train MAE: 0.1222,
                            Val Loss: 0.1403, Val MAE: 0.1401
2023-01-22 08:06:44,645:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-22 08:18:48,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.97s, LR: 0.00070, Train Loss: 0.1215, Train MAE: 0.1215,
                            Val Loss: 0.1544, Val MAE: 0.1542
2023-01-22 08:18:48,620:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-22 08:29:50,759:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1308048814535141
2023-01-22 08:29:50,760:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.14s, LR: 0.00070, Train Loss: 0.1204, Train MAE: 0.1204,
                            Val Loss: 0.1310, Val MAE: 0.1308
2023-01-22 08:29:50,761:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-22 08:40:53,163:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.40s, LR: 0.00070, Train Loss: 0.1198, Train MAE: 0.1198,
                            Val Loss: 0.1464, Val MAE: 0.1462
2023-01-22 08:40:53,164:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-22 08:51:54,942:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.78s, LR: 0.00070, Train Loss: 0.1192, Train MAE: 0.1192,
                            Val Loss: 0.1324, Val MAE: 0.1322
2023-01-22 08:51:54,944:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-22 09:02:57,759:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.81s, LR: 0.00070, Train Loss: 0.1185, Train MAE: 0.1185,
                            Val Loss: 0.1580, Val MAE: 0.1579
2023-01-22 09:02:57,761:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-22 09:14:02,661:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.90s, LR: 0.00070, Train Loss: 0.1184, Train MAE: 0.1184,
                            Val Loss: 0.1604, Val MAE: 0.1602
2023-01-22 09:14:02,663:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-22 09:25:06,172:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13035407662391663
2023-01-22 09:25:06,174:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.51s, LR: 0.00070, Train Loss: 0.1177, Train MAE: 0.1177,
                            Val Loss: 0.1305, Val MAE: 0.1304
2023-01-22 09:25:06,174:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-22 09:36:09,331:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1268431544303894
2023-01-22 09:36:09,332:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.16s, LR: 0.00070, Train Loss: 0.1169, Train MAE: 0.1169,
                            Val Loss: 0.1270, Val MAE: 0.1268
2023-01-22 09:36:09,333:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-22 09:47:13,681:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.35s, LR: 0.00070, Train Loss: 0.1174, Train MAE: 0.1174,
                            Val Loss: 0.1291, Val MAE: 0.1289
2023-01-22 09:47:13,682:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-22 09:58:16,865:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.18s, LR: 0.00070, Train Loss: 0.1188, Train MAE: 0.1188,
                            Val Loss: 0.1345, Val MAE: 0.1343
2023-01-22 09:58:16,866:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-22 10:09:20,248:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12261354923248291
2023-01-22 10:09:20,250:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.38s, LR: 0.00070, Train Loss: 0.1155, Train MAE: 0.1155,
                            Val Loss: 0.1228, Val MAE: 0.1226
2023-01-22 10:09:20,251:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-22 10:20:23,775:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.52s, LR: 0.00070, Train Loss: 0.1152, Train MAE: 0.1152,
                            Val Loss: 0.1376, Val MAE: 0.1374
2023-01-22 10:20:23,776:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-22 10:31:27,366:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.59s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1358, Val MAE: 0.1356
2023-01-22 10:31:27,367:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-22 10:42:31,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 664.04s, LR: 0.00070, Train Loss: 0.1149, Train MAE: 0.1149,
                            Val Loss: 0.1267, Val MAE: 0.1265
2023-01-22 10:42:31,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-22 10:53:34,471:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.06s, LR: 0.00070, Train Loss: 0.1152, Train MAE: 0.1152,
                            Val Loss: 0.1305, Val MAE: 0.1303
2023-01-22 10:53:34,472:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-22 11:04:38,228:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 663.75s, LR: 0.00070, Train Loss: 0.1147, Train MAE: 0.1147,
                            Val Loss: 0.1268, Val MAE: 0.1266
2023-01-22 11:04:38,230:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-22 11:15:40,366:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.14s, LR: 0.00070, Train Loss: 0.1135, Train MAE: 0.1135,
                            Val Loss: 0.1410, Val MAE: 0.1408
2023-01-22 11:15:40,368:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-22 11:27:40,625:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.26s, LR: 0.00070, Train Loss: 0.1174, Train MAE: 0.1174,
                            Val Loss: 0.1298, Val MAE: 0.1297
2023-01-22 11:27:40,626:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-22 11:38:39,324:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.70s, LR: 0.00070, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.1358, Val MAE: 0.1357
2023-01-22 11:38:39,325:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-22 11:49:38,781:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.46s, LR: 0.00070, Train Loss: 0.1122, Train MAE: 0.1122,
                            Val Loss: 0.1307, Val MAE: 0.1305
2023-01-22 11:49:38,782:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-22 12:00:37,229:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.45s, LR: 0.00070, Train Loss: 0.1116, Train MAE: 0.1116,
                            Val Loss: 0.1340, Val MAE: 0.1338
2023-01-22 12:00:37,230:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-22 12:11:35,782:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.55s, LR: 0.00070, Train Loss: 0.1116, Train MAE: 0.1116,
                            Val Loss: 0.1263, Val MAE: 0.1261
2023-01-22 12:11:35,784:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-22 12:22:35,605:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.82s, LR: 0.00070, Train Loss: 0.1114, Train MAE: 0.1114,
                            Val Loss: 0.1263, Val MAE: 0.1261
2023-01-22 12:22:35,606:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-22 12:33:34,182:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.57s, LR: 0.00070, Train Loss: 0.1114, Train MAE: 0.1114,
                            Val Loss: 0.1260, Val MAE: 0.1258
2023-01-22 12:33:34,183:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-22 12:44:32,648:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12216958403587341
2023-01-22 12:44:32,651:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.47s, LR: 0.00070, Train Loss: 0.1109, Train MAE: 0.1109,
                            Val Loss: 0.1224, Val MAE: 0.1222
2023-01-22 12:44:32,651:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-22 12:55:31,747:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.09s, LR: 0.00070, Train Loss: 0.1105, Train MAE: 0.1105,
                            Val Loss: 0.1364, Val MAE: 0.1362
2023-01-22 12:55:31,749:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-22 13:06:28,966:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.22s, LR: 0.00070, Train Loss: 0.1110, Train MAE: 0.1110,
                            Val Loss: 0.1247, Val MAE: 0.1245
2023-01-22 13:06:28,966:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-22 13:17:25,968:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.00s, LR: 0.00070, Train Loss: 0.1108, Train MAE: 0.1108,
                            Val Loss: 0.1238, Val MAE: 0.1236
2023-01-22 13:17:25,969:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-22 13:28:22,323:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.35s, LR: 0.00070, Train Loss: 0.1096, Train MAE: 0.1096,
                            Val Loss: 0.1272, Val MAE: 0.1270
2023-01-22 13:28:22,324:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-22 13:39:18,532:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.21s, LR: 0.00070, Train Loss: 0.1091, Train MAE: 0.1091,
                            Val Loss: 0.1261, Val MAE: 0.1260
2023-01-22 13:39:18,533:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-22 13:50:13,824:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.29s, LR: 0.00070, Train Loss: 0.1091, Train MAE: 0.1091,
                            Val Loss: 0.1271, Val MAE: 0.1270
2023-01-22 13:50:13,825:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-22 14:01:10,159:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.33s, LR: 0.00070, Train Loss: 0.1089, Train MAE: 0.1089,
                            Val Loss: 0.1353, Val MAE: 0.1351
2023-01-22 14:01:10,160:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-22 14:12:06,293:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.13s, LR: 0.00070, Train Loss: 0.1086, Train MAE: 0.1086,
                            Val Loss: 0.1234, Val MAE: 0.1232
2023-01-22 14:12:06,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-22 14:23:02,140:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.85s, LR: 0.00070, Train Loss: 0.1082, Train MAE: 0.1082,
                            Val Loss: 0.1261, Val MAE: 0.1259
2023-01-22 14:23:02,141:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-22 14:34:59,239:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.10s, LR: 0.00070, Train Loss: 0.1082, Train MAE: 0.1082,
                            Val Loss: 0.1492, Val MAE: 0.1490
2023-01-22 14:34:59,240:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-22 14:45:57,590:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12091884762048721
2023-01-22 14:45:57,592:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.35s, LR: 0.00070, Train Loss: 0.1088, Train MAE: 0.1088,
                            Val Loss: 0.1211, Val MAE: 0.1209
2023-01-22 14:45:57,593:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-22 14:56:55,524:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.93s, LR: 0.00070, Train Loss: 0.1079, Train MAE: 0.1079,
                            Val Loss: 0.1229, Val MAE: 0.1227
2023-01-22 14:56:55,525:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-22 15:07:53,099:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.57s, LR: 0.00070, Train Loss: 0.1079, Train MAE: 0.1079,
                            Val Loss: 0.1225, Val MAE: 0.1223
2023-01-22 15:07:53,100:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-22 15:18:51,117:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12043271958827972
2023-01-22 15:18:51,119:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.02s, LR: 0.00070, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.1206, Val MAE: 0.1204
2023-01-22 15:18:51,120:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-22 15:29:48,465:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.34s, LR: 0.00070, Train Loss: 0.1069, Train MAE: 0.1069,
                            Val Loss: 0.1236, Val MAE: 0.1234
2023-01-22 15:29:48,466:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-22 15:40:46,164:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.120179183781147
2023-01-22 15:40:46,166:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.70s, LR: 0.00070, Train Loss: 0.1069, Train MAE: 0.1069,
                            Val Loss: 0.1204, Val MAE: 0.1202
2023-01-22 15:40:46,166:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-22 15:51:44,109:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.94s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1253, Val MAE: 0.1251
2023-01-22 15:51:44,109:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-22 16:02:40,947:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.84s, LR: 0.00070, Train Loss: 0.1067, Train MAE: 0.1067,
                            Val Loss: 0.1399, Val MAE: 0.1397
2023-01-22 16:02:40,948:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-22 16:13:38,336:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11849622428417206
2023-01-22 16:13:38,338:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.39s, LR: 0.00070, Train Loss: 0.1064, Train MAE: 0.1064,
                            Val Loss: 0.1187, Val MAE: 0.1185
2023-01-22 16:13:38,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-22 16:24:36,394:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.05s, LR: 0.00070, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.1247, Val MAE: 0.1245
2023-01-22 16:24:36,395:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-22 16:35:33,007:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.61s, LR: 0.00070, Train Loss: 0.1066, Train MAE: 0.1066,
                            Val Loss: 0.1232, Val MAE: 0.1230
2023-01-22 16:35:33,008:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-22 16:46:30,100:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.09s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1213, Val MAE: 0.1211
2023-01-22 16:46:30,101:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-22 16:57:30,500:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.40s, LR: 0.00070, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-22 16:57:30,501:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-22 17:08:32,224:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.72s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1222, Val MAE: 0.1220
2023-01-22 17:08:32,225:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-22 17:19:34,533:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.31s, LR: 0.00070, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.1216, Val MAE: 0.1214
2023-01-22 17:19:34,535:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-22 17:30:36,598:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.06s, LR: 0.00070, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.1238, Val MAE: 0.1236
2023-01-22 17:30:36,599:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-22 17:42:39,761:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.16s, LR: 0.00070, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.1290, Val MAE: 0.1288
2023-01-22 17:42:39,762:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-22 17:53:41,634:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.87s, LR: 0.00070, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1210, Val MAE: 0.1207
2023-01-22 17:53:41,635:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-22 18:04:43,663:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.03s, LR: 0.00070, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1216, Val MAE: 0.1214
2023-01-22 18:04:43,664:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-22 18:15:45,079:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.41s, LR: 0.00070, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1214, Val MAE: 0.1212
2023-01-22 18:15:45,080:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-22 18:26:47,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.51s, LR: 0.00070, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.1279, Val MAE: 0.1277
2023-01-22 18:26:47,589:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-22 18:37:49,146:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.56s, LR: 0.00070, Train Loss: 0.1084, Train MAE: 0.1084,
                            Val Loss: 0.1218, Val MAE: 0.1217
2023-01-22 18:37:49,147:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-22 18:48:50,225:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.08s, LR: 0.00070, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-22 18:48:50,226:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-22 18:59:52,605:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.38s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-22 18:59:52,606:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-22 19:10:53,497:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.89s, LR: 0.00070, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.1208, Val MAE: 0.1206
2023-01-22 19:10:53,498:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-22 19:21:50,936:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11240576207637787
2023-01-22 19:21:50,938:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.44s, LR: 0.00035, Train Loss: 0.0984, Train MAE: 0.0984,
                            Val Loss: 0.1126, Val MAE: 0.1124
2023-01-22 19:21:50,939:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-22 19:32:52,258:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.32s, LR: 0.00035, Train Loss: 0.0973, Train MAE: 0.0973,
                            Val Loss: 0.1128, Val MAE: 0.1125
2023-01-22 19:32:52,259:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-22 19:43:53,536:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.28s, LR: 0.00035, Train Loss: 0.0964, Train MAE: 0.0964,
                            Val Loss: 0.1137, Val MAE: 0.1135
2023-01-22 19:43:53,537:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-22 19:54:51,058:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.52s, LR: 0.00035, Train Loss: 0.0962, Train MAE: 0.0962,
                            Val Loss: 0.1170, Val MAE: 0.1168
2023-01-22 19:54:51,059:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-22 20:05:45,174:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.11s, LR: 0.00035, Train Loss: 0.0957, Train MAE: 0.0957,
                            Val Loss: 0.1127, Val MAE: 0.1125
2023-01-22 20:05:45,176:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-22 20:16:39,272:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.10s, LR: 0.00035, Train Loss: 0.0957, Train MAE: 0.0957,
                            Val Loss: 0.1164, Val MAE: 0.1163
2023-01-22 20:16:39,273:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-22 20:27:33,001:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11084584146738052
2023-01-22 20:27:33,003:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.73s, LR: 0.00035, Train Loss: 0.0956, Train MAE: 0.0956,
                            Val Loss: 0.1110, Val MAE: 0.1108
2023-01-22 20:27:33,004:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-22 20:38:26,914:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.91s, LR: 0.00035, Train Loss: 0.0951, Train MAE: 0.0951,
                            Val Loss: 0.1219, Val MAE: 0.1217
2023-01-22 20:38:26,915:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-22 20:50:21,804:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.89s, LR: 0.00035, Train Loss: 0.0950, Train MAE: 0.0950,
                            Val Loss: 0.1122, Val MAE: 0.1120
2023-01-22 20:50:21,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-22 21:01:16,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.50s, LR: 0.00035, Train Loss: 0.0948, Train MAE: 0.0948,
                            Val Loss: 0.1167, Val MAE: 0.1165
2023-01-22 21:01:16,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-22 21:12:09,639:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.33s, LR: 0.00035, Train Loss: 0.0946, Train MAE: 0.0946,
                            Val Loss: 0.1123, Val MAE: 0.1121
2023-01-22 21:12:09,640:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-22 21:23:02,976:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.34s, LR: 0.00035, Train Loss: 0.0945, Train MAE: 0.0945,
                            Val Loss: 0.1114, Val MAE: 0.1112
2023-01-22 21:23:02,978:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-22 21:33:57,337:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.36s, LR: 0.00035, Train Loss: 0.0943, Train MAE: 0.0943,
                            Val Loss: 0.1114, Val MAE: 0.1112
2023-01-22 21:33:57,338:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-22 21:44:51,034:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.70s, LR: 0.00035, Train Loss: 0.0942, Train MAE: 0.0942,
                            Val Loss: 0.1119, Val MAE: 0.1117
2023-01-22 21:44:51,036:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-22 21:55:44,383:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.35s, LR: 0.00035, Train Loss: 0.0941, Train MAE: 0.0941,
                            Val Loss: 0.1134, Val MAE: 0.1132
2023-01-22 21:55:44,384:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-22 22:06:38,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.06s, LR: 0.00035, Train Loss: 0.0940, Train MAE: 0.0940,
                            Val Loss: 0.1116, Val MAE: 0.1114
2023-01-22 22:06:38,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-22 22:17:31,837:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.39s, LR: 0.00035, Train Loss: 0.0938, Train MAE: 0.0938,
                            Val Loss: 0.1128, Val MAE: 0.1126
2023-01-22 22:17:31,838:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-22 22:28:25,022:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.18s, LR: 0.00035, Train Loss: 0.0939, Train MAE: 0.0939,
                            Val Loss: 0.1130, Val MAE: 0.1128
2023-01-22 22:28:25,023:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-22 22:39:18,000:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.98s, LR: 0.00035, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.1123, Val MAE: 0.1121
2023-01-22 22:39:18,001:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-22 22:50:11,525:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.52s, LR: 0.00035, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.1142, Val MAE: 0.1140
2023-01-22 22:50:11,526:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-22 23:01:05,347:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.82s, LR: 0.00035, Train Loss: 0.0938, Train MAE: 0.0938,
                            Val Loss: 0.1125, Val MAE: 0.1124
2023-01-22 23:01:05,348:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-22 23:11:58,315:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.97s, LR: 0.00035, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.1116, Val MAE: 0.1114
2023-01-22 23:11:58,316:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-22 23:22:51,212:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.90s, LR: 0.00035, Train Loss: 0.0934, Train MAE: 0.0934,
                            Val Loss: 0.1111, Val MAE: 0.1109
2023-01-22 23:22:51,213:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-22 23:33:44,874:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10856099426746368
2023-01-22 23:33:44,875:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.66s, LR: 0.00017, Train Loss: 0.0897, Train MAE: 0.0897,
                            Val Loss: 0.1087, Val MAE: 0.1086
2023-01-22 23:33:44,876:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-22 23:45:40,746:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 715.87s, LR: 0.00017, Train Loss: 0.0892, Train MAE: 0.0892,
                            Val Loss: 0.1092, Val MAE: 0.1090
2023-01-22 23:45:40,747:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-22 23:56:30,992:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.24s, LR: 0.00017, Train Loss: 0.0891, Train MAE: 0.0891,
                            Val Loss: 0.1089, Val MAE: 0.1087
2023-01-22 23:56:30,993:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-23 00:07:22,974:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.98s, LR: 0.00017, Train Loss: 0.0888, Train MAE: 0.0888,
                            Val Loss: 0.1093, Val MAE: 0.1091
2023-01-23 00:07:22,975:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
