2023-01-22 02:28:33,583:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-22 02:28:33,583:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-22 02:40:21,911:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-22 02:40:57,049:ogbdata.py:332 -             __init__(): Time taken: 743.4659s
2023-01-22 02:40:57,049:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-22 02:40:57,049:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-22 02:40:57,050:ogbdata.py:348 -             __init__(): [I] Data load time: 743.4662s
2023-01-22 02:40:57,050:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0.02', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/gt_ogb_b1024-rand-32-scale002-noedge-scale002/32_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-22 02:40:57,050:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b128-prwpe', 'job_num': 32}
2023-01-22 02:40:57,051:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:40:58,910:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:40:58,910:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:40:58,910:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:40:58,927:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-22 02:40:58,929:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-22 02:40:58,929:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-22 02:40:58,930:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:40:58,931:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:40:58,931:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:40:58,931:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:40:58,955:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-22 03:59:11,057:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4692.127371072769
2023-01-22 03:59:11,121:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-22 03:59:11,122:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-22 03:59:11,131:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-22 04:13:03,803:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.24935899674892426
2023-01-22 04:13:03,805:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 832.67s, LR: 0.00070, Train Loss: 0.3234, Train MAE: 0.3234,
                            Val Loss: 0.2497, Val MAE: 0.2494
2023-01-22 04:13:03,805:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-22 04:24:44,777:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.22249311208724976
2023-01-22 04:24:44,779:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 700.97s, LR: 0.00070, Train Loss: 0.1805, Train MAE: 0.1805,
                            Val Loss: 0.2229, Val MAE: 0.2225
2023-01-22 04:24:44,779:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-22 04:36:57,255:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.47s, LR: 0.00070, Train Loss: 0.1642, Train MAE: 0.1642,
                            Val Loss: 0.2444, Val MAE: 0.2440
2023-01-22 04:36:57,257:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-22 04:49:09,382:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1679544746875763
2023-01-22 04:49:09,385:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 732.13s, LR: 0.00070, Train Loss: 0.1557, Train MAE: 0.1557,
                            Val Loss: 0.1684, Val MAE: 0.1680
2023-01-22 04:49:09,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-22 05:01:23,168:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 733.78s, LR: 0.00070, Train Loss: 0.1505, Train MAE: 0.1505,
                            Val Loss: 0.1856, Val MAE: 0.1852
2023-01-22 05:01:23,170:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-22 05:13:11,903:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16339801251888275
2023-01-22 05:13:11,905:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.73s, LR: 0.00070, Train Loss: 0.1456, Train MAE: 0.1456,
                            Val Loss: 0.1638, Val MAE: 0.1634
2023-01-22 05:13:11,906:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-22 05:24:23,681:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.77s, LR: 0.00070, Train Loss: 0.1437, Train MAE: 0.1437,
                            Val Loss: 0.1890, Val MAE: 0.1886
2023-01-22 05:24:23,683:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-22 05:36:45,633:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16090799868106842
2023-01-22 05:36:45,635:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 741.95s, LR: 0.00070, Train Loss: 0.1403, Train MAE: 0.1403,
                            Val Loss: 0.1613, Val MAE: 0.1609
2023-01-22 05:36:45,636:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-22 05:47:57,423:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 671.79s, LR: 0.00070, Train Loss: 0.1382, Train MAE: 0.1382,
                            Val Loss: 0.1902, Val MAE: 0.1899
2023-01-22 05:47:57,424:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-22 05:59:40,827:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15080520510673523
2023-01-22 05:59:40,830:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 703.40s, LR: 0.00070, Train Loss: 0.1356, Train MAE: 0.1356,
                            Val Loss: 0.1511, Val MAE: 0.1508
2023-01-22 05:59:40,830:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-22 06:11:54,056:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14872263371944427
2023-01-22 06:11:54,058:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 733.23s, LR: 0.00070, Train Loss: 0.1344, Train MAE: 0.1344,
                            Val Loss: 0.1491, Val MAE: 0.1487
2023-01-22 06:11:54,059:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-22 06:24:04,838:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 730.78s, LR: 0.00070, Train Loss: 0.1331, Train MAE: 0.1331,
                            Val Loss: 0.1539, Val MAE: 0.1536
2023-01-22 06:24:04,840:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-22 06:36:13,484:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.64s, LR: 0.00070, Train Loss: 0.1314, Train MAE: 0.1314,
                            Val Loss: 0.1602, Val MAE: 0.1599
2023-01-22 06:36:13,485:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-22 06:48:21,710:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 728.22s, LR: 0.00070, Train Loss: 0.1303, Train MAE: 0.1303,
                            Val Loss: 0.1729, Val MAE: 0.1727
2023-01-22 06:48:21,712:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-22 07:00:27,653:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.94s, LR: 0.00070, Train Loss: 0.1294, Train MAE: 0.1294,
                            Val Loss: 0.3583, Val MAE: 0.3582
2023-01-22 07:00:27,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-22 07:12:34,134:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.48s, LR: 0.00070, Train Loss: 0.1284, Train MAE: 0.1284,
                            Val Loss: 0.1658, Val MAE: 0.1655
2023-01-22 07:12:34,136:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-22 07:24:41,178:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.04s, LR: 0.00070, Train Loss: 0.1274, Train MAE: 0.1274,
                            Val Loss: 0.1965, Val MAE: 0.1962
2023-01-22 07:24:41,180:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-22 07:36:47,607:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.43s, LR: 0.00070, Train Loss: 0.1269, Train MAE: 0.1269,
                            Val Loss: 0.1584, Val MAE: 0.1582
2023-01-22 07:36:47,608:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-22 07:48:53,251:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14739719033241272
2023-01-22 07:48:53,253:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.64s, LR: 0.00070, Train Loss: 0.1254, Train MAE: 0.1254,
                            Val Loss: 0.1477, Val MAE: 0.1474
2023-01-22 07:48:53,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-22 08:01:00,384:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 727.13s, LR: 0.00070, Train Loss: 0.1248, Train MAE: 0.1248,
                            Val Loss: 0.1520, Val MAE: 0.1518
2023-01-22 08:01:00,385:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-22 08:13:06,789:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.40s, LR: 0.00070, Train Loss: 0.1244, Train MAE: 0.1244,
                            Val Loss: 0.1731, Val MAE: 0.1728
2023-01-22 08:13:06,791:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-22 08:25:12,455:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.66s, LR: 0.00070, Train Loss: 0.1235, Train MAE: 0.1235,
                            Val Loss: 0.1738, Val MAE: 0.1735
2023-01-22 08:25:12,456:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-22 08:37:18,866:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.145108163356781
2023-01-22 08:37:18,868:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.41s, LR: 0.00070, Train Loss: 0.1229, Train MAE: 0.1229,
                            Val Loss: 0.1454, Val MAE: 0.1451
2023-01-22 08:37:18,869:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-22 08:50:32,349:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 793.48s, LR: 0.00070, Train Loss: 0.1221, Train MAE: 0.1221,
                            Val Loss: 0.1881, Val MAE: 0.1879
2023-01-22 08:50:32,351:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-22 09:02:39,330:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14440347254276276
2023-01-22 09:02:39,332:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.98s, LR: 0.00070, Train Loss: 0.1217, Train MAE: 0.1217,
                            Val Loss: 0.1447, Val MAE: 0.1444
2023-01-22 09:02:39,333:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-22 09:14:44,815:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.48s, LR: 0.00070, Train Loss: 0.1211, Train MAE: 0.1211,
                            Val Loss: 0.1761, Val MAE: 0.1758
2023-01-22 09:14:44,816:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-22 09:26:51,360:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1332385092973709
2023-01-22 09:26:51,362:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.54s, LR: 0.00070, Train Loss: 0.1206, Train MAE: 0.1206,
                            Val Loss: 0.1335, Val MAE: 0.1332
2023-01-22 09:26:51,363:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-22 09:38:57,059:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.70s, LR: 0.00070, Train Loss: 0.1205, Train MAE: 0.1205,
                            Val Loss: 0.1418, Val MAE: 0.1416
2023-01-22 09:38:57,060:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-22 09:51:02,925:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.86s, LR: 0.00070, Train Loss: 0.1195, Train MAE: 0.1195,
                            Val Loss: 0.1407, Val MAE: 0.1404
2023-01-22 09:51:02,926:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-22 10:03:03,765:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1280781477689743
2023-01-22 10:03:03,768:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 720.84s, LR: 0.00070, Train Loss: 0.1191, Train MAE: 0.1191,
                            Val Loss: 0.1283, Val MAE: 0.1281
2023-01-22 10:03:03,768:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-22 10:14:00,420:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.65s, LR: 0.00070, Train Loss: 0.1188, Train MAE: 0.1188,
                            Val Loss: 0.1631, Val MAE: 0.1630
2023-01-22 10:14:00,422:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-22 10:24:57,239:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.82s, LR: 0.00070, Train Loss: 0.1184, Train MAE: 0.1184,
                            Val Loss: 0.1394, Val MAE: 0.1391
2023-01-22 10:24:57,240:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-22 10:35:53,790:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.55s, LR: 0.00070, Train Loss: 0.1184, Train MAE: 0.1184,
                            Val Loss: 0.1353, Val MAE: 0.1350
2023-01-22 10:35:53,792:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-22 10:46:49,895:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.10s, LR: 0.00070, Train Loss: 0.1176, Train MAE: 0.1176,
                            Val Loss: 0.1455, Val MAE: 0.1453
2023-01-22 10:46:49,896:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-22 10:57:46,693:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.80s, LR: 0.00070, Train Loss: 0.1175, Train MAE: 0.1175,
                            Val Loss: 0.1444, Val MAE: 0.1442
2023-01-22 10:57:46,695:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-22 11:08:43,407:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.71s, LR: 0.00070, Train Loss: 0.1171, Train MAE: 0.1171,
                            Val Loss: 0.1399, Val MAE: 0.1397
2023-01-22 11:08:43,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-22 11:19:40,131:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.72s, LR: 0.00070, Train Loss: 0.1168, Train MAE: 0.1168,
                            Val Loss: 0.1334, Val MAE: 0.1332
2023-01-22 11:19:40,132:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-22 11:30:35,961:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.83s, LR: 0.00070, Train Loss: 0.1165, Train MAE: 0.1165,
                            Val Loss: 0.1334, Val MAE: 0.1331
2023-01-22 11:30:35,963:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-22 11:41:31,756:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.79s, LR: 0.00070, Train Loss: 0.1160, Train MAE: 0.1160,
                            Val Loss: 0.1457, Val MAE: 0.1454
2023-01-22 11:41:31,757:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-22 11:53:16,418:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 704.66s, LR: 0.00070, Train Loss: 0.1155, Train MAE: 0.1155,
                            Val Loss: 0.1289, Val MAE: 0.1287
2023-01-22 11:53:16,418:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-22 12:05:22,552:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 726.13s, LR: 0.00070, Train Loss: 0.1157, Train MAE: 0.1157,
                            Val Loss: 0.1332, Val MAE: 0.1329
2023-01-22 12:05:22,554:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-22 12:16:23,198:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.64s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1346, Val MAE: 0.1344
2023-01-22 12:16:23,200:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-22 12:27:23,963:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.76s, LR: 0.00070, Train Loss: 0.1149, Train MAE: 0.1149,
                            Val Loss: 0.1671, Val MAE: 0.1669
2023-01-22 12:27:23,964:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-22 12:38:24,402:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.44s, LR: 0.00070, Train Loss: 0.1143, Train MAE: 0.1143,
                            Val Loss: 0.1484, Val MAE: 0.1481
2023-01-22 12:38:24,403:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-22 12:49:24,151:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.75s, LR: 0.00070, Train Loss: 0.1140, Train MAE: 0.1140,
                            Val Loss: 0.1470, Val MAE: 0.1467
2023-01-22 12:49:24,152:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-22 13:00:24,376:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.22s, LR: 0.00070, Train Loss: 0.1144, Train MAE: 0.1144,
                            Val Loss: 0.1287, Val MAE: 0.1284
2023-01-22 13:00:24,377:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-22 13:11:25,756:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12077786773443222
2023-01-22 13:11:25,758:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.38s, LR: 0.00035, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-22 13:11:25,759:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-22 13:22:25,957:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.20s, LR: 0.00035, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.1235, Val MAE: 0.1233
2023-01-22 13:22:25,958:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-22 13:33:25,292:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11800943315029144
2023-01-22 13:33:25,293:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.34s, LR: 0.00035, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1182, Val MAE: 0.1180
2023-01-22 13:33:25,294:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-22 13:44:25,665:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.37s, LR: 0.00035, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.1194, Val MAE: 0.1191
2023-01-22 13:44:25,665:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-22 13:55:39,803:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 674.14s, LR: 0.00035, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1249, Val MAE: 0.1247
2023-01-22 13:55:39,804:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-22 14:07:44,608:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.80s, LR: 0.00035, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.1195, Val MAE: 0.1193
2023-01-22 14:07:44,609:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-22 14:19:49,627:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.02s, LR: 0.00035, Train Loss: 0.1027, Train MAE: 0.1027,
                            Val Loss: 0.1234, Val MAE: 0.1232
2023-01-22 14:19:49,628:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-22 14:31:55,303:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11725519597530365
2023-01-22 14:31:55,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.68s, LR: 0.00035, Train Loss: 0.1025, Train MAE: 0.1025,
                            Val Loss: 0.1175, Val MAE: 0.1173
2023-01-22 14:31:55,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-22 14:43:59,573:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.27s, LR: 0.00035, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.1182, Val MAE: 0.1180
2023-01-22 14:43:59,574:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-22 14:55:47,927:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 708.35s, LR: 0.00035, Train Loss: 0.1018, Train MAE: 0.1018,
                            Val Loss: 0.1187, Val MAE: 0.1185
2023-01-22 14:55:47,928:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-22 15:06:47,721:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11709540337324142
2023-01-22 15:06:47,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.79s, LR: 0.00035, Train Loss: 0.1016, Train MAE: 0.1016,
                            Val Loss: 0.1173, Val MAE: 0.1171
2023-01-22 15:06:47,723:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-22 15:18:53,132:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 725.41s, LR: 0.00035, Train Loss: 0.1016, Train MAE: 0.1016,
                            Val Loss: 0.1213, Val MAE: 0.1211
2023-01-22 15:18:53,133:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-22 15:29:53,428:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.29s, LR: 0.00035, Train Loss: 0.1014, Train MAE: 0.1014,
                            Val Loss: 0.1187, Val MAE: 0.1184
2023-01-22 15:29:53,429:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-22 15:40:53,488:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.06s, LR: 0.00035, Train Loss: 0.1011, Train MAE: 0.1011,
                            Val Loss: 0.1232, Val MAE: 0.1229
2023-01-22 15:40:53,489:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-22 15:51:53,595:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.11s, LR: 0.00035, Train Loss: 0.1008, Train MAE: 0.1008,
                            Val Loss: 0.1177, Val MAE: 0.1174
2023-01-22 15:51:53,596:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-22 16:03:51,418:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.82s, LR: 0.00035, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.1203, Val MAE: 0.1201
2023-01-22 16:03:51,419:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-22 16:15:56,220:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.80s, LR: 0.00035, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.1257, Val MAE: 0.1255
2023-01-22 16:15:56,221:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-22 16:28:00,210:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.99s, LR: 0.00035, Train Loss: 0.1003, Train MAE: 0.1003,
                            Val Loss: 0.1212, Val MAE: 0.1209
2023-01-22 16:28:00,211:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-22 16:40:04,308:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11523611098527908
2023-01-22 16:40:04,310:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.10s, LR: 0.00035, Train Loss: 0.1004, Train MAE: 0.1004,
                            Val Loss: 0.1155, Val MAE: 0.1152
2023-01-22 16:40:04,310:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-22 16:52:08,235:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.92s, LR: 0.00035, Train Loss: 0.1000, Train MAE: 0.1000,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-22 16:52:08,236:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-22 17:04:13,017:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.78s, LR: 0.00035, Train Loss: 0.0998, Train MAE: 0.0998,
                            Val Loss: 0.1164, Val MAE: 0.1161
2023-01-22 17:04:13,018:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-22 17:16:17,002:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.98s, LR: 0.00035, Train Loss: 0.0999, Train MAE: 0.0999,
                            Val Loss: 0.1219, Val MAE: 0.1216
2023-01-22 17:16:17,003:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-22 17:28:20,687:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.68s, LR: 0.00035, Train Loss: 0.0996, Train MAE: 0.0996,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-22 17:28:20,688:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-22 17:40:24,581:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.89s, LR: 0.00035, Train Loss: 0.0994, Train MAE: 0.0994,
                            Val Loss: 0.1155, Val MAE: 0.1153
2023-01-22 17:40:24,582:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-22 17:52:29,014:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.43s, LR: 0.00035, Train Loss: 0.0993, Train MAE: 0.0993,
                            Val Loss: 0.1181, Val MAE: 0.1179
2023-01-22 17:52:29,014:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-22 18:04:33,042:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.03s, LR: 0.00035, Train Loss: 0.0992, Train MAE: 0.0992,
                            Val Loss: 0.1183, Val MAE: 0.1180
2023-01-22 18:04:33,043:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-22 18:16:36,419:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.38s, LR: 0.00035, Train Loss: 0.0990, Train MAE: 0.0990,
                            Val Loss: 0.1190, Val MAE: 0.1187
2023-01-22 18:16:36,420:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-22 18:27:50,468:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 674.05s, LR: 0.00035, Train Loss: 0.0988, Train MAE: 0.0988,
                            Val Loss: 0.1204, Val MAE: 0.1202
2023-01-22 18:27:50,469:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-22 18:39:48,202:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.73s, LR: 0.00035, Train Loss: 0.0990, Train MAE: 0.0990,
                            Val Loss: 0.1180, Val MAE: 0.1177
2023-01-22 18:39:48,203:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-22 18:50:40,828:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.62s, LR: 0.00035, Train Loss: 0.0987, Train MAE: 0.0987,
                            Val Loss: 0.1161, Val MAE: 0.1158
2023-01-22 18:50:40,829:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-22 19:02:30,603:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 709.77s, LR: 0.00035, Train Loss: 0.0987, Train MAE: 0.0987,
                            Val Loss: 0.1254, Val MAE: 0.1252
2023-01-22 19:02:30,604:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-22 19:14:34,085:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.48s, LR: 0.00035, Train Loss: 0.0983, Train MAE: 0.0983,
                            Val Loss: 0.1215, Val MAE: 0.1213
2023-01-22 19:14:34,086:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-22 19:26:37,575:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.49s, LR: 0.00035, Train Loss: 0.0983, Train MAE: 0.0983,
                            Val Loss: 0.1157, Val MAE: 0.1155
2023-01-22 19:26:37,576:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-22 19:38:40,499:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.92s, LR: 0.00035, Train Loss: 0.0984, Train MAE: 0.0984,
                            Val Loss: 0.1196, Val MAE: 0.1193
2023-01-22 19:38:40,500:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-22 19:50:43,886:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.39s, LR: 0.00035, Train Loss: 0.0983, Train MAE: 0.0983,
                            Val Loss: 0.1184, Val MAE: 0.1182
2023-01-22 19:50:43,887:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-22 20:02:48,225:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11107523739337921
2023-01-22 20:02:48,226:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 724.34s, LR: 0.00017, Train Loss: 0.0936, Train MAE: 0.0936,
                            Val Loss: 0.1113, Val MAE: 0.1111
2023-01-22 20:02:48,227:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-22 20:14:51,612:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.39s, LR: 0.00017, Train Loss: 0.0930, Train MAE: 0.0930,
                            Val Loss: 0.1118, Val MAE: 0.1115
2023-01-22 20:14:51,613:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-22 20:26:55,408:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.79s, LR: 0.00017, Train Loss: 0.0928, Train MAE: 0.0928,
                            Val Loss: 0.1154, Val MAE: 0.1152
2023-01-22 20:26:55,409:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-22 20:38:58,950:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.54s, LR: 0.00017, Train Loss: 0.0925, Train MAE: 0.0925,
                            Val Loss: 0.1130, Val MAE: 0.1127
2023-01-22 20:38:58,951:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-22 20:51:02,523:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.57s, LR: 0.00017, Train Loss: 0.0924, Train MAE: 0.0924,
                            Val Loss: 0.1129, Val MAE: 0.1126
2023-01-22 20:51:02,524:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-22 21:03:06,444:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.92s, LR: 0.00017, Train Loss: 0.0922, Train MAE: 0.0922,
                            Val Loss: 0.1132, Val MAE: 0.1129
2023-01-22 21:03:06,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-22 21:15:09,182:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.74s, LR: 0.00017, Train Loss: 0.0921, Train MAE: 0.0921,
                            Val Loss: 0.1137, Val MAE: 0.1134
2023-01-22 21:15:09,183:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-22 21:27:12,252:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.07s, LR: 0.00017, Train Loss: 0.0920, Train MAE: 0.0920,
                            Val Loss: 0.1140, Val MAE: 0.1138
2023-01-22 21:27:12,254:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-22 21:39:15,348:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.09s, LR: 0.00017, Train Loss: 0.0919, Train MAE: 0.0919,
                            Val Loss: 0.1134, Val MAE: 0.1131
2023-01-22 21:39:15,349:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-22 21:51:18,044:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 722.69s, LR: 0.00017, Train Loss: 0.0918, Train MAE: 0.0918,
                            Val Loss: 0.1141, Val MAE: 0.1139
2023-01-22 21:51:18,045:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-22 22:04:25,371:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 787.33s, LR: 0.00017, Train Loss: 0.0917, Train MAE: 0.0917,
                            Val Loss: 0.1133, Val MAE: 0.1131
2023-01-22 22:04:25,372:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-22 22:15:24,702:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.33s, LR: 0.00017, Train Loss: 0.0917, Train MAE: 0.0917,
                            Val Loss: 0.1119, Val MAE: 0.1117
2023-01-22 22:15:24,703:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-22 22:26:18,088:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.38s, LR: 0.00017, Train Loss: 0.0915, Train MAE: 0.0915,
                            Val Loss: 0.1120, Val MAE: 0.1118
2023-01-22 22:26:18,089:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-22 22:37:11,437:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.35s, LR: 0.00017, Train Loss: 0.0915, Train MAE: 0.0915,
                            Val Loss: 0.1118, Val MAE: 0.1116
2023-01-22 22:37:11,438:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-22 22:48:04,292:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.85s, LR: 0.00017, Train Loss: 0.0914, Train MAE: 0.0914,
                            Val Loss: 0.1129, Val MAE: 0.1127
2023-01-22 22:48:04,293:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-22 22:58:57,022:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.73s, LR: 0.00017, Train Loss: 0.0913, Train MAE: 0.0913,
                            Val Loss: 0.1120, Val MAE: 0.1118
2023-01-22 22:58:57,023:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-22 23:09:50,312:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.29s, LR: 0.00017, Train Loss: 0.0912, Train MAE: 0.0912,
                            Val Loss: 0.1139, Val MAE: 0.1137
2023-01-22 23:09:50,313:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-22 23:20:43,608:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11008908599615097
2023-01-22 23:20:43,609:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.30s, LR: 0.00009, Train Loss: 0.0888, Train MAE: 0.0888,
                            Val Loss: 0.1103, Val MAE: 0.1101
2023-01-22 23:20:43,610:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-22 23:31:36,830:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.22s, LR: 0.00009, Train Loss: 0.0885, Train MAE: 0.0885,
                            Val Loss: 0.1104, Val MAE: 0.1101
2023-01-22 23:31:36,831:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-22 23:42:29,898:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10973849147558212
2023-01-22 23:42:29,900:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.07s, LR: 0.00009, Train Loss: 0.0884, Train MAE: 0.0884,
                            Val Loss: 0.1100, Val MAE: 0.1097
2023-01-22 23:42:29,900:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-22 23:53:23,541:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.64s, LR: 0.00009, Train Loss: 0.0882, Train MAE: 0.0882,
                            Val Loss: 0.1100, Val MAE: 0.1098
2023-01-22 23:53:23,542:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-23 00:04:16,510:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10946306586265564
2023-01-23 00:04:16,512:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.97s, LR: 0.00009, Train Loss: 0.0882, Train MAE: 0.0882,
                            Val Loss: 0.1097, Val MAE: 0.1095
2023-01-23 00:04:16,513:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-23 00:15:09,708:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.19s, LR: 0.00009, Train Loss: 0.0881, Train MAE: 0.0881,
                            Val Loss: 0.1100, Val MAE: 0.1098
2023-01-23 00:15:09,709:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-23 00:26:03,361:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.65s, LR: 0.00009, Train Loss: 0.0881, Train MAE: 0.0881,
                            Val Loss: 0.1112, Val MAE: 0.1110
2023-01-23 00:26:03,362:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-23 00:36:56,254:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.89s, LR: 0.00009, Train Loss: 0.0880, Train MAE: 0.0880,
                            Val Loss: 0.1104, Val MAE: 0.1102
2023-01-23 00:36:56,255:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-23 00:47:48,079:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.82s, LR: 0.00009, Train Loss: 0.0879, Train MAE: 0.0879,
                            Val Loss: 0.1098, Val MAE: 0.1096
2023-01-23 00:47:48,080:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-23 00:59:45,278:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 717.20s, LR: 0.00009, Train Loss: 0.0879, Train MAE: 0.0879,
                            Val Loss: 0.1098, Val MAE: 0.1096
2023-01-23 00:59:45,279:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-23 01:10:35,987:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 650.71s, LR: 0.00009, Train Loss: 0.0879, Train MAE: 0.0879,
                            Val Loss: 0.1099, Val MAE: 0.1097
2023-01-23 01:10:35,988:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-23 01:21:27,590:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.60s, LR: 0.00009, Train Loss: 0.0878, Train MAE: 0.0878,
                            Val Loss: 0.1097, Val MAE: 0.1095
2023-01-23 01:21:27,591:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-23 01:32:19,115:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.52s, LR: 0.00009, Train Loss: 0.0877, Train MAE: 0.0877,
                            Val Loss: 0.1104, Val MAE: 0.1102
2023-01-23 01:32:19,116:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-23 01:43:10,496:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.38s, LR: 0.00009, Train Loss: 0.0877, Train MAE: 0.0877,
                            Val Loss: 0.1104, Val MAE: 0.1101
2023-01-23 01:43:10,497:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-23 01:54:03,338:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.84s, LR: 0.00009, Train Loss: 0.0877, Train MAE: 0.0877,
                            Val Loss: 0.1098, Val MAE: 0.1096
2023-01-23 01:54:03,339:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-23 02:04:59,675:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.34s, LR: 0.00009, Train Loss: 0.0876, Train MAE: 0.0876,
                            Val Loss: 0.1105, Val MAE: 0.1103
2023-01-23 02:04:59,676:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-23 02:15:55,987:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.31s, LR: 0.00009, Train Loss: 0.0875, Train MAE: 0.0875,
                            Val Loss: 0.1098, Val MAE: 0.1096
2023-01-23 02:15:55,989:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-23 02:26:51,944:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.96s, LR: 0.00009, Train Loss: 0.0874, Train MAE: 0.0874,
                            Val Loss: 0.1097, Val MAE: 0.1095
2023-01-23 02:26:51,945:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-23 02:37:48,411:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.46s, LR: 0.00009, Train Loss: 0.0874, Train MAE: 0.0874,
                            Val Loss: 0.1098, Val MAE: 0.1095
2023-01-23 02:37:48,412:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-23 02:48:44,990:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.58s, LR: 0.00009, Train Loss: 0.0874, Train MAE: 0.0874,
                            Val Loss: 0.1098, Val MAE: 0.1096
2023-01-23 02:48:44,991:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-23 02:48:44,991:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-23 02:56:05,845:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1096
2023-01-23 02:56:05,846:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0849
2023-01-23 02:56:05,848:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-23 02:56:05,849:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 117.0000
2023-01-23 02:56:05,849:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87306.9197s
2023-01-23 02:56:05,850:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 696.3881s
2023-01-23 02:56:05,865:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b128-prwpe', 'job_num': 32}
2023-01-23 02:56:05,979:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0849)]
2023-01-23 02:56:05,979:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1096)]
