2023-01-22 02:29:44,927:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA TITAN X (Pascal)
2023-01-22 02:29:44,927:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-22 02:41:04,299:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-22 02:41:34,457:ogbdata.py:332 -             __init__(): Time taken: 709.5299s
2023-01-22 02:41:34,458:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-22 02:41:34,458:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-22 02:41:34,458:ogbdata.py:348 -             __init__(): [I] Data load time: 709.5306s
2023-01-22 02:41:34,458:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'partial_rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0.02', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/GraphTransformer/rand_pos_enc/gt_ogb_b1024-rand-32-scale002-noedge-scale002/32_DEBUG_0_41.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [41]}
2023-01-22 02:41:34,458:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-prwpe', 'job_num': 32}
2023-01-22 02:41:34,461:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:41:35,730:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:41:35,730:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:41:35,731:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:41:35,746:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-22 02:41:35,748:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 541073
2023-01-22 02:41:35,749:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2023-01-22 02:41:35,749:pe_layer.py:99 -             __init__(): rand_pos_enc
2023-01-22 02:41:35,750:pe_layer.py:194 -             __init__(): Using 32 dimension positional encoding
2023-01-22 02:41:35,750:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-22 02:41:35,750:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-22 02:41:35,773:main_OGB_graph_regression.py:61 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2023-01-22 03:50:08,120:main_OGB_graph_regression.py:67 -   train_val_pipeline(): Time PE:4112.371655464172
2023-01-22 03:50:08,134:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-22 03:50:08,134:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-22 03:50:08,144:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-22 04:03:28,636:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2937659025192261
2023-01-22 04:03:28,647:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 800.50s, LR: 0.00070, Train Loss: 0.3441, Train MAE: 0.3441,
                            Val Loss: 0.2940, Val MAE: 0.2938
2023-01-22 04:03:28,648:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-22 04:14:23,516:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.2059522569179535
2023-01-22 04:14:23,518:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.87s, LR: 0.00070, Train Loss: 0.1872, Train MAE: 0.1872,
                            Val Loss: 0.2062, Val MAE: 0.2060
2023-01-22 04:14:23,518:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-22 04:25:17,451:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.93s, LR: 0.00070, Train Loss: 0.1700, Train MAE: 0.1700,
                            Val Loss: 0.2558, Val MAE: 0.2555
2023-01-22 04:25:17,452:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-22 04:36:10,469:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.02s, LR: 0.00070, Train Loss: 0.1621, Train MAE: 0.1621,
                            Val Loss: 0.2467, Val MAE: 0.2465
2023-01-22 04:36:10,471:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-22 04:47:07,394:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.92s, LR: 0.00070, Train Loss: 0.1576, Train MAE: 0.1576,
                            Val Loss: 0.2219, Val MAE: 0.2216
2023-01-22 04:47:07,396:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-22 04:58:01,382:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.99s, LR: 0.00070, Train Loss: 0.1528, Train MAE: 0.1528,
                            Val Loss: 0.2344, Val MAE: 0.2340
2023-01-22 04:58:01,383:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-22 05:08:54,857:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.47s, LR: 0.00070, Train Loss: 0.1524, Train MAE: 0.1524,
                            Val Loss: 0.2774, Val MAE: 0.2772
2023-01-22 05:08:54,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-22 05:20:47,368:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.51s, LR: 0.00070, Train Loss: 0.1469, Train MAE: 0.1469,
                            Val Loss: 0.2146, Val MAE: 0.2143
2023-01-22 05:20:47,369:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-22 05:31:43,984:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1834450513124466
2023-01-22 05:31:43,986:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.62s, LR: 0.00070, Train Loss: 0.1468, Train MAE: 0.1468,
                            Val Loss: 0.1836, Val MAE: 0.1834
2023-01-22 05:31:43,987:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-22 05:42:39,909:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.15650920569896698
2023-01-22 05:42:39,911:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.92s, LR: 0.00070, Train Loss: 0.1475, Train MAE: 0.1475,
                            Val Loss: 0.1568, Val MAE: 0.1565
2023-01-22 05:42:39,911:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-22 05:53:37,463:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.55s, LR: 0.00070, Train Loss: 0.1475, Train MAE: 0.1475,
                            Val Loss: 0.2004, Val MAE: 0.2002
2023-01-22 05:53:37,464:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-22 06:04:33,718:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1488334983587265
2023-01-22 06:04:33,720:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.25s, LR: 0.00070, Train Loss: 0.1385, Train MAE: 0.1385,
                            Val Loss: 0.1491, Val MAE: 0.1488
2023-01-22 06:04:33,721:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-22 06:15:28,021:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.30s, LR: 0.00070, Train Loss: 0.1358, Train MAE: 0.1358,
                            Val Loss: 0.1517, Val MAE: 0.1515
2023-01-22 06:15:28,022:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-22 06:26:23,752:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.73s, LR: 0.00070, Train Loss: 0.1334, Train MAE: 0.1334,
                            Val Loss: 0.1758, Val MAE: 0.1755
2023-01-22 06:26:23,753:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-22 06:37:21,652:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.90s, LR: 0.00070, Train Loss: 0.1314, Train MAE: 0.1314,
                            Val Loss: 0.1678, Val MAE: 0.1676
2023-01-22 06:37:21,654:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-22 06:48:16,925:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14309526979923248
2023-01-22 06:48:16,927:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.27s, LR: 0.00070, Train Loss: 0.1312, Train MAE: 0.1312,
                            Val Loss: 0.1433, Val MAE: 0.1431
2023-01-22 06:48:16,927:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-22 06:59:13,534:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1384013593196869
2023-01-22 06:59:13,536:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.61s, LR: 0.00070, Train Loss: 0.1291, Train MAE: 0.1291,
                            Val Loss: 0.1387, Val MAE: 0.1384
2023-01-22 06:59:13,536:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-22 07:10:09,568:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.03s, LR: 0.00070, Train Loss: 0.1273, Train MAE: 0.1273,
                            Val Loss: 0.1444, Val MAE: 0.1442
2023-01-22 07:10:09,569:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-22 07:21:05,884:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.31s, LR: 0.00070, Train Loss: 0.1260, Train MAE: 0.1260,
                            Val Loss: 0.1427, Val MAE: 0.1425
2023-01-22 07:21:05,885:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-22 07:32:00,074:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.19s, LR: 0.00070, Train Loss: 0.1247, Train MAE: 0.1247,
                            Val Loss: 0.1457, Val MAE: 0.1455
2023-01-22 07:32:00,076:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-22 07:42:52,745:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.67s, LR: 0.00070, Train Loss: 0.1250, Train MAE: 0.1250,
                            Val Loss: 0.1411, Val MAE: 0.1409
2023-01-22 07:42:52,747:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-22 07:53:44,067:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.32s, LR: 0.00070, Train Loss: 0.1226, Train MAE: 0.1226,
                            Val Loss: 0.1549, Val MAE: 0.1547
2023-01-22 07:53:44,068:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-22 08:04:37,181:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13641631603240967
2023-01-22 08:04:37,183:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.11s, LR: 0.00070, Train Loss: 0.1224, Train MAE: 0.1224,
                            Val Loss: 0.1366, Val MAE: 0.1364
2023-01-22 08:04:37,183:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-22 08:16:29,468:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.28s, LR: 0.00070, Train Loss: 0.1215, Train MAE: 0.1215,
                            Val Loss: 0.1371, Val MAE: 0.1368
2023-01-22 08:16:29,469:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-22 08:27:21,045:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 651.57s, LR: 0.00070, Train Loss: 0.1213, Train MAE: 0.1213,
                            Val Loss: 0.1375, Val MAE: 0.1373
2023-01-22 08:27:21,046:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-22 08:38:13,500:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13260041177272797
2023-01-22 08:38:13,502:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.46s, LR: 0.00070, Train Loss: 0.1202, Train MAE: 0.1202,
                            Val Loss: 0.1328, Val MAE: 0.1326
2023-01-22 08:38:13,503:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-22 08:49:06,980:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.48s, LR: 0.00070, Train Loss: 0.1191, Train MAE: 0.1191,
                            Val Loss: 0.1342, Val MAE: 0.1340
2023-01-22 08:49:06,981:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-22 09:00:00,639:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.66s, LR: 0.00070, Train Loss: 0.1191, Train MAE: 0.1191,
                            Val Loss: 0.1380, Val MAE: 0.1378
2023-01-22 09:00:00,641:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-22 09:10:55,802:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12838608026504517
2023-01-22 09:10:55,804:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.16s, LR: 0.00070, Train Loss: 0.1224, Train MAE: 0.1224,
                            Val Loss: 0.1286, Val MAE: 0.1284
2023-01-22 09:10:55,804:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-22 09:21:49,492:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12468734383583069
2023-01-22 09:21:49,494:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.69s, LR: 0.00070, Train Loss: 0.1186, Train MAE: 0.1186,
                            Val Loss: 0.1249, Val MAE: 0.1247
2023-01-22 09:21:49,494:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-22 09:32:43,020:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.52s, LR: 0.00070, Train Loss: 0.1194, Train MAE: 0.1194,
                            Val Loss: 0.1303, Val MAE: 0.1301
2023-01-22 09:32:43,021:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-22 09:43:37,928:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.91s, LR: 0.00070, Train Loss: 0.1181, Train MAE: 0.1181,
                            Val Loss: 0.1299, Val MAE: 0.1297
2023-01-22 09:43:37,929:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-22 09:54:31,577:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.65s, LR: 0.00070, Train Loss: 0.1175, Train MAE: 0.1175,
                            Val Loss: 0.1498, Val MAE: 0.1496
2023-01-22 09:54:31,579:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-22 10:05:26,241:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.66s, LR: 0.00070, Train Loss: 0.1176, Train MAE: 0.1176,
                            Val Loss: 0.1257, Val MAE: 0.1254
2023-01-22 10:05:26,242:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-22 10:16:19,989:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.75s, LR: 0.00070, Train Loss: 0.1164, Train MAE: 0.1164,
                            Val Loss: 0.1529, Val MAE: 0.1527
2023-01-22 10:16:19,991:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-22 10:27:12,714:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.72s, LR: 0.00070, Train Loss: 0.1168, Train MAE: 0.1168,
                            Val Loss: 0.1283, Val MAE: 0.1281
2023-01-22 10:27:12,715:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-22 10:38:06,451:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.74s, LR: 0.00070, Train Loss: 0.1157, Train MAE: 0.1157,
                            Val Loss: 0.1981, Val MAE: 0.1981
2023-01-22 10:38:06,452:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-22 10:49:01,038:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.58s, LR: 0.00070, Train Loss: 0.1156, Train MAE: 0.1156,
                            Val Loss: 0.1283, Val MAE: 0.1281
2023-01-22 10:49:01,039:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-22 10:59:54,717:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.68s, LR: 0.00070, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.1414, Val MAE: 0.1411
2023-01-22 10:59:54,719:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-22 11:10:49,693:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.97s, LR: 0.00070, Train Loss: 0.1148, Train MAE: 0.1148,
                            Val Loss: 0.1309, Val MAE: 0.1307
2023-01-22 11:10:49,694:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-22 11:22:42,049:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.35s, LR: 0.00070, Train Loss: 0.1144, Train MAE: 0.1144,
                            Val Loss: 0.1278, Val MAE: 0.1276
2023-01-22 11:22:42,050:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-22 11:33:36,175:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.13s, LR: 0.00070, Train Loss: 0.1139, Train MAE: 0.1139,
                            Val Loss: 0.1448, Val MAE: 0.1447
2023-01-22 11:33:36,177:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-22 11:44:29,310:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.13s, LR: 0.00070, Train Loss: 0.1141, Train MAE: 0.1141,
                            Val Loss: 0.1331, Val MAE: 0.1329
2023-01-22 11:44:29,312:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-22 11:55:24,952:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.64s, LR: 0.00070, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.1263, Val MAE: 0.1261
2023-01-22 11:55:24,953:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-22 12:06:19,833:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12189427018165588
2023-01-22 12:06:19,836:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.88s, LR: 0.00070, Train Loss: 0.1129, Train MAE: 0.1129,
                            Val Loss: 0.1221, Val MAE: 0.1219
2023-01-22 12:06:19,836:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-22 12:17:12,564:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.73s, LR: 0.00070, Train Loss: 0.1129, Train MAE: 0.1129,
                            Val Loss: 0.1315, Val MAE: 0.1313
2023-01-22 12:17:12,565:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-22 12:28:06,920:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.35s, LR: 0.00070, Train Loss: 0.1126, Train MAE: 0.1126,
                            Val Loss: 0.1327, Val MAE: 0.1325
2023-01-22 12:28:06,921:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-22 12:39:04,214:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.29s, LR: 0.00070, Train Loss: 0.1135, Train MAE: 0.1135,
                            Val Loss: 0.1225, Val MAE: 0.1223
2023-01-22 12:39:04,215:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-22 12:49:57,091:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.88s, LR: 0.00070, Train Loss: 0.1121, Train MAE: 0.1121,
                            Val Loss: 0.1337, Val MAE: 0.1335
2023-01-22 12:49:57,092:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-22 13:00:51,128:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12036091089248657
2023-01-22 13:00:51,129:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.04s, LR: 0.00070, Train Loss: 0.1125, Train MAE: 0.1125,
                            Val Loss: 0.1206, Val MAE: 0.1204
2023-01-22 13:00:51,129:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-22 13:11:46,859:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.73s, LR: 0.00070, Train Loss: 0.1112, Train MAE: 0.1112,
                            Val Loss: 0.1212, Val MAE: 0.1210
2023-01-22 13:11:46,859:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-22 13:22:42,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.73s, LR: 0.00070, Train Loss: 0.1112, Train MAE: 0.1112,
                            Val Loss: 0.1320, Val MAE: 0.1319
2023-01-22 13:22:42,589:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-22 13:33:36,083:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.49s, LR: 0.00070, Train Loss: 0.1115, Train MAE: 0.1115,
                            Val Loss: 0.1233, Val MAE: 0.1232
2023-01-22 13:33:36,084:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-22 13:44:32,133:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.05s, LR: 0.00070, Train Loss: 0.1110, Train MAE: 0.1110,
                            Val Loss: 0.1285, Val MAE: 0.1284
2023-01-22 13:44:32,134:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-22 13:55:29,749:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12028149515390396
2023-01-22 13:55:29,750:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.61s, LR: 0.00070, Train Loss: 0.1116, Train MAE: 0.1116,
                            Val Loss: 0.1205, Val MAE: 0.1203
2023-01-22 13:55:29,750:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-22 14:06:26,536:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.79s, LR: 0.00070, Train Loss: 0.1105, Train MAE: 0.1105,
                            Val Loss: 0.1434, Val MAE: 0.1432
2023-01-22 14:06:26,537:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-22 14:17:23,852:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.31s, LR: 0.00070, Train Loss: 0.1098, Train MAE: 0.1098,
                            Val Loss: 0.1223, Val MAE: 0.1221
2023-01-22 14:17:23,853:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-22 14:29:18,151:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 714.30s, LR: 0.00070, Train Loss: 0.1102, Train MAE: 0.1102,
                            Val Loss: 0.1274, Val MAE: 0.1272
2023-01-22 14:29:18,152:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-22 14:40:13,469:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11832623183727264
2023-01-22 14:40:13,470:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.32s, LR: 0.00070, Train Loss: 0.1095, Train MAE: 0.1095,
                            Val Loss: 0.1185, Val MAE: 0.1183
2023-01-22 14:40:13,470:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-22 14:51:09,781:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.31s, LR: 0.00070, Train Loss: 0.1094, Train MAE: 0.1094,
                            Val Loss: 0.1357, Val MAE: 0.1355
2023-01-22 14:51:09,782:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-22 15:02:05,579:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.80s, LR: 0.00070, Train Loss: 0.1094, Train MAE: 0.1094,
                            Val Loss: 0.1332, Val MAE: 0.1330
2023-01-22 15:02:05,580:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-22 15:13:01,930:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.35s, LR: 0.00070, Train Loss: 0.1091, Train MAE: 0.1091,
                            Val Loss: 0.1267, Val MAE: 0.1266
2023-01-22 15:13:01,931:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-22 15:23:59,509:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.58s, LR: 0.00070, Train Loss: 0.1090, Train MAE: 0.1090,
                            Val Loss: 0.1646, Val MAE: 0.1645
2023-01-22 15:23:59,510:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-22 15:34:53,636:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.12s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1408, Val MAE: 0.1406
2023-01-22 15:34:53,637:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-22 15:45:48,162:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.52s, LR: 0.00070, Train Loss: 0.1085, Train MAE: 0.1085,
                            Val Loss: 0.1190, Val MAE: 0.1188
2023-01-22 15:45:48,163:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-22 15:56:40,295:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.13s, LR: 0.00070, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.1210, Val MAE: 0.1208
2023-01-22 15:56:40,296:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-22 16:07:35,149:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.85s, LR: 0.00070, Train Loss: 0.1086, Train MAE: 0.1086,
                            Val Loss: 0.1220, Val MAE: 0.1218
2023-01-22 16:07:35,150:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-22 16:18:28,794:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.64s, LR: 0.00070, Train Loss: 0.1074, Train MAE: 0.1074,
                            Val Loss: 0.1204, Val MAE: 0.1201
2023-01-22 16:18:28,794:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-22 16:29:24,049:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.25s, LR: 0.00070, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.1296, Val MAE: 0.1293
2023-01-22 16:29:24,050:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-22 16:40:17,213:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.16s, LR: 0.00070, Train Loss: 0.1075, Train MAE: 0.1075,
                            Val Loss: 0.1187, Val MAE: 0.1185
2023-01-22 16:40:17,214:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-22 16:51:09,907:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.69s, LR: 0.00070, Train Loss: 0.1073, Train MAE: 0.1073,
                            Val Loss: 0.1301, Val MAE: 0.1299
2023-01-22 16:51:09,908:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-22 17:02:02,581:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11635743826627731
2023-01-22 17:02:02,583:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.67s, LR: 0.00070, Train Loss: 0.1094, Train MAE: 0.1094,
                            Val Loss: 0.1165, Val MAE: 0.1164
2023-01-22 17:02:02,583:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-22 17:12:55,462:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.88s, LR: 0.00070, Train Loss: 0.1069, Train MAE: 0.1069,
                            Val Loss: 0.1200, Val MAE: 0.1198
2023-01-22 17:12:55,464:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-22 17:23:50,659:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.19s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1336, Val MAE: 0.1335
2023-01-22 17:23:50,660:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-22 17:35:43,170:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.51s, LR: 0.00070, Train Loss: 0.1071, Train MAE: 0.1071,
                            Val Loss: 0.1191, Val MAE: 0.1189
2023-01-22 17:35:43,170:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-22 17:46:35,403:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 652.23s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1227, Val MAE: 0.1225
2023-01-22 17:46:35,404:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-22 17:57:28,620:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 653.22s, LR: 0.00070, Train Loss: 0.1068, Train MAE: 0.1068,
                            Val Loss: 0.1762, Val MAE: 0.1760
2023-01-22 17:57:28,621:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-22 18:08:24,060:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11544446647167206
2023-01-22 18:08:24,061:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.44s, LR: 0.00070, Train Loss: 0.1107, Train MAE: 0.1107,
                            Val Loss: 0.1156, Val MAE: 0.1154
2023-01-22 18:08:24,062:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-22 18:19:19,230:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.17s, LR: 0.00070, Train Loss: 0.1062, Train MAE: 0.1062,
                            Val Loss: 0.1204, Val MAE: 0.1202
2023-01-22 18:19:19,231:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-22 18:30:13,597:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.37s, LR: 0.00070, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.1334, Val MAE: 0.1332
2023-01-22 18:30:13,598:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-22 18:41:08,165:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.57s, LR: 0.00070, Train Loss: 0.1058, Train MAE: 0.1058,
                            Val Loss: 0.1214, Val MAE: 0.1212
2023-01-22 18:41:08,167:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 82/1000
2023-01-22 18:52:04,596:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.43s, LR: 0.00070, Train Loss: 0.1058, Train MAE: 0.1058,
                            Val Loss: 0.1239, Val MAE: 0.1237
2023-01-22 18:52:04,598:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 83/1000
2023-01-22 19:03:00,722:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.12s, LR: 0.00070, Train Loss: 0.1053, Train MAE: 0.1053,
                            Val Loss: 0.1221, Val MAE: 0.1219
2023-01-22 19:03:00,723:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 84/1000
2023-01-22 19:13:55,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.39s, LR: 0.00070, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.1164, Val MAE: 0.1162
2023-01-22 19:13:55,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 85/1000
2023-01-22 19:24:53,112:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11506098508834839
2023-01-22 19:24:53,114:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.00s, LR: 0.00070, Train Loss: 0.1049, Train MAE: 0.1049,
                            Val Loss: 0.1153, Val MAE: 0.1151
2023-01-22 19:24:53,115:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 86/1000
2023-01-22 19:35:51,688:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.57s, LR: 0.00070, Train Loss: 0.1050, Train MAE: 0.1050,
                            Val Loss: 0.1190, Val MAE: 0.1188
2023-01-22 19:35:51,689:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 87/1000
2023-01-22 19:46:46,266:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.58s, LR: 0.00070, Train Loss: 0.1044, Train MAE: 0.1044,
                            Val Loss: 0.1215, Val MAE: 0.1213
2023-01-22 19:46:46,268:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 88/1000
2023-01-22 19:57:45,993:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.72s, LR: 0.00070, Train Loss: 0.1043, Train MAE: 0.1043,
                            Val Loss: 0.1285, Val MAE: 0.1283
2023-01-22 19:57:45,994:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 89/1000
2023-01-22 20:08:43,362:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 657.37s, LR: 0.00070, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.1243, Val MAE: 0.1241
2023-01-22 20:08:43,363:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 90/1000
2023-01-22 20:19:38,404:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 655.04s, LR: 0.00070, Train Loss: 0.1042, Train MAE: 0.1042,
                            Val Loss: 0.1188, Val MAE: 0.1185
2023-01-22 20:19:38,405:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 91/1000
2023-01-22 20:30:34,406:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 656.00s, LR: 0.00070, Train Loss: 0.1043, Train MAE: 0.1043,
                            Val Loss: 0.1191, Val MAE: 0.1189
2023-01-22 20:30:34,408:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 92/1000
2023-01-22 20:42:26,853:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 712.44s, LR: 0.00070, Train Loss: 0.1040, Train MAE: 0.1040,
                            Val Loss: 0.1320, Val MAE: 0.1318
2023-01-22 20:42:26,854:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 93/1000
2023-01-22 20:53:25,857:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.00s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1374, Val MAE: 0.1372
2023-01-22 20:53:25,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 94/1000
2023-01-22 21:04:26,023:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.16s, LR: 0.00070, Train Loss: 0.1041, Train MAE: 0.1041,
                            Val Loss: 0.1177, Val MAE: 0.1175
2023-01-22 21:04:26,024:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 95/1000
2023-01-22 21:15:25,365:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.34s, LR: 0.00070, Train Loss: 0.1037, Train MAE: 0.1037,
                            Val Loss: 0.1189, Val MAE: 0.1187
2023-01-22 21:15:25,366:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 96/1000
2023-01-22 21:26:20,340:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.97s, LR: 0.00070, Train Loss: 0.1036, Train MAE: 0.1036,
                            Val Loss: 0.1193, Val MAE: 0.1192
2023-01-22 21:26:20,341:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 97/1000
2023-01-22 21:37:14,947:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.61s, LR: 0.00070, Train Loss: 0.1033, Train MAE: 0.1033,
                            Val Loss: 0.1186, Val MAE: 0.1184
2023-01-22 21:37:14,948:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 98/1000
2023-01-22 21:48:09,564:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 654.61s, LR: 0.00070, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.1199, Val MAE: 0.1197
2023-01-22 21:48:09,564:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 99/1000
2023-01-22 21:59:08,885:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.32s, LR: 0.00070, Train Loss: 0.1029, Train MAE: 0.1029,
                            Val Loss: 0.1277, Val MAE: 0.1275
2023-01-22 21:59:08,886:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 100/1000
2023-01-22 22:10:09,868:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.98s, LR: 0.00070, Train Loss: 0.1026, Train MAE: 0.1026,
                            Val Loss: 0.1178, Val MAE: 0.1176
2023-01-22 22:10:09,868:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 101/1000
2023-01-22 22:21:09,231:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.36s, LR: 0.00070, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.1156, Val MAE: 0.1154
2023-01-22 22:21:09,232:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 102/1000
2023-01-22 22:32:10,205:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1109241470694542
2023-01-22 22:32:10,207:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.97s, LR: 0.00035, Train Loss: 0.0956, Train MAE: 0.0956,
                            Val Loss: 0.1111, Val MAE: 0.1109
2023-01-22 22:32:10,208:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 103/1000
2023-01-22 22:43:11,834:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11056677252054214
2023-01-22 22:43:11,836:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.63s, LR: 0.00035, Train Loss: 0.0946, Train MAE: 0.0946,
                            Val Loss: 0.1108, Val MAE: 0.1106
2023-01-22 22:43:11,836:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 104/1000
2023-01-22 22:54:12,597:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.76s, LR: 0.00035, Train Loss: 0.0941, Train MAE: 0.0941,
                            Val Loss: 0.1111, Val MAE: 0.1109
2023-01-22 22:54:12,598:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 105/1000
2023-01-22 23:05:14,935:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1091340035200119
2023-01-22 23:05:14,936:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.34s, LR: 0.00035, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.1093, Val MAE: 0.1091
2023-01-22 23:05:14,936:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 106/1000
2023-01-22 23:16:15,847:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.91s, LR: 0.00035, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.1113, Val MAE: 0.1111
2023-01-22 23:16:15,848:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 107/1000
2023-01-22 23:27:18,133:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.28s, LR: 0.00035, Train Loss: 0.0933, Train MAE: 0.0933,
                            Val Loss: 0.1117, Val MAE: 0.1115
2023-01-22 23:27:18,134:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 108/1000
2023-01-22 23:39:21,970:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 723.84s, LR: 0.00035, Train Loss: 0.0932, Train MAE: 0.0932,
                            Val Loss: 0.1108, Val MAE: 0.1105
2023-01-22 23:39:21,971:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 109/1000
2023-01-22 23:50:20,272:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 658.30s, LR: 0.00035, Train Loss: 0.0931, Train MAE: 0.0931,
                            Val Loss: 0.1109, Val MAE: 0.1107
2023-01-22 23:50:20,273:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 110/1000
2023-01-23 00:01:21,729:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.46s, LR: 0.00035, Train Loss: 0.0929, Train MAE: 0.0929,
                            Val Loss: 0.1114, Val MAE: 0.1112
2023-01-23 00:01:21,730:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 111/1000
2023-01-23 00:12:23,305:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.57s, LR: 0.00035, Train Loss: 0.0928, Train MAE: 0.0928,
                            Val Loss: 0.1101, Val MAE: 0.1099
2023-01-23 00:12:23,306:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 112/1000
2023-01-23 00:23:23,424:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.12s, LR: 0.00035, Train Loss: 0.0926, Train MAE: 0.0926,
                            Val Loss: 0.1112, Val MAE: 0.1110
2023-01-23 00:23:23,425:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 113/1000
2023-01-23 00:34:25,110:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10864830762147903
2023-01-23 00:34:25,112:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.69s, LR: 0.00035, Train Loss: 0.0923, Train MAE: 0.0923,
                            Val Loss: 0.1089, Val MAE: 0.1086
2023-01-23 00:34:25,112:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 114/1000
2023-01-23 00:45:26,449:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.34s, LR: 0.00035, Train Loss: 0.0922, Train MAE: 0.0922,
                            Val Loss: 0.1094, Val MAE: 0.1092
2023-01-23 00:45:26,450:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 115/1000
2023-01-23 00:56:27,654:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.10838627070188522
2023-01-23 00:56:27,655:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.20s, LR: 0.00035, Train Loss: 0.0921, Train MAE: 0.0921,
                            Val Loss: 0.1086, Val MAE: 0.1084
2023-01-23 00:56:27,656:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 116/1000
2023-01-23 01:07:29,297:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.64s, LR: 0.00035, Train Loss: 0.0920, Train MAE: 0.0920,
                            Val Loss: 0.1091, Val MAE: 0.1089
2023-01-23 01:07:29,298:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 117/1000
2023-01-23 01:18:30,439:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.14s, LR: 0.00035, Train Loss: 0.0919, Train MAE: 0.0919,
                            Val Loss: 0.1088, Val MAE: 0.1086
2023-01-23 01:18:30,440:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 118/1000
2023-01-23 01:29:32,621:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 662.18s, LR: 0.00035, Train Loss: 0.0919, Train MAE: 0.0919,
                            Val Loss: 0.1100, Val MAE: 0.1099
2023-01-23 01:29:32,622:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 119/1000
2023-01-23 01:40:33,148:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.53s, LR: 0.00035, Train Loss: 0.0919, Train MAE: 0.0919,
                            Val Loss: 0.1114, Val MAE: 0.1111
2023-01-23 01:40:33,149:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 120/1000
2023-01-23 01:51:32,816:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 659.67s, LR: 0.00035, Train Loss: 0.0916, Train MAE: 0.0916,
                            Val Loss: 0.1094, Val MAE: 0.1092
2023-01-23 01:51:32,817:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 121/1000
2023-01-23 02:02:34,031:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.21s, LR: 0.00035, Train Loss: 0.0915, Train MAE: 0.0915,
                            Val Loss: 0.1093, Val MAE: 0.1091
2023-01-23 02:02:34,032:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 122/1000
2023-01-23 02:13:34,588:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.56s, LR: 0.00035, Train Loss: 0.0914, Train MAE: 0.0914,
                            Val Loss: 0.1104, Val MAE: 0.1102
2023-01-23 02:13:34,589:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 123/1000
2023-01-23 02:24:34,642:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 660.05s, LR: 0.00035, Train Loss: 0.0914, Train MAE: 0.0914,
                            Val Loss: 0.1094, Val MAE: 0.1092
2023-01-23 02:24:34,643:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 124/1000
2023-01-23 02:35:36,157:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 661.51s, LR: 0.00035, Train Loss: 0.0914, Train MAE: 0.0914,
                            Val Loss: 0.1128, Val MAE: 0.1126
2023-01-23 02:35:36,158:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 125/1000
2023-01-23 02:47:35,754:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 719.59s, LR: 0.00035, Train Loss: 0.0913, Train MAE: 0.0913,
                            Val Loss: 0.1148, Val MAE: 0.1146
2023-01-23 02:47:35,755:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-23 02:47:35,755:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-23 02:55:01,718:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1146
2023-01-23 02:55:01,765:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0976
2023-01-23 02:55:01,767:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-23 02:55:01,767:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 124.0000
2023-01-23 02:55:01,767:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87206.0186s
2023-01-23 02:55:01,844:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 661.1804s
2023-01-23 02:55:01,884:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-prwpe', 'job_num': 32}
2023-01-23 02:55:02,204:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0976)]
2023-01-23 02:55:02,204:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1146)]
