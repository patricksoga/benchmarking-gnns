2023-01-21 01:28:43,598:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2023-01-21 01:28:43,599:ogbdata.py:297 -             __init__(): [I] Loading dataset OGB...
2023-01-21 01:40:40,502:ogbdata.py:313 -             __init__(): Splitting dataset...
2023-01-21 01:41:10,501:ogbdata.py:332 -             __init__(): Time taken: 746.9021s
2023-01-21 01:41:10,501:ogbdata.py:346 -             __init__(): train, val sizes: 3378606,73545
2023-01-21 01:41:10,501:ogbdata.py:347 -             __init__(): [I] Finished loading.
2023-01-21 01:41:10,501:ogbdata.py:348 -             __init__(): [I] Data load time: 746.9028s
2023-01-21 01:41:10,502:main_OGB_graph_regression.py:359 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 1, 'pos_enc_dim': 10, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 1024, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'OGB', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'learned_pos_enc': False, 'partial_rw_pos_enc': False, 'lpe_dim': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0', 'gape_per_layer': False, 'gape_scalar': False, 'gape_stoch': False, 'gape_softmax_init': False, 'gape_uniform_init': False, 'gape_stack_strat': '2', 'gape_normalize_mat': False, 'gape_tau': False, 'gape_tau_mat': False, 'gape_beta': 1.0, 'gape_weight_id': False, 'gape_break_batch': False, 'ngape_betas': [], 'gape_cond_lbl': False, 'ngape_agg': 'sum', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/OGB_OGB/SAGraphTransformer/no_pe/gt_ogb_b1024-baseline-noedge/10_DEBUG_0_22.log', 'device': device(type='cuda'), 'num_atom_type': 14, 'seed_array': [22]}
2023-01-21 01:41:10,502:main_OGB_graph_regression.py:360 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b128-noedge', 'job_num': 10}
2023-01-21 01:41:10,520:pe_layer.py:99 -             __init__(): no_pe
2023-01-21 01:41:10,520:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-21 01:41:10,520:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-21 01:41:10,607:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2023-01-21 01:41:10,626:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 570215
2023-01-21 01:41:10,626:main_OGB_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 22 in [22]...
2023-01-21 01:41:10,626:pe_layer.py:99 -             __init__(): no_pe
2023-01-21 01:41:10,626:pe_layer.py:196 -             __init__(): Using matrix: A
2023-01-21 01:41:10,626:pe_layer.py:197 -             __init__(): Matrix power: 1
2023-01-21 01:41:18,085:main_OGB_graph_regression.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2023-01-21 03:42:25,178:main_OGB_graph_regression.py:85 -   train_val_pipeline(): Time PE:7274.54475402832
2023-01-21 03:42:25,590:main_OGB_graph_regression.py:120 -   train_val_pipeline(): Training Graphs: 3378606
2023-01-21 03:42:25,590:main_OGB_graph_regression.py:121 -   train_val_pipeline(): Validation Graphs: 73545
2023-01-21 03:42:25,686:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 1/1000
2023-01-21 04:01:29,708:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.37097451090812683
2023-01-21 04:01:29,851:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 1144.16s, LR: 0.00070, Train Loss: 0.2727, Train MAE: 0.2727,
                            Val Loss: 0.3712, Val MAE: 0.3710
2023-01-21 04:01:29,852:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 2/1000
2023-01-21 04:17:31,066:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.21528707444667816
2023-01-21 04:17:31,069:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 961.22s, LR: 0.00070, Train Loss: 0.1916, Train MAE: 0.1916,
                            Val Loss: 0.2159, Val MAE: 0.2153
2023-01-21 04:17:31,069:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 3/1000
2023-01-21 04:33:39,193:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.20038864016532898
2023-01-21 04:33:39,195:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 968.13s, LR: 0.00070, Train Loss: 0.1762, Train MAE: 0.1762,
                            Val Loss: 0.2010, Val MAE: 0.2004
2023-01-21 04:33:39,197:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 4/1000
2023-01-21 04:49:48,544:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.17933395504951477
2023-01-21 04:49:48,546:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 969.35s, LR: 0.00070, Train Loss: 0.1651, Train MAE: 0.1651,
                            Val Loss: 0.1800, Val MAE: 0.1793
2023-01-21 04:49:48,547:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 5/1000
2023-01-21 05:05:57,783:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 969.23s, LR: 0.00070, Train Loss: 0.1579, Train MAE: 0.1579,
                            Val Loss: 0.1979, Val MAE: 0.1975
2023-01-21 05:05:57,785:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 6/1000
2023-01-21 05:22:09,998:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 972.21s, LR: 0.00070, Train Loss: 0.1540, Train MAE: 0.1540,
                            Val Loss: 0.2247, Val MAE: 0.2239
2023-01-21 05:22:10,000:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 7/1000
2023-01-21 05:38:25,341:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.16000591218471527
2023-01-21 05:38:25,344:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.34s, LR: 0.00070, Train Loss: 0.1497, Train MAE: 0.1497,
                            Val Loss: 0.1605, Val MAE: 0.1600
2023-01-21 05:38:25,345:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 8/1000
2023-01-21 05:54:44,668:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 979.32s, LR: 0.00070, Train Loss: 0.1464, Train MAE: 0.1464,
                            Val Loss: 0.1683, Val MAE: 0.1679
2023-01-21 05:54:44,669:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 9/1000
2023-01-21 06:10:59,297:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 974.63s, LR: 0.00070, Train Loss: 0.1444, Train MAE: 0.1444,
                            Val Loss: 0.1865, Val MAE: 0.1862
2023-01-21 06:10:59,298:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 10/1000
2023-01-21 06:27:14,725:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.43s, LR: 0.00070, Train Loss: 0.1405, Train MAE: 0.1405,
                            Val Loss: 0.1618, Val MAE: 0.1614
2023-01-21 06:27:14,727:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 11/1000
2023-01-21 06:43:29,951:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.155600905418396
2023-01-21 06:43:29,954:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.23s, LR: 0.00070, Train Loss: 0.1375, Train MAE: 0.1375,
                            Val Loss: 0.1561, Val MAE: 0.1556
2023-01-21 06:43:29,954:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 12/1000
2023-01-21 06:59:47,925:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.14824892580509186
2023-01-21 06:59:47,928:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 977.97s, LR: 0.00070, Train Loss: 0.1352, Train MAE: 0.1352,
                            Val Loss: 0.1487, Val MAE: 0.1482
2023-01-21 06:59:47,929:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 13/1000
2023-01-21 07:16:08,436:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 980.51s, LR: 0.00070, Train Loss: 0.1327, Train MAE: 0.1327,
                            Val Loss: 0.1704, Val MAE: 0.1701
2023-01-21 07:16:08,457:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 14/1000
2023-01-21 07:32:29,961:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 981.50s, LR: 0.00070, Train Loss: 0.1312, Train MAE: 0.1312,
                            Val Loss: 0.1555, Val MAE: 0.1549
2023-01-21 07:32:29,963:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 15/1000
2023-01-21 07:48:50,851:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1413785219192505
2023-01-21 07:48:50,854:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 980.89s, LR: 0.00070, Train Loss: 0.1293, Train MAE: 0.1293,
                            Val Loss: 0.1419, Val MAE: 0.1414
2023-01-21 07:48:50,854:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 16/1000
2023-01-21 08:06:28,326:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 1057.47s, LR: 0.00070, Train Loss: 0.1285, Train MAE: 0.1285,
                            Val Loss: 0.1469, Val MAE: 0.1462
2023-01-21 08:06:28,340:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 17/1000
2023-01-21 08:22:37,142:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 968.80s, LR: 0.00070, Train Loss: 0.1270, Train MAE: 0.1270,
                            Val Loss: 0.1581, Val MAE: 0.1577
2023-01-21 08:22:37,161:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 18/1000
2023-01-21 08:38:52,772:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.61s, LR: 0.00070, Train Loss: 0.1254, Train MAE: 0.1254,
                            Val Loss: 0.1559, Val MAE: 0.1556
2023-01-21 08:38:52,773:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 19/1000
2023-01-21 08:55:07,244:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 974.47s, LR: 0.00070, Train Loss: 0.1242, Train MAE: 0.1242,
                            Val Loss: 0.1499, Val MAE: 0.1494
2023-01-21 08:55:07,255:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 20/1000
2023-01-21 09:11:22,548:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.29s, LR: 0.00070, Train Loss: 0.1232, Train MAE: 0.1232,
                            Val Loss: 0.1437, Val MAE: 0.1431
2023-01-21 09:11:22,550:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 21/1000
2023-01-21 09:27:42,478:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13687096536159515
2023-01-21 09:27:42,492:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 979.94s, LR: 0.00070, Train Loss: 0.1224, Train MAE: 0.1224,
                            Val Loss: 0.1377, Val MAE: 0.1369
2023-01-21 09:27:42,493:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 22/1000
2023-01-21 09:43:58,201:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.71s, LR: 0.00070, Train Loss: 0.1213, Train MAE: 0.1213,
                            Val Loss: 0.1572, Val MAE: 0.1565
2023-01-21 09:43:58,221:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 23/1000
2023-01-21 10:00:12,997:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 974.78s, LR: 0.00070, Train Loss: 0.1204, Train MAE: 0.1204,
                            Val Loss: 0.1434, Val MAE: 0.1429
2023-01-21 10:00:13,018:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 24/1000
2023-01-21 10:16:29,841:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13428868353366852
2023-01-21 10:16:29,858:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 976.84s, LR: 0.00070, Train Loss: 0.1194, Train MAE: 0.1194,
                            Val Loss: 0.1352, Val MAE: 0.1343
2023-01-21 10:16:29,858:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 25/1000
2023-01-21 10:32:43,422:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 973.56s, LR: 0.00070, Train Loss: 0.1188, Train MAE: 0.1188,
                            Val Loss: 0.1452, Val MAE: 0.1447
2023-01-21 10:32:43,437:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 26/1000
2023-01-21 10:48:55,020:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 971.58s, LR: 0.00070, Train Loss: 0.1183, Train MAE: 0.1183,
                            Val Loss: 0.1373, Val MAE: 0.1367
2023-01-21 10:48:55,025:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 27/1000
2023-01-21 11:05:11,230:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 976.20s, LR: 0.00070, Train Loss: 0.1177, Train MAE: 0.1177,
                            Val Loss: 0.1422, Val MAE: 0.1416
2023-01-21 11:05:11,247:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 28/1000
2023-01-21 11:21:26,767:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.13015690445899963
2023-01-21 11:21:26,786:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.54s, LR: 0.00070, Train Loss: 0.1173, Train MAE: 0.1173,
                            Val Loss: 0.1305, Val MAE: 0.1302
2023-01-21 11:21:26,787:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 29/1000
2023-01-21 11:37:41,688:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 974.90s, LR: 0.00070, Train Loss: 0.1165, Train MAE: 0.1165,
                            Val Loss: 0.1314, Val MAE: 0.1310
2023-01-21 11:37:41,689:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 30/1000
2023-01-21 11:53:57,529:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.84s, LR: 0.00070, Train Loss: 0.1159, Train MAE: 0.1159,
                            Val Loss: 0.1371, Val MAE: 0.1366
2023-01-21 11:53:57,546:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 31/1000
2023-01-21 12:10:13,339:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12919332087039948
2023-01-21 12:10:13,352:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.81s, LR: 0.00070, Train Loss: 0.1148, Train MAE: 0.1148,
                            Val Loss: 0.1296, Val MAE: 0.1292
2023-01-21 12:10:13,352:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 32/1000
2023-01-21 12:26:22,802:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 969.45s, LR: 0.00070, Train Loss: 0.1145, Train MAE: 0.1145,
                            Val Loss: 0.1361, Val MAE: 0.1357
2023-01-21 12:26:22,823:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 33/1000
2023-01-21 12:42:31,616:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 968.79s, LR: 0.00070, Train Loss: 0.1142, Train MAE: 0.1142,
                            Val Loss: 0.1379, Val MAE: 0.1374
2023-01-21 12:42:31,618:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 34/1000
2023-01-21 12:58:44,786:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12605857849121094
2023-01-21 12:58:44,801:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 973.18s, LR: 0.00070, Train Loss: 0.1137, Train MAE: 0.1137,
                            Val Loss: 0.1264, Val MAE: 0.1261
2023-01-21 12:58:44,802:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 35/1000
2023-01-21 13:14:59,114:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 974.31s, LR: 0.00070, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.1343, Val MAE: 0.1339
2023-01-21 13:14:59,130:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 36/1000
2023-01-21 13:32:30,933:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 1051.80s, LR: 0.00070, Train Loss: 0.1126, Train MAE: 0.1126,
                            Val Loss: 0.1331, Val MAE: 0.1326
2023-01-21 13:32:30,952:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 37/1000
2023-01-21 13:48:43,279:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 972.33s, LR: 0.00070, Train Loss: 0.1124, Train MAE: 0.1124,
                            Val Loss: 0.1311, Val MAE: 0.1306
2023-01-21 13:48:43,299:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 38/1000
2023-01-21 14:04:52,065:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 968.77s, LR: 0.00070, Train Loss: 0.1121, Train MAE: 0.1121,
                            Val Loss: 0.1292, Val MAE: 0.1288
2023-01-21 14:04:52,087:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 39/1000
2023-01-21 14:21:01,447:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 969.36s, LR: 0.00070, Train Loss: 0.1116, Train MAE: 0.1116,
                            Val Loss: 0.1327, Val MAE: 0.1321
2023-01-21 14:21:01,467:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 40/1000
2023-01-21 14:37:06,346:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.12205425649881363
2023-01-21 14:37:06,365:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 964.90s, LR: 0.00070, Train Loss: 0.1112, Train MAE: 0.1112,
                            Val Loss: 0.1224, Val MAE: 0.1221
2023-01-21 14:37:06,366:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 41/1000
2023-01-21 14:53:10,505:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 964.14s, LR: 0.00070, Train Loss: 0.1108, Train MAE: 0.1108,
                            Val Loss: 0.1235, Val MAE: 0.1232
2023-01-21 14:53:10,519:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 42/1000
2023-01-21 15:09:22,023:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 971.50s, LR: 0.00070, Train Loss: 0.1101, Train MAE: 0.1101,
                            Val Loss: 0.1292, Val MAE: 0.1284
2023-01-21 15:09:22,041:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 43/1000
2023-01-21 15:25:28,612:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.57s, LR: 0.00070, Train Loss: 0.1101, Train MAE: 0.1101,
                            Val Loss: 0.1342, Val MAE: 0.1336
2023-01-21 15:25:28,630:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 44/1000
2023-01-21 15:41:35,219:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.59s, LR: 0.00070, Train Loss: 0.1097, Train MAE: 0.1097,
                            Val Loss: 0.1306, Val MAE: 0.1296
2023-01-21 15:41:35,221:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 45/1000
2023-01-21 15:57:41,945:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.72s, LR: 0.00070, Train Loss: 0.1092, Train MAE: 0.1092,
                            Val Loss: 0.1320, Val MAE: 0.1313
2023-01-21 15:57:41,965:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 46/1000
2023-01-21 16:13:48,117:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.15s, LR: 0.00070, Train Loss: 0.1095, Train MAE: 0.1095,
                            Val Loss: 0.1289, Val MAE: 0.1284
2023-01-21 16:13:48,118:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 47/1000
2023-01-21 16:29:53,420:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.1200735792517662
2023-01-21 16:29:53,422:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 965.30s, LR: 0.00070, Train Loss: 0.1085, Train MAE: 0.1085,
                            Val Loss: 0.1207, Val MAE: 0.1201
2023-01-21 16:29:53,423:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 48/1000
2023-01-21 16:45:58,840:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 965.42s, LR: 0.00070, Train Loss: 0.1084, Train MAE: 0.1084,
                            Val Loss: 0.1286, Val MAE: 0.1279
2023-01-21 16:45:58,856:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 49/1000
2023-01-21 17:02:05,427:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.57s, LR: 0.00070, Train Loss: 0.1082, Train MAE: 0.1082,
                            Val Loss: 0.1246, Val MAE: 0.1241
2023-01-21 17:02:05,445:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 50/1000
2023-01-21 17:18:12,692:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 967.25s, LR: 0.00070, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.1382, Val MAE: 0.1369
2023-01-21 17:18:12,708:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 51/1000
2023-01-21 17:34:19,513:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.80s, LR: 0.00070, Train Loss: 0.1076, Train MAE: 0.1076,
                            Val Loss: 0.1325, Val MAE: 0.1315
2023-01-21 17:34:19,530:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 52/1000
2023-01-21 17:50:27,181:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 967.65s, LR: 0.00070, Train Loss: 0.1077, Train MAE: 0.1077,
                            Val Loss: 0.1348, Val MAE: 0.1337
2023-01-21 17:50:27,202:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 53/1000
2023-01-21 18:06:33,594:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.39s, LR: 0.00070, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.1350, Val MAE: 0.1340
2023-01-21 18:06:33,607:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 54/1000
2023-01-21 18:22:38,925:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 965.32s, LR: 0.00070, Train Loss: 0.1067, Train MAE: 0.1067,
                            Val Loss: 0.1292, Val MAE: 0.1281
2023-01-21 18:22:38,937:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 55/1000
2023-01-21 18:40:05,244:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 1046.31s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1257, Val MAE: 0.1248
2023-01-21 18:40:05,250:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 56/1000
2023-01-21 18:56:15,274:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 970.02s, LR: 0.00070, Train Loss: 0.1059, Train MAE: 0.1059,
                            Val Loss: 0.1260, Val MAE: 0.1255
2023-01-21 18:56:15,289:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 57/1000
2023-01-21 19:12:31,153:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.86s, LR: 0.00070, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.1290, Val MAE: 0.1280
2023-01-21 19:12:31,169:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 58/1000
2023-01-21 19:28:40,689:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 969.52s, LR: 0.00070, Train Loss: 0.1058, Train MAE: 0.1058,
                            Val Loss: 0.1323, Val MAE: 0.1312
2023-01-21 19:28:40,699:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 59/1000
2023-01-21 19:44:45,362:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 964.66s, LR: 0.00035, Train Loss: 0.0980, Train MAE: 0.0980,
                            Val Loss: 0.1307, Val MAE: 0.1287
2023-01-21 19:44:45,380:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 60/1000
2023-01-21 20:00:52,310:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 966.93s, LR: 0.00035, Train Loss: 0.0965, Train MAE: 0.0965,
                            Val Loss: 0.1227, Val MAE: 0.1213
2023-01-21 20:00:52,326:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 61/1000
2023-01-21 20:17:06,400:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 974.07s, LR: 0.00035, Train Loss: 0.0959, Train MAE: 0.0959,
                            Val Loss: 0.1309, Val MAE: 0.1288
2023-01-21 20:17:06,415:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 62/1000
2023-01-21 20:33:20,040:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 973.62s, LR: 0.00035, Train Loss: 0.0955, Train MAE: 0.0955,
                            Val Loss: 0.1278, Val MAE: 0.1261
2023-01-21 20:33:20,046:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 63/1000
2023-01-21 20:49:34,269:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 974.22s, LR: 0.00035, Train Loss: 0.0952, Train MAE: 0.0952,
                            Val Loss: 0.1282, Val MAE: 0.1263
2023-01-21 20:49:34,284:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 64/1000
2023-01-21 21:05:50,795:main_OGB_graph_regression.py:179 -   train_val_pipeline(): Best model with val MAE 0.11967995762825012
2023-01-21 21:05:50,816:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 976.53s, LR: 0.00035, Train Loss: 0.0950, Train MAE: 0.0950,
                            Val Loss: 0.1208, Val MAE: 0.1197
2023-01-21 21:05:50,817:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 65/1000
2023-01-21 21:22:05,952:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.13s, LR: 0.00035, Train Loss: 0.0945, Train MAE: 0.0945,
                            Val Loss: 0.1247, Val MAE: 0.1230
2023-01-21 21:22:05,970:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 66/1000
2023-01-21 21:38:21,868:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.90s, LR: 0.00035, Train Loss: 0.0944, Train MAE: 0.0944,
                            Val Loss: 0.1221, Val MAE: 0.1207
2023-01-21 21:38:21,870:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 67/1000
2023-01-21 21:54:38,347:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 976.48s, LR: 0.00035, Train Loss: 0.0940, Train MAE: 0.0940,
                            Val Loss: 0.1288, Val MAE: 0.1267
2023-01-21 21:54:38,364:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 68/1000
2023-01-21 22:10:51,495:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 973.13s, LR: 0.00035, Train Loss: 0.0940, Train MAE: 0.0940,
                            Val Loss: 0.1242, Val MAE: 0.1226
2023-01-21 22:10:51,496:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 69/1000
2023-01-21 22:27:06,599:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 975.10s, LR: 0.00035, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.1491, Val MAE: 0.1455
2023-01-21 22:27:06,600:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 70/1000
2023-01-21 22:43:22,618:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 976.02s, LR: 0.00017, Train Loss: 0.0893, Train MAE: 0.0893,
                            Val Loss: 0.1339, Val MAE: 0.1312
2023-01-21 22:43:22,619:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 71/1000
2023-01-21 22:59:34,855:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 972.23s, LR: 0.00017, Train Loss: 0.0886, Train MAE: 0.0886,
                            Val Loss: 0.1356, Val MAE: 0.1328
2023-01-21 22:59:34,856:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 72/1000
2023-01-21 23:15:42,650:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 967.79s, LR: 0.00017, Train Loss: 0.0883, Train MAE: 0.0883,
                            Val Loss: 0.1336, Val MAE: 0.1309
2023-01-21 23:15:42,651:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 73/1000
2023-01-21 23:31:47,575:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 964.92s, LR: 0.00017, Train Loss: 0.0880, Train MAE: 0.0880,
                            Val Loss: 0.1340, Val MAE: 0.1313
2023-01-21 23:31:47,576:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 74/1000
2023-01-21 23:49:15,843:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 1048.27s, LR: 0.00017, Train Loss: 0.0877, Train MAE: 0.0877,
                            Val Loss: 0.1308, Val MAE: 0.1283
2023-01-21 23:49:15,844:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 75/1000
2023-01-22 00:05:21,333:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 965.49s, LR: 0.00017, Train Loss: 0.0874, Train MAE: 0.0874,
                            Val Loss: 0.1299, Val MAE: 0.1276
2023-01-22 00:05:21,355:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 76/1000
2023-01-22 00:21:26,596:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 965.24s, LR: 0.00017, Train Loss: 0.0874, Train MAE: 0.0874,
                            Val Loss: 0.1389, Val MAE: 0.1357
2023-01-22 00:21:26,611:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 77/1000
2023-01-22 00:37:29,183:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 962.57s, LR: 0.00017, Train Loss: 0.0872, Train MAE: 0.0872,
                            Val Loss: 0.1343, Val MAE: 0.1315
2023-01-22 00:37:29,185:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 78/1000
2023-01-22 00:53:30,381:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 961.20s, LR: 0.00017, Train Loss: 0.0870, Train MAE: 0.0870,
                            Val Loss: 0.1400, Val MAE: 0.1369
2023-01-22 00:53:30,388:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 79/1000
2023-01-22 01:09:32,177:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 961.79s, LR: 0.00017, Train Loss: 0.0869, Train MAE: 0.0869,
                            Val Loss: 0.1353, Val MAE: 0.1323
2023-01-22 01:09:32,179:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 80/1000
2023-01-22 01:25:36,186:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 964.01s, LR: 0.00017, Train Loss: 0.0867, Train MAE: 0.0867,
                            Val Loss: 0.1377, Val MAE: 0.1346
2023-01-22 01:25:36,206:main_OGB_graph_regression.py:161 -   train_val_pipeline(): Epoch 81/1000
2023-01-22 01:41:44,263:main_OGB_graph_regression.py:205 -   train_val_pipeline(): 	Time: 968.06s, LR: 0.00009, Train Loss: 0.0843, Train MAE: 0.0843,
                            Val Loss: 0.1404, Val MAE: 0.1370
2023-01-22 01:41:44,265:main_OGB_graph_regression.py:231 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2023-01-22 01:41:44,266:main_OGB_graph_regression.py:232 -   train_val_pipeline(): Max_time for training elapsed 24.00 hours, so stopping
2023-01-22 01:51:13,562:main_OGB_graph_regression.py:248 -   train_val_pipeline(): Val MAE: 0.1370
2023-01-22 01:51:13,576:main_OGB_graph_regression.py:249 -   train_val_pipeline(): Train MAE: 0.0807
2023-01-22 01:51:13,578:main_OGB_graph_regression.py:250 -   train_val_pipeline(): Best Train MAE Corresponding to Best Val MAE: inf
2023-01-22 01:51:13,579:main_OGB_graph_regression.py:251 -   train_val_pipeline(): Convergence Time (Epochs): 80.0000
2023-01-22 01:51:13,581:main_OGB_graph_regression.py:252 -   train_val_pipeline(): TOTAL TIME TAKEN: 87002.9549s
2023-01-22 01:51:13,584:main_OGB_graph_regression.py:253 -   train_val_pipeline(): AVG TIME PER EPOCH: 977.2658s
2023-01-22 01:51:13,588:main_OGB_graph_regression.py:257 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 1024, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [22], 'save_name': 'b128-noedge', 'job_num': 10}
2023-01-22 01:51:13,729:main_OGB_graph_regression.py:258 -   train_val_pipeline(): train history: [tensor(0.0807)]
2023-01-22 01:51:13,729:main_OGB_graph_regression.py:260 -   train_val_pipeline(): val history: [tensor(0.1370)]
