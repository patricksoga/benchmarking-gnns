2022-10-05 15:40:34,702:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA TITAN X (Pascal)
2022-10-05 15:40:53,847:main_SBMs_node_classification.py:385 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0.02', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-32-scale50-trials/32_DEBUG_0_41.log', 'device': device(type='cuda'), 'pos_enc_dim': 32, 'in_dim': 3, 'n_classes': 2, 'seed_array': [41]}
2022-10-05 15:40:53,847:main_SBMs_node_classification.py:386 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-10-05 15:40:53,849:pe_layer.py:81 -             __init__(): rand_pos_enc
2022-10-05 15:40:55,397:pe_layer.py:239 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-10-05 15:40:55,397:pe_layer.py:244 -             __init__(): Using matrix: A
2022-10-05 15:40:55,397:pe_layer.py:245 -             __init__(): Matrix power: 1
2022-10-05 15:40:55,413:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2022-10-05 15:40:55,416:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527494
2022-10-05 15:40:55,416:main_SBMs_node_classification.py:44 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-10-05 15:40:55,417:pe_layer.py:81 -             __init__(): rand_pos_enc
2022-10-05 15:40:55,418:pe_layer.py:239 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-10-05 15:40:55,418:pe_layer.py:244 -             __init__(): Using matrix: A
2022-10-05 15:40:55,418:pe_layer.py:245 -             __init__(): Matrix power: 1
2022-10-05 15:40:55,441:main_SBMs_node_classification.py:86 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-10-05 15:42:46,320:main_SBMs_node_classification.py:94 -   train_val_pipeline(): Time PE:110.87909054756165
2022-10-05 15:42:46,324:main_SBMs_node_classification.py:165 -   train_val_pipeline(): Training Graphs: 10000
2022-10-05 15:42:46,324:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Validation Graphs: 2000
2022-10-05 15:42:46,324:main_SBMs_node_classification.py:167 -   train_val_pipeline(): Test Graphs: 2000
2022-10-05 15:42:46,324:main_SBMs_node_classification.py:168 -   train_val_pipeline(): Number of Classes: 2
2022-10-05 15:42:46,330:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 1/1000
2022-10-05 15:45:16,242:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.1236 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 15:45:16,243:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 149.91s, LR: 0.00050, Train Loss: 0.3599, Train Acc: 84.2221,
                            Val Loss: 0.3380, Val Acc: 84.9472, Test Acc: 85.1236
2022-10-05 15:45:16,243:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 2/1000
2022-10-05 15:47:46,145:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.4297 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 15:47:46,145:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 149.90s, LR: 0.00050, Train Loss: 0.3354, Train Acc: 85.1211,
                            Val Loss: 0.3330, Val Acc: 85.2716, Test Acc: 85.4297
2022-10-05 15:47:46,145:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 3/1000
2022-10-05 15:50:08,272:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.4862 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 15:50:08,273:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 142.13s, LR: 0.00050, Train Loss: 0.3330, Train Acc: 85.2766,
                            Val Loss: 0.3341, Val Acc: 85.2170, Test Acc: 85.4862
2022-10-05 15:50:08,273:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 4/1000
2022-10-05 15:52:26,298:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.7320 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 15:52:26,298:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 138.03s, LR: 0.00050, Train Loss: 0.3319, Train Acc: 85.3146,
                            Val Loss: 0.3305, Val Acc: 85.4701, Test Acc: 85.7320
2022-10-05 15:52:26,299:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 5/1000
2022-10-05 15:54:43,235:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 136.94s, LR: 0.00050, Train Loss: 0.3313, Train Acc: 85.3662,
                            Val Loss: 0.3356, Val Acc: 85.0490, Test Acc: 85.1911
2022-10-05 15:54:43,236:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 6/1000
2022-10-05 15:57:00,056:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 136.82s, LR: 0.00050, Train Loss: 0.3312, Train Acc: 85.3897,
                            Val Loss: 0.3313, Val Acc: 85.3541, Test Acc: 85.5923
2022-10-05 15:57:00,057:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 7/1000
2022-10-05 15:59:15,847:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 135.79s, LR: 0.00050, Train Loss: 0.3305, Train Acc: 85.4065,
                            Val Loss: 0.3303, Val Acc: 85.4463, Test Acc: 85.6366
2022-10-05 15:59:15,848:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 8/1000
2022-10-05 16:01:31,378:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 135.53s, LR: 0.00050, Train Loss: 0.3300, Train Acc: 85.4413,
                            Val Loss: 0.3320, Val Acc: 85.3264, Test Acc: 85.4939
2022-10-05 16:01:31,378:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 9/1000
2022-10-05 16:03:47,206:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 135.83s, LR: 0.00050, Train Loss: 0.3297, Train Acc: 85.4474,
                            Val Loss: 0.3377, Val Acc: 84.9951, Test Acc: 85.2092
2022-10-05 16:03:47,207:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 10/1000
2022-10-05 16:06:03,363:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 136.16s, LR: 0.00050, Train Loss: 0.3290, Train Acc: 85.4716,
                            Val Loss: 0.3295, Val Acc: 85.4679, Test Acc: 85.6966
2022-10-05 16:06:03,363:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 11/1000
2022-10-05 16:08:20,678:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.31s, LR: 0.00050, Train Loss: 0.3289, Train Acc: 85.5175,
                            Val Loss: 0.3282, Val Acc: 85.5019, Test Acc: 85.6754
2022-10-05 16:08:20,679:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 12/1000
2022-10-05 16:10:35,506:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 134.83s, LR: 0.00050, Train Loss: 0.3288, Train Acc: 85.5067,
                            Val Loss: 0.3301, Val Acc: 85.5050, Test Acc: 85.7078
2022-10-05 16:10:35,507:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 13/1000
2022-10-05 16:12:52,550:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.04s, LR: 0.00050, Train Loss: 0.3281, Train Acc: 85.5129,
                            Val Loss: 0.3293, Val Acc: 85.4609, Test Acc: 85.6200
2022-10-05 16:12:52,550:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 14/1000
2022-10-05 16:15:08,874:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.7837 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 16:15:08,875:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 136.32s, LR: 0.00050, Train Loss: 0.3283, Train Acc: 85.5008,
                            Val Loss: 0.3280, Val Acc: 85.5159, Test Acc: 85.7837
2022-10-05 16:15:08,875:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 15/1000
2022-10-05 16:17:26,059:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.18s, LR: 0.00050, Train Loss: 0.3281, Train Acc: 85.5175,
                            Val Loss: 0.3294, Val Acc: 85.5516, Test Acc: 85.6903
2022-10-05 16:17:26,059:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 16/1000
2022-10-05 16:19:43,254:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.19s, LR: 0.00050, Train Loss: 0.3275, Train Acc: 85.5397,
                            Val Loss: 0.3298, Val Acc: 85.5195, Test Acc: 85.7306
2022-10-05 16:19:43,255:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 17/1000
2022-10-05 16:22:00,536:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.28s, LR: 0.00050, Train Loss: 0.3274, Train Acc: 85.5599,
                            Val Loss: 0.3275, Val Acc: 85.5347, Test Acc: 85.6698
2022-10-05 16:22:00,536:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 18/1000
2022-10-05 16:24:18,236:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.7895 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 16:24:18,237:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.70s, LR: 0.00050, Train Loss: 0.3271, Train Acc: 85.5975,
                            Val Loss: 0.3262, Val Acc: 85.6123, Test Acc: 85.7895
2022-10-05 16:24:18,237:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 19/1000
2022-10-05 16:26:36,291:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.8099 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 16:26:36,292:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 138.05s, LR: 0.00050, Train Loss: 0.3268, Train Acc: 85.5875,
                            Val Loss: 0.3281, Val Acc: 85.5887, Test Acc: 85.8099
2022-10-05 16:26:36,292:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 20/1000
2022-10-05 16:28:54,219:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.93s, LR: 0.00050, Train Loss: 0.3261, Train Acc: 85.6285,
                            Val Loss: 0.3296, Val Acc: 85.4358, Test Acc: 85.6078
2022-10-05 16:28:54,220:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 21/1000
2022-10-05 16:31:11,858:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.64s, LR: 0.00050, Train Loss: 0.3255, Train Acc: 85.6748,
                            Val Loss: 0.3335, Val Acc: 85.2383, Test Acc: 85.3792
2022-10-05 16:31:11,859:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 22/1000
2022-10-05 16:33:28,552:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 136.69s, LR: 0.00050, Train Loss: 0.3231, Train Acc: 85.7653,
                            Val Loss: 0.3317, Val Acc: 85.3834, Test Acc: 85.5294
2022-10-05 16:33:28,552:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 23/1000
2022-10-05 16:35:45,799:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 85.9551 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 16:35:45,800:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.25s, LR: 0.00050, Train Loss: 0.3199, Train Acc: 85.9650,
                            Val Loss: 0.3245, Val Acc: 85.8569, Test Acc: 85.9551
2022-10-05 16:35:45,800:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 24/1000
2022-10-05 16:38:02,896:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 86.0118 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 16:38:02,896:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 137.10s, LR: 0.00050, Train Loss: 0.3171, Train Acc: 86.1219,
                            Val Loss: 0.3223, Val Acc: 85.9210, Test Acc: 86.0118
2022-10-05 16:38:02,896:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 25/1000
2022-10-05 16:40:19,871:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 86.0395 to out/SBMs_node_classification_b26-bnorm-alt-32-scale50-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_15h40m53s_on_Oct_05_2022/MODELS_
2022-10-05 16:40:19,872:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 136.98s, LR: 0.00050, Train Loss: 0.3158, Train Acc: 86.1541,
                            Val Loss: 0.3217, Val Acc: 85.8974, Test Acc: 86.0395
2022-10-05 16:40:19,872:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 26/1000
