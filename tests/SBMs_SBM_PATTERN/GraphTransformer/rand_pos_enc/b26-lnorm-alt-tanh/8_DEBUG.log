2022-09-11 02:34:09,609:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2022-09-11 02:34:27,487:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-lnorm-alt-tanh/8_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-11 02:34:27,487:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-11 02:34:27,488:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-11 02:34:28,743:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-11 02:34:28,743:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-11 02:34:28,743:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-11 02:34:28,757:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-11 02:34:28,760:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-11 02:34:28,760:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-11 02:34:28,760:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-11 02:34:28,761:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-11 02:34:28,761:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-11 02:34:28,761:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-11 02:34:28,782:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-11 02:36:54,310:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:145.52722215652466
2022-09-11 02:36:54,312:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10000
2022-09-11 02:36:54,313:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-11 02:36:54,313:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 2000
2022-09-11 02:36:54,313:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 2
2022-09-11 02:36:54,332:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-11 02:39:05,343:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 84.7002 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 02:39:05,344:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 131.01s, LR: 0.00050, Train Loss: 0.3893, Train Acc: 82.2173,
                            Val Loss: 0.3511, Val Acc: 84.5092, Test Acc: 84.7002
2022-09-11 02:39:05,344:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 2/1000
2022-09-11 02:41:18,468:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 133.12s, LR: 0.00050, Train Loss: 0.3471, Train Acc: 84.5860,
                            Val Loss: 0.3794, Val Acc: 83.0869, Test Acc: 83.3493
2022-09-11 02:41:18,469:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 3/1000
2022-09-11 02:43:33,182:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 134.71s, LR: 0.00050, Train Loss: 0.3402, Train Acc: 84.9937,
                            Val Loss: 0.3636, Val Acc: 83.7180, Test Acc: 83.9658
2022-09-11 02:43:33,183:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 4/1000
2022-09-11 02:45:47,679:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 84.8723 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 02:45:47,679:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 134.50s, LR: 0.00050, Train Loss: 0.3377, Train Acc: 85.0727,
                            Val Loss: 0.3463, Val Acc: 84.7161, Test Acc: 84.8723
2022-09-11 02:45:47,679:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 5/1000
2022-09-11 02:48:01,712:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 134.03s, LR: 0.00050, Train Loss: 0.3364, Train Acc: 85.1408,
                            Val Loss: 0.3517, Val Acc: 84.2211, Test Acc: 84.4563
2022-09-11 02:48:01,713:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 6/1000
2022-09-11 02:50:17,266:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 84.9189 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 02:50:17,267:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 135.55s, LR: 0.00050, Train Loss: 0.3359, Train Acc: 85.1643,
                            Val Loss: 0.3428, Val Acc: 84.8238, Test Acc: 84.9189
2022-09-11 02:50:17,267:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 7/1000
2022-09-11 02:52:32,059:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.2474 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 02:52:32,060:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 134.79s, LR: 0.00050, Train Loss: 0.3351, Train Acc: 85.1875,
                            Val Loss: 0.3382, Val Acc: 85.0592, Test Acc: 85.2474
2022-09-11 02:52:32,060:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 8/1000
2022-09-11 02:54:47,094:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 135.03s, LR: 0.00050, Train Loss: 0.3341, Train Acc: 85.2322,
                            Val Loss: 0.3394, Val Acc: 85.0497, Test Acc: 85.1248
2022-09-11 02:54:47,095:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 9/1000
2022-09-11 02:57:02,943:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 135.85s, LR: 0.00050, Train Loss: 0.3339, Train Acc: 85.2690,
                            Val Loss: 0.3405, Val Acc: 84.9290, Test Acc: 85.1546
2022-09-11 02:57:02,943:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 10/1000
2022-09-11 02:59:18,774:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 135.83s, LR: 0.00050, Train Loss: 0.3330, Train Acc: 85.2895,
                            Val Loss: 0.3412, Val Acc: 84.8959, Test Acc: 85.1572
2022-09-11 02:59:18,775:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 11/1000
2022-09-11 03:01:35,088:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.3643 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:01:35,089:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 136.31s, LR: 0.00050, Train Loss: 0.3328, Train Acc: 85.3326,
                            Val Loss: 0.3337, Val Acc: 85.1854, Test Acc: 85.3643
2022-09-11 03:01:35,089:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 12/1000
2022-09-11 03:03:52,334:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 137.25s, LR: 0.00050, Train Loss: 0.3314, Train Acc: 85.3504,
                            Val Loss: 0.3372, Val Acc: 85.1821, Test Acc: 85.3182
2022-09-11 03:03:52,335:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 13/1000
2022-09-11 03:06:11,836:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.4452 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:06:11,837:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.50s, LR: 0.00050, Train Loss: 0.3312, Train Acc: 85.4292,
                            Val Loss: 0.3335, Val Acc: 85.2974, Test Acc: 85.4452
2022-09-11 03:06:11,837:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 14/1000
2022-09-11 03:08:31,491:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.65s, LR: 0.00050, Train Loss: 0.3306, Train Acc: 85.4130,
                            Val Loss: 0.3453, Val Acc: 84.5844, Test Acc: 84.8658
2022-09-11 03:08:31,492:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 15/1000
2022-09-11 03:10:51,068:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.5341 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:10:51,068:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.58s, LR: 0.00050, Train Loss: 0.3306, Train Acc: 85.4078,
                            Val Loss: 0.3336, Val Acc: 85.3736, Test Acc: 85.5341
2022-09-11 03:10:51,068:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 16/1000
2022-09-11 03:13:09,323:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 138.25s, LR: 0.00050, Train Loss: 0.3294, Train Acc: 85.4629,
                            Val Loss: 0.3342, Val Acc: 85.3282, Test Acc: 85.4240
2022-09-11 03:13:09,324:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 17/1000
2022-09-11 03:15:28,894:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.57s, LR: 0.00050, Train Loss: 0.3293, Train Acc: 85.5015,
                            Val Loss: 0.3345, Val Acc: 85.2659, Test Acc: 85.4040
2022-09-11 03:15:28,894:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 18/1000
2022-09-11 03:17:48,940:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.05s, LR: 0.00050, Train Loss: 0.3284, Train Acc: 85.5410,
                            Val Loss: 0.3390, Val Acc: 84.9922, Test Acc: 85.1264
2022-09-11 03:17:48,941:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 19/1000
2022-09-11 03:20:08,168:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.5399 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:20:08,169:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.23s, LR: 0.00050, Train Loss: 0.3278, Train Acc: 85.5405,
                            Val Loss: 0.3320, Val Acc: 85.4318, Test Acc: 85.5399
2022-09-11 03:20:08,169:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 20/1000
2022-09-11 03:22:27,651:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.48s, LR: 0.00050, Train Loss: 0.3275, Train Acc: 85.5557,
                            Val Loss: 0.3340, Val Acc: 85.2539, Test Acc: 85.4989
2022-09-11 03:22:27,652:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 21/1000
2022-09-11 03:24:47,075:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.42s, LR: 0.00050, Train Loss: 0.3267, Train Acc: 85.5957,
                            Val Loss: 0.3415, Val Acc: 84.9244, Test Acc: 85.0674
2022-09-11 03:24:47,076:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 22/1000
2022-09-11 03:27:02,821:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 135.74s, LR: 0.00050, Train Loss: 0.3262, Train Acc: 85.6153,
                            Val Loss: 0.3391, Val Acc: 85.1110, Test Acc: 85.1504
2022-09-11 03:27:02,821:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 23/1000
2022-09-11 03:29:19,434:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 136.61s, LR: 0.00050, Train Loss: 0.3258, Train Acc: 85.6333,
                            Val Loss: 0.3330, Val Acc: 85.3546, Test Acc: 85.5326
2022-09-11 03:29:19,434:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 24/1000
2022-09-11 03:31:35,894:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 136.46s, LR: 0.00050, Train Loss: 0.3249, Train Acc: 85.6686,
                            Val Loss: 0.3396, Val Acc: 84.9840, Test Acc: 85.0445
2022-09-11 03:31:35,895:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 25/1000
2022-09-11 03:33:51,739:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 135.84s, LR: 0.00050, Train Loss: 0.3243, Train Acc: 85.7155,
                            Val Loss: 0.3340, Val Acc: 85.3019, Test Acc: 85.3312
2022-09-11 03:33:51,739:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 26/1000
2022-09-11 03:36:08,084:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 136.35s, LR: 0.00050, Train Loss: 0.3239, Train Acc: 85.7532,
                            Val Loss: 0.3407, Val Acc: 85.2501, Test Acc: 85.3931
2022-09-11 03:36:08,085:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 27/1000
2022-09-11 03:38:23,654:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 135.57s, LR: 0.00050, Train Loss: 0.3228, Train Acc: 85.7802,
                            Val Loss: 0.3462, Val Acc: 84.8351, Test Acc: 84.9580
2022-09-11 03:38:23,654:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 28/1000
