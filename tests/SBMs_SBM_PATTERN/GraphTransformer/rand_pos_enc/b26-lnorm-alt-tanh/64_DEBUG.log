2022-09-11 02:34:08,859:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2022-09-11 02:34:27,761:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-lnorm-alt-tanh/64_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-11 02:34:27,761:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-11 02:34:27,762:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-11 02:34:29,038:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-11 02:34:29,038:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-11 02:34:29,038:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-11 02:34:29,054:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-11 02:34:29,057:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532103
2022-09-11 02:34:29,057:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-11 02:34:29,058:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-11 02:34:29,059:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-11 02:34:29,059:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-11 02:34:29,059:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-11 02:34:29,085:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-11 02:37:54,326:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:205.24126386642456
2022-09-11 02:37:54,329:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10000
2022-09-11 02:37:54,329:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-11 02:37:54,329:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 2000
2022-09-11 02:37:54,329:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 2
2022-09-11 02:37:54,334:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-11 02:40:05,969:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 84.6317 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 02:40:05,970:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 131.64s, LR: 0.00050, Train Loss: 0.3792, Train Acc: 82.6185,
                            Val Loss: 0.3484, Val Acc: 84.5045, Test Acc: 84.6317
2022-09-11 02:40:05,970:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 2/1000
2022-09-11 02:42:18,383:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 132.41s, LR: 0.00050, Train Loss: 0.3442, Train Acc: 84.6999,
                            Val Loss: 0.3546, Val Acc: 84.2214, Test Acc: 84.4267
2022-09-11 02:42:18,384:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 3/1000
2022-09-11 02:44:37,568:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.18s, LR: 0.00050, Train Loss: 0.3385, Train Acc: 85.0264,
                            Val Loss: 0.3577, Val Acc: 83.9906, Test Acc: 84.2555
2022-09-11 02:44:37,568:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 4/1000
2022-09-11 02:46:58,004:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 84.9573 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 02:46:58,004:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.44s, LR: 0.00050, Train Loss: 0.3374, Train Acc: 85.0817,
                            Val Loss: 0.3436, Val Acc: 84.7027, Test Acc: 84.9573
2022-09-11 02:46:58,004:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 5/1000
2022-09-11 02:49:18,652:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.65s, LR: 0.00050, Train Loss: 0.3355, Train Acc: 85.1688,
                            Val Loss: 0.3439, Val Acc: 84.7215, Test Acc: 84.8992
2022-09-11 02:49:18,652:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 6/1000
2022-09-11 02:51:37,818:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.4657 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 02:51:37,819:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.17s, LR: 0.00050, Train Loss: 0.3350, Train Acc: 85.2095,
                            Val Loss: 0.3340, Val Acc: 85.2740, Test Acc: 85.4657
2022-09-11 02:51:37,819:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 7/1000
2022-09-11 02:53:57,856:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.04s, LR: 0.00050, Train Loss: 0.3341, Train Acc: 85.2410,
                            Val Loss: 0.3468, Val Acc: 84.8819, Test Acc: 85.1407
2022-09-11 02:53:57,857:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 8/1000
2022-09-11 02:56:16,877:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.02s, LR: 0.00050, Train Loss: 0.3334, Train Acc: 85.2636,
                            Val Loss: 0.3337, Val Acc: 85.2695, Test Acc: 85.4337
2022-09-11 02:56:16,878:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 9/1000
2022-09-11 02:58:36,170:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.29s, LR: 0.00050, Train Loss: 0.3332, Train Acc: 85.2813,
                            Val Loss: 0.3384, Val Acc: 85.1029, Test Acc: 85.3210
2022-09-11 02:58:36,171:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 10/1000
2022-09-11 03:00:52,250:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 136.08s, LR: 0.00050, Train Loss: 0.3323, Train Acc: 85.3105,
                            Val Loss: 0.3405, Val Acc: 85.0352, Test Acc: 85.1921
2022-09-11 03:00:52,251:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 11/1000
2022-09-11 03:03:11,624:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.37s, LR: 0.00050, Train Loss: 0.3321, Train Acc: 85.3308,
                            Val Loss: 0.3396, Val Acc: 85.1999, Test Acc: 85.4120
2022-09-11 03:03:11,624:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 12/1000
2022-09-11 03:05:31,254:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.63s, LR: 0.00050, Train Loss: 0.3316, Train Acc: 85.3573,
                            Val Loss: 0.3372, Val Acc: 85.1688, Test Acc: 85.3088
2022-09-11 03:05:31,255:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 13/1000
2022-09-11 03:07:50,702:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.45s, LR: 0.00050, Train Loss: 0.3311, Train Acc: 85.4047,
                            Val Loss: 0.3335, Val Acc: 85.3608, Test Acc: 85.4092
2022-09-11 03:07:50,703:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 14/1000
2022-09-11 03:10:10,522:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.82s, LR: 0.00050, Train Loss: 0.3301, Train Acc: 85.4366,
                            Val Loss: 0.3357, Val Acc: 85.1824, Test Acc: 85.4024
2022-09-11 03:10:10,523:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 15/1000
2022-09-11 03:12:28,776:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.4802 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:12:28,776:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 138.25s, LR: 0.00050, Train Loss: 0.3303, Train Acc: 85.4167,
                            Val Loss: 0.3347, Val Acc: 85.2849, Test Acc: 85.4802
2022-09-11 03:12:28,776:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 16/1000
2022-09-11 03:14:47,750:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.4999 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:14:47,750:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 138.97s, LR: 0.00050, Train Loss: 0.3297, Train Acc: 85.4156,
                            Val Loss: 0.3315, Val Acc: 85.3864, Test Acc: 85.4999
2022-09-11 03:14:47,750:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 17/1000
2022-09-11 03:17:06,322:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.5385 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:17:06,322:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 138.57s, LR: 0.00050, Train Loss: 0.3293, Train Acc: 85.4638,
                            Val Loss: 0.3324, Val Acc: 85.3718, Test Acc: 85.5385
2022-09-11 03:17:06,322:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 18/1000
2022-09-11 03:19:26,285:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.96s, LR: 0.00050, Train Loss: 0.3286, Train Acc: 85.5064,
                            Val Loss: 0.3325, Val Acc: 85.2368, Test Acc: 85.4155
2022-09-11 03:19:26,286:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 19/1000
2022-09-11 03:21:47,679:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.7232 to out/SBMs_node_classification_b26-lnorm-alt-tanhcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_02h34m27s_on_Sep_11_2022/MODELS_
2022-09-11 03:21:47,679:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 141.39s, LR: 0.00050, Train Loss: 0.3281, Train Acc: 85.5149,
                            Val Loss: 0.3299, Val Acc: 85.5059, Test Acc: 85.7232
2022-09-11 03:21:47,679:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 20/1000
2022-09-11 03:24:07,702:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.02s, LR: 0.00050, Train Loss: 0.3274, Train Acc: 85.5734,
                            Val Loss: 0.3401, Val Acc: 85.0509, Test Acc: 85.3402
2022-09-11 03:24:07,702:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 21/1000
2022-09-11 03:26:28,483:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.78s, LR: 0.00050, Train Loss: 0.3270, Train Acc: 85.5656,
                            Val Loss: 0.3404, Val Acc: 84.9878, Test Acc: 85.1516
2022-09-11 03:26:28,484:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 22/1000
2022-09-11 03:28:48,420:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.94s, LR: 0.00050, Train Loss: 0.3264, Train Acc: 85.6159,
                            Val Loss: 0.3331, Val Acc: 85.4107, Test Acc: 85.5036
2022-09-11 03:28:48,421:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 23/1000
2022-09-11 03:31:09,260:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.84s, LR: 0.00050, Train Loss: 0.3260, Train Acc: 85.6326,
                            Val Loss: 0.3325, Val Acc: 85.3708, Test Acc: 85.5169
2022-09-11 03:31:09,261:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 24/1000
2022-09-11 03:33:29,428:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.17s, LR: 0.00050, Train Loss: 0.3256, Train Acc: 85.6565,
                            Val Loss: 0.3473, Val Acc: 84.5234, Test Acc: 84.6084
2022-09-11 03:33:29,428:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 25/1000
2022-09-11 03:35:48,924:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 139.50s, LR: 0.00050, Train Loss: 0.3248, Train Acc: 85.6670,
                            Val Loss: 0.3364, Val Acc: 85.1434, Test Acc: 85.3223
2022-09-11 03:35:48,925:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 26/1000
2022-09-11 03:38:09,151:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 140.23s, LR: 0.00050, Train Loss: 0.3242, Train Acc: 85.7085,
                            Val Loss: 0.3315, Val Acc: 85.4973, Test Acc: 85.6057
2022-09-11 03:38:09,152:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 27/1000
