2022-10-06 04:21:17,335:main_utils.py:62 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2022-10-06 04:21:34,386:main_SBMs_node_classification.py:385 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': False, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'gape_div': False, 'gape_norm': False, 'gape_symmetric': False, 'gape_weight_gen': False, 'cycles_k': 6, 'gape_scale': '0.1', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-64-scale10-trials/64_DEBUG_0_35.log', 'device': device(type='cuda'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2, 'seed_array': [35]}
2022-10-06 04:21:34,387:main_SBMs_node_classification.py:386 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [35], 'job_num': 64}
2022-10-06 04:21:34,389:pe_layer.py:81 -             __init__(): rand_pos_enc
2022-10-06 04:21:35,532:pe_layer.py:239 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-10-06 04:21:35,532:pe_layer.py:244 -             __init__(): Using matrix: A
2022-10-06 04:21:35,532:pe_layer.py:245 -             __init__(): Matrix power: 1
2022-10-06 04:21:35,549:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2022-10-06 04:21:35,551:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536262
2022-10-06 04:21:35,552:main_SBMs_node_classification.py:44 -   train_val_pipeline(): [!] Starting seed: 35 in [35]...
2022-10-06 04:21:35,552:pe_layer.py:81 -             __init__(): rand_pos_enc
2022-10-06 04:21:35,554:pe_layer.py:239 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-10-06 04:21:35,554:pe_layer.py:244 -             __init__(): Using matrix: A
2022-10-06 04:21:35,554:pe_layer.py:245 -             __init__(): Matrix power: 1
2022-10-06 04:21:35,579:main_SBMs_node_classification.py:86 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-10-06 04:23:38,954:main_SBMs_node_classification.py:94 -   train_val_pipeline(): Time PE:123.37440824508667
2022-10-06 04:23:38,957:main_SBMs_node_classification.py:165 -   train_val_pipeline(): Training Graphs: 10000
2022-10-06 04:23:38,957:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Validation Graphs: 2000
2022-10-06 04:23:38,957:main_SBMs_node_classification.py:167 -   train_val_pipeline(): Test Graphs: 2000
2022-10-06 04:23:38,957:main_SBMs_node_classification.py:168 -   train_val_pipeline(): Number of Classes: 2
2022-10-06 04:23:38,961:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 1/1000
2022-10-06 04:26:10,378:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 83.5143 to out/SBMs_node_classification_b26-bnorm-alt-64-scale10-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_04h21m34s_on_Oct_06_2022/MODELS_
2022-10-06 04:26:10,378:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 151.42s, LR: 0.00050, Train Loss: 0.3745, Train Acc: 83.1426,
                            Val Loss: 0.3747, Val Acc: 83.4742, Test Acc: 83.5143
2022-10-06 04:26:10,378:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 2/1000
2022-10-06 04:28:44,536:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.16s, LR: 0.00050, Train Loss: 0.3442, Train Acc: 84.7147,
                            Val Loss: 0.4985, Val Acc: 74.3886, Test Acc: 74.5817
2022-10-06 04:28:44,536:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 3/1000
2022-10-06 04:31:19,384:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.85s, LR: 0.00050, Train Loss: 0.3411, Train Acc: 84.8570,
                            Val Loss: 0.3818, Val Acc: 83.4530, Test Acc: 83.4744
2022-10-06 04:31:19,385:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 4/1000
2022-10-06 04:33:54,245:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.86s, LR: 0.00050, Train Loss: 0.3374, Train Acc: 85.0766,
                            Val Loss: 0.6940, Val Acc: 55.2460, Test Acc: 55.4636
2022-10-06 04:33:54,245:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 5/1000
2022-10-06 04:36:28,826:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.58s, LR: 0.00050, Train Loss: 0.3360, Train Acc: 85.1220,
                            Val Loss: 0.8118, Val Acc: 50.8923, Test Acc: 50.8557
2022-10-06 04:36:28,827:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 6/1000
2022-10-06 04:39:03,844:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 155.02s, LR: 0.00050, Train Loss: 0.3336, Train Acc: 85.2330,
                            Val Loss: 0.4058, Val Acc: 82.4996, Test Acc: 82.8367
2022-10-06 04:39:03,845:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 7/1000
2022-10-06 04:41:37,957:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.11s, LR: 0.00050, Train Loss: 0.3342, Train Acc: 85.2233,
                            Val Loss: 0.8773, Val Acc: 50.2803, Test Acc: 50.2543
2022-10-06 04:41:37,957:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 8/1000
2022-10-06 04:44:11,775:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 153.82s, LR: 0.00050, Train Loss: 0.3345, Train Acc: 85.2132,
                            Val Loss: 0.4737, Val Acc: 75.9525, Test Acc: 76.3343
2022-10-06 04:44:11,775:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 9/1000
2022-10-06 04:46:46,225:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.45s, LR: 0.00050, Train Loss: 0.3328, Train Acc: 85.2849,
                            Val Loss: 0.3913, Val Acc: 82.5289, Test Acc: 82.7338
2022-10-06 04:46:46,225:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 10/1000
2022-10-06 04:49:21,211:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.99s, LR: 0.00050, Train Loss: 0.3331, Train Acc: 85.3050,
                            Val Loss: 0.5566, Val Acc: 67.4278, Test Acc: 67.9532
2022-10-06 04:49:21,211:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 11/1000
2022-10-06 04:51:56,174:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.96s, LR: 0.00050, Train Loss: 0.3319, Train Acc: 85.3567,
                            Val Loss: 0.4214, Val Acc: 80.4169, Test Acc: 80.3917
2022-10-06 04:51:56,174:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 12/1000
2022-10-06 04:54:31,047:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.87s, LR: 0.00050, Train Loss: 0.3323, Train Acc: 85.3334,
                            Val Loss: 0.7918, Val Acc: 64.4868, Test Acc: 64.7259
2022-10-06 04:54:31,048:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 13/1000
2022-10-06 04:57:05,857:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.81s, LR: 0.00025, Train Loss: 0.3291, Train Acc: 85.4794,
                            Val Loss: 2.1211, Val Acc: 50.0075, Test Acc: 50.0232
2022-10-06 04:57:05,858:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 14/1000
2022-10-06 04:59:40,489:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 83.6932 to out/SBMs_node_classification_b26-bnorm-alt-64-scale10-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_04h21m34s_on_Oct_06_2022/MODELS_
2022-10-06 04:59:40,490:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.63s, LR: 0.00025, Train Loss: 0.3285, Train Acc: 85.4897,
                            Val Loss: 0.3699, Val Acc: 83.5872, Test Acc: 83.6932
2022-10-06 04:59:40,490:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 15/1000
2022-10-06 05:02:14,348:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 153.86s, LR: 0.00025, Train Loss: 0.3280, Train Acc: 85.5064,
                            Val Loss: 0.4273, Val Acc: 80.2957, Test Acc: 80.6366
2022-10-06 05:02:14,348:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 16/1000
2022-10-06 05:04:48,787:main_SBMs_node_classification.py:222 -   train_val_pipeline(): Saving best model with test accuracy: 84.7231 to out/SBMs_node_classification_b26-bnorm-alt-64-scale10-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_04h21m34s_on_Oct_06_2022/MODELS_
2022-10-06 05:04:48,787:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.44s, LR: 0.00025, Train Loss: 0.3287, Train Acc: 85.4726,
                            Val Loss: 0.3468, Val Acc: 84.6918, Test Acc: 84.7231
2022-10-06 05:04:48,787:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 17/1000
2022-10-06 05:07:23,746:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.96s, LR: 0.00025, Train Loss: 0.3282, Train Acc: 85.5055,
                            Val Loss: 3.4868, Val Acc: 50.0056, Test Acc: 50.0226
2022-10-06 05:07:23,746:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 18/1000
2022-10-06 05:09:58,371:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.62s, LR: 0.00025, Train Loss: 0.3275, Train Acc: 85.5241,
                            Val Loss: 1.1309, Val Acc: 52.6410, Test Acc: 52.6457
2022-10-06 05:09:58,372:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 19/1000
2022-10-06 05:12:33,058:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.69s, LR: 0.00025, Train Loss: 0.3281, Train Acc: 85.5279,
                            Val Loss: 2.1785, Val Acc: 50.0076, Test Acc: 50.0252
2022-10-06 05:12:33,059:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 20/1000
2022-10-06 05:15:07,273:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.21s, LR: 0.00025, Train Loss: 0.3273, Train Acc: 85.5394,
                            Val Loss: 0.5512, Val Acc: 72.6288, Test Acc: 73.4587
2022-10-06 05:15:07,273:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 21/1000
2022-10-06 05:17:41,852:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.58s, LR: 0.00025, Train Loss: 0.3268, Train Acc: 85.6101,
                            Val Loss: 3.2634, Val Acc: 50.0000, Test Acc: 50.0099
2022-10-06 05:17:41,852:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 22/1000
2022-10-06 05:20:16,743:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.89s, LR: 0.00025, Train Loss: 0.3270, Train Acc: 85.5716,
                            Val Loss: 0.4230, Val Acc: 80.7325, Test Acc: 81.0927
2022-10-06 05:20:16,743:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 23/1000
2022-10-06 05:22:51,032:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.29s, LR: 0.00025, Train Loss: 0.3264, Train Acc: 85.6151,
                            Val Loss: 0.4996, Val Acc: 75.9158, Test Acc: 76.5117
2022-10-06 05:22:51,033:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 24/1000
2022-10-06 05:25:25,962:main_SBMs_node_classification.py:244 -   train_val_pipeline(): 	Time: 154.93s, LR: 0.00025, Train Loss: 0.3261, Train Acc: 85.6041,
                            Val Loss: 4.2669, Val Acc: 50.0000, Test Acc: 50.0114
2022-10-06 05:25:25,963:main_SBMs_node_classification.py:202 -   train_val_pipeline(): Epoch 25/1000
