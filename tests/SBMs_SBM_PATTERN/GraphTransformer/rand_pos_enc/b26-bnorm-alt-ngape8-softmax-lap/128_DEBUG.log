2022-09-05 11:12:59,342:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2022-09-05 11:13:17,415:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'L', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-ngape8-softmax-lap/128_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 11:13:17,416:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 11:13:17,421:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 11:13:18,885:pe_layer.py:132 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 11:13:18,885:pe_layer.py:137 -             __init__(): Using matrix: L
2022-09-05 11:13:18,885:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 11:13:18,902:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 11:13:18,905:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 814991
2022-09-05 11:13:18,910:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 11:13:18,920:pe_layer.py:132 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 11:13:18,920:pe_layer.py:137 -             __init__(): Using matrix: L
2022-09-05 11:13:18,920:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 11:13:18,946:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 11:13:18,946:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 11:54:18,053:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:2459.1066489219666
2022-09-05 11:54:18,112:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 11:54:18,112:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-05 11:54:18,112:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 2000
2022-09-05 11:54:18,112:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 11:54:18,117:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 11:56:33,852:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 59.8453 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_128_128_11h13m17s_on_Sep_05_2022/MODELS_
2022-09-05 11:56:33,853:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.74s, LR: 0.00050, Train Loss: 0.6710, Train Acc: 58.1763,
                        Val Loss: 0.6622, Val Acc: 60.0144, Test Acc: 59.8453
2022-09-05 11:56:33,853:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 11:58:48,446:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 63.2804 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_128_128_11h13m17s_on_Sep_05_2022/MODELS_
2022-09-05 11:58:48,447:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 134.59s, LR: 0.00050, Train Loss: 0.5719, Train Acc: 68.3914,
                        Val Loss: 0.8855, Val Acc: 63.0207, Test Acc: 63.2804
2022-09-05 11:58:48,447:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 12:01:03,897:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.45s, LR: 0.00050, Train Loss: 0.3613, Train Acc: 83.9307,
                        Val Loss: 0.7108, Val Acc: 58.2320, Test Acc: 58.0823
2022-09-05 12:01:03,898:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 12:03:20,406:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 136.51s, LR: 0.00050, Train Loss: 0.3419, Train Acc: 84.8931,
                        Val Loss: 0.6641, Val Acc: 61.9097, Test Acc: 61.8135
2022-09-05 12:03:20,406:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 12:05:35,944:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 67.4555 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_128_128_11h13m17s_on_Sep_05_2022/MODELS_
2022-09-05 12:05:35,945:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.54s, LR: 0.00050, Train Loss: 0.3370, Train Acc: 85.1556,
                        Val Loss: 0.7784, Val Acc: 67.5426, Test Acc: 67.4555
2022-09-05 12:05:35,945:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 12:07:52,518:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 83.5950 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_128_128_11h13m17s_on_Sep_05_2022/MODELS_
2022-09-05 12:07:52,519:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 136.57s, LR: 0.00050, Train Loss: 0.3349, Train Acc: 85.2741,
                        Val Loss: 0.3701, Val Acc: 83.3277, Test Acc: 83.5950
2022-09-05 12:07:52,519:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 12:10:08,436:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.92s, LR: 0.00050, Train Loss: 0.3339, Train Acc: 85.3085,
                        Val Loss: 0.4832, Val Acc: 77.3047, Test Acc: 77.3889
2022-09-05 12:10:08,436:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 12:12:25,179:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 136.74s, LR: 0.00050, Train Loss: 0.3328, Train Acc: 85.3553,
                        Val Loss: 0.6628, Val Acc: 62.5569, Test Acc: 62.8104
2022-09-05 12:12:25,180:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 12:14:40,521:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.34s, LR: 0.00050, Train Loss: 0.3319, Train Acc: 85.4053,
                        Val Loss: 0.4717, Val Acc: 77.3250, Test Acc: 77.7381
2022-09-05 12:14:40,522:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 12:16:56,448:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.93s, LR: 0.00050, Train Loss: 0.3311, Train Acc: 85.4123,
                        Val Loss: 0.5774, Val Acc: 68.1502, Test Acc: 68.1327
2022-09-05 12:16:56,448:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 12:19:13,684:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 137.24s, LR: 0.00050, Train Loss: 0.3310, Train Acc: 85.4169,
                        Val Loss: 0.5223, Val Acc: 74.2012, Test Acc: 74.3759
2022-09-05 12:19:13,684:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 12:21:29,331:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.65s, LR: 0.00050, Train Loss: 0.3298, Train Acc: 85.4554,
                        Val Loss: 0.4544, Val Acc: 78.5092, Test Acc: 78.7248
2022-09-05 12:21:29,331:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 12:23:46,723:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 137.39s, LR: 0.00050, Train Loss: 0.3294, Train Acc: 85.5046,
                        Val Loss: 0.5894, Val Acc: 69.9149, Test Acc: 69.9580
2022-09-05 12:23:46,724:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 12:26:02,214:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.49s, LR: 0.00050, Train Loss: 0.3286, Train Acc: 85.5194,
                        Val Loss: 0.4203, Val Acc: 81.8364, Test Acc: 81.8996
2022-09-05 12:26:02,215:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 12:28:18,981:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.1755 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_128_128_11h13m17s_on_Sep_05_2022/MODELS_
2022-09-05 12:28:18,982:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 136.77s, LR: 0.00050, Train Loss: 0.3288, Train Acc: 85.5234,
                        Val Loss: 0.3393, Val Acc: 85.0906, Test Acc: 85.1755
2022-09-05 12:28:18,982:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 12:30:34,507:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.53s, LR: 0.00050, Train Loss: 0.3285, Train Acc: 85.5478,
                        Val Loss: 0.3551, Val Acc: 84.1113, Test Acc: 84.0909
2022-09-05 12:30:34,508:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 12:32:49,870:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.36s, LR: 0.00050, Train Loss: 0.3279, Train Acc: 85.5772,
                        Val Loss: 0.4423, Val Acc: 78.7285, Test Acc: 78.7424
2022-09-05 12:32:49,870:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 12:35:07,567:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 137.70s, LR: 0.00050, Train Loss: 0.3274, Train Acc: 85.6034,
                        Val Loss: 0.6090, Val Acc: 67.3327, Test Acc: 67.3109
2022-09-05 12:35:07,568:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 12:37:23,444:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.88s, LR: 0.00050, Train Loss: 0.3269, Train Acc: 85.6443,
                        Val Loss: 0.4030, Val Acc: 81.3754, Test Acc: 81.4525
2022-09-05 12:37:23,444:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 12:39:38,635:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 135.19s, LR: 0.00050, Train Loss: 0.3261, Train Acc: 85.6415,
                        Val Loss: 0.3556, Val Acc: 84.1710, Test Acc: 84.3101
2022-09-05 12:39:38,635:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 12:41:56,369:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 137.73s, LR: 0.00050, Train Loss: 0.3255, Train Acc: 85.6808,
                        Val Loss: 0.5382, Val Acc: 74.0946, Test Acc: 74.2804
2022-09-05 12:41:56,369:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
