2022-09-05 21:13:14,154:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA TITAN X (Pascal)
2022-09-05 21:13:31,175:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'L', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': False, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-ngape4-softmax-lap/16_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-05 21:13:31,175:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-05 21:13:31,178:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 21:13:32,618:pe_layer.py:132 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 21:13:32,618:pe_layer.py:137 -             __init__(): Using matrix: L
2022-09-05 21:13:32,618:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 21:13:32,632:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 21:13:32,635:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 529643
2022-09-05 21:13:32,638:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 21:13:32,639:pe_layer.py:132 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 21:13:32,640:pe_layer.py:137 -             __init__(): Using matrix: L
2022-09-05 21:13:32,640:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 21:13:32,661:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 21:13:32,661:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 21:21:47,424:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:494.7624897956848
2022-09-05 21:21:47,426:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 21:21:47,426:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-05 21:21:47,426:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 2000
2022-09-05 21:21:47,426:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 21:21:47,430:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 21:23:49,678:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 81.9051 to out/SBMs_node_classification_b26-bnorm-alt-ngape4-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_21h13m31s_on_Sep_05_2022/MODELS_
2022-09-05 21:23:49,679:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 122.25s, LR: 0.00050, Train Loss: 0.4455, Train Acc: 78.1167,
                        Val Loss: 0.3953, Val Acc: 81.9120, Test Acc: 81.9051
2022-09-05 21:23:49,679:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 21:25:59,808:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.13s, LR: 0.00050, Train Loss: 0.3633, Train Acc: 83.8150,
                        Val Loss: 0.6058, Val Acc: 71.9085, Test Acc: 72.0388
2022-09-05 21:25:59,808:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 21:28:09,831:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.02s, LR: 0.00050, Train Loss: 0.3466, Train Acc: 84.7228,
                        Val Loss: 0.4394, Val Acc: 79.3820, Test Acc: 79.5081
2022-09-05 21:28:09,831:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 21:30:20,407:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.58s, LR: 0.00050, Train Loss: 0.3413, Train Acc: 84.9150,
                        Val Loss: 0.4140, Val Acc: 81.3013, Test Acc: 81.3701
2022-09-05 21:30:20,407:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 21:32:31,526:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 131.12s, LR: 0.00050, Train Loss: 0.3383, Train Acc: 85.0759,
                        Val Loss: 0.5198, Val Acc: 76.0843, Test Acc: 76.2011
2022-09-05 21:32:31,527:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 21:34:42,242:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 84.5545 to out/SBMs_node_classification_b26-bnorm-alt-ngape4-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_21h13m31s_on_Sep_05_2022/MODELS_
2022-09-05 21:34:42,242:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.72s, LR: 0.00050, Train Loss: 0.3367, Train Acc: 85.1464,
                        Val Loss: 0.3506, Val Acc: 84.4819, Test Acc: 84.5545
2022-09-05 21:34:42,242:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 21:36:53,331:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 131.09s, LR: 0.00050, Train Loss: 0.3353, Train Acc: 85.2286,
                        Val Loss: 0.3532, Val Acc: 84.3773, Test Acc: 84.4963
2022-09-05 21:36:53,331:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 21:39:03,281:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 129.95s, LR: 0.00050, Train Loss: 0.3340, Train Acc: 85.2686,
                        Val Loss: 0.3703, Val Acc: 83.8529, Test Acc: 84.0829
2022-09-05 21:39:03,281:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 21:41:12,004:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 128.72s, LR: 0.00050, Train Loss: 0.3335, Train Acc: 85.3103,
                        Val Loss: 0.3803, Val Acc: 83.1298, Test Acc: 83.1347
2022-09-05 21:41:12,005:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 21:43:22,899:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.89s, LR: 0.00050, Train Loss: 0.3329, Train Acc: 85.3160,
                        Val Loss: 0.4023, Val Acc: 81.4009, Test Acc: 81.6698
2022-09-05 21:43:22,900:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 21:45:33,522:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 84.9226 to out/SBMs_node_classification_b26-bnorm-alt-ngape4-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_21h13m31s_on_Sep_05_2022/MODELS_
2022-09-05 21:45:33,522:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.62s, LR: 0.00050, Train Loss: 0.3324, Train Acc: 85.3497,
                        Val Loss: 0.3442, Val Acc: 84.7445, Test Acc: 84.9226
2022-09-05 21:45:33,522:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 21:47:43,224:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 129.70s, LR: 0.00050, Train Loss: 0.3313, Train Acc: 85.4180,
                        Val Loss: 0.3701, Val Acc: 83.4456, Test Acc: 83.4308
2022-09-05 21:47:43,224:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 21:49:53,804:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.58s, LR: 0.00050, Train Loss: 0.3310, Train Acc: 85.4385,
                        Val Loss: 0.3849, Val Acc: 82.8687, Test Acc: 82.9660
2022-09-05 21:49:53,804:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 21:52:03,176:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 129.37s, LR: 0.00050, Train Loss: 0.3300, Train Acc: 85.4738,
                        Val Loss: 0.3577, Val Acc: 84.1085, Test Acc: 84.3443
2022-09-05 21:52:03,177:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 21:54:13,796:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.62s, LR: 0.00050, Train Loss: 0.3301, Train Acc: 85.4889,
                        Val Loss: 0.3630, Val Acc: 83.8483, Test Acc: 83.8817
2022-09-05 21:54:13,796:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 21:56:24,423:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.63s, LR: 0.00050, Train Loss: 0.3296, Train Acc: 85.4954,
                        Val Loss: 0.3559, Val Acc: 83.9948, Test Acc: 84.0755
2022-09-05 21:56:24,423:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 21:58:35,586:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 84.9982 to out/SBMs_node_classification_b26-bnorm-alt-ngape4-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_21h13m31s_on_Sep_05_2022/MODELS_
2022-09-05 21:58:35,586:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 131.16s, LR: 0.00050, Train Loss: 0.3290, Train Acc: 85.5377,
                        Val Loss: 0.3396, Val Acc: 85.0258, Test Acc: 84.9982
2022-09-05 21:58:35,586:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 22:00:46,290:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.3721 to out/SBMs_node_classification_b26-bnorm-alt-ngape4-softmax-lapcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_21h13m31s_on_Sep_05_2022/MODELS_
2022-09-05 22:00:46,290:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.70s, LR: 0.00050, Train Loss: 0.3287, Train Acc: 85.5324,
                        Val Loss: 0.3373, Val Acc: 85.1661, Test Acc: 85.3721
2022-09-05 22:00:46,291:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 22:02:56,887:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.60s, LR: 0.00050, Train Loss: 0.3282, Train Acc: 85.5794,
                        Val Loss: 0.3494, Val Acc: 84.5666, Test Acc: 84.7042
2022-09-05 22:02:56,887:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 22:05:09,159:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 132.27s, LR: 0.00050, Train Loss: 0.3278, Train Acc: 85.5694,
                        Val Loss: 0.3990, Val Acc: 81.9237, Test Acc: 82.0483
2022-09-05 22:05:09,159:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 22:07:20,087:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.93s, LR: 0.00050, Train Loss: 0.3271, Train Acc: 85.6192,
                        Val Loss: 0.3623, Val Acc: 83.7701, Test Acc: 83.9422
2022-09-05 22:07:20,088:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 22:09:33,000:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 132.91s, LR: 0.00050, Train Loss: 0.3269, Train Acc: 85.6183,
                        Val Loss: 0.3967, Val Acc: 82.5233, Test Acc: 82.3730
2022-09-05 22:09:33,000:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 22:11:45,630:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 132.63s, LR: 0.00050, Train Loss: 0.3268, Train Acc: 85.6433,
                        Val Loss: 0.3527, Val Acc: 84.4117, Test Acc: 84.5619
2022-09-05 22:11:45,631:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 22:13:56,335:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 130.70s, LR: 0.00050, Train Loss: 0.3258, Train Acc: 85.6766,
                        Val Loss: 0.3434, Val Acc: 84.9248, Test Acc: 85.0362
2022-09-05 22:13:56,335:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 22:16:18,456:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 142.12s, LR: 0.00050, Train Loss: 0.3255, Train Acc: 85.6893,
                        Val Loss: 0.3379, Val Acc: 85.1421, Test Acc: 85.2664
2022-09-05 22:16:18,457:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 22:18:47,290:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 148.83s, LR: 0.00050, Train Loss: 0.3250, Train Acc: 85.7117,
                        Val Loss: 0.3696, Val Acc: 83.5332, Test Acc: 83.5995
2022-09-05 22:18:47,290:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
