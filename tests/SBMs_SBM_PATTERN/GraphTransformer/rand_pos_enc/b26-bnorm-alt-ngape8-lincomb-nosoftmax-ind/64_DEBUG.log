2022-09-05 17:52:01,453:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2022-09-05 17:52:19,926:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-ngape8-lincomb-nosoftmax-ind/64_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 17:52:19,927:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 17:52:19,932:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 17:52:21,167:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:52:21,167:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 17:52:21,167:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 17:52:21,182:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:52:21,186:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536933
2022-09-05 17:52:21,190:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 17:52:21,195:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:52:21,195:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 17:52:21,195:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 17:52:21,221:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 17:52:21,221:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 18:07:16,875:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:895.6533942222595
2022-09-05 18:07:16,903:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 18:07:16,903:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-05 18:07:16,903:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 2000
2022-09-05 18:07:16,903:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 18:07:16,908:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 18:09:21,970:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.1471 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_17h52m19s_on_Sep_05_2022/MODELS_
2022-09-05 18:09:21,970:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 125.06s, LR: 0.00050, Train Loss: 0.3745, Train Acc: 82.6226,
                        Val Loss: 0.3397, Val Acc: 84.9464, Test Acc: 85.1471
2022-09-05 18:09:21,970:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 18:11:24,199:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 122.23s, LR: 0.00050, Train Loss: 0.3374, Train Acc: 85.0601,
                        Val Loss: 0.3430, Val Acc: 84.7771, Test Acc: 85.0592
2022-09-05 18:11:24,199:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 18:13:26,176:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.2064 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_17h52m19s_on_Sep_05_2022/MODELS_
2022-09-05 18:13:26,176:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.98s, LR: 0.00050, Train Loss: 0.3356, Train Acc: 85.1873,
                        Val Loss: 0.3386, Val Acc: 84.9726, Test Acc: 85.2064
2022-09-05 18:13:26,176:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 18:15:27,099:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.5051 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_17h52m19s_on_Sep_05_2022/MODELS_
2022-09-05 18:15:27,099:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.92s, LR: 0.00050, Train Loss: 0.3332, Train Acc: 85.2777,
                        Val Loss: 0.3329, Val Acc: 85.3050, Test Acc: 85.5051
2022-09-05 18:15:27,099:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 18:17:28,529:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.43s, LR: 0.00050, Train Loss: 0.3324, Train Acc: 85.3089,
                        Val Loss: 0.3342, Val Acc: 85.1728, Test Acc: 85.4445
2022-09-05 18:17:28,529:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 18:19:28,776:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.5329 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_17h52m19s_on_Sep_05_2022/MODELS_
2022-09-05 18:19:28,777:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.25s, LR: 0.00050, Train Loss: 0.3321, Train Acc: 85.3288,
                        Val Loss: 0.3304, Val Acc: 85.4384, Test Acc: 85.5329
2022-09-05 18:19:28,777:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 18:21:29,219:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.6002 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_17h52m19s_on_Sep_05_2022/MODELS_
2022-09-05 18:21:29,219:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.44s, LR: 0.00050, Train Loss: 0.3317, Train Acc: 85.3461,
                        Val Loss: 0.3326, Val Acc: 85.3849, Test Acc: 85.6002
2022-09-05 18:21:29,220:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 18:23:29,287:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.07s, LR: 0.00050, Train Loss: 0.3311, Train Acc: 85.3705,
                        Val Loss: 0.3309, Val Acc: 85.4268, Test Acc: 85.5509
2022-09-05 18:23:29,288:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 18:25:30,172:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.88s, LR: 0.00050, Train Loss: 0.3303, Train Acc: 85.4099,
                        Val Loss: 0.3407, Val Acc: 85.0135, Test Acc: 85.1462
2022-09-05 18:25:30,172:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 18:27:30,832:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.66s, LR: 0.00050, Train Loss: 0.3298, Train Acc: 85.4767,
                        Val Loss: 0.3408, Val Acc: 84.9083, Test Acc: 85.0880
2022-09-05 18:27:30,833:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 18:29:32,520:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.69s, LR: 0.00050, Train Loss: 0.3300, Train Acc: 85.4525,
                        Val Loss: 0.3325, Val Acc: 85.3564, Test Acc: 85.5605
2022-09-05 18:29:32,521:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 18:31:34,077:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.56s, LR: 0.00050, Train Loss: 0.3293, Train Acc: 85.4595,
                        Val Loss: 0.3351, Val Acc: 85.3248, Test Acc: 85.4765
2022-09-05 18:31:34,077:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 18:33:36,228:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 122.15s, LR: 0.00050, Train Loss: 0.3287, Train Acc: 85.4900,
                        Val Loss: 0.3327, Val Acc: 85.3064, Test Acc: 85.3580
2022-09-05 18:33:36,228:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 18:35:37,157:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.6799 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_17h52m19s_on_Sep_05_2022/MODELS_
2022-09-05 18:35:37,157:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.93s, LR: 0.00050, Train Loss: 0.3282, Train Acc: 85.5318,
                        Val Loss: 0.3295, Val Acc: 85.4962, Test Acc: 85.6799
2022-09-05 18:35:37,157:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 18:37:39,024:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.87s, LR: 0.00050, Train Loss: 0.3276, Train Acc: 85.5546,
                        Val Loss: 0.3325, Val Acc: 85.3479, Test Acc: 85.5987
2022-09-05 18:37:39,025:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 18:39:40,171:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.15s, LR: 0.00050, Train Loss: 0.3278, Train Acc: 85.5267,
                        Val Loss: 0.3311, Val Acc: 85.3666, Test Acc: 85.5684
2022-09-05 18:39:40,172:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 18:41:41,841:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.67s, LR: 0.00050, Train Loss: 0.3272, Train Acc: 85.5738,
                        Val Loss: 0.3305, Val Acc: 85.4256, Test Acc: 85.5597
2022-09-05 18:41:41,842:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 18:43:42,594:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.75s, LR: 0.00050, Train Loss: 0.3263, Train Acc: 85.6050,
                        Val Loss: 0.3397, Val Acc: 84.8583, Test Acc: 85.0798
2022-09-05 18:43:42,595:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 18:45:44,575:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.98s, LR: 0.00050, Train Loss: 0.3258, Train Acc: 85.6330,
                        Val Loss: 0.3343, Val Acc: 85.3317, Test Acc: 85.4987
2022-09-05 18:45:44,576:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 18:47:45,724:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 121.15s, LR: 0.00050, Train Loss: 0.3254, Train Acc: 85.6748,
                        Val Loss: 0.3311, Val Acc: 85.3594, Test Acc: 85.5695
2022-09-05 18:47:45,725:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 18:49:46,016:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 120.29s, LR: 0.00050, Train Loss: 0.3250, Train Acc: 85.6824,
                        Val Loss: 0.3363, Val Acc: 85.1692, Test Acc: 85.3572
2022-09-05 18:49:46,016:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 18:51:45,794:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 119.78s, LR: 0.00050, Train Loss: 0.3246, Train Acc: 85.6830,
                        Val Loss: 0.3312, Val Acc: 85.4514, Test Acc: 85.6224
2022-09-05 18:51:45,795:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 18:53:45,187:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 119.39s, LR: 0.00050, Train Loss: 0.3242, Train Acc: 85.7462,
                        Val Loss: 0.3346, Val Acc: 85.2768, Test Acc: 85.4882
2022-09-05 18:53:45,188:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 18:55:44,272:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 119.08s, LR: 0.00050, Train Loss: 0.3234, Train Acc: 85.7446,
                        Val Loss: 0.3319, Val Acc: 85.3838, Test Acc: 85.6445
2022-09-05 18:55:44,273:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 18:57:43,598:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 119.32s, LR: 0.00050, Train Loss: 0.3224, Train Acc: 85.8587,
                        Val Loss: 0.3363, Val Acc: 85.1268, Test Acc: 85.3136
2022-09-05 18:57:43,598:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 18:59:43,219:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 119.62s, LR: 0.00025, Train Loss: 0.3178, Train Acc: 86.0099,
                        Val Loss: 0.3327, Val Acc: 85.3706, Test Acc: 85.6118
2022-09-05 18:59:43,219:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 19:01:41,951:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 118.73s, LR: 0.00025, Train Loss: 0.3158, Train Acc: 86.1493,
                        Val Loss: 0.3361, Val Acc: 85.2432, Test Acc: 85.5406
2022-09-05 19:01:41,952:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
