2022-09-05 17:14:40,367:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX 1080 Ti
2022-09-05 17:14:58,162:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-ngape8-lincomb-nosoftmax-ind/32_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 32, 'in_dim': 3, 'n_classes': 2}
2022-09-05 17:14:58,162:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-09-05 17:14:58,167:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 17:14:59,740:pe_layer.py:132 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:14:59,740:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 17:14:59,740:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 17:14:59,755:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:14:59,758:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 565247
2022-09-05 17:14:59,762:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 17:14:59,765:pe_layer.py:132 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:14:59,765:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 17:14:59,766:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 17:14:59,789:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 17:14:59,789:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 17:27:18,269:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:738.4791707992554
2022-09-05 17:27:18,272:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 17:27:18,272:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-05 17:27:18,272:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 2000
2022-09-05 17:27:18,272:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:27:18,277:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:30:05,769:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 84.5827 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 17:30:05,770:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 167.49s, LR: 0.00050, Train Loss: 0.4213, Train Acc: 79.6554,
                        Val Loss: 0.3524, Val Acc: 84.3910, Test Acc: 84.5827
2022-09-05 17:30:05,770:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:32:56,185:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 170.42s, LR: 0.00050, Train Loss: 0.3499, Train Acc: 84.4110,
                        Val Loss: 0.3539, Val Acc: 84.2189, Test Acc: 84.5219
2022-09-05 17:32:56,186:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:35:47,625:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.44s, LR: 0.00050, Train Loss: 0.3454, Train Acc: 84.6398,
                        Val Loss: 2.0643, Val Acc: 50.1554, Test Acc: 50.1431
2022-09-05 17:35:47,625:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:38:39,640:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 84.9713 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 17:38:39,641:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 172.02s, LR: 0.00050, Train Loss: 0.3413, Train Acc: 84.8503,
                        Val Loss: 0.3471, Val Acc: 84.7324, Test Acc: 84.9713
2022-09-05 17:38:39,641:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:41:31,452:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.81s, LR: 0.00050, Train Loss: 0.3388, Train Acc: 84.9845,
                        Val Loss: 0.3788, Val Acc: 83.2661, Test Acc: 83.4574
2022-09-05 17:41:31,452:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:44:23,292:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.84s, LR: 0.00050, Train Loss: 0.3381, Train Acc: 85.0145,
                        Val Loss: 0.6699, Val Acc: 67.3456, Test Acc: 67.6051
2022-09-05 17:44:23,292:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 17:47:14,729:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.44s, LR: 0.00050, Train Loss: 0.3361, Train Acc: 85.1205,
                        Val Loss: 0.3544, Val Acc: 84.2834, Test Acc: 84.4336
2022-09-05 17:47:14,730:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 17:50:04,761:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 170.03s, LR: 0.00050, Train Loss: 0.3352, Train Acc: 85.1415,
                        Val Loss: 0.9155, Val Acc: 55.1145, Test Acc: 55.1278
2022-09-05 17:50:04,762:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 17:53:04,646:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 179.88s, LR: 0.00050, Train Loss: 0.3354, Train Acc: 85.1692,
                        Val Loss: 0.6495, Val Acc: 72.4734, Test Acc: 72.7301
2022-09-05 17:53:04,647:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 17:56:00,379:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 175.73s, LR: 0.00050, Train Loss: 0.3345, Train Acc: 85.1967,
                        Val Loss: 0.5946, Val Acc: 71.8609, Test Acc: 72.2004
2022-09-05 17:56:00,379:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 17:58:56,810:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 176.43s, LR: 0.00050, Train Loss: 0.3328, Train Acc: 85.2862,
                        Val Loss: 0.3484, Val Acc: 84.5975, Test Acc: 84.7918
2022-09-05 17:58:56,811:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 18:01:46,418:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.0667 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 18:01:46,419:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 169.61s, LR: 0.00050, Train Loss: 0.3323, Train Acc: 85.3240,
                        Val Loss: 0.3461, Val Acc: 84.9232, Test Acc: 85.0667
2022-09-05 18:01:46,419:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 18:04:38,106:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.69s, LR: 0.00050, Train Loss: 0.3319, Train Acc: 85.3260,
                        Val Loss: 1.7856, Val Acc: 50.0467, Test Acc: 50.0531
2022-09-05 18:04:38,107:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 18:07:30,638:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.3731 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 18:07:30,639:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 172.53s, LR: 0.00050, Train Loss: 0.3317, Train Acc: 85.3332,
                        Val Loss: 0.3427, Val Acc: 85.0997, Test Acc: 85.3731
2022-09-05 18:07:30,639:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 18:10:22,173:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.53s, LR: 0.00050, Train Loss: 0.3317, Train Acc: 85.3419,
                        Val Loss: 0.5815, Val Acc: 71.8177, Test Acc: 72.0696
2022-09-05 18:10:22,174:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 18:13:15,381:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 173.21s, LR: 0.00050, Train Loss: 0.3314, Train Acc: 85.3482,
                        Val Loss: 0.3403, Val Acc: 85.0807, Test Acc: 85.2116
2022-09-05 18:13:15,382:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 18:16:07,558:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 172.18s, LR: 0.00050, Train Loss: 0.3314, Train Acc: 85.3695,
                        Val Loss: 0.7250, Val Acc: 64.1492, Test Acc: 64.4835
2022-09-05 18:16:07,558:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 18:19:03,130:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 175.57s, LR: 0.00050, Train Loss: 0.3309, Train Acc: 85.3888,
                        Val Loss: 0.3402, Val Acc: 85.0555, Test Acc: 85.1556
2022-09-05 18:19:03,131:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 18:21:54,253:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.3742 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 18:21:54,254:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.12s, LR: 0.00050, Train Loss: 0.3304, Train Acc: 85.4007,
                        Val Loss: 0.3412, Val Acc: 85.0830, Test Acc: 85.3742
2022-09-05 18:21:54,254:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 18:24:44,585:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 170.33s, LR: 0.00050, Train Loss: 0.3297, Train Acc: 85.4479,
                        Val Loss: 0.9287, Val Acc: 59.0523, Test Acc: 59.2651
2022-09-05 18:24:44,585:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 18:27:37,890:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 173.30s, LR: 0.00050, Train Loss: 0.3313, Train Acc: 85.3451,
                        Val Loss: 0.3366, Val Acc: 85.2289, Test Acc: 85.3469
2022-09-05 18:27:37,891:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 18:30:29,692:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.80s, LR: 0.00050, Train Loss: 0.3298, Train Acc: 85.4230,
                        Val Loss: 0.3783, Val Acc: 83.1998, Test Acc: 83.4356
2022-09-05 18:30:29,692:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 18:33:21,737:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 172.04s, LR: 0.00050, Train Loss: 0.3297, Train Acc: 85.4541,
                        Val Loss: 0.3406, Val Acc: 85.1140, Test Acc: 85.2153
2022-09-05 18:33:21,738:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 18:36:12,969:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.4961 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 18:36:12,970:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.23s, LR: 0.00050, Train Loss: 0.3287, Train Acc: 85.4832,
                        Val Loss: 0.3335, Val Acc: 85.3418, Test Acc: 85.4961
2022-09-05 18:36:12,970:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 18:39:01,131:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 168.16s, LR: 0.00050, Train Loss: 0.3284, Train Acc: 85.4824,
                        Val Loss: 0.3624, Val Acc: 83.9671, Test Acc: 84.1817
2022-09-05 18:39:01,132:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 18:41:50,956:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.4964 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 18:41:50,956:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 169.82s, LR: 0.00050, Train Loss: 0.3282, Train Acc: 85.5132,
                        Val Loss: 0.3335, Val Acc: 85.2866, Test Acc: 85.4964
2022-09-05 18:41:50,956:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 18:44:44,081:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 173.12s, LR: 0.00050, Train Loss: 0.3277, Train Acc: 85.5274,
                        Val Loss: 0.3557, Val Acc: 84.6934, Test Acc: 84.7178
2022-09-05 18:44:44,081:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 18:47:36,298:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.5452 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_17h14m58s_on_Sep_05_2022/MODELS_
2022-09-05 18:47:36,298:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 172.22s, LR: 0.00050, Train Loss: 0.3277, Train Acc: 85.5242,
                        Val Loss: 0.3316, Val Acc: 85.4188, Test Acc: 85.5452
2022-09-05 18:47:36,298:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 18:50:27,969:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.67s, LR: 0.00050, Train Loss: 0.3278, Train Acc: 85.5299,
                        Val Loss: 0.9738, Val Acc: 58.1249, Test Acc: 58.2533
2022-09-05 18:50:27,970:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 18:53:17,956:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 169.99s, LR: 0.00050, Train Loss: 0.3274, Train Acc: 85.5389,
                        Val Loss: 1.3382, Val Acc: 50.3682, Test Acc: 50.3310
2022-09-05 18:53:17,956:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 18:56:10,353:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 172.40s, LR: 0.00050, Train Loss: 0.3272, Train Acc: 85.5385,
                        Val Loss: 0.3381, Val Acc: 85.1206, Test Acc: 85.4265
2022-09-05 18:56:10,353:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 18:59:01,937:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 171.58s, LR: 0.00050, Train Loss: 0.3266, Train Acc: 85.6343,
                        Val Loss: 0.3445, Val Acc: 84.8382, Test Acc: 85.0969
2022-09-05 18:59:01,937:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 19:01:55,935:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 174.00s, LR: 0.00050, Train Loss: 0.3264, Train Acc: 85.6078,
                        Val Loss: 0.3406, Val Acc: 84.9548, Test Acc: 84.9719
2022-09-05 19:01:55,935:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 34/1000
