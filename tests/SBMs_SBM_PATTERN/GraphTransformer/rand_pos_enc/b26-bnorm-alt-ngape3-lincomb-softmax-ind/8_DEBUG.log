2022-09-05 16:11:32,795:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2022-09-05 16:11:49,606:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-ngape3-lincomb-softmax-ind/8_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:11:49,606:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 16:11:49,623:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 16:11:50,848:pe_layer.py:132 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:11:50,848:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 16:11:50,848:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 16:11:50,862:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:11:50,864:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526866
2022-09-05 16:11:50,867:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 16:11:50,868:pe_layer.py:132 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:11:50,868:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 16:11:50,868:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 16:11:50,890:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 16:11:50,890:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 16:15:44,870:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:233.97961974143982
2022-09-05 16:15:44,884:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 16:15:44,884:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-05 16:15:44,884:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 2000
2022-09-05 16:15:44,884:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:15:44,892:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:18:17,418:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 60.7889 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:18:17,419:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.53s, LR: 0.00050, Train Loss: 0.6696, Train Acc: 58.1812,
                        Val Loss: 0.6579, Val Acc: 60.8350, Test Acc: 60.7889
2022-09-05 16:18:17,419:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:20:49,155:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 62.5345 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:20:49,155:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 151.74s, LR: 0.00050, Train Loss: 0.6443, Train Acc: 62.5964,
                        Val Loss: 0.6449, Val Acc: 62.8244, Test Acc: 62.5345
2022-09-05 16:20:49,155:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:23:21,023:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 63.9978 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:23:21,023:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 151.87s, LR: 0.00050, Train Loss: 0.6341, Train Acc: 63.9015,
                        Val Loss: 0.6318, Val Acc: 64.1201, Test Acc: 63.9978
2022-09-05 16:23:21,023:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:25:52,975:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 64.8848 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:25:52,976:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 151.95s, LR: 0.00050, Train Loss: 0.6250, Train Acc: 64.8568,
                        Val Loss: 0.6230, Val Acc: 65.0505, Test Acc: 64.8848
2022-09-05 16:25:52,976:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:28:25,124:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 65.1696 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:28:25,125:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.15s, LR: 0.00050, Train Loss: 0.6144, Train Acc: 66.0884,
                        Val Loss: 0.6232, Val Acc: 65.3971, Test Acc: 65.1696
2022-09-05 16:28:25,125:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:30:57,327:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 66.5914 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:30:57,327:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.20s, LR: 0.00050, Train Loss: 0.6064, Train Acc: 66.9270,
                        Val Loss: 0.6086, Val Acc: 66.6586, Test Acc: 66.5914
2022-09-05 16:30:57,327:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:33:29,719:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 68.4843 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:33:29,720:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.39s, LR: 0.00050, Train Loss: 0.5918, Train Acc: 68.2272,
                        Val Loss: 0.5882, Val Acc: 68.6177, Test Acc: 68.4843
2022-09-05 16:33:29,720:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:37:15,528:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 69.4856 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:37:15,528:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 225.81s, LR: 0.00050, Train Loss: 0.5727, Train Acc: 69.8643,
                        Val Loss: 0.5741, Val Acc: 69.5254, Test Acc: 69.4856
2022-09-05 16:37:15,528:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:39:53,611:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 70.4824 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:39:53,611:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.08s, LR: 0.00050, Train Loss: 0.5283, Train Acc: 72.7120,
                        Val Loss: 0.5507, Val Acc: 70.6817, Test Acc: 70.4824
2022-09-05 16:39:53,611:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:42:33,303:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 75.7472 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:42:33,303:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.69s, LR: 0.00050, Train Loss: 0.4921, Train Acc: 74.9891,
                        Val Loss: 0.4802, Val Acc: 75.6737, Test Acc: 75.7472
2022-09-05 16:42:33,303:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 16:45:12,395:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 76.3359 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:45:12,396:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.09s, LR: 0.00050, Train Loss: 0.4763, Train Acc: 76.0450,
                        Val Loss: 0.4741, Val Acc: 76.1114, Test Acc: 76.3359
2022-09-05 16:45:12,396:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 16:47:46,336:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 76.9514 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:47:46,337:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 153.94s, LR: 0.00050, Train Loss: 0.4555, Train Acc: 77.6473,
                        Val Loss: 0.4693, Val Acc: 76.9004, Test Acc: 76.9514
2022-09-05 16:47:46,337:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 16:50:21,354:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 155.02s, LR: 0.00050, Train Loss: 0.4423, Train Acc: 78.5921,
                        Val Loss: 0.5540, Val Acc: 68.4213, Test Acc: 68.8181
2022-09-05 16:50:21,355:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 16:52:59,242:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 78.6080 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:52:59,243:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 157.89s, LR: 0.00050, Train Loss: 0.4358, Train Acc: 79.1487,
                        Val Loss: 0.4477, Val Acc: 78.5903, Test Acc: 78.6080
2022-09-05 16:52:59,243:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 16:55:31,968:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.73s, LR: 0.00050, Train Loss: 0.4271, Train Acc: 79.7133,
                        Val Loss: 0.5089, Val Acc: 73.0820, Test Acc: 72.5084
2022-09-05 16:55:31,969:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 16:58:04,719:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 80.0958 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 16:58:04,719:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.75s, LR: 0.00050, Train Loss: 0.4249, Train Acc: 79.8424,
                        Val Loss: 0.4239, Val Acc: 79.8748, Test Acc: 80.0958
2022-09-05 16:58:04,719:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 17:00:36,940:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 80.4696 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 17:00:36,940:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.22s, LR: 0.00050, Train Loss: 0.4136, Train Acc: 80.6428,
                        Val Loss: 0.4180, Val Acc: 80.4316, Test Acc: 80.4696
2022-09-05 17:00:36,941:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 17:03:08,780:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 151.84s, LR: 0.00050, Train Loss: 0.4232, Train Acc: 80.0107,
                        Val Loss: 0.5946, Val Acc: 68.5681, Test Acc: 68.8239
2022-09-05 17:03:08,781:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 17:05:41,353:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.57s, LR: 0.00050, Train Loss: 0.4380, Train Acc: 79.0954,
                        Val Loss: 0.4605, Val Acc: 77.5295, Test Acc: 77.3276
2022-09-05 17:05:41,353:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 17:08:19,725:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.37s, LR: 0.00050, Train Loss: 0.4425, Train Acc: 78.7319,
                        Val Loss: 0.6143, Val Acc: 65.5483, Test Acc: 65.5265
2022-09-05 17:08:19,726:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 17:11:31,611:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 191.89s, LR: 0.00050, Train Loss: 0.4380, Train Acc: 79.0818,
                        Val Loss: 0.4951, Val Acc: 75.9188, Test Acc: 75.7642
2022-09-05 17:11:31,611:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 17:15:37,401:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 245.79s, LR: 0.00050, Train Loss: 0.4139, Train Acc: 80.6758,
                        Val Loss: 0.5644, Val Acc: 70.1471, Test Acc: 69.9259
2022-09-05 17:15:37,402:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 17:18:16,010:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 80.9263 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 17:18:16,011:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.61s, LR: 0.00050, Train Loss: 0.4115, Train Acc: 80.8636,
                        Val Loss: 0.4083, Val Acc: 81.0039, Test Acc: 80.9263
2022-09-05 17:18:16,011:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 17:20:49,783:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 81.4635 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 17:20:49,784:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 153.77s, LR: 0.00050, Train Loss: 0.4084, Train Acc: 81.0090,
                        Val Loss: 0.4042, Val Acc: 81.3586, Test Acc: 81.4635
2022-09-05 17:20:49,784:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 17:23:23,522:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 153.74s, LR: 0.00050, Train Loss: 0.4056, Train Acc: 81.2132,
                        Val Loss: 0.4023, Val Acc: 81.3079, Test Acc: 81.3482
2022-09-05 17:23:23,523:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 17:26:07,898:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 81.6183 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_16h11m49s_on_Sep_05_2022/MODELS_
2022-09-05 17:26:07,898:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 164.38s, LR: 0.00050, Train Loss: 0.4016, Train Acc: 81.4563,
                        Val Loss: 0.3997, Val Acc: 81.4705, Test Acc: 81.6183
2022-09-05 17:26:07,898:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 17:28:42,193:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 154.29s, LR: 0.00050, Train Loss: 0.3943, Train Acc: 81.8730,
                        Val Loss: 0.4271, Val Acc: 79.8964, Test Acc: 79.9745
2022-09-05 17:28:42,193:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 17:31:16,833:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 154.64s, LR: 0.00050, Train Loss: 0.4119, Train Acc: 80.7767,
                        Val Loss: 0.4133, Val Acc: 80.7064, Test Acc: 80.8596
2022-09-05 17:31:16,833:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 17:33:49,112:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.28s, LR: 0.00050, Train Loss: 0.4139, Train Acc: 80.5776,
                        Val Loss: 0.4201, Val Acc: 80.1937, Test Acc: 80.3947
2022-09-05 17:33:49,112:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 17:36:21,168:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.06s, LR: 0.00050, Train Loss: 0.4087, Train Acc: 80.9332,
                        Val Loss: 0.4220, Val Acc: 80.2024, Test Acc: 80.1141
2022-09-05 17:36:21,169:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 17:38:53,379:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.21s, LR: 0.00050, Train Loss: 0.4199, Train Acc: 80.2168,
                        Val Loss: 0.4301, Val Acc: 79.6466, Test Acc: 79.8235
2022-09-05 17:38:53,380:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 17:41:25,334:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 151.95s, LR: 0.00050, Train Loss: 0.4258, Train Acc: 79.8582,
                        Val Loss: 0.4174, Val Acc: 80.5377, Test Acc: 80.4009
2022-09-05 17:41:25,334:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 17:43:58,013:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.68s, LR: 0.00050, Train Loss: 0.4154, Train Acc: 80.5476,
                        Val Loss: 0.4053, Val Acc: 81.2590, Test Acc: 81.1086
2022-09-05 17:43:58,014:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 17:46:29,820:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 151.81s, LR: 0.00050, Train Loss: 0.4049, Train Acc: 81.2429,
                        Val Loss: 0.4040, Val Acc: 81.3244, Test Acc: 81.3942
2022-09-05 17:46:29,820:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 17:49:02,359:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.54s, LR: 0.00050, Train Loss: 0.4060, Train Acc: 81.1144,
                        Val Loss: 0.4497, Val Acc: 78.1851, Test Acc: 77.9788
2022-09-05 17:49:02,359:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 17:51:34,493:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 152.13s, LR: 0.00050, Train Loss: 0.4139, Train Acc: 80.5341,
                        Val Loss: 0.4300, Val Acc: 79.5694, Test Acc: 79.5088
2022-09-05 17:51:34,493:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 37/1000
