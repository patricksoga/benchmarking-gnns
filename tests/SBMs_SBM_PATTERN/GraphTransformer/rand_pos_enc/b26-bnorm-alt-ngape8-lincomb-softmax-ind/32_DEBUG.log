2022-09-05 08:17:32,117:main_utils.py:39 -            gpu_setup(): cuda available with GPU: NVIDIA GeForce GTX TITAN X
2022-09-05 08:17:49,506:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/rand_pos_enc/b26-bnorm-alt-ngape8-lincomb-softmax-ind/32_DEBUG.log', 'device': device(type='cuda'), 'pos_enc_dim': 32, 'in_dim': 3, 'n_classes': 2}
2022-09-05 08:17:49,506:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-09-05 08:17:49,511:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 08:17:50,644:pe_layer.py:132 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 08:17:50,644:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 08:17:50,644:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 08:17:50,659:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 08:17:50,662:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 565247
2022-09-05 08:17:50,665:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 08:17:50,667:pe_layer.py:132 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 08:17:50,667:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 08:17:50,668:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 08:17:50,690:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 08:17:50,690:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 08:29:20,317:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:689.6268446445465
2022-09-05 08:29:20,318:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 08:29:20,318:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-05 08:29:20,319:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 2000
2022-09-05 08:29:20,319:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 08:29:20,321:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 08:32:01,645:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 60.1376 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_08h17m49s_on_Sep_05_2022/MODELS_
2022-09-05 08:32:01,645:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.32s, LR: 0.00050, Train Loss: 0.6721, Train Acc: 57.9099,
                        Val Loss: 0.6612, Val Acc: 60.1851, Test Acc: 60.1376
2022-09-05 08:32:01,645:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 08:34:42,988:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 62.5946 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_08h17m49s_on_Sep_05_2022/MODELS_
2022-09-05 08:34:42,988:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.34s, LR: 0.00050, Train Loss: 0.6482, Train Acc: 62.0956,
                        Val Loss: 0.6445, Val Acc: 62.6314, Test Acc: 62.5946
2022-09-05 08:34:42,988:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 08:37:24,111:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 64.3049 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_08h17m49s_on_Sep_05_2022/MODELS_
2022-09-05 08:37:24,111:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.12s, LR: 0.00050, Train Loss: 0.6358, Train Acc: 63.6942,
                        Val Loss: 0.6280, Val Acc: 64.4854, Test Acc: 64.3049
2022-09-05 08:37:24,111:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 08:40:05,877:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 82.1975 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_08h17m49s_on_Sep_05_2022/MODELS_
2022-09-05 08:40:05,877:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.77s, LR: 0.00050, Train Loss: 0.4624, Train Acc: 77.5101,
                        Val Loss: 0.3972, Val Acc: 81.9760, Test Acc: 82.1975
2022-09-05 08:40:05,877:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 08:42:47,245:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.37s, LR: 0.00050, Train Loss: 0.3699, Train Acc: 83.4758,
                        Val Loss: 0.6313, Val Acc: 69.2408, Test Acc: 69.2991
2022-09-05 08:42:47,245:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 08:45:27,849:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 160.60s, LR: 0.00050, Train Loss: 0.3492, Train Acc: 84.5298,
                        Val Loss: 0.4922, Val Acc: 78.2213, Test Acc: 78.2270
2022-09-05 08:45:27,849:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 08:48:08,904:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 84.2155 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_08h17m49s_on_Sep_05_2022/MODELS_
2022-09-05 08:48:08,904:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.05s, LR: 0.00050, Train Loss: 0.3432, Train Acc: 84.7809,
                        Val Loss: 0.3575, Val Acc: 84.1079, Test Acc: 84.2155
2022-09-05 08:48:08,904:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 08:50:49,606:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 160.70s, LR: 0.00050, Train Loss: 0.3407, Train Acc: 84.9691,
                        Val Loss: 0.6686, Val Acc: 71.6139, Test Acc: 71.5653
2022-09-05 08:50:49,607:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 08:53:31,572:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.96s, LR: 0.00050, Train Loss: 0.3381, Train Acc: 85.0543,
                        Val Loss: 0.3742, Val Acc: 83.1795, Test Acc: 83.4209
2022-09-05 08:53:31,572:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 08:56:12,461:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 160.89s, LR: 0.00050, Train Loss: 0.3365, Train Acc: 85.1663,
                        Val Loss: 0.5960, Val Acc: 77.7659, Test Acc: 77.9911
2022-09-05 08:56:12,461:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 08:58:53,732:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 161.27s, LR: 0.00050, Train Loss: 0.3350, Train Acc: 85.2118,
                        Val Loss: 0.4058, Val Acc: 82.9361, Test Acc: 83.0680
2022-09-05 08:58:53,732:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 09:01:34,532:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 160.80s, LR: 0.00050, Train Loss: 0.3352, Train Acc: 85.2246,
                        Val Loss: 0.4309, Val Acc: 81.2689, Test Acc: 81.3631
2022-09-05 09:01:34,532:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 09:04:14,943:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 160.41s, LR: 0.00050, Train Loss: 0.3341, Train Acc: 85.2665,
                        Val Loss: 0.4301, Val Acc: 81.7109, Test Acc: 81.7497
2022-09-05 09:04:14,944:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 09:06:55,019:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 160.08s, LR: 0.00050, Train Loss: 0.3331, Train Acc: 85.3366,
                        Val Loss: 0.5844, Val Acc: 74.5782, Test Acc: 74.8207
2022-09-05 09:06:55,020:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 09:09:34,624:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.60s, LR: 0.00050, Train Loss: 0.3329, Train Acc: 85.2916,
                        Val Loss: 0.6628, Val Acc: 72.8454, Test Acc: 73.0288
2022-09-05 09:09:34,624:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 09:12:14,123:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.50s, LR: 0.00050, Train Loss: 0.3315, Train Acc: 85.3589,
                        Val Loss: 0.5452, Val Acc: 74.2376, Test Acc: 74.4128
2022-09-05 09:12:14,123:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 09:14:53,525:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.40s, LR: 0.00050, Train Loss: 0.3317, Train Acc: 85.3519,
                        Val Loss: 0.5608, Val Acc: 77.2032, Test Acc: 77.4325
2022-09-05 09:14:53,525:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 09:17:33,335:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.81s, LR: 0.00050, Train Loss: 0.3309, Train Acc: 85.4149,
                        Val Loss: 0.3950, Val Acc: 81.8622, Test Acc: 81.9220
2022-09-05 09:17:33,336:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 09:20:14,327:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 84.7752 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_08h17m49s_on_Sep_05_2022/MODELS_
2022-09-05 09:20:14,327:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 160.99s, LR: 0.00025, Train Loss: 0.3256, Train Acc: 85.6363,
                        Val Loss: 0.3485, Val Acc: 84.6198, Test Acc: 84.7752
2022-09-05 09:20:14,327:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 09:22:53,776:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.45s, LR: 0.00025, Train Loss: 0.3244, Train Acc: 85.7009,
                        Val Loss: 0.3965, Val Acc: 81.9483, Test Acc: 82.0628
2022-09-05 09:22:53,776:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 09:25:33,362:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.59s, LR: 0.00025, Train Loss: 0.3243, Train Acc: 85.6965,
                        Val Loss: 0.6111, Val Acc: 65.9947, Test Acc: 66.1169
2022-09-05 09:25:33,363:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 09:28:12,476:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 159.11s, LR: 0.00025, Train Loss: 0.3234, Train Acc: 85.7480,
                        Val Loss: 0.6475, Val Acc: 71.4328, Test Acc: 71.5683
2022-09-05 09:28:12,476:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 09:30:51,344:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.87s, LR: 0.00025, Train Loss: 0.3234, Train Acc: 85.7442,
                        Val Loss: 0.4808, Val Acc: 79.4729, Test Acc: 79.7765
2022-09-05 09:30:51,344:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 09:33:30,054:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.71s, LR: 0.00025, Train Loss: 0.3225, Train Acc: 85.7847,
                        Val Loss: 0.4796, Val Acc: 75.6117, Test Acc: 75.7955
2022-09-05 09:33:30,054:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 09:36:08,502:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.45s, LR: 0.00025, Train Loss: 0.3214, Train Acc: 85.8610,
                        Val Loss: 0.3807, Val Acc: 84.2238, Test Acc: 84.4733
2022-09-05 09:36:08,502:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 09:38:47,296:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 85.4020 to out/SBMs_node_classification_b26-bnorm-alt-ngape8-lincomb-softmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_32_32_08h17m49s_on_Sep_05_2022/MODELS_
2022-09-05 09:38:47,296:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.79s, LR: 0.00025, Train Loss: 0.3210, Train Acc: 85.8456,
                        Val Loss: 0.3377, Val Acc: 85.0407, Test Acc: 85.4020
2022-09-05 09:38:47,296:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 09:41:25,506:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.21s, LR: 0.00025, Train Loss: 0.3197, Train Acc: 85.9146,
                        Val Loss: 0.4820, Val Acc: 76.6019, Test Acc: 76.6526
2022-09-05 09:41:25,506:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 09:44:03,400:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 157.89s, LR: 0.00025, Train Loss: 0.3192, Train Acc: 85.9330,
                        Val Loss: 0.6260, Val Acc: 64.6594, Test Acc: 64.8236
2022-09-05 09:44:03,401:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 09:46:41,528:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 158.13s, LR: 0.00025, Train Loss: 0.3190, Train Acc: 85.9518,
                        Val Loss: 0.3910, Val Acc: 84.5240, Test Acc: 84.6471
2022-09-05 09:46:41,528:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 09:49:19,372:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 157.84s, LR: 0.00025, Train Loss: 0.3211, Train Acc: 85.8991,
                        Val Loss: 0.3965, Val Acc: 81.8137, Test Acc: 81.8072
2022-09-05 09:49:19,372:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 09:51:56,829:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 157.46s, LR: 0.00025, Train Loss: 0.3195, Train Acc: 85.8803,
                        Val Loss: 2.3798, Val Acc: 50.0299, Test Acc: 50.0271
2022-09-05 09:51:56,830:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 09:54:34,024:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 157.19s, LR: 0.00025, Train Loss: 0.3169, Train Acc: 86.0537,
                        Val Loss: 0.3781, Val Acc: 83.0354, Test Acc: 83.2576
2022-09-05 09:54:34,025:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 09:57:11,405:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 157.38s, LR: 0.00025, Train Loss: 0.3154, Train Acc: 86.0913,
                        Val Loss: 0.9170, Val Acc: 78.2311, Test Acc: 78.3804
2022-09-05 09:57:11,405:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 09:59:47,923:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 156.52s, LR: 0.00025, Train Loss: 0.3148, Train Acc: 86.1140,
                        Val Loss: 0.3661, Val Acc: 83.6929, Test Acc: 83.9171
2022-09-05 09:59:47,923:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 10:02:24,910:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 156.99s, LR: 0.00025, Train Loss: 0.3137, Train Acc: 86.1545,
                        Val Loss: 0.3976, Val Acc: 83.3492, Test Acc: 83.3933
2022-09-05 10:02:24,910:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 10:05:01,152:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 156.24s, LR: 0.00025, Train Loss: 0.3133, Train Acc: 86.1572,
                        Val Loss: 0.3795, Val Acc: 82.8343, Test Acc: 82.9365
2022-09-05 10:05:01,152:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 10:07:36,890:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 155.74s, LR: 0.00025, Train Loss: 0.3121, Train Acc: 86.2491,
                        Val Loss: 1.3525, Val Acc: 72.0123, Test Acc: 72.4510
2022-09-05 10:07:36,891:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 10:10:12,563:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 155.67s, LR: 0.00013, Train Loss: 0.3069, Train Acc: 86.4694,
                        Val Loss: 0.3531, Val Acc: 84.5661, Test Acc: 84.5816
2022-09-05 10:10:12,563:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 10:12:48,643:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 156.08s, LR: 0.00013, Train Loss: 0.3061, Train Acc: 86.5055,
                        Val Loss: 0.3497, Val Acc: 84.7595, Test Acc: 85.0622
2022-09-05 10:12:48,643:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 10:15:24,753:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 156.11s, LR: 0.00013, Train Loss: 0.3047, Train Acc: 86.5794,
                        Val Loss: 0.3720, Val Acc: 84.2588, Test Acc: 84.2965
2022-09-05 10:15:24,753:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 10:18:01,025:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 156.27s, LR: 0.00013, Train Loss: 0.3042, Train Acc: 86.5710,
                        Val Loss: 0.3512, Val Acc: 84.8635, Test Acc: 85.0488
2022-09-05 10:18:01,025:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 42/1000
