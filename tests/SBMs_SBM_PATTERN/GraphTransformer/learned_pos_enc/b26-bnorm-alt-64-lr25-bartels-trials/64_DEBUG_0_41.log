2022-09-29 00:35:44,155:main_utils.py:62 -            gpu_setup(): cuda available with GPU: Quadro RTX 6000
2022-09-29 00:35:56,926:main_SBMs_node_classification.py:387 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'learned_pos_enc': True, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'gape_clamp': False, 'rand_sketchy_pos_enc': False, 'eigen_bartels_stewart': True, 'gape_rand': False, 'experiment_1': False, 'gape_normalization': False, 'gape_squash': 'none', 'log_file': '/afs/crc.nd.edu/user/p/psoga/benchmarking-gnns/tests/SBMs_SBM_PATTERN/GraphTransformer/learned_pos_enc/b26-bnorm-alt-64-lr25-bartels-trials/64_DEBUG_0_41.log', 'device': device(type='cuda'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2, 'seed_array': [41]}
2022-09-29 00:35:56,927:main_SBMs_node_classification.py:388 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.00025, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-07, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-29 00:35:56,928:pe_layer.py:72 -             __init__(): learned_pos_enc
2022-09-29 00:35:58,560:pe_layer.py:137 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-29 00:35:58,560:pe_layer.py:142 -             __init__(): Using matrix: A
2022-09-29 00:35:58,560:pe_layer.py:143 -             __init__(): Matrix power: 1
2022-09-29 00:35:58,634:main_utils.py:76 -     view_model_param(): MODEL DETAILS:

2022-09-29 00:35:58,636:main_utils.py:81 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 540358
2022-09-29 00:35:58,636:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-29 00:35:58,637:pe_layer.py:72 -             __init__(): learned_pos_enc
2022-09-29 00:35:58,637:pe_layer.py:137 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-29 00:35:58,637:pe_layer.py:142 -             __init__(): Using matrix: A
2022-09-29 00:35:58,637:pe_layer.py:143 -             __init__(): Matrix power: 1
2022-09-29 00:35:58,656:main_SBMs_node_classification.py:167 -   train_val_pipeline(): Training Graphs: 10000
2022-09-29 00:35:58,656:main_SBMs_node_classification.py:168 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-29 00:35:58,656:main_SBMs_node_classification.py:169 -   train_val_pipeline(): Test Graphs: 2000
2022-09-29 00:35:58,656:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Number of Classes: 2
2022-09-29 00:35:58,659:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 1/1000
2022-09-29 00:48:05,778:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 82.4091 to out/SBMs_node_classification_b26-bnorm-alt-64-lr25-bartels-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_00h35m56s_on_Sep_29_2022/MODELS_
2022-09-29 00:48:05,779:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 727.12s, LR: 0.00025, Train Loss: 0.4237, Train Acc: 80.1199,
                            Val Loss: 0.4004, Val Acc: 82.2389, Test Acc: 82.4091
2022-09-29 00:48:05,779:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 2/1000
2022-09-29 01:00:11,143:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 725.36s, LR: 0.00025, Train Loss: 0.3682, Train Acc: 83.3836,
                            Val Loss: 0.4020, Val Acc: 81.3503, Test Acc: 81.8004
2022-09-29 01:00:11,144:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 3/1000
2022-09-29 01:12:13,585:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 722.44s, LR: 0.00025, Train Loss: 0.3568, Train Acc: 84.0069,
                            Val Loss: 0.4641, Val Acc: 78.9252, Test Acc: 79.1855
2022-09-29 01:12:13,586:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 4/1000
2022-09-29 01:24:17,708:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 84.7062 to out/SBMs_node_classification_b26-bnorm-alt-64-lr25-bartels-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_00h35m56s_on_Sep_29_2022/MODELS_
2022-09-29 01:24:17,709:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 724.12s, LR: 0.00025, Train Loss: 0.3453, Train Acc: 84.6227,
                            Val Loss: 0.3474, Val Acc: 84.6154, Test Acc: 84.7062
2022-09-29 01:24:17,710:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 5/1000
2022-09-29 01:36:21,657:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 723.95s, LR: 0.00025, Train Loss: 0.3536, Train Acc: 84.1257,
                            Val Loss: 1.3294, Val Acc: 50.0481, Test Acc: 50.0365
2022-09-29 01:36:21,658:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 6/1000
2022-09-29 01:48:27,113:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 84.8102 to out/SBMs_node_classification_b26-bnorm-alt-64-lr25-bartels-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_00h35m56s_on_Sep_29_2022/MODELS_
2022-09-29 01:48:27,114:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 725.46s, LR: 0.00025, Train Loss: 0.3420, Train Acc: 84.8133,
                            Val Loss: 0.3595, Val Acc: 84.3879, Test Acc: 84.8102
2022-09-29 01:48:27,114:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 7/1000
2022-09-29 02:00:31,136:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 724.02s, LR: 0.00025, Train Loss: 0.3414, Train Acc: 84.8114,
                            Val Loss: 0.5003, Val Acc: 75.9214, Test Acc: 76.1003
2022-09-29 02:00:31,137:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 8/1000
2022-09-29 02:12:34,707:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 85.1684 to out/SBMs_node_classification_b26-bnorm-alt-64-lr25-bartels-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_00h35m56s_on_Sep_29_2022/MODELS_
2022-09-29 02:12:34,708:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 723.57s, LR: 0.00025, Train Loss: 0.3450, Train Acc: 84.6005,
                            Val Loss: 0.3433, Val Acc: 84.8937, Test Acc: 85.1684
2022-09-29 02:12:34,708:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 9/1000
2022-09-29 02:24:39,960:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 725.25s, LR: 0.00025, Train Loss: 0.3370, Train Acc: 85.0716,
                            Val Loss: 0.3419, Val Acc: 84.8391, Test Acc: 85.0471
2022-09-29 02:24:39,961:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 10/1000
2022-09-29 02:36:44,554:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 85.2883 to out/SBMs_node_classification_b26-bnorm-alt-64-lr25-bartels-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_00h35m56s_on_Sep_29_2022/MODELS_
2022-09-29 02:36:44,555:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 724.59s, LR: 0.00025, Train Loss: 0.3419, Train Acc: 84.7761,
                            Val Loss: 0.3344, Val Acc: 85.1597, Test Acc: 85.2883
2022-09-29 02:36:44,555:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 11/1000
2022-09-29 02:48:47,445:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 722.89s, LR: 0.00025, Train Loss: 0.3341, Train Acc: 85.2012,
                            Val Loss: 0.3397, Val Acc: 84.9855, Test Acc: 85.1078
2022-09-29 02:48:47,447:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 12/1000
2022-09-29 03:01:15,071:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 747.62s, LR: 0.00025, Train Loss: 0.3351, Train Acc: 85.1482,
                            Val Loss: 0.3959, Val Acc: 82.9032, Test Acc: 83.2190
2022-09-29 03:01:15,072:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 13/1000
2022-09-29 03:13:16,513:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 721.44s, LR: 0.00025, Train Loss: 0.3379, Train Acc: 84.9983,
                            Val Loss: 0.3540, Val Acc: 84.3958, Test Acc: 84.4517
2022-09-29 03:13:16,514:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 14/1000
2022-09-29 03:25:21,655:main_SBMs_node_classification.py:224 -   train_val_pipeline(): Saving best model with test accuracy: 85.4542 to out/SBMs_node_classification_b26-bnorm-alt-64-lr25-bartels-trialscheckpoints/GraphTransformer_SBM_PATTERN_GPU0_64_64_00h35m56s_on_Sep_29_2022/MODELS_
2022-09-29 03:25:21,656:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 725.14s, LR: 0.00025, Train Loss: 0.3348, Train Acc: 85.1717,
                            Val Loss: 0.3354, Val Acc: 85.2845, Test Acc: 85.4542
2022-09-29 03:25:21,656:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 15/1000
2022-09-29 03:37:26,536:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 724.88s, LR: 0.00025, Train Loss: 0.3349, Train Acc: 85.1363,
                            Val Loss: 0.3656, Val Acc: 84.3540, Test Acc: 84.5643
2022-09-29 03:37:26,537:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 16/1000
2022-09-29 03:49:47,765:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 741.23s, LR: 0.00025, Train Loss: 0.3329, Train Acc: 85.2790,
                            Val Loss: 0.3521, Val Acc: 84.8685, Test Acc: 85.1293
2022-09-29 03:49:47,766:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 17/1000
2022-09-29 04:01:44,293:main_SBMs_node_classification.py:246 -   train_val_pipeline(): 	Time: 716.53s, LR: 0.00025, Train Loss: 0.3313, Train Acc: 85.3678,
                            Val Loss: 0.3347, Val Acc: 85.1942, Test Acc: 85.3216
2022-09-29 04:01:44,293:main_SBMs_node_classification.py:204 -   train_val_pipeline(): Epoch 18/1000
