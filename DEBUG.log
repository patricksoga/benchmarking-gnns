2022-08-30 23:05:25,627:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-30 23:05:31,642:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 7, 'n_classes': 6}
2022-08-30 23:05:31,642:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-30 23:05:31,643:pe_layer.py:62 -             __init__(): no_pe
2022-08-30 23:05:31,643:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-30 23:05:31,643:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-30 23:05:31,651:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-30 23:05:31,652:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523146
2022-08-30 23:05:31,653:pe_layer.py:62 -             __init__(): no_pe
2022-08-30 23:05:31,653:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-30 23:05:31,653:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-30 23:05:31,664:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-08-30 23:05:31,664:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-30 23:05:31,664:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 1000
2022-08-30 23:05:31,664:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-08-30 23:05:31,668:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-08-30 23:06:31,174:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-30 23:06:37,152:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 6, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 32, 'in_dim': 7, 'n_classes': 6}
2022-08-30 23:06:37,152:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-08-30 23:06:37,153:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-30 23:06:37,157:pe_layer.py:119 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-30 23:06:37,157:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-30 23:06:37,158:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-30 23:06:37,165:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-30 23:06:37,167:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 545323
2022-08-30 23:06:37,168:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-30 23:06:37,169:pe_layer.py:119 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-30 23:06:37,169:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-30 23:06:37,169:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-30 23:06:37,179:main_SBMs_node_classification.py:94 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-08-30 23:06:37,179:main_SBMs_node_classification.py:98 -   train_val_pipeline(): [!] Using 6 random automata.
2022-08-30 23:11:30,353:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:293.1742751598358
2022-08-30 23:11:30,356:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10000
2022-08-30 23:11:30,356:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-30 23:11:30,356:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 1000
2022-08-30 23:11:30,356:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-08-30 23:11:30,358:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-08-30 23:14:33,654:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-30 23:14:33,654:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 00:49:31,048:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 00:49:35,391:main_CYCLES_graph_classification.py:326 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 00:49:35,391:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 00:49:35,397:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 00:49:35,398:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 00:49:54,740:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 00:49:59,162:main_CYCLES_graph_classification.py:326 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 00:49:59,163:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 00:49:59,169:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 00:49:59,169:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 00:50:17,484:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 00:50:21,800:main_CYCLES_graph_classification.py:326 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 00:50:21,801:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 00:50:21,807:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 00:50:21,807:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 00:50:21,830:main_CYCLES_graph_classification.py:110 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 00:50:21,831:main_CYCLES_graph_classification.py:111 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 00:50:21,831:main_CYCLES_graph_classification.py:112 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 00:50:21,831:main_CYCLES_graph_classification.py:113 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 00:50:21,834:main_CYCLES_graph_classification.py:138 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 00:52:22,241:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 00:52:51,551:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 00:52:56,231:main_CYCLES_graph_classification.py:326 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 00:52:56,232:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 00:52:56,238:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 00:52:56,238:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 00:52:56,259:main_CYCLES_graph_classification.py:110 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 00:52:56,259:main_CYCLES_graph_classification.py:111 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 00:52:56,260:main_CYCLES_graph_classification.py:112 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 00:52:56,260:main_CYCLES_graph_classification.py:113 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 00:52:56,262:main_CYCLES_graph_classification.py:138 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 00:59:16,338:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 00:59:20,635:main_CYCLES_graph_classification.py:326 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 00:59:20,635:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 00:59:20,642:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 00:59:20,642:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 00:59:20,662:main_CYCLES_graph_classification.py:110 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 00:59:20,663:main_CYCLES_graph_classification.py:111 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 00:59:20,663:main_CYCLES_graph_classification.py:112 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 00:59:20,663:main_CYCLES_graph_classification.py:113 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 00:59:20,666:main_CYCLES_graph_classification.py:138 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 00:59:55,057:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 00:59:59,421:main_CYCLES_graph_classification.py:326 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 00:59:59,421:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 00:59:59,427:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 00:59:59,428:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 00:59:59,448:main_CYCLES_graph_classification.py:110 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 00:59:59,449:main_CYCLES_graph_classification.py:111 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 00:59:59,449:main_CYCLES_graph_classification.py:112 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 00:59:59,449:main_CYCLES_graph_classification.py:113 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 00:59:59,451:main_CYCLES_graph_classification.py:138 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 01:00:14,545:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:00:18,865:main_CYCLES_graph_classification.py:326 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 01:00:18,865:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:00:18,871:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:00:18,872:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 01:00:50,511:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:01:28,161:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:01:32,669:main_CYCLES_graph_classification.py:326 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 01:01:32,669:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:01:32,675:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:01:32,676:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 01:01:42,131:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:01:46,574:main_CYCLES_graph_classification.py:326 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 01:01:46,575:main_CYCLES_graph_classification.py:327 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:01:46,581:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:01:46,582:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 01:01:46,606:main_CYCLES_graph_classification.py:110 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 01:01:46,606:main_CYCLES_graph_classification.py:111 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 01:01:46,606:main_CYCLES_graph_classification.py:112 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 01:01:46,606:main_CYCLES_graph_classification.py:113 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 01:01:46,608:main_CYCLES_graph_classification.py:138 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 01:02:40,245:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:02:44,748:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 01:02:44,748:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:02:44,754:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:02:44,755:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 01:02:44,761:main_CYCLES_graph_classification.py:88 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-08-31 01:03:03,183:main_CYCLES_graph_classification.py:90 -   train_val_pipeline(): Time PE:18.427977085113525
2022-08-31 01:03:03,201:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 01:03:03,201:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 01:03:03,201:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 01:03:03,201:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 01:03:03,203:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 01:03:48,700:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:03:53,148:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 01:03:53,148:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:03:53,154:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:03:53,155:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608598
2022-08-31 01:03:53,161:main_CYCLES_graph_classification.py:88 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-08-31 01:04:12,164:main_CYCLES_graph_classification.py:90 -   train_val_pipeline(): Time PE:19.009175062179565
2022-08-31 01:04:12,181:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 01:04:12,181:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 01:04:12,181:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 01:04:12,181:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 01:04:12,183:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 01:04:34,929:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:04:39,355:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-08-31 01:04:39,355:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:04:39,361:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:04:39,361:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608678
2022-08-31 01:04:39,368:main_CYCLES_graph_classification.py:88 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-08-31 01:04:58,475:main_CYCLES_graph_classification.py:90 -   train_val_pipeline(): Time PE:19.11299180984497
2022-08-31 01:04:58,491:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-08-31 01:04:58,491:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 01:04:58,491:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-08-31 01:04:58,491:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-08-31 01:04:58,494:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 01:05:23,111:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5558 to out/CYCLES_sparse_spd_BN/checkpoints/PseudoGraphormer_CYCLES_GPU0_1_01h04m39s_on_Aug_31_2022/MODELS_
2022-08-31 01:05:23,112:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 24.62s, LR: 0.00050, Train Loss: 0.6885, Train Acc: 0.5200,
                        Val Loss: 0.6715, Val Acc: 0.5650, Test Acc: 0.5558
2022-08-31 01:05:23,113:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 01:26:17,282:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:26:32,132:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:26:32,194:main_CSL_graph_classification.py:329 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:26:32,195:main_CSL_graph_classification.py:330 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:26:32,195:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:26:32,196:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:26:32,196:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:26:32,196:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:26:32,199:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:26:32,200:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:27:09,803:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:27:09,869:main_CSL_graph_classification.py:331 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:27:09,869:main_CSL_graph_classification.py:332 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:27:09,869:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:27:09,870:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:27:09,870:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:27:09,870:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:27:09,873:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:27:09,874:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:27:09,874:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:27:09,875:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:27:09,875:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:27:09,875:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:27:21,370:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:27:21,435:main_CSL_graph_classification.py:332 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:27:21,435:main_CSL_graph_classification.py:333 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:27:21,435:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:27:21,436:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:27:21,437:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:27:21,437:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:27:21,439:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:27:21,440:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:27:21,440:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:27:21,441:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:27:21,441:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:27:21,441:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:27:21,548:main_CSL_graph_classification.py:59 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-08-31 01:27:21,548:main_CSL_graph_classification.py:63 -   train_val_pipeline(): [!] Using 3 random automata.
2022-08-31 01:38:52,837:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:38:52,898:main_CSL_graph_classification.py:332 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:38:52,898:main_CSL_graph_classification.py:333 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:38:52,898:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:38:52,899:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:38:52,900:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:38:52,900:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:38:52,903:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:38:52,903:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:38:52,903:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:38:52,904:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:38:52,904:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:38:52,904:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:38:53,012:main_CSL_graph_classification.py:59 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-08-31 01:38:53,012:main_CSL_graph_classification.py:63 -   train_val_pipeline(): [!] Using 3 random automata.
2022-08-31 01:39:48,746:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:39:48,810:main_CSL_graph_classification.py:332 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:39:48,810:main_CSL_graph_classification.py:333 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:39:48,810:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:39:48,812:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:39:48,812:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:39:48,812:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:39:48,815:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:39:48,815:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:39:48,815:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:39:48,816:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:39:48,816:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:39:48,816:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:39:48,928:main_CSL_graph_classification.py:59 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-08-31 01:39:48,928:main_CSL_graph_classification.py:63 -   train_val_pipeline(): [!] Using 3 random automata.
2022-08-31 01:41:00,499:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:41:00,565:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:41:00,565:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:41:00,566:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:41:00,567:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:41:00,567:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:41:00,567:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:41:00,570:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:41:00,571:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:41:00,684:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-08-31 01:41:00,684:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:41:00,686:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:41:00,686:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:41:00,686:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:41:00,689:main_CSL_graph_classification.py:86 -   train_val_pipeline(): [!] Using 3 random automata.
2022-08-31 01:41:16,283:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:41:16,348:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:41:16,348:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:41:16,348:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:41:16,350:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:41:16,350:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:41:16,350:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:41:16,353:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:41:16,354:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:41:16,468:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-08-31 01:41:16,469:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:41:16,471:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:41:16,471:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:41:16,471:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:41:16,475:main_CSL_graph_classification.py:86 -   train_val_pipeline(): [!] Using 3 random automata.
2022-08-31 01:41:58,312:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:41:58,375:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:41:58,375:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:41:58,375:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:41:58,376:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:41:58,376:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:41:58,376:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:41:58,379:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:41:58,379:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:41:58,495:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-08-31 01:41:58,496:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:41:58,497:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:41:58,497:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:41:58,497:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:41:58,501:main_CSL_graph_classification.py:86 -   train_val_pipeline(): [!] Using 3 random automata.
2022-08-31 01:42:53,225:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 01:42:53,289:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 01:42:53,289:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 01:42:53,290:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:42:53,291:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:42:53,291:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:42:53,291:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:42:53,294:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 01:42:53,294:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321691
2022-08-31 01:42:53,416:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-08-31 01:42:53,417:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 01:42:53,418:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 01:42:53,418:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 01:42:53,419:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 01:42:53,423:main_CSL_graph_classification.py:86 -   train_val_pipeline(): [!] Using 3 random automata.
2022-08-31 01:42:53,672:main_CSL_graph_classification.py:95 -   train_val_pipeline(): Training Graphs: 90
2022-08-31 01:42:53,672:main_CSL_graph_classification.py:96 -   train_val_pipeline(): Validation Graphs: 30
2022-08-31 01:42:53,672:main_CSL_graph_classification.py:97 -   train_val_pipeline(): Test Graphs: 30
2022-08-31 01:42:53,672:main_CSL_graph_classification.py:98 -   train_val_pipeline(): Number of Classes: 10
2022-08-31 01:42:53,675:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 0
2022-08-31 01:42:54,629:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.95s, LR: 0.00050, Train Loss: 1.8624, Train Acc: 0.3778,
                            Val Loss: 1.3155, Val Acc: 0.6000, Test Acc: 0.6000
2022-08-31 01:42:54,633:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 1
2022-08-31 01:42:55,571:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 1.0904, Train Acc: 0.6889,
                            Val Loss: 0.8544, Val Acc: 0.6000, Test Acc: 0.6000
2022-08-31 01:42:55,576:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 2
2022-08-31 01:42:56,480:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.7325, Train Acc: 0.7667,
                            Val Loss: 0.4786, Val Acc: 0.9000, Test Acc: 0.9000
2022-08-31 01:42:56,485:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 3
2022-08-31 01:42:57,398:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4926, Train Acc: 0.8222,
                            Val Loss: 0.2877, Val Acc: 0.9000, Test Acc: 0.9000
2022-08-31 01:42:57,402:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 4
2022-08-31 01:42:58,293:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.3616, Train Acc: 0.8889,
                            Val Loss: 0.1513, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:42:58,297:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 5
2022-08-31 01:42:59,137:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.84s, LR: 0.00050, Train Loss: 0.2348, Train Acc: 0.9222,
                            Val Loss: 0.1027, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:42:59,142:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 6
2022-08-31 01:42:59,991:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 0.3337, Train Acc: 0.8778,
                            Val Loss: 0.0832, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:42:59,996:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 7
2022-08-31 01:43:00,838:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.84s, LR: 0.00050, Train Loss: 0.2354, Train Acc: 0.9333,
                            Val Loss: 0.0396, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:43:00,843:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 8
2022-08-31 01:43:01,679:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.84s, LR: 0.00050, Train Loss: 0.2116, Train Acc: 0.9111,
                            Val Loss: 0.0662, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:43:01,684:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 9
2022-08-31 01:43:02,588:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.2444, Train Acc: 0.9444,
                            Val Loss: 0.0643, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:43:02,593:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 10
2022-08-31 01:43:03,567:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.97s, LR: 0.00050, Train Loss: 0.1343, Train Acc: 0.9444,
                            Val Loss: 0.0068, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:43:03,572:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 11
2022-08-31 01:43:04,419:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 0.0461, Train Acc: 1.0000,
                            Val Loss: 0.0089, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:43:04,424:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 12
2022-08-31 01:43:05,281:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.86s, LR: 0.00050, Train Loss: 0.1208, Train Acc: 0.9667,
                            Val Loss: 0.0029, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:43:05,286:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 13
2022-08-31 01:43:06,161:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 0.0320, Train Acc: 1.0000,
                            Val Loss: 0.0020, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 01:43:06,166:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 14
2022-08-31 01:43:06,666:main_CSL_graph_classification.py:221 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-08-31 01:43:06,666:main_CSL_graph_classification.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 01:43:06,666:main_CSL_graph_classification.py:225 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0037hrs
2022-08-31 01:43:06,666:main_CSL_graph_classification.py:226 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.8879s
2022-08-31 01:43:06,669:main_CSL_graph_classification.py:229 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-08-31 01:43:06,669:main_CSL_graph_classification.py:230 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-08-31 01:43:06,669:main_CSL_graph_classification.py:231 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-08-31 01:43:06,669:main_CSL_graph_classification.py:232 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-08-31 02:20:38,741:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 02:20:38,819:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 1, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 02:20:38,819:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 02:20:38,820:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 02:20:38,832:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 02:20:38,832:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 02:20:38,833:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 02:20:38,837:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 02:20:38,838:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317491
2022-08-31 02:20:38,957:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-08-31 02:20:38,957:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 02:20:38,958:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 02:20:38,958:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 02:20:38,958:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 02:21:04,282:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 02:21:04,345:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 1, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 02:21:04,345:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 02:21:04,345:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 02:21:04,346:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 02:21:04,346:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 02:21:04,346:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 02:21:04,349:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 02:21:04,349:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317491
2022-08-31 02:21:04,464:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-08-31 02:21:04,465:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 02:21:04,466:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 02:21:04,466:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 02:21:04,466:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 02:21:04,561:main_CSL_graph_classification.py:95 -   train_val_pipeline(): Training Graphs: 90
2022-08-31 02:21:04,562:main_CSL_graph_classification.py:96 -   train_val_pipeline(): Validation Graphs: 30
2022-08-31 02:21:04,562:main_CSL_graph_classification.py:97 -   train_val_pipeline(): Test Graphs: 30
2022-08-31 02:21:04,562:main_CSL_graph_classification.py:98 -   train_val_pipeline(): Number of Classes: 10
2022-08-31 02:21:04,564:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 0
2022-08-31 02:21:05,464:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 2.7825, Train Acc: 0.0889,
                            Val Loss: 15.7039, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:05,469:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 1
2022-08-31 02:21:06,314:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.84s, LR: 0.00050, Train Loss: 2.5002, Train Acc: 0.1667,
                            Val Loss: 251.9542, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:06,318:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 2
2022-08-31 02:21:07,168:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 2.4452, Train Acc: 0.0889,
                            Val Loss: 2065.6089, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:07,172:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 3
2022-08-31 02:21:08,015:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.84s, LR: 0.00050, Train Loss: 2.2291, Train Acc: 0.1667,
                            Val Loss: 35133.4456, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:08,019:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 4
2022-08-31 02:21:08,866:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 2.2478, Train Acc: 0.2000,
                            Val Loss: 331947.3568, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:08,870:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 5
2022-08-31 02:21:09,677:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.81s, LR: 0.00050, Train Loss: 2.3462, Train Acc: 0.2222,
                            Val Loss: 1025653.0104, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:09,682:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 6
2022-08-31 02:21:10,454:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.77s, LR: 0.00050, Train Loss: 2.1282, Train Acc: 0.2000,
                            Val Loss: 1160330.4479, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:10,458:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 7
2022-08-31 02:21:11,225:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.77s, LR: 0.00050, Train Loss: 2.0757, Train Acc: 0.2222,
                            Val Loss: 2152833.7708, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:11,229:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 8
2022-08-31 02:21:11,988:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.76s, LR: 0.00050, Train Loss: 2.0847, Train Acc: 0.1778,
                            Val Loss: 2074343.1667, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:11,993:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 9
2022-08-31 02:21:12,783:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.79s, LR: 0.00050, Train Loss: 2.2004, Train Acc: 0.1667,
                            Val Loss: 2063295.4583, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:12,787:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 10
2022-08-31 02:21:13,674:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 2.0132, Train Acc: 0.2222,
                            Val Loss: 3821997.9167, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:13,679:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 11
2022-08-31 02:21:14,479:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.80s, LR: 0.00050, Train Loss: 1.9524, Train Acc: 0.3444,
                            Val Loss: 3993572.8333, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:14,483:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 12
2022-08-31 02:21:15,275:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.79s, LR: 0.00025, Train Loss: 1.8604, Train Acc: 0.2889,
                            Val Loss: 4923062.5000, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:15,280:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 13
2022-08-31 02:21:16,081:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.80s, LR: 0.00025, Train Loss: 1.7071, Train Acc: 0.4333,
                            Val Loss: 5895981.6667, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:16,086:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 14
2022-08-31 02:21:16,904:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.82s, LR: 0.00025, Train Loss: 1.8287, Train Acc: 0.2889,
                            Val Loss: 3873422.0000, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:16,908:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 15
2022-08-31 02:21:17,755:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00025, Train Loss: 1.8601, Train Acc: 0.3111,
                            Val Loss: 3035462.9583, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:17,760:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 16
2022-08-31 02:21:18,606:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00025, Train Loss: 1.9306, Train Acc: 0.2889,
                            Val Loss: 2092676.8958, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:18,611:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 17
2022-08-31 02:21:19,416:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.81s, LR: 0.00025, Train Loss: 1.7109, Train Acc: 0.3667,
                            Val Loss: 2576279.1250, Val Acc: 0.1000, Test Acc: 0.1000
2022-08-31 02:21:19,420:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 18
2022-08-31 02:21:19,776:main_CSL_graph_classification.py:221 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-08-31 02:21:19,776:main_CSL_graph_classification.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 02:21:19,776:main_CSL_graph_classification.py:225 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0043hrs
2022-08-31 02:21:19,776:main_CSL_graph_classification.py:226 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.8212s
2022-08-31 02:21:19,778:main_CSL_graph_classification.py:229 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-08-31 02:21:19,778:main_CSL_graph_classification.py:230 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-08-31 02:21:19,778:main_CSL_graph_classification.py:231 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-08-31 02:21:19,778:main_CSL_graph_classification.py:232 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-08-31 02:21:28,215:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 02:21:28,278:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 1, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-08-31 02:21:28,278:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-08-31 02:21:28,278:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 02:21:28,279:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 02:21:28,279:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 02:21:28,279:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 02:21:28,283:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 02:21:28,284:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 319591
2022-08-31 02:21:28,399:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-08-31 02:21:28,400:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 02:21:28,401:pe_layer.py:119 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 02:21:28,401:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 02:21:28,401:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 02:21:28,405:main_CSL_graph_classification.py:86 -   train_val_pipeline(): [!] Using 2 random automata.
2022-08-31 02:21:28,557:main_CSL_graph_classification.py:95 -   train_val_pipeline(): Training Graphs: 90
2022-08-31 02:21:28,557:main_CSL_graph_classification.py:96 -   train_val_pipeline(): Validation Graphs: 30
2022-08-31 02:21:28,557:main_CSL_graph_classification.py:97 -   train_val_pipeline(): Test Graphs: 30
2022-08-31 02:21:28,558:main_CSL_graph_classification.py:98 -   train_val_pipeline(): Number of Classes: 10
2022-08-31 02:21:28,559:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 0
2022-08-31 02:21:29,470:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 1.9532, Train Acc: 0.2667,
                            Val Loss: 2.1057, Val Acc: 0.2000, Test Acc: 0.2000
2022-08-31 02:21:29,474:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 1
2022-08-31 02:21:30,364:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 1.2268, Train Acc: 0.5667,
                            Val Loss: 1.1830, Val Acc: 0.6000, Test Acc: 0.6000
2022-08-31 02:21:30,369:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 2
2022-08-31 02:21:31,465:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 1.10s, LR: 0.00050, Train Loss: 0.7862, Train Acc: 0.7667,
                            Val Loss: 0.4242, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 02:21:31,554:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 3
2022-08-31 02:21:32,426:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 0.4243, Train Acc: 0.9000,
                            Val Loss: 0.1267, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 02:21:32,430:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 4
2022-08-31 02:21:33,276:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 0.4367, Train Acc: 0.9222,
                            Val Loss: 0.1023, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 02:21:33,281:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 5
2022-08-31 02:21:34,112:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.83s, LR: 0.00050, Train Loss: 0.1904, Train Acc: 0.9333,
                            Val Loss: 0.0347, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 02:21:34,116:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 6
2022-08-31 02:21:34,947:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.83s, LR: 0.00050, Train Loss: 0.1406, Train Acc: 0.9667,
                            Val Loss: 0.0066, Val Acc: 1.0000, Test Acc: 1.0000
2022-08-31 02:21:34,951:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 7
2022-08-31 02:21:35,386:main_CSL_graph_classification.py:221 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-08-31 02:21:35,386:main_CSL_graph_classification.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 02:21:35,386:main_CSL_graph_classification.py:225 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0020hrs
2022-08-31 02:21:35,386:main_CSL_graph_classification.py:226 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.9089s
2022-08-31 02:21:35,388:main_CSL_graph_classification.py:229 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-08-31 02:21:35,388:main_CSL_graph_classification.py:230 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-08-31 02:21:35,388:main_CSL_graph_classification.py:231 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-08-31 02:21:35,388:main_CSL_graph_classification.py:232 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-08-31 17:34:26,624:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 17:34:29,881:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 15, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 17:34:29,882:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 2}
2022-08-31 17:34:29,883:pe_layer.py:62 -             __init__(): pos_enc
2022-08-31 17:34:29,887:pe_layer.py:119 -             __init__(): Using 15 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 17:34:29,887:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 17:34:29,887:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 17:34:29,895:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 17:34:29,896:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 346497
2022-08-31 17:34:29,896:pe_layer.py:62 -             __init__(): pos_enc
2022-08-31 17:34:29,896:pe_layer.py:119 -             __init__(): Using 15 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 17:34:29,896:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 17:34:29,896:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 17:34:29,901:main_molecules_graph_regression.py:60 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-08-31 17:34:37,427:main_molecules_graph_regression.py:62 -   train_val_pipeline(): Time PE: 7.53099799156189
2022-08-31 17:34:37,444:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 17:34:37,444:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 17:34:37,444:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 17:34:37,447:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 17:34:50,395:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.1735337674617767
2022-08-31 17:34:50,397:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.95s, LR: 0.00070, Train Loss: 1.0381, Train MAE: 1.0381,
                            Val Loss: 1.1366, Val Acc: 1.1366, Test MAE: 1.1735
2022-08-31 17:34:50,403:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 17:35:03,098:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.6745735108852386
2022-08-31 17:35:03,099:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.70s, LR: 0.00070, Train Loss: 0.6629, Train MAE: 0.6629,
                            Val Loss: 0.6351, Val Acc: 0.6351, Test MAE: 0.6746
2022-08-31 17:35:03,105:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-08-31 17:35:15,923:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.82s, LR: 0.00070, Train Loss: 0.6400, Train MAE: 0.6400,
                            Val Loss: 0.6991, Val Acc: 0.6991, Test MAE: 0.7241
2022-08-31 17:35:15,929:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 4/1000
2022-08-31 17:35:28,642:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.71s, LR: 0.00070, Train Loss: 0.6037, Train MAE: 0.6037,
                            Val Loss: 0.7871, Val Acc: 0.7871, Test MAE: 0.8226
2022-08-31 17:35:28,648:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 5/1000
2022-08-31 17:35:41,143:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.50s, LR: 0.00070, Train Loss: 0.5961, Train MAE: 0.5961,
                            Val Loss: 0.7020, Val Acc: 0.7020, Test MAE: 0.7410
2022-08-31 17:35:41,150:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 6/1000
2022-08-31 17:35:53,582:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.6174957230687141
2022-08-31 17:35:53,582:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.43s, LR: 0.00070, Train Loss: 0.5749, Train MAE: 0.5749,
                            Val Loss: 0.5854, Val Acc: 0.5854, Test MAE: 0.6175
2022-08-31 17:35:53,588:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 7/1000
2022-08-31 17:36:06,475:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.89s, LR: 0.00070, Train Loss: 0.5722, Train MAE: 0.5722,
                            Val Loss: 0.7968, Val Acc: 0.7968, Test MAE: 0.8318
2022-08-31 17:36:06,481:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 8/1000
2022-08-31 17:36:19,117:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.64s, LR: 0.00070, Train Loss: 0.5461, Train MAE: 0.5461,
                            Val Loss: 0.6014, Val Acc: 0.6014, Test MAE: 0.6375
2022-08-31 17:36:19,123:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 9/1000
2022-08-31 17:36:31,727:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.60s, LR: 0.00070, Train Loss: 0.5454, Train MAE: 0.5454,
                            Val Loss: 0.6012, Val Acc: 0.6012, Test MAE: 0.6243
2022-08-31 17:36:31,732:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 10/1000
2022-08-31 17:36:44,981:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.25s, LR: 0.00070, Train Loss: 0.5354, Train MAE: 0.5354,
                            Val Loss: 0.6116, Val Acc: 0.6116, Test MAE: 0.6483
2022-08-31 17:36:44,988:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 11/1000
2022-08-31 17:36:58,198:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5912546366453171
2022-08-31 17:36:58,199:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.21s, LR: 0.00070, Train Loss: 0.5372, Train MAE: 0.5372,
                            Val Loss: 0.5680, Val Acc: 0.5680, Test MAE: 0.5913
2022-08-31 17:36:58,204:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 12/1000
2022-08-31 17:37:11,018:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5812064856290817
2022-08-31 17:37:11,018:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.81s, LR: 0.00070, Train Loss: 0.5096, Train MAE: 0.5096,
                            Val Loss: 0.5373, Val Acc: 0.5373, Test MAE: 0.5812
2022-08-31 17:37:11,024:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 13/1000
2022-08-31 17:37:23,850:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5446504466235638
2022-08-31 17:37:23,850:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.83s, LR: 0.00070, Train Loss: 0.5022, Train MAE: 0.5022,
                            Val Loss: 0.4971, Val Acc: 0.4971, Test MAE: 0.5447
2022-08-31 17:37:23,857:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 14/1000
2022-08-31 17:37:36,704:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.85s, LR: 0.00070, Train Loss: 0.5002, Train MAE: 0.5002,
                            Val Loss: 0.5484, Val Acc: 0.5484, Test MAE: 0.5838
2022-08-31 17:37:36,710:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 15/1000
2022-08-31 17:37:50,037:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.33s, LR: 0.00070, Train Loss: 0.4923, Train MAE: 0.4923,
                            Val Loss: 0.5726, Val Acc: 0.5726, Test MAE: 0.6009
2022-08-31 17:37:50,046:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 16/1000
2022-08-31 17:38:03,886:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.84s, LR: 0.00070, Train Loss: 0.4790, Train MAE: 0.4790,
                            Val Loss: 0.5244, Val Acc: 0.5244, Test MAE: 0.5573
2022-08-31 17:38:03,892:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 17/1000
2022-08-31 17:38:17,388:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.50s, LR: 0.00070, Train Loss: 0.4806, Train MAE: 0.4806,
                            Val Loss: 0.6926, Val Acc: 0.6926, Test MAE: 0.7150
2022-08-31 17:38:17,394:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 18/1000
2022-08-31 17:38:30,212:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.82s, LR: 0.00070, Train Loss: 0.4806, Train MAE: 0.4806,
                            Val Loss: 0.9097, Val Acc: 0.9097, Test MAE: 0.9470
2022-08-31 17:38:30,218:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 19/1000
2022-08-31 17:38:42,954:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.74s, LR: 0.00070, Train Loss: 0.4828, Train MAE: 0.4828,
                            Val Loss: 0.5170, Val Acc: 0.5170, Test MAE: 0.5509
2022-08-31 17:38:42,960:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 20/1000
2022-08-31 17:38:55,825:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5146981738507748
2022-08-31 17:38:55,825:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.87s, LR: 0.00070, Train Loss: 0.4595, Train MAE: 0.4595,
                            Val Loss: 0.4916, Val Acc: 0.4916, Test MAE: 0.5147
2022-08-31 17:38:55,832:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 21/1000
2022-08-31 17:39:08,437:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.61s, LR: 0.00070, Train Loss: 0.4573, Train MAE: 0.4573,
                            Val Loss: 0.5438, Val Acc: 0.5438, Test MAE: 0.5822
2022-08-31 17:39:08,443:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 22/1000
2022-08-31 17:39:21,335:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.89s, LR: 0.00070, Train Loss: 0.4585, Train MAE: 0.4585,
                            Val Loss: 0.5480, Val Acc: 0.5480, Test MAE: 0.5804
2022-08-31 17:39:21,341:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 23/1000
2022-08-31 17:39:34,616:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.27s, LR: 0.00070, Train Loss: 0.4463, Train MAE: 0.4463,
                            Val Loss: 0.5355, Val Acc: 0.5355, Test MAE: 0.5692
2022-08-31 17:39:34,623:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 24/1000
2022-08-31 17:39:48,295:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.49696050211787224
2022-08-31 17:39:48,296:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.67s, LR: 0.00070, Train Loss: 0.4522, Train MAE: 0.4522,
                            Val Loss: 0.4697, Val Acc: 0.4697, Test MAE: 0.4970
2022-08-31 17:39:48,301:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 25/1000
2022-08-31 17:40:01,814:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.51s, LR: 0.00070, Train Loss: 0.4403, Train MAE: 0.4403,
                            Val Loss: 0.6451, Val Acc: 0.6451, Test MAE: 0.6584
2022-08-31 17:40:01,820:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 26/1000
2022-08-31 17:40:15,334:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.51s, LR: 0.00070, Train Loss: 0.4405, Train MAE: 0.4405,
                            Val Loss: 0.4701, Val Acc: 0.4701, Test MAE: 0.5021
2022-08-31 17:40:15,339:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 27/1000
2022-08-31 17:40:28,543:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.20s, LR: 0.00070, Train Loss: 0.4316, Train MAE: 0.4316,
                            Val Loss: 0.5596, Val Acc: 0.5596, Test MAE: 0.5718
2022-08-31 17:40:28,549:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 28/1000
2022-08-31 17:40:41,554:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.48010897636413574
2022-08-31 17:40:41,556:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.01s, LR: 0.00070, Train Loss: 0.4313, Train MAE: 0.4313,
                            Val Loss: 0.4557, Val Acc: 0.4557, Test MAE: 0.4801
2022-08-31 17:40:41,562:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 29/1000
2022-08-31 17:40:54,454:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.89s, LR: 0.00070, Train Loss: 0.4454, Train MAE: 0.4454,
                            Val Loss: 0.4863, Val Acc: 0.4863, Test MAE: 0.5227
2022-08-31 17:40:54,461:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 30/1000
2022-08-31 17:41:07,997:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.54s, LR: 0.00070, Train Loss: 0.4359, Train MAE: 0.4359,
                            Val Loss: 0.4889, Val Acc: 0.4889, Test MAE: 0.5137
2022-08-31 17:41:08,004:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 31/1000
2022-08-31 17:41:21,985:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.98s, LR: 0.00070, Train Loss: 0.4524, Train MAE: 0.4524,
                            Val Loss: 0.5170, Val Acc: 0.5170, Test MAE: 0.5443
2022-08-31 17:41:21,992:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 32/1000
2022-08-31 17:41:34,887:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.90s, LR: 0.00070, Train Loss: 0.4371, Train MAE: 0.4371,
                            Val Loss: 0.5803, Val Acc: 0.5803, Test MAE: 0.6080
2022-08-31 17:41:34,893:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 33/1000
2022-08-31 17:41:48,293:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.40s, LR: 0.00070, Train Loss: 0.4292, Train MAE: 0.4292,
                            Val Loss: 0.5030, Val Acc: 0.5030, Test MAE: 0.5440
2022-08-31 17:41:48,299:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 34/1000
2022-08-31 17:42:01,194:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.89s, LR: 0.00070, Train Loss: 0.4119, Train MAE: 0.4119,
                            Val Loss: 0.5108, Val Acc: 0.5108, Test MAE: 0.5471
2022-08-31 17:42:01,200:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 35/1000
2022-08-31 17:42:14,252:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.05s, LR: 0.00070, Train Loss: 0.4229, Train MAE: 0.4229,
                            Val Loss: 0.5531, Val Acc: 0.5531, Test MAE: 0.5876
2022-08-31 17:42:14,258:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 36/1000
2022-08-31 17:42:26,927:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4537934362888336
2022-08-31 17:42:26,927:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.67s, LR: 0.00070, Train Loss: 0.4165, Train MAE: 0.4165,
                            Val Loss: 0.4381, Val Acc: 0.4381, Test MAE: 0.4538
2022-08-31 17:42:26,933:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 37/1000
2022-08-31 17:42:39,902:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.97s, LR: 0.00070, Train Loss: 0.4090, Train MAE: 0.4090,
                            Val Loss: 0.6019, Val Acc: 0.6019, Test MAE: 0.6140
2022-08-31 17:42:39,908:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 38/1000
2022-08-31 17:42:53,133:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.22s, LR: 0.00070, Train Loss: 0.4015, Train MAE: 0.4015,
                            Val Loss: 0.4748, Val Acc: 0.4748, Test MAE: 0.5032
2022-08-31 17:42:53,139:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 39/1000
2022-08-31 17:43:06,247:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4293980002403259
2022-08-31 17:43:06,247:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.11s, LR: 0.00070, Train Loss: 0.3991, Train MAE: 0.3991,
                            Val Loss: 0.4147, Val Acc: 0.4147, Test MAE: 0.4294
2022-08-31 17:43:06,253:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 40/1000
2022-08-31 17:43:19,593:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.34s, LR: 0.00070, Train Loss: 0.3953, Train MAE: 0.3953,
                            Val Loss: 0.4391, Val Acc: 0.4391, Test MAE: 0.4518
2022-08-31 17:43:19,602:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 41/1000
2022-08-31 17:43:32,899:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.30s, LR: 0.00070, Train Loss: 0.3919, Train MAE: 0.3919,
                            Val Loss: 0.4655, Val Acc: 0.4655, Test MAE: 0.4745
2022-08-31 17:43:32,905:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 42/1000
2022-08-31 17:43:45,929:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.02s, LR: 0.00070, Train Loss: 0.3888, Train MAE: 0.3888,
                            Val Loss: 0.4192, Val Acc: 0.4192, Test MAE: 0.4343
2022-08-31 17:43:45,935:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 43/1000
2022-08-31 17:43:59,057:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.12s, LR: 0.00070, Train Loss: 0.3841, Train MAE: 0.3841,
                            Val Loss: 0.4379, Val Acc: 0.4379, Test MAE: 0.4475
2022-08-31 17:43:59,064:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 44/1000
2022-08-31 17:44:12,016:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.95s, LR: 0.00070, Train Loss: 0.3890, Train MAE: 0.3890,
                            Val Loss: 0.4276, Val Acc: 0.4276, Test MAE: 0.4521
2022-08-31 17:44:12,021:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 45/1000
2022-08-31 17:44:25,277:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.26s, LR: 0.00070, Train Loss: 0.3801, Train MAE: 0.3801,
                            Val Loss: 0.4614, Val Acc: 0.4614, Test MAE: 0.4920
2022-08-31 17:44:25,283:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 46/1000
2022-08-31 17:44:38,537:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.25s, LR: 0.00070, Train Loss: 0.3730, Train MAE: 0.3730,
                            Val Loss: 0.4379, Val Acc: 0.4379, Test MAE: 0.4748
2022-08-31 17:44:38,544:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 47/1000
2022-08-31 17:44:51,891:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.35s, LR: 0.00070, Train Loss: 0.3917, Train MAE: 0.3917,
                            Val Loss: 0.4266, Val Acc: 0.4266, Test MAE: 0.4432
2022-08-31 17:44:51,897:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 48/1000
2022-08-31 17:45:04,861:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.96s, LR: 0.00070, Train Loss: 0.3894, Train MAE: 0.3894,
                            Val Loss: 0.4278, Val Acc: 0.4278, Test MAE: 0.4509
2022-08-31 17:45:04,867:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 49/1000
2022-08-31 17:45:14,589:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 17:45:17,900:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4204971715807915
2022-08-31 17:45:17,900:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.03s, LR: 0.00070, Train Loss: 0.3744, Train MAE: 0.3744,
                            Val Loss: 0.4081, Val Acc: 0.4081, Test MAE: 0.4205
2022-08-31 17:45:17,907:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 50/1000
2022-08-31 17:45:18,093:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 3, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 4, 'gape_pooling': 'sum', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 17:45:18,093:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 2}
2022-08-31 17:45:18,093:pe_layer.py:62 -             __init__(): pos_enc
2022-08-31 17:45:18,093:pe_layer.py:119 -             __init__(): Using 3 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 17:45:18,093:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 17:45:18,093:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 17:45:18,099:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 17:45:18,100:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 345729
2022-08-31 17:45:18,101:pe_layer.py:62 -             __init__(): pos_enc
2022-08-31 17:45:18,101:pe_layer.py:119 -             __init__(): Using 3 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 17:45:18,101:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 17:45:18,101:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 17:45:18,106:main_molecules_graph_regression.py:60 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-08-31 17:45:26,314:main_molecules_graph_regression.py:62 -   train_val_pipeline(): Time PE: 8.2131187915802
2022-08-31 17:45:26,329:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 17:45:26,330:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 17:45:26,330:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 17:45:26,332:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 17:45:31,918:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.01s, LR: 0.00070, Train Loss: 0.3716, Train MAE: 0.3716,
                            Val Loss: 0.4504, Val Acc: 0.4504, Test MAE: 0.4760
2022-08-31 17:45:31,925:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 51/1000
2022-08-31 17:45:46,141:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.41568106785416603
2022-08-31 17:45:46,142:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.22s, LR: 0.00070, Train Loss: 0.3612, Train MAE: 0.3612,
                            Val Loss: 0.4080, Val Acc: 0.4080, Test MAE: 0.4157
2022-08-31 17:45:46,148:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 52/1000
2022-08-31 17:46:00,019:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.87s, LR: 0.00070, Train Loss: 0.3665, Train MAE: 0.3665,
                            Val Loss: 0.4354, Val Acc: 0.4354, Test MAE: 0.4513
2022-08-31 17:46:00,025:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 53/1000
2022-08-31 17:46:13,932:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.91s, LR: 0.00070, Train Loss: 0.3546, Train MAE: 0.3546,
                            Val Loss: 0.4169, Val Acc: 0.4169, Test MAE: 0.4378
2022-08-31 17:46:13,945:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 54/1000
2022-08-31 17:46:28,692:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.75s, LR: 0.00070, Train Loss: 0.3804, Train MAE: 0.3804,
                            Val Loss: 0.4238, Val Acc: 0.4238, Test MAE: 0.4358
2022-08-31 17:46:28,698:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 55/1000
2022-08-31 17:46:41,902:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4137078858911991
2022-08-31 17:46:41,902:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.20s, LR: 0.00070, Train Loss: 0.3649, Train MAE: 0.3649,
                            Val Loss: 0.4023, Val Acc: 0.4023, Test MAE: 0.4137
2022-08-31 17:46:41,908:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 56/1000
2022-08-31 17:46:44,891:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-31 17:46:44,891:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 18:14:02,258:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 18:14:05,666:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 5, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 18:14:05,666:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 18:14:05,666:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:14:05,682:pe_layer.py:119 -             __init__(): Using 5 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:14:05,683:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:14:05,683:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:14:05,689:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 18:14:05,690:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 345888
2022-08-31 18:14:05,690:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:14:05,691:pe_layer.py:119 -             __init__(): Using 5 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:14:05,691:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:14:05,691:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:14:05,699:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (5).
2022-08-31 18:14:09,177:main_molecules_graph_regression.py:74 -   train_val_pipeline(): Time PE:3.486387252807617
2022-08-31 18:14:09,193:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 18:14:09,193:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 18:14:09,193:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 18:14:09,195:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 18:14:22,066:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5482749789953232
2022-08-31 18:14:22,068:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.87s, LR: 0.00070, Train Loss: 1.5075, Train MAE: 1.5075,
                            Val Loss: 1.4350, Val Acc: 1.4350, Test MAE: 1.5483
2022-08-31 18:14:22,075:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 18:14:36,613:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 18:14:39,821:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 4, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 18:14:39,822:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 18:14:39,822:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:14:39,823:pe_layer.py:119 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:14:39,823:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:14:39,823:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:14:39,828:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 18:14:39,829:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 345814
2022-08-31 18:14:39,829:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:14:39,830:pe_layer.py:119 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:14:39,830:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:14:39,830:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:14:39,834:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (4).
2022-08-31 18:14:42,921:main_molecules_graph_regression.py:74 -   train_val_pipeline(): Time PE:3.0917000770568848
2022-08-31 18:14:42,935:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 18:14:42,935:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 18:14:42,935:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 18:14:42,937:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 18:14:55,710:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.2353149056434631
2022-08-31 18:14:55,711:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.77s, LR: 0.00070, Train Loss: 1.0367, Train MAE: 1.0367,
                            Val Loss: 1.1851, Val Acc: 1.1851, Test MAE: 1.2353
2022-08-31 18:14:55,717:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 18:15:08,332:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.660071961581707
2022-08-31 18:15:08,332:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.62s, LR: 0.00070, Train Loss: 0.6351, Train MAE: 0.6351,
                            Val Loss: 0.6031, Val Acc: 0.6031, Test MAE: 0.6601
2022-08-31 18:15:08,338:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-08-31 18:15:20,655:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.6226908713579178
2022-08-31 18:15:20,656:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.32s, LR: 0.00070, Train Loss: 0.6027, Train MAE: 0.6027,
                            Val Loss: 0.5853, Val Acc: 0.5853, Test MAE: 0.6227
2022-08-31 18:15:20,662:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 4/1000
2022-08-31 18:15:33,198:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.54s, LR: 0.00070, Train Loss: 0.5837, Train MAE: 0.5837,
                            Val Loss: 0.7668, Val Acc: 0.7668, Test MAE: 0.8180
2022-08-31 18:15:33,204:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 5/1000
2022-08-31 18:15:56,644:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 18:15:59,808:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 10, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 18:15:59,808:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 18:15:59,808:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:15:59,809:pe_layer.py:119 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:15:59,809:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:15:59,809:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:15:59,815:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 18:15:59,816:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 346288
2022-08-31 18:15:59,816:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:15:59,816:pe_layer.py:119 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:15:59,816:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:15:59,816:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:15:59,821:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (10).
2022-08-31 18:16:03,204:main_molecules_graph_regression.py:74 -   train_val_pipeline(): Time PE:3.388540267944336
2022-08-31 18:16:03,219:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 18:16:03,220:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 18:16:03,220:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 18:16:03,222:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 18:16:16,295:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.8603950962424278
2022-08-31 18:16:16,296:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.07s, LR: 0.00070, Train Loss: 0.9026, Train MAE: 0.9026,
                            Val Loss: 0.8385, Val Acc: 0.8385, Test MAE: 0.8604
2022-08-31 18:16:16,302:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 18:16:29,328:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.6055720970034599
2022-08-31 18:16:29,328:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.03s, LR: 0.00070, Train Loss: 0.5981, Train MAE: 0.5981,
                            Val Loss: 0.5722, Val Acc: 0.5722, Test MAE: 0.6056
2022-08-31 18:16:29,335:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-08-31 18:16:41,297:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 18:16:42,301:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 12.97s, LR: 0.00070, Train Loss: 0.5633, Train MAE: 0.5633,
                            Val Loss: 0.7390, Val Acc: 0.7390, Test MAE: 0.7798
2022-08-31 18:16:42,310:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 4/1000
2022-08-31 18:16:44,909:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 12, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 18:16:44,910:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 18:16:44,910:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:16:44,911:pe_layer.py:119 -             __init__(): Using 12 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:16:44,911:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:16:44,911:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:16:44,916:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 18:16:44,917:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 346462
2022-08-31 18:16:44,917:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 18:16:44,918:pe_layer.py:119 -             __init__(): Using 12 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 18:16:44,918:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 18:16:44,918:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 18:16:44,923:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (12).
2022-08-31 18:16:48,923:main_molecules_graph_regression.py:74 -   train_val_pipeline(): Time PE:4.00557804107666
2022-08-31 18:16:48,939:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 18:16:48,939:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 18:16:48,939:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 18:16:48,941:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 18:16:50,125:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-31 18:16:50,125:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 18:16:55,821:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.51s, LR: 0.00070, Train Loss: 0.5384, Train MAE: 0.5384,
                            Val Loss: 0.6438, Val Acc: 0.6438, Test MAE: 0.6832
2022-08-31 18:16:55,827:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 5/1000
2022-08-31 18:17:09,748:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5839930735528469
2022-08-31 18:17:09,749:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.92s, LR: 0.00070, Train Loss: 0.5159, Train MAE: 0.5159,
                            Val Loss: 0.5432, Val Acc: 0.5432, Test MAE: 0.5840
2022-08-31 18:17:09,755:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 6/1000
2022-08-31 18:17:24,888:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.558440238237381
2022-08-31 18:17:24,889:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.13s, LR: 0.00070, Train Loss: 0.4933, Train MAE: 0.4933,
                            Val Loss: 0.5371, Val Acc: 0.5371, Test MAE: 0.5584
2022-08-31 18:17:24,898:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 7/1000
2022-08-31 18:17:39,829:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.93s, LR: 0.00070, Train Loss: 0.5110, Train MAE: 0.5110,
                            Val Loss: 0.5729, Val Acc: 0.5729, Test MAE: 0.6136
2022-08-31 18:17:39,836:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 8/1000
2022-08-31 18:17:55,689:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4982875995337963
2022-08-31 18:17:55,690:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.85s, LR: 0.00070, Train Loss: 0.4637, Train MAE: 0.4637,
                            Val Loss: 0.4821, Val Acc: 0.4821, Test MAE: 0.4983
2022-08-31 18:17:55,699:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 9/1000
2022-08-31 18:18:12,351:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.47978295385837555
2022-08-31 18:18:12,351:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.65s, LR: 0.00070, Train Loss: 0.4667, Train MAE: 0.4667,
                            Val Loss: 0.4767, Val Acc: 0.4767, Test MAE: 0.4798
2022-08-31 18:18:12,359:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 10/1000
2022-08-31 18:18:28,274:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.92s, LR: 0.00070, Train Loss: 0.4471, Train MAE: 0.4471,
                            Val Loss: 0.6089, Val Acc: 0.6089, Test MAE: 0.6245
2022-08-31 18:18:28,280:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 11/1000
2022-08-31 18:18:43,458:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.18s, LR: 0.00070, Train Loss: 0.4459, Train MAE: 0.4459,
                            Val Loss: 0.5875, Val Acc: 0.5875, Test MAE: 0.6101
2022-08-31 18:18:43,465:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 12/1000
2022-08-31 18:18:59,160:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.70s, LR: 0.00070, Train Loss: 0.4473, Train MAE: 0.4473,
                            Val Loss: 0.5203, Val Acc: 0.5203, Test MAE: 0.5344
2022-08-31 18:18:59,167:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 13/1000
2022-08-31 18:19:14,735:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.57s, LR: 0.00070, Train Loss: 0.4326, Train MAE: 0.4326,
                            Val Loss: 0.6441, Val Acc: 0.6441, Test MAE: 0.6811
2022-08-31 18:19:14,740:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 14/1000
2022-08-31 18:19:26,704:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 11.96s, LR: 0.00070, Train Loss: 0.4334, Train MAE: 0.4334,
                            Val Loss: 0.5748, Val Acc: 0.5748, Test MAE: 0.5820
2022-08-31 18:19:26,710:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 15/1000
2022-08-31 18:19:41,390:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.68s, LR: 0.00070, Train Loss: 0.4319, Train MAE: 0.4319,
                            Val Loss: 0.4905, Val Acc: 0.4905, Test MAE: 0.5054
2022-08-31 18:19:41,397:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 16/1000
2022-08-31 18:19:58,221:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.82s, LR: 0.00070, Train Loss: 0.4265, Train MAE: 0.4265,
                            Val Loss: 0.5029, Val Acc: 0.5029, Test MAE: 0.5120
2022-08-31 18:19:58,227:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 17/1000
2022-08-31 18:20:15,589:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.36s, LR: 0.00070, Train Loss: 0.4306, Train MAE: 0.4306,
                            Val Loss: 0.5077, Val Acc: 0.5077, Test MAE: 0.5443
2022-08-31 18:20:15,596:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 18/1000
2022-08-31 18:20:30,726:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.459724772721529
2022-08-31 18:20:30,726:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.13s, LR: 0.00070, Train Loss: 0.4310, Train MAE: 0.4310,
                            Val Loss: 0.4490, Val Acc: 0.4490, Test MAE: 0.4597
2022-08-31 18:20:30,733:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 19/1000
2022-08-31 18:20:45,637:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.90s, LR: 0.00070, Train Loss: 0.4198, Train MAE: 0.4198,
                            Val Loss: 0.5851, Val Acc: 0.5851, Test MAE: 0.5865
2022-08-31 18:20:45,645:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 20/1000
2022-08-31 18:21:01,627:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.98s, LR: 0.00070, Train Loss: 0.4089, Train MAE: 0.4089,
                            Val Loss: 0.4731, Val Acc: 0.4731, Test MAE: 0.4869
2022-08-31 18:21:01,635:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 21/1000
2022-08-31 18:21:15,803:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.17s, LR: 0.00070, Train Loss: 0.4090, Train MAE: 0.4090,
                            Val Loss: 0.4809, Val Acc: 0.4809, Test MAE: 0.4925
2022-08-31 18:21:15,810:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 22/1000
2022-08-31 18:21:29,972:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.16s, LR: 0.00070, Train Loss: 0.3946, Train MAE: 0.3946,
                            Val Loss: 0.5773, Val Acc: 0.5773, Test MAE: 0.6042
2022-08-31 18:21:29,979:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 23/1000
2022-08-31 18:21:44,408:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.43s, LR: 0.00070, Train Loss: 0.3956, Train MAE: 0.3956,
                            Val Loss: 0.4789, Val Acc: 0.4789, Test MAE: 0.4791
2022-08-31 18:21:44,415:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 24/1000
2022-08-31 18:21:59,667:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.25s, LR: 0.00070, Train Loss: 0.3985, Train MAE: 0.3985,
                            Val Loss: 0.5745, Val Acc: 0.5745, Test MAE: 0.5913
2022-08-31 18:21:59,674:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 25/1000
2022-08-31 18:22:16,498:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.82s, LR: 0.00070, Train Loss: 0.3920, Train MAE: 0.3920,
                            Val Loss: 0.4837, Val Acc: 0.4837, Test MAE: 0.5092
2022-08-31 18:22:16,505:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 26/1000
2022-08-31 18:22:33,538:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.03s, LR: 0.00070, Train Loss: 0.3910, Train MAE: 0.3910,
                            Val Loss: 0.7537, Val Acc: 0.7537, Test MAE: 0.7339
2022-08-31 18:22:33,545:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 27/1000
2022-08-31 18:22:49,781:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00070, Train Loss: 0.3833, Train MAE: 0.3833,
                            Val Loss: 0.5037, Val Acc: 0.5037, Test MAE: 0.5294
2022-08-31 18:22:49,789:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 28/1000
2022-08-31 18:23:06,288:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.44207893311977386
2022-08-31 18:23:06,289:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.50s, LR: 0.00070, Train Loss: 0.3775, Train MAE: 0.3775,
                            Val Loss: 0.4408, Val Acc: 0.4408, Test MAE: 0.4421
2022-08-31 18:23:06,296:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 29/1000
2022-08-31 18:23:24,046:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.75s, LR: 0.00070, Train Loss: 0.3680, Train MAE: 0.3680,
                            Val Loss: 0.6283, Val Acc: 0.6283, Test MAE: 0.6505
2022-08-31 18:23:24,053:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 30/1000
2022-08-31 18:23:54,011:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 29.96s, LR: 0.00070, Train Loss: 0.3567, Train MAE: 0.3567,
                            Val Loss: 0.5086, Val Acc: 0.5086, Test MAE: 0.5069
2022-08-31 18:23:54,019:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 31/1000
2022-08-31 18:24:23,484:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4379638619720936
2022-08-31 18:24:23,485:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 29.47s, LR: 0.00070, Train Loss: 0.3663, Train MAE: 0.3663,
                            Val Loss: 0.4456, Val Acc: 0.4456, Test MAE: 0.4380
2022-08-31 18:24:23,495:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 32/1000
2022-08-31 18:24:52,912:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.3929077498614788
2022-08-31 18:24:52,913:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 29.42s, LR: 0.00070, Train Loss: 0.3550, Train MAE: 0.3550,
                            Val Loss: 0.4118, Val Acc: 0.4118, Test MAE: 0.3929
2022-08-31 18:24:52,920:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 33/1000
2022-08-31 18:25:23,634:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 30.71s, LR: 0.00070, Train Loss: 0.3294, Train MAE: 0.3294,
                            Val Loss: 0.4192, Val Acc: 0.4192, Test MAE: 0.3967
2022-08-31 18:25:23,640:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 34/1000
2022-08-31 18:25:53,490:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 29.85s, LR: 0.00070, Train Loss: 0.3491, Train MAE: 0.3491,
                            Val Loss: 0.4547, Val Acc: 0.4547, Test MAE: 0.4592
2022-08-31 18:25:53,498:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 35/1000
2022-08-31 18:26:24,163:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 30.67s, LR: 0.00070, Train Loss: 0.3484, Train MAE: 0.3484,
                            Val Loss: 0.4283, Val Acc: 0.4283, Test MAE: 0.4207
2022-08-31 18:26:24,170:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 36/1000
2022-08-31 18:26:47,971:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.80s, LR: 0.00070, Train Loss: 0.3422, Train MAE: 0.3422,
                            Val Loss: 0.5012, Val Acc: 0.5012, Test MAE: 0.5079
2022-08-31 18:26:47,978:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 37/1000
2022-08-31 18:27:05,427:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.45s, LR: 0.00070, Train Loss: 0.3428, Train MAE: 0.3428,
                            Val Loss: 0.5895, Val Acc: 0.5895, Test MAE: 0.5712
2022-08-31 18:27:05,434:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 38/1000
2022-08-31 18:27:21,654:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.3898276574909687
2022-08-31 18:27:21,655:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00070, Train Loss: 0.3394, Train MAE: 0.3394,
                            Val Loss: 0.4071, Val Acc: 0.4071, Test MAE: 0.3898
2022-08-31 18:27:21,662:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 39/1000
2022-08-31 18:27:37,703:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.04s, LR: 0.00070, Train Loss: 0.3259, Train MAE: 0.3259,
                            Val Loss: 0.4980, Val Acc: 0.4980, Test MAE: 0.4940
2022-08-31 18:27:37,709:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 40/1000
2022-08-31 18:27:53,975:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.27s, LR: 0.00070, Train Loss: 0.3109, Train MAE: 0.3109,
                            Val Loss: 0.5436, Val Acc: 0.5436, Test MAE: 0.5239
2022-08-31 18:27:53,981:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 41/1000
2022-08-31 18:28:11,950:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.38674356788396835
2022-08-31 18:28:11,951:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.97s, LR: 0.00070, Train Loss: 0.3071, Train MAE: 0.3071,
                            Val Loss: 0.4094, Val Acc: 0.4094, Test MAE: 0.3867
2022-08-31 18:28:11,958:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 42/1000
2022-08-31 18:28:30,240:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.28s, LR: 0.00070, Train Loss: 0.2983, Train MAE: 0.2983,
                            Val Loss: 0.3937, Val Acc: 0.3937, Test MAE: 0.3911
2022-08-31 18:28:30,250:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 43/1000
2022-08-31 18:28:48,721:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.36389585584402084
2022-08-31 18:28:48,722:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.47s, LR: 0.00070, Train Loss: 0.3139, Train MAE: 0.3139,
                            Val Loss: 0.3702, Val Acc: 0.3702, Test MAE: 0.3639
2022-08-31 18:28:48,730:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 44/1000
2022-08-31 18:29:06,506:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.78s, LR: 0.00070, Train Loss: 0.3061, Train MAE: 0.3061,
                            Val Loss: 0.4457, Val Acc: 0.4457, Test MAE: 0.4047
2022-08-31 18:29:06,524:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 45/1000
2022-08-31 18:29:23,672:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.15s, LR: 0.00070, Train Loss: 0.3048, Train MAE: 0.3048,
                            Val Loss: 0.4209, Val Acc: 0.4209, Test MAE: 0.4165
2022-08-31 18:29:23,679:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 46/1000
2022-08-31 18:29:39,705:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.03s, LR: 0.00070, Train Loss: 0.3049, Train MAE: 0.3049,
                            Val Loss: 0.4034, Val Acc: 0.4034, Test MAE: 0.3704
2022-08-31 18:29:39,712:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 47/1000
2022-08-31 18:29:56,453:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.74s, LR: 0.00070, Train Loss: 0.3103, Train MAE: 0.3103,
                            Val Loss: 0.5131, Val Acc: 0.5131, Test MAE: 0.5059
2022-08-31 18:29:56,461:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 48/1000
2022-08-31 18:30:14,519:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.06s, LR: 0.00070, Train Loss: 0.2871, Train MAE: 0.2871,
                            Val Loss: 0.3964, Val Acc: 0.3964, Test MAE: 0.3825
2022-08-31 18:30:14,526:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 49/1000
2022-08-31 18:30:32,672:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.15s, LR: 0.00070, Train Loss: 0.2911, Train MAE: 0.2911,
                            Val Loss: 0.5250, Val Acc: 0.5250, Test MAE: 0.5232
2022-08-31 18:30:32,680:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 50/1000
2022-08-31 18:30:50,479:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.80s, LR: 0.00070, Train Loss: 0.2853, Train MAE: 0.2853,
                            Val Loss: 0.4301, Val Acc: 0.4301, Test MAE: 0.4233
2022-08-31 18:30:50,486:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 51/1000
2022-08-31 18:31:08,931:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.44s, LR: 0.00070, Train Loss: 0.2882, Train MAE: 0.2882,
                            Val Loss: 0.3709, Val Acc: 0.3709, Test MAE: 0.3640
2022-08-31 18:31:08,940:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 52/1000
2022-08-31 18:31:26,874:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.3343014642596245
2022-08-31 18:31:26,874:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.93s, LR: 0.00070, Train Loss: 0.2892, Train MAE: 0.2892,
                            Val Loss: 0.3615, Val Acc: 0.3615, Test MAE: 0.3343
2022-08-31 18:31:26,881:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 53/1000
2022-08-31 18:31:44,240:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.36s, LR: 0.00070, Train Loss: 0.2720, Train MAE: 0.2720,
                            Val Loss: 0.4214, Val Acc: 0.4214, Test MAE: 0.3981
2022-08-31 18:31:44,248:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 54/1000
2022-08-31 18:32:02,653:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.40s, LR: 0.00070, Train Loss: 0.2739, Train MAE: 0.2739,
                            Val Loss: 0.4074, Val Acc: 0.4074, Test MAE: 0.3842
2022-08-31 18:32:02,664:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 55/1000
2022-08-31 18:32:20,453:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.79s, LR: 0.00070, Train Loss: 0.2804, Train MAE: 0.2804,
                            Val Loss: 0.4171, Val Acc: 0.4171, Test MAE: 0.3996
2022-08-31 18:32:20,461:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 56/1000
2022-08-31 18:32:38,009:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.55s, LR: 0.00070, Train Loss: 0.2788, Train MAE: 0.2788,
                            Val Loss: 0.3853, Val Acc: 0.3853, Test MAE: 0.3359
2022-08-31 18:32:38,018:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 57/1000
2022-08-31 18:32:55,655:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.64s, LR: 0.00070, Train Loss: 0.2650, Train MAE: 0.2650,
                            Val Loss: 0.3634, Val Acc: 0.3634, Test MAE: 0.3419
2022-08-31 18:32:55,663:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 58/1000
2022-08-31 18:33:12,851:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.19s, LR: 0.00070, Train Loss: 0.2711, Train MAE: 0.2711,
                            Val Loss: 0.5425, Val Acc: 0.5425, Test MAE: 0.5152
2022-08-31 18:33:12,858:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 59/1000
2022-08-31 18:33:30,198:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.34s, LR: 0.00070, Train Loss: 0.2716, Train MAE: 0.2716,
                            Val Loss: 0.3773, Val Acc: 0.3773, Test MAE: 0.3518
2022-08-31 18:33:30,205:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 60/1000
2022-08-31 18:33:48,409:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.20s, LR: 0.00070, Train Loss: 0.2680, Train MAE: 0.2680,
                            Val Loss: 0.3736, Val Acc: 0.3736, Test MAE: 0.3630
2022-08-31 18:33:48,416:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 61/1000
2022-08-31 18:34:06,308:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.89s, LR: 0.00070, Train Loss: 0.2572, Train MAE: 0.2572,
                            Val Loss: 0.3761, Val Acc: 0.3761, Test MAE: 0.3662
2022-08-31 18:34:06,316:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 62/1000
2022-08-31 18:34:23,850:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.53s, LR: 0.00070, Train Loss: 0.2636, Train MAE: 0.2636,
                            Val Loss: 0.3742, Val Acc: 0.3742, Test MAE: 0.3459
2022-08-31 18:34:23,858:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 63/1000
2022-08-31 18:34:41,479:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.62s, LR: 0.00070, Train Loss: 0.2775, Train MAE: 0.2775,
                            Val Loss: 0.3792, Val Acc: 0.3792, Test MAE: 0.3599
2022-08-31 18:34:41,487:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 64/1000
2022-08-31 18:34:59,372:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.89s, LR: 0.00070, Train Loss: 0.2661, Train MAE: 0.2661,
                            Val Loss: 0.4047, Val Acc: 0.4047, Test MAE: 0.3959
2022-08-31 18:34:59,379:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 65/1000
2022-08-31 18:35:16,116:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.74s, LR: 0.00070, Train Loss: 0.2668, Train MAE: 0.2668,
                            Val Loss: 0.3736, Val Acc: 0.3736, Test MAE: 0.3388
2022-08-31 18:35:16,123:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 66/1000
2022-08-31 18:35:33,592:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.29508505016565323
2022-08-31 18:35:33,593:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.47s, LR: 0.00070, Train Loss: 0.2605, Train MAE: 0.2605,
                            Val Loss: 0.3418, Val Acc: 0.3418, Test MAE: 0.2951
2022-08-31 18:35:33,600:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 67/1000
2022-08-31 18:35:51,477:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.88s, LR: 0.00070, Train Loss: 0.2446, Train MAE: 0.2446,
                            Val Loss: 0.3583, Val Acc: 0.3583, Test MAE: 0.3343
2022-08-31 18:35:51,487:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 68/1000
2022-08-31 18:36:09,220:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.73s, LR: 0.00070, Train Loss: 0.2554, Train MAE: 0.2554,
                            Val Loss: 0.3817, Val Acc: 0.3817, Test MAE: 0.3356
2022-08-31 18:36:09,228:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 69/1000
2022-08-31 18:36:27,407:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.18s, LR: 0.00070, Train Loss: 0.2489, Train MAE: 0.2489,
                            Val Loss: 0.3436, Val Acc: 0.3436, Test MAE: 0.3084
2022-08-31 18:36:27,416:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 70/1000
2022-08-31 18:36:45,362:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.95s, LR: 0.00070, Train Loss: 0.2395, Train MAE: 0.2395,
                            Val Loss: 0.3553, Val Acc: 0.3553, Test MAE: 0.3228
2022-08-31 18:36:45,369:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 71/1000
2022-08-31 18:37:03,495:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.13s, LR: 0.00070, Train Loss: 0.2342, Train MAE: 0.2342,
                            Val Loss: 0.3419, Val Acc: 0.3419, Test MAE: 0.3051
2022-08-31 18:37:03,502:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 72/1000
2022-08-31 18:37:21,033:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.53s, LR: 0.00070, Train Loss: 0.2439, Train MAE: 0.2439,
                            Val Loss: 0.3592, Val Acc: 0.3592, Test MAE: 0.3063
2022-08-31 18:37:21,041:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 73/1000
2022-08-31 18:37:38,524:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.48s, LR: 0.00070, Train Loss: 0.2378, Train MAE: 0.2378,
                            Val Loss: 0.3635, Val Acc: 0.3635, Test MAE: 0.3185
2022-08-31 18:37:38,531:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 74/1000
2022-08-31 18:37:56,143:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.61s, LR: 0.00070, Train Loss: 0.2488, Train MAE: 0.2488,
                            Val Loss: 0.3727, Val Acc: 0.3727, Test MAE: 0.3368
2022-08-31 18:37:56,152:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 75/1000
2022-08-31 18:38:13,768:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.62s, LR: 0.00070, Train Loss: 0.2381, Train MAE: 0.2381,
                            Val Loss: 0.3484, Val Acc: 0.3484, Test MAE: 0.3092
2022-08-31 18:38:13,775:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 76/1000
2022-08-31 18:38:31,555:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.78s, LR: 0.00070, Train Loss: 0.2513, Train MAE: 0.2513,
                            Val Loss: 0.4723, Val Acc: 0.4723, Test MAE: 0.4343
2022-08-31 18:38:31,563:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 77/1000
2022-08-31 18:38:49,328:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.76s, LR: 0.00070, Train Loss: 0.2427, Train MAE: 0.2427,
                            Val Loss: 0.3993, Val Acc: 0.3993, Test MAE: 0.3655
2022-08-31 18:38:49,335:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 78/1000
2022-08-31 18:39:07,508:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.17s, LR: 0.00070, Train Loss: 0.2352, Train MAE: 0.2352,
                            Val Loss: 0.3594, Val Acc: 0.3594, Test MAE: 0.3099
2022-08-31 18:39:07,515:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 79/1000
2022-08-31 18:39:25,518:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.00s, LR: 0.00070, Train Loss: 0.2310, Train MAE: 0.2310,
                            Val Loss: 0.3524, Val Acc: 0.3524, Test MAE: 0.3311
2022-08-31 18:39:25,526:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 80/1000
2022-08-31 18:39:43,591:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.07s, LR: 0.00070, Train Loss: 0.2456, Train MAE: 0.2456,
                            Val Loss: 0.3735, Val Acc: 0.3735, Test MAE: 0.3339
2022-08-31 18:39:43,599:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 81/1000
2022-08-31 18:40:01,547:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.95s, LR: 0.00070, Train Loss: 0.2325, Train MAE: 0.2325,
                            Val Loss: 0.3646, Val Acc: 0.3646, Test MAE: 0.3238
2022-08-31 18:40:01,554:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 82/1000
2022-08-31 18:40:19,508:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.95s, LR: 0.00070, Train Loss: 0.2332, Train MAE: 0.2332,
                            Val Loss: 0.3772, Val Acc: 0.3772, Test MAE: 0.3447
2022-08-31 18:40:19,516:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 83/1000
2022-08-31 18:40:37,524:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.01s, LR: 0.00035, Train Loss: 0.2132, Train MAE: 0.2132,
                            Val Loss: 0.3450, Val Acc: 0.3450, Test MAE: 0.3147
2022-08-31 18:40:37,535:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 84/1000
2022-08-31 18:40:55,308:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.28024648502469063
2022-08-31 18:40:55,308:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.77s, LR: 0.00035, Train Loss: 0.2072, Train MAE: 0.2072,
                            Val Loss: 0.3253, Val Acc: 0.3253, Test MAE: 0.2802
2022-08-31 18:40:55,316:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 85/1000
2022-08-31 18:41:13,703:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.39s, LR: 0.00035, Train Loss: 0.1928, Train MAE: 0.1928,
                            Val Loss: 0.3245, Val Acc: 0.3245, Test MAE: 0.2821
2022-08-31 18:41:13,710:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 86/1000
2022-08-31 18:41:31,659:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.95s, LR: 0.00035, Train Loss: 0.1849, Train MAE: 0.1849,
                            Val Loss: 0.3323, Val Acc: 0.3323, Test MAE: 0.2896
2022-08-31 18:41:31,667:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 87/1000
2022-08-31 18:41:49,637:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.97s, LR: 0.00035, Train Loss: 0.1872, Train MAE: 0.1872,
                            Val Loss: 0.3545, Val Acc: 0.3545, Test MAE: 0.3074
2022-08-31 18:41:49,645:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 88/1000
2022-08-31 18:42:07,446:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.80s, LR: 0.00035, Train Loss: 0.1846, Train MAE: 0.1846,
                            Val Loss: 0.3391, Val Acc: 0.3391, Test MAE: 0.2938
2022-08-31 18:42:07,454:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 89/1000
2022-08-31 18:42:25,540:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.09s, LR: 0.00035, Train Loss: 0.1841, Train MAE: 0.1841,
                            Val Loss: 0.3366, Val Acc: 0.3366, Test MAE: 0.2865
2022-08-31 18:42:25,548:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 90/1000
2022-08-31 18:42:44,152:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.60s, LR: 0.00035, Train Loss: 0.1751, Train MAE: 0.1751,
                            Val Loss: 0.3432, Val Acc: 0.3432, Test MAE: 0.3046
2022-08-31 18:42:44,160:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 91/1000
2022-08-31 18:43:02,533:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.37s, LR: 0.00035, Train Loss: 0.1838, Train MAE: 0.1838,
                            Val Loss: 0.3317, Val Acc: 0.3317, Test MAE: 0.2991
2022-08-31 18:43:02,546:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 92/1000
2022-08-31 18:43:20,197:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.65s, LR: 0.00035, Train Loss: 0.1751, Train MAE: 0.1751,
                            Val Loss: 0.3223, Val Acc: 0.3223, Test MAE: 0.2937
2022-08-31 18:43:20,205:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 93/1000
2022-08-31 18:43:37,928:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.72s, LR: 0.00035, Train Loss: 0.1814, Train MAE: 0.1814,
                            Val Loss: 0.3356, Val Acc: 0.3356, Test MAE: 0.2966
2022-08-31 18:43:37,937:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 94/1000
2022-08-31 18:43:55,493:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.56s, LR: 0.00035, Train Loss: 0.1785, Train MAE: 0.1785,
                            Val Loss: 0.3389, Val Acc: 0.3389, Test MAE: 0.2871
2022-08-31 18:43:55,500:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 95/1000
2022-08-31 18:44:13,404:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.90s, LR: 0.00035, Train Loss: 0.1767, Train MAE: 0.1767,
                            Val Loss: 0.3310, Val Acc: 0.3310, Test MAE: 0.2853
2022-08-31 18:44:13,411:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 96/1000
2022-08-31 18:44:31,559:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.15s, LR: 0.00035, Train Loss: 0.1821, Train MAE: 0.1821,
                            Val Loss: 0.3229, Val Acc: 0.3229, Test MAE: 0.2825
2022-08-31 18:44:31,568:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 97/1000
2022-08-31 18:44:49,277:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.71s, LR: 0.00035, Train Loss: 0.1817, Train MAE: 0.1817,
                            Val Loss: 0.3333, Val Acc: 0.3333, Test MAE: 0.2835
2022-08-31 18:44:49,285:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 98/1000
2022-08-31 18:45:07,194:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.91s, LR: 0.00035, Train Loss: 0.1798, Train MAE: 0.1798,
                            Val Loss: 0.3274, Val Acc: 0.3274, Test MAE: 0.2879
2022-08-31 18:45:07,201:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 99/1000
2022-08-31 18:45:24,984:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.78s, LR: 0.00035, Train Loss: 0.1719, Train MAE: 0.1719,
                            Val Loss: 0.3253, Val Acc: 0.3253, Test MAE: 0.2899
2022-08-31 18:45:24,991:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 100/1000
2022-08-31 18:45:42,701:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.71s, LR: 0.00035, Train Loss: 0.1714, Train MAE: 0.1714,
                            Val Loss: 0.3301, Val Acc: 0.3301, Test MAE: 0.2933
2022-08-31 18:45:42,709:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 101/1000
2022-08-31 18:46:00,370:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.66s, LR: 0.00035, Train Loss: 0.1720, Train MAE: 0.1720,
                            Val Loss: 0.3308, Val Acc: 0.3308, Test MAE: 0.2814
2022-08-31 18:46:00,378:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 102/1000
2022-08-31 18:46:18,025:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.65s, LR: 0.00035, Train Loss: 0.1792, Train MAE: 0.1792,
                            Val Loss: 0.3411, Val Acc: 0.3411, Test MAE: 0.3001
2022-08-31 18:46:18,032:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 103/1000
2022-08-31 18:46:35,659:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.63s, LR: 0.00035, Train Loss: 0.1844, Train MAE: 0.1844,
                            Val Loss: 0.3417, Val Acc: 0.3417, Test MAE: 0.2901
2022-08-31 18:46:35,666:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 104/1000
2022-08-31 18:46:53,456:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.79s, LR: 0.00035, Train Loss: 0.1837, Train MAE: 0.1837,
                            Val Loss: 0.3434, Val Acc: 0.3434, Test MAE: 0.3002
2022-08-31 18:46:53,465:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 105/1000
2022-08-31 18:47:11,204:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.2784266024827957
2022-08-31 18:47:11,205:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.74s, LR: 0.00035, Train Loss: 0.1616, Train MAE: 0.1616,
                            Val Loss: 0.3238, Val Acc: 0.3238, Test MAE: 0.2784
2022-08-31 18:47:11,213:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 106/1000
2022-08-31 18:47:29,315:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.10s, LR: 0.00035, Train Loss: 0.1668, Train MAE: 0.1668,
                            Val Loss: 0.3649, Val Acc: 0.3649, Test MAE: 0.3273
2022-08-31 18:47:29,324:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 107/1000
2022-08-31 18:47:47,210:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.89s, LR: 0.00035, Train Loss: 0.1747, Train MAE: 0.1747,
                            Val Loss: 0.3399, Val Acc: 0.3399, Test MAE: 0.2949
2022-08-31 18:47:47,217:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 108/1000
2022-08-31 18:48:05,070:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.85s, LR: 0.00035, Train Loss: 0.1713, Train MAE: 0.1713,
                            Val Loss: 0.3382, Val Acc: 0.3382, Test MAE: 0.2878
2022-08-31 18:48:05,079:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 109/1000
2022-08-31 18:48:22,642:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.56s, LR: 0.00017, Train Loss: 0.1528, Train MAE: 0.1528,
                            Val Loss: 0.3331, Val Acc: 0.3331, Test MAE: 0.2847
2022-08-31 18:48:22,650:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 110/1000
2022-08-31 18:48:40,602:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.95s, LR: 0.00017, Train Loss: 0.1624, Train MAE: 0.1624,
                            Val Loss: 0.3353, Val Acc: 0.3353, Test MAE: 0.2896
2022-08-31 18:48:40,609:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 111/1000
2022-08-31 18:48:58,329:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.72s, LR: 0.00017, Train Loss: 0.1489, Train MAE: 0.1489,
                            Val Loss: 0.3449, Val Acc: 0.3449, Test MAE: 0.2983
2022-08-31 18:48:58,337:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 112/1000
2022-08-31 18:49:15,782:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.45s, LR: 0.00017, Train Loss: 0.1455, Train MAE: 0.1455,
                            Val Loss: 0.3428, Val Acc: 0.3428, Test MAE: 0.3042
2022-08-31 18:49:15,789:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 113/1000
2022-08-31 18:49:33,616:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.83s, LR: 0.00017, Train Loss: 0.1517, Train MAE: 0.1517,
                            Val Loss: 0.3316, Val Acc: 0.3316, Test MAE: 0.2852
2022-08-31 18:49:33,623:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 114/1000
2022-08-31 18:49:51,295:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.67s, LR: 0.00017, Train Loss: 0.1373, Train MAE: 0.1373,
                            Val Loss: 0.3331, Val Acc: 0.3331, Test MAE: 0.2895
2022-08-31 18:49:51,304:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 115/1000
2022-08-31 18:50:08,929:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.62s, LR: 0.00017, Train Loss: 0.1327, Train MAE: 0.1327,
                            Val Loss: 0.3300, Val Acc: 0.3300, Test MAE: 0.2834
2022-08-31 18:50:08,937:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 116/1000
2022-08-31 18:50:26,872:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.93s, LR: 0.00017, Train Loss: 0.1399, Train MAE: 0.1399,
                            Val Loss: 0.3339, Val Acc: 0.3339, Test MAE: 0.2954
2022-08-31 18:50:26,879:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 117/1000
2022-08-31 18:50:44,811:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.93s, LR: 0.00017, Train Loss: 0.1388, Train MAE: 0.1388,
                            Val Loss: 0.3452, Val Acc: 0.3452, Test MAE: 0.3029
2022-08-31 18:50:44,818:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 118/1000
2022-08-31 18:51:02,450:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.63s, LR: 0.00017, Train Loss: 0.1344, Train MAE: 0.1344,
                            Val Loss: 0.3282, Val Acc: 0.3282, Test MAE: 0.2810
2022-08-31 18:51:02,458:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 119/1000
2022-08-31 18:51:20,440:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.98s, LR: 0.00017, Train Loss: 0.1393, Train MAE: 0.1393,
                            Val Loss: 0.3254, Val Acc: 0.3254, Test MAE: 0.2859
2022-08-31 18:51:20,447:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 120/1000
2022-08-31 18:51:38,326:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.88s, LR: 0.00017, Train Loss: 0.1293, Train MAE: 0.1293,
                            Val Loss: 0.3267, Val Acc: 0.3267, Test MAE: 0.2844
2022-08-31 18:51:38,334:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 121/1000
2022-08-31 18:51:56,120:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.79s, LR: 0.00017, Train Loss: 0.1295, Train MAE: 0.1295,
                            Val Loss: 0.3306, Val Acc: 0.3306, Test MAE: 0.2882
2022-08-31 18:51:56,128:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 122/1000
2022-08-31 18:52:13,733:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.60s, LR: 0.00017, Train Loss: 0.1402, Train MAE: 0.1402,
                            Val Loss: 0.3335, Val Acc: 0.3335, Test MAE: 0.2903
2022-08-31 18:52:13,741:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 123/1000
2022-08-31 18:52:31,473:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.73s, LR: 0.00017, Train Loss: 0.1363, Train MAE: 0.1363,
                            Val Loss: 0.3408, Val Acc: 0.3408, Test MAE: 0.2998
2022-08-31 18:52:31,480:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 124/1000
2022-08-31 18:52:49,532:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.05s, LR: 0.00017, Train Loss: 0.1356, Train MAE: 0.1356,
                            Val Loss: 0.3375, Val Acc: 0.3375, Test MAE: 0.2971
2022-08-31 18:52:49,539:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 125/1000
2022-08-31 18:53:07,398:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.86s, LR: 0.00009, Train Loss: 0.1261, Train MAE: 0.1261,
                            Val Loss: 0.3251, Val Acc: 0.3251, Test MAE: 0.2878
2022-08-31 18:53:07,407:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 126/1000
2022-08-31 18:53:25,241:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.83s, LR: 0.00009, Train Loss: 0.1132, Train MAE: 0.1132,
                            Val Loss: 0.3255, Val Acc: 0.3255, Test MAE: 0.2877
2022-08-31 18:53:25,248:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 127/1000
2022-08-31 18:53:43,127:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.88s, LR: 0.00009, Train Loss: 0.1256, Train MAE: 0.1256,
                            Val Loss: 0.3316, Val Acc: 0.3316, Test MAE: 0.2970
2022-08-31 18:53:43,135:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 128/1000
2022-08-31 18:54:00,827:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.69s, LR: 0.00009, Train Loss: 0.1290, Train MAE: 0.1290,
                            Val Loss: 0.3273, Val Acc: 0.3273, Test MAE: 0.2835
2022-08-31 18:54:00,835:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 129/1000
2022-08-31 18:54:18,802:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.97s, LR: 0.00009, Train Loss: 0.1201, Train MAE: 0.1201,
                            Val Loss: 0.3294, Val Acc: 0.3294, Test MAE: 0.2846
2022-08-31 18:54:18,810:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 130/1000
2022-08-31 18:54:36,295:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.49s, LR: 0.00009, Train Loss: 0.1337, Train MAE: 0.1337,
                            Val Loss: 0.3318, Val Acc: 0.3318, Test MAE: 0.2878
2022-08-31 18:54:36,303:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 131/1000
2022-08-31 18:54:53,798:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.50s, LR: 0.00009, Train Loss: 0.1119, Train MAE: 0.1119,
                            Val Loss: 0.3294, Val Acc: 0.3294, Test MAE: 0.2856
2022-08-31 18:54:53,806:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 132/1000
2022-08-31 18:55:11,551:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.75s, LR: 0.00009, Train Loss: 0.1206, Train MAE: 0.1206,
                            Val Loss: 0.3263, Val Acc: 0.3263, Test MAE: 0.2843
2022-08-31 18:55:11,559:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 133/1000
2022-08-31 18:55:29,001:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.44s, LR: 0.00009, Train Loss: 0.1272, Train MAE: 0.1272,
                            Val Loss: 0.3328, Val Acc: 0.3328, Test MAE: 0.2928
2022-08-31 18:55:29,010:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 134/1000
2022-08-31 18:55:46,929:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.92s, LR: 0.00009, Train Loss: 0.1226, Train MAE: 0.1226,
                            Val Loss: 0.3334, Val Acc: 0.3334, Test MAE: 0.2893
2022-08-31 18:55:46,937:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 135/1000
2022-08-31 18:56:04,926:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.99s, LR: 0.00009, Train Loss: 0.1223, Train MAE: 0.1223,
                            Val Loss: 0.3344, Val Acc: 0.3344, Test MAE: 0.2865
2022-08-31 18:56:04,934:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 136/1000
2022-08-31 18:56:22,731:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.80s, LR: 0.00009, Train Loss: 0.1245, Train MAE: 0.1245,
                            Val Loss: 0.3328, Val Acc: 0.3328, Test MAE: 0.2887
2022-08-31 18:56:22,738:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 137/1000
2022-08-31 18:56:40,450:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.71s, LR: 0.00009, Train Loss: 0.1251, Train MAE: 0.1251,
                            Val Loss: 0.3296, Val Acc: 0.3296, Test MAE: 0.2908
2022-08-31 18:56:40,457:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 138/1000
2022-08-31 18:56:58,342:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.89s, LR: 0.00009, Train Loss: 0.1084, Train MAE: 0.1084,
                            Val Loss: 0.3318, Val Acc: 0.3318, Test MAE: 0.2905
2022-08-31 18:56:58,350:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 139/1000
2022-08-31 18:57:17,027:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.68s, LR: 0.00009, Train Loss: 0.1192, Train MAE: 0.1192,
                            Val Loss: 0.3327, Val Acc: 0.3327, Test MAE: 0.2941
2022-08-31 18:57:17,036:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 140/1000
2022-08-31 18:57:35,605:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.57s, LR: 0.00009, Train Loss: 0.1122, Train MAE: 0.1122,
                            Val Loss: 0.3414, Val Acc: 0.3414, Test MAE: 0.2992
2022-08-31 18:57:35,613:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 141/1000
2022-08-31 18:57:53,674:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.06s, LR: 0.00004, Train Loss: 0.1117, Train MAE: 0.1117,
                            Val Loss: 0.3294, Val Acc: 0.3294, Test MAE: 0.2877
2022-08-31 18:57:53,682:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 142/1000
2022-08-31 18:58:11,402:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.72s, LR: 0.00004, Train Loss: 0.1025, Train MAE: 0.1025,
                            Val Loss: 0.3289, Val Acc: 0.3289, Test MAE: 0.2895
2022-08-31 18:58:11,408:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 143/1000
2022-08-31 18:58:28,817:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.41s, LR: 0.00004, Train Loss: 0.1185, Train MAE: 0.1185,
                            Val Loss: 0.3305, Val Acc: 0.3305, Test MAE: 0.2879
2022-08-31 18:58:28,824:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 144/1000
2022-08-31 18:58:46,966:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.14s, LR: 0.00004, Train Loss: 0.1042, Train MAE: 0.1042,
                            Val Loss: 0.3300, Val Acc: 0.3300, Test MAE: 0.2871
2022-08-31 18:58:46,973:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 145/1000
2022-08-31 18:59:04,629:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.66s, LR: 0.00004, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.3337, Val Acc: 0.3337, Test MAE: 0.2912
2022-08-31 18:59:04,638:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 146/1000
2022-08-31 18:59:22,221:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.58s, LR: 0.00004, Train Loss: 0.1105, Train MAE: 0.1105,
                            Val Loss: 0.3352, Val Acc: 0.3352, Test MAE: 0.2902
2022-08-31 18:59:22,230:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 147/1000
2022-08-31 18:59:40,154:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.92s, LR: 0.00004, Train Loss: 0.0984, Train MAE: 0.0984,
                            Val Loss: 0.3300, Val Acc: 0.3300, Test MAE: 0.2885
2022-08-31 18:59:40,162:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 148/1000
2022-08-31 18:59:59,124:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.96s, LR: 0.00004, Train Loss: 0.1100, Train MAE: 0.1100,
                            Val Loss: 0.3286, Val Acc: 0.3286, Test MAE: 0.2910
2022-08-31 18:59:59,132:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 149/1000
2022-08-31 19:00:17,376:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.24s, LR: 0.00004, Train Loss: 0.1197, Train MAE: 0.1197,
                            Val Loss: 0.3336, Val Acc: 0.3336, Test MAE: 0.2881
2022-08-31 19:00:17,386:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 150/1000
2022-08-31 19:00:36,292:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.91s, LR: 0.00004, Train Loss: 0.1098, Train MAE: 0.1098,
                            Val Loss: 0.3324, Val Acc: 0.3324, Test MAE: 0.2930
2022-08-31 19:00:36,303:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 151/1000
2022-08-31 19:00:54,724:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.42s, LR: 0.00004, Train Loss: 0.1140, Train MAE: 0.1140,
                            Val Loss: 0.3338, Val Acc: 0.3338, Test MAE: 0.2893
2022-08-31 19:00:54,733:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 152/1000
2022-08-31 19:01:13,142:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.41s, LR: 0.00004, Train Loss: 0.1062, Train MAE: 0.1062,
                            Val Loss: 0.3419, Val Acc: 0.3419, Test MAE: 0.2964
2022-08-31 19:01:13,151:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 153/1000
2022-08-31 19:01:32,141:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.99s, LR: 0.00004, Train Loss: 0.1052, Train MAE: 0.1052,
                            Val Loss: 0.3361, Val Acc: 0.3361, Test MAE: 0.2961
2022-08-31 19:01:32,149:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 154/1000
2022-08-31 19:01:51,340:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.19s, LR: 0.00004, Train Loss: 0.1078, Train MAE: 0.1078,
                            Val Loss: 0.3352, Val Acc: 0.3352, Test MAE: 0.2930
2022-08-31 19:01:51,352:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 155/1000
2022-08-31 19:02:11,337:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.98s, LR: 0.00004, Train Loss: 0.1067, Train MAE: 0.1067,
                            Val Loss: 0.3397, Val Acc: 0.3397, Test MAE: 0.2929
2022-08-31 19:02:11,347:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 156/1000
2022-08-31 19:02:30,402:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.05s, LR: 0.00004, Train Loss: 0.1015, Train MAE: 0.1015,
                            Val Loss: 0.3350, Val Acc: 0.3350, Test MAE: 0.2900
2022-08-31 19:02:30,410:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 157/1000
2022-08-31 19:02:49,152:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.74s, LR: 0.00002, Train Loss: 0.1050, Train MAE: 0.1050,
                            Val Loss: 0.3397, Val Acc: 0.3397, Test MAE: 0.2966
2022-08-31 19:02:49,160:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 158/1000
2022-08-31 19:03:08,733:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.57s, LR: 0.00002, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.3343, Val Acc: 0.3343, Test MAE: 0.2907
2022-08-31 19:03:08,741:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 159/1000
2022-08-31 19:03:29,030:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.29s, LR: 0.00002, Train Loss: 0.0990, Train MAE: 0.0990,
                            Val Loss: 0.3353, Val Acc: 0.3353, Test MAE: 0.2904
2022-08-31 19:03:29,040:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 160/1000
2022-08-31 19:03:48,333:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.29s, LR: 0.00002, Train Loss: 0.0948, Train MAE: 0.0948,
                            Val Loss: 0.3329, Val Acc: 0.3329, Test MAE: 0.2920
2022-08-31 19:03:48,343:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 161/1000
2022-08-31 19:04:07,764:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.42s, LR: 0.00002, Train Loss: 0.0991, Train MAE: 0.0991,
                            Val Loss: 0.3332, Val Acc: 0.3332, Test MAE: 0.2909
2022-08-31 19:04:07,771:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 162/1000
2022-08-31 19:04:27,928:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.16s, LR: 0.00002, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.3348, Val Acc: 0.3348, Test MAE: 0.2913
2022-08-31 19:04:27,937:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 163/1000
2022-08-31 19:04:47,357:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.42s, LR: 0.00002, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.3359, Val Acc: 0.3359, Test MAE: 0.2949
2022-08-31 19:04:47,365:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 164/1000
2022-08-31 19:05:06,759:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.39s, LR: 0.00002, Train Loss: 0.1020, Train MAE: 0.1020,
                            Val Loss: 0.3379, Val Acc: 0.3379, Test MAE: 0.2929
2022-08-31 19:05:06,766:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 165/1000
2022-08-31 19:05:26,021:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.25s, LR: 0.00002, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.3371, Val Acc: 0.3371, Test MAE: 0.2936
2022-08-31 19:05:26,030:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 166/1000
2022-08-31 19:05:45,446:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.42s, LR: 0.00002, Train Loss: 0.0948, Train MAE: 0.0948,
                            Val Loss: 0.3373, Val Acc: 0.3373, Test MAE: 0.2941
2022-08-31 19:05:45,453:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 167/1000
2022-08-31 19:06:05,256:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.80s, LR: 0.00002, Train Loss: 0.0985, Train MAE: 0.0985,
                            Val Loss: 0.3350, Val Acc: 0.3350, Test MAE: 0.2907
2022-08-31 19:06:05,264:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 168/1000
2022-08-31 19:06:24,875:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.61s, LR: 0.00002, Train Loss: 0.0956, Train MAE: 0.0956,
                            Val Loss: 0.3351, Val Acc: 0.3351, Test MAE: 0.2911
2022-08-31 19:06:24,883:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 169/1000
2022-08-31 19:06:43,911:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.03s, LR: 0.00002, Train Loss: 0.0964, Train MAE: 0.0964,
                            Val Loss: 0.3319, Val Acc: 0.3319, Test MAE: 0.2902
2022-08-31 19:06:43,919:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 170/1000
2022-08-31 19:07:03,787:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.87s, LR: 0.00002, Train Loss: 0.0985, Train MAE: 0.0985,
                            Val Loss: 0.3379, Val Acc: 0.3379, Test MAE: 0.2950
2022-08-31 19:07:03,795:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 171/1000
2022-08-31 19:07:22,682:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.89s, LR: 0.00002, Train Loss: 0.0980, Train MAE: 0.0980,
                            Val Loss: 0.3339, Val Acc: 0.3339, Test MAE: 0.2921
2022-08-31 19:07:22,690:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 172/1000
2022-08-31 19:07:42,614:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.92s, LR: 0.00002, Train Loss: 0.0988, Train MAE: 0.0988,
                            Val Loss: 0.3316, Val Acc: 0.3316, Test MAE: 0.2899
2022-08-31 19:07:42,623:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 173/1000
2022-08-31 19:08:02,758:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.13s, LR: 0.00001, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.3338, Val Acc: 0.3338, Test MAE: 0.2891
2022-08-31 19:08:02,767:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 174/1000
2022-08-31 19:08:22,224:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.46s, LR: 0.00001, Train Loss: 0.1011, Train MAE: 0.1011,
                            Val Loss: 0.3336, Val Acc: 0.3336, Test MAE: 0.2906
2022-08-31 19:08:22,232:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 175/1000
2022-08-31 19:08:41,656:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.42s, LR: 0.00001, Train Loss: 0.0927, Train MAE: 0.0927,
                            Val Loss: 0.3348, Val Acc: 0.3348, Test MAE: 0.2897
2022-08-31 19:08:41,664:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 176/1000
2022-08-31 19:09:01,102:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.44s, LR: 0.00001, Train Loss: 0.1029, Train MAE: 0.1029,
                            Val Loss: 0.3349, Val Acc: 0.3349, Test MAE: 0.2919
2022-08-31 19:09:01,111:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 177/1000
2022-08-31 19:09:21,034:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.92s, LR: 0.00001, Train Loss: 0.1045, Train MAE: 0.1045,
                            Val Loss: 0.3339, Val Acc: 0.3339, Test MAE: 0.2902
2022-08-31 19:09:21,041:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 178/1000
2022-08-31 19:09:39,426:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.39s, LR: 0.00001, Train Loss: 0.1010, Train MAE: 0.1010,
                            Val Loss: 0.3317, Val Acc: 0.3317, Test MAE: 0.2898
2022-08-31 19:09:39,435:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 179/1000
2022-08-31 19:09:58,643:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.21s, LR: 0.00001, Train Loss: 0.1031, Train MAE: 0.1031,
                            Val Loss: 0.3300, Val Acc: 0.3300, Test MAE: 0.2910
2022-08-31 19:09:58,650:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 180/1000
2022-08-31 19:10:18,270:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.62s, LR: 0.00001, Train Loss: 0.0896, Train MAE: 0.0896,
                            Val Loss: 0.3369, Val Acc: 0.3369, Test MAE: 0.2946
2022-08-31 19:10:18,278:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 181/1000
2022-08-31 19:10:37,771:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.49s, LR: 0.00001, Train Loss: 0.0942, Train MAE: 0.0942,
                            Val Loss: 0.3344, Val Acc: 0.3344, Test MAE: 0.2922
2022-08-31 19:10:37,778:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 182/1000
2022-08-31 19:10:57,341:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.56s, LR: 0.00001, Train Loss: 0.1046, Train MAE: 0.1046,
                            Val Loss: 0.3337, Val Acc: 0.3337, Test MAE: 0.2908
2022-08-31 19:10:57,349:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 183/1000
2022-08-31 19:11:15,709:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.36s, LR: 0.00001, Train Loss: 0.0992, Train MAE: 0.0992,
                            Val Loss: 0.3362, Val Acc: 0.3362, Test MAE: 0.2939
2022-08-31 19:11:15,717:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 184/1000
2022-08-31 19:11:34,232:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.52s, LR: 0.00001, Train Loss: 0.0905, Train MAE: 0.0905,
                            Val Loss: 0.3329, Val Acc: 0.3329, Test MAE: 0.2907
2022-08-31 19:11:34,241:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 185/1000
2022-08-31 19:11:53,255:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.01s, LR: 0.00001, Train Loss: 0.1013, Train MAE: 0.1013,
                            Val Loss: 0.3372, Val Acc: 0.3372, Test MAE: 0.2930
2022-08-31 19:11:53,263:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 186/1000
2022-08-31 19:12:12,809:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.55s, LR: 0.00001, Train Loss: 0.0944, Train MAE: 0.0944,
                            Val Loss: 0.3352, Val Acc: 0.3352, Test MAE: 0.2904
2022-08-31 19:12:12,816:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 187/1000
2022-08-31 19:12:32,423:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.61s, LR: 0.00001, Train Loss: 0.0977, Train MAE: 0.0977,
                            Val Loss: 0.3336, Val Acc: 0.3336, Test MAE: 0.2948
2022-08-31 19:12:32,432:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 188/1000
2022-08-31 19:12:51,558:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.13s, LR: 0.00001, Train Loss: 0.0919, Train MAE: 0.0919,
                            Val Loss: 0.3373, Val Acc: 0.3373, Test MAE: 0.2947
2022-08-31 19:12:51,566:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 189/1000
2022-08-31 19:13:11,132:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.57s, LR: 0.00001, Train Loss: 0.0917, Train MAE: 0.0917,
                            Val Loss: 0.3342, Val Acc: 0.3342, Test MAE: 0.2923
2022-08-31 19:13:11,140:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 190/1000
2022-08-31 19:13:31,351:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.21s, LR: 0.00001, Train Loss: 0.0959, Train MAE: 0.0959,
                            Val Loss: 0.3333, Val Acc: 0.3333, Test MAE: 0.2945
2022-08-31 19:13:31,358:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 191/1000
2022-08-31 19:13:49,600:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.24s, LR: 0.00001, Train Loss: 0.0956, Train MAE: 0.0956,
                            Val Loss: 0.3362, Val Acc: 0.3362, Test MAE: 0.2915
2022-08-31 19:13:49,608:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 192/1000
2022-08-31 19:14:08,798:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.19s, LR: 0.00001, Train Loss: 0.0934, Train MAE: 0.0934,
                            Val Loss: 0.3347, Val Acc: 0.3347, Test MAE: 0.2907
2022-08-31 19:14:08,805:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 193/1000
2022-08-31 19:14:29,795:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.99s, LR: 0.00001, Train Loss: 0.0998, Train MAE: 0.0998,
                            Val Loss: 0.3359, Val Acc: 0.3359, Test MAE: 0.2913
2022-08-31 19:14:29,807:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 194/1000
2022-08-31 19:14:51,267:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.46s, LR: 0.00001, Train Loss: 0.1010, Train MAE: 0.1010,
                            Val Loss: 0.3331, Val Acc: 0.3331, Test MAE: 0.2916
2022-08-31 19:14:51,275:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 195/1000
2022-08-31 19:15:09,853:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.58s, LR: 0.00001, Train Loss: 0.0947, Train MAE: 0.0947,
                            Val Loss: 0.3347, Val Acc: 0.3347, Test MAE: 0.2899
2022-08-31 19:15:09,863:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 196/1000
2022-08-31 19:15:29,039:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.18s, LR: 0.00001, Train Loss: 0.0926, Train MAE: 0.0926,
                            Val Loss: 0.3369, Val Acc: 0.3369, Test MAE: 0.2929
2022-08-31 19:15:29,047:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 197/1000
2022-08-31 19:15:49,166:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.12s, LR: 0.00001, Train Loss: 0.0922, Train MAE: 0.0922,
                            Val Loss: 0.3344, Val Acc: 0.3344, Test MAE: 0.2922
2022-08-31 19:15:49,174:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 198/1000
2022-08-31 19:16:09,301:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.13s, LR: 0.00001, Train Loss: 0.0938, Train MAE: 0.0938,
                            Val Loss: 0.3336, Val Acc: 0.3336, Test MAE: 0.2898
2022-08-31 19:16:09,310:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 199/1000
2022-08-31 19:16:28,111:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.80s, LR: 0.00001, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.3335, Val Acc: 0.3335, Test MAE: 0.2908
2022-08-31 19:16:28,118:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 200/1000
2022-08-31 19:16:47,824:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.71s, LR: 0.00001, Train Loss: 0.1002, Train MAE: 0.1002,
                            Val Loss: 0.3320, Val Acc: 0.3320, Test MAE: 0.2904
2022-08-31 19:16:47,831:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 201/1000
2022-08-31 19:17:19,127:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 19:17:23,570:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 10, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 6, 'gape_pooling': 'sum', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 19:17:23,570:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 19:17:23,570:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:17:23,573:pe_layer.py:119 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:17:23,574:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:17:23,574:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:17:23,580:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 19:17:23,581:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 350358
2022-08-31 19:17:23,582:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:17:23,584:pe_layer.py:119 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:17:23,584:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:17:23,584:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:17:23,590:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (10).
2022-08-31 19:17:23,590:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 6 random automata.
2022-08-31 19:18:01,287:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 19:18:01,287:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 19:18:01,287:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 19:18:01,290:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 19:18:22,259:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5545023828744888
2022-08-31 19:18:22,261:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.97s, LR: 0.00070, Train Loss: 1.5102, Train MAE: 1.5102,
                            Val Loss: 1.4404, Val Acc: 1.4404, Test MAE: 1.5545
2022-08-31 19:18:22,270:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 19:18:27,681:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-31 19:18:27,681:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 19:18:40,257:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 19:18:44,533:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 10, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 6, 'gape_pooling': 'sum', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 19:18:44,533:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 19:18:44,533:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:18:44,535:pe_layer.py:119 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:18:44,535:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:18:44,535:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:18:44,543:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 19:18:44,544:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 543542
2022-08-31 19:18:44,545:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:18:44,546:pe_layer.py:119 -             __init__(): Using 10 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:18:44,547:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:18:44,547:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:18:44,553:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (10).
2022-08-31 19:18:44,553:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 6 random automata.
2022-08-31 19:19:21,459:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 19:19:21,459:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 19:19:21,459:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 19:19:21,462:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 19:19:45,066:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5670621544122696
2022-08-31 19:19:45,068:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.61s, LR: 0.00070, Train Loss: 1.4978, Train MAE: 1.4978,
                            Val Loss: 1.4912, Val Acc: 1.4912, Test MAE: 1.5671
2022-08-31 19:19:45,076:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 19:20:00,745:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-31 19:20:00,745:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 19:20:12,355:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 19:20:16,726:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 10, 'gape_pooling': 'max', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 19:20:16,726:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 19:20:16,726:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:20:16,729:pe_layer.py:119 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:20:16,730:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:20:16,730:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:20:16,736:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 19:20:16,737:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 553922
2022-08-31 19:20:16,737:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:20:16,740:pe_layer.py:119 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:20:16,740:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:20:16,740:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:20:16,751:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-08-31 19:20:16,751:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 10 random automata.
2022-08-31 19:21:28,242:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 19:21:28,242:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 19:21:28,242:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 19:21:28,245:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 19:21:51,018:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5620793402194977
2022-08-31 19:21:51,019:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 22.77s, LR: 0.00070, Train Loss: 1.4886, Train MAE: 1.4886,
                            Val Loss: 1.4683, Val Acc: 1.4683, Test MAE: 1.5621
2022-08-31 19:21:51,027:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 19:22:12,738:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.71s, LR: 0.00070, Train Loss: 1.4598, Train MAE: 1.4598,
                            Val Loss: 1.7322, Val Acc: 1.7322, Test MAE: 1.8900
2022-08-31 19:22:12,746:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-08-31 19:22:15,466:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-31 19:22:15,467:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 19:23:06,906:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 19:23:11,340:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 12, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 5, 'gape_pooling': 'max', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 19:23:11,340:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 19:23:11,340:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:23:11,344:pe_layer.py:119 -             __init__(): Using 12 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:23:11,345:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:23:11,345:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:23:11,352:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 19:23:11,353:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 543582
2022-08-31 19:23:11,353:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:23:11,358:pe_layer.py:119 -             __init__(): Using 12 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:23:11,359:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:23:11,359:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:23:11,370:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (12).
2022-08-31 19:23:11,370:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 5 random automata.
2022-08-31 19:23:48,524:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 19:23:48,524:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 19:23:48,524:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 19:23:48,528:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 19:24:12,477:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5563557744026184
2022-08-31 19:24:12,480:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.95s, LR: 0.00070, Train Loss: 1.4772, Train MAE: 1.4772,
                            Val Loss: 1.4796, Val Acc: 1.4796, Test MAE: 1.5564
2022-08-31 19:24:12,489:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 19:24:35,474:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5431919544935226
2022-08-31 19:24:35,476:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 22.99s, LR: 0.00070, Train Loss: 1.4616, Train MAE: 1.4616,
                            Val Loss: 1.4426, Val Acc: 1.4426, Test MAE: 1.5432
2022-08-31 19:24:35,485:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-08-31 19:24:38,034:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-31 19:24:38,034:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 19:24:52,956:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 19:24:57,400:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 4, 'gape_pooling': 'mean', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 19:24:57,400:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 19:24:57,400:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:24:57,403:pe_layer.py:119 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:24:57,403:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:24:57,403:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:24:57,410:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 19:24:57,411:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 540770
2022-08-31 19:24:57,412:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:24:57,414:pe_layer.py:119 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:24:57,414:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:24:57,414:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:24:57,425:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-08-31 19:24:57,425:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 4 random automata.
2022-08-31 19:25:27,018:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 19:25:27,018:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 19:25:27,018:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 19:25:27,020:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 19:25:49,338:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5565034002065659
2022-08-31 19:25:49,340:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 22.32s, LR: 0.00070, Train Loss: 1.4824, Train MAE: 1.4824,
                            Val Loss: 1.4430, Val Acc: 1.4430, Test MAE: 1.5565
2022-08-31 19:25:49,347:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 19:25:56,974:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-08-31 19:25:56,974:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-08-31 19:26:06,041:main_utils.py:42 -            gpu_setup(): cuda not available
2022-08-31 19:26:11,075:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 2, 'gape_pooling': 'max', 'num_atom_type': 28, 'num_bond_type': 4}
2022-08-31 19:26:11,076:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge', 'job_num': 5}
2022-08-31 19:26:11,076:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:26:11,077:pe_layer.py:119 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:26:11,077:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:26:11,077:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:26:11,085:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-08-31 19:26:11,086:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 539186
2022-08-31 19:26:11,086:pe_layer.py:62 -             __init__(): rand_pos_enc
2022-08-31 19:26:11,087:pe_layer.py:119 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-08-31 19:26:11,087:pe_layer.py:124 -             __init__(): Using matrix: A
2022-08-31 19:26:11,087:pe_layer.py:125 -             __init__(): Matrix power: 1
2022-08-31 19:26:11,095:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-08-31 19:26:11,095:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-08-31 19:26:25,636:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-08-31 19:26:25,637:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-08-31 19:26:25,637:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-08-31 19:26:25,639:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-08-31 19:26:49,820:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.8277904093265533
2022-08-31 19:26:49,822:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00070, Train Loss: 0.9111, Train MAE: 0.9111,
                            Val Loss: 0.8072, Val Acc: 0.8072, Test MAE: 0.8278
2022-08-31 19:26:49,830:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-08-31 19:27:12,986:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.6613814756274223
2022-08-31 19:27:12,987:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.16s, LR: 0.00070, Train Loss: 0.6528, Train MAE: 0.6528,
                            Val Loss: 0.6248, Val Acc: 0.6248, Test MAE: 0.6614
2022-08-31 19:27:12,995:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-08-31 19:27:35,638:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 22.64s, LR: 0.00070, Train Loss: 0.6305, Train MAE: 0.6305,
                            Val Loss: 0.6446, Val Acc: 0.6446, Test MAE: 0.6761
2022-08-31 19:27:35,646:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 4/1000
2022-08-31 19:28:00,723:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.08s, LR: 0.00070, Train Loss: 0.6060, Train MAE: 0.6060,
                            Val Loss: 0.7473, Val Acc: 0.7473, Test MAE: 0.7685
2022-08-31 19:28:00,731:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 5/1000
2022-08-31 19:28:22,409:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.68s, LR: 0.00070, Train Loss: 0.5853, Train MAE: 0.5853,
                            Val Loss: 0.7306, Val Acc: 0.7306, Test MAE: 0.7801
2022-08-31 19:28:22,417:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 6/1000
2022-08-31 19:28:43,358:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.6126193851232529
2022-08-31 19:28:43,359:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.94s, LR: 0.00070, Train Loss: 0.5709, Train MAE: 0.5709,
                            Val Loss: 0.5956, Val Acc: 0.5956, Test MAE: 0.6126
2022-08-31 19:28:43,367:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 7/1000
2022-08-31 19:29:04,199:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.83s, LR: 0.00070, Train Loss: 0.5839, Train MAE: 0.5839,
                            Val Loss: 0.5940, Val Acc: 0.5940, Test MAE: 0.6387
2022-08-31 19:29:04,208:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 8/1000
2022-08-31 19:29:26,071:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.6117815263569355
2022-08-31 19:29:26,072:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.86s, LR: 0.00070, Train Loss: 0.5387, Train MAE: 0.5387,
                            Val Loss: 0.5883, Val Acc: 0.5883, Test MAE: 0.6118
2022-08-31 19:29:26,079:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 9/1000
2022-08-31 19:29:48,305:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5697780884802341
2022-08-31 19:29:48,306:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 22.23s, LR: 0.00070, Train Loss: 0.5447, Train MAE: 0.5447,
                            Val Loss: 0.5358, Val Acc: 0.5358, Test MAE: 0.5698
2022-08-31 19:29:48,314:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 10/1000
2022-08-31 19:30:12,164:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.85s, LR: 0.00070, Train Loss: 0.5214, Train MAE: 0.5214,
                            Val Loss: 0.6287, Val Acc: 0.6287, Test MAE: 0.6552
2022-08-31 19:30:12,171:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 11/1000
2022-08-31 19:30:35,730:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5410172119736671
2022-08-31 19:30:35,732:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.56s, LR: 0.00070, Train Loss: 0.5140, Train MAE: 0.5140,
                            Val Loss: 0.5120, Val Acc: 0.5120, Test MAE: 0.5410
2022-08-31 19:30:35,740:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 12/1000
2022-08-31 19:30:57,028:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.29s, LR: 0.00070, Train Loss: 0.5083, Train MAE: 0.5083,
                            Val Loss: 0.6688, Val Acc: 0.6688, Test MAE: 0.7091
2022-08-31 19:30:57,037:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 13/1000
2022-08-31 19:31:18,037:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5336598679423332
2022-08-31 19:31:18,038:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.00s, LR: 0.00070, Train Loss: 0.5002, Train MAE: 0.5002,
                            Val Loss: 0.5075, Val Acc: 0.5075, Test MAE: 0.5337
2022-08-31 19:31:18,046:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 14/1000
2022-08-31 19:31:39,166:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.12s, LR: 0.00070, Train Loss: 0.5031, Train MAE: 0.5031,
                            Val Loss: 0.5989, Val Acc: 0.5989, Test MAE: 0.6012
2022-08-31 19:31:39,174:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 15/1000
2022-08-31 19:32:00,212:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.04s, LR: 0.00070, Train Loss: 0.5000, Train MAE: 0.5000,
                            Val Loss: 0.7552, Val Acc: 0.7552, Test MAE: 0.7794
2022-08-31 19:32:00,220:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 16/1000
2022-08-31 19:32:21,899:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.68s, LR: 0.00070, Train Loss: 0.4873, Train MAE: 0.4873,
                            Val Loss: 0.5841, Val Acc: 0.5841, Test MAE: 0.5973
2022-08-31 19:32:21,908:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 17/1000
2022-08-31 19:32:43,868:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.96s, LR: 0.00070, Train Loss: 0.4903, Train MAE: 0.4903,
                            Val Loss: 0.5313, Val Acc: 0.5313, Test MAE: 0.5473
2022-08-31 19:32:43,877:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 18/1000
2022-08-31 19:33:05,111:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.23s, LR: 0.00070, Train Loss: 0.4930, Train MAE: 0.4930,
                            Val Loss: 0.6266, Val Acc: 0.6266, Test MAE: 0.6408
2022-08-31 19:33:05,126:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 19/1000
2022-08-31 19:33:26,415:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.29s, LR: 0.00070, Train Loss: 0.4811, Train MAE: 0.4811,
                            Val Loss: 0.5502, Val Acc: 0.5502, Test MAE: 0.5603
2022-08-31 19:33:26,424:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 20/1000
2022-08-31 19:33:47,928:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.50s, LR: 0.00070, Train Loss: 0.4648, Train MAE: 0.4648,
                            Val Loss: 0.6471, Val Acc: 0.6471, Test MAE: 0.6519
2022-08-31 19:33:47,936:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 21/1000
2022-08-31 19:34:09,249:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.31s, LR: 0.00070, Train Loss: 0.4786, Train MAE: 0.4786,
                            Val Loss: 0.6091, Val Acc: 0.6091, Test MAE: 0.6191
2022-08-31 19:34:09,259:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 22/1000
2022-08-31 19:34:30,636:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.38s, LR: 0.00070, Train Loss: 0.4535, Train MAE: 0.4535,
                            Val Loss: 0.5686, Val Acc: 0.5686, Test MAE: 0.5758
2022-08-31 19:34:30,644:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 23/1000
2022-08-31 19:34:52,025:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5266792252659798
2022-08-31 19:34:52,026:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.38s, LR: 0.00070, Train Loss: 0.4560, Train MAE: 0.4560,
                            Val Loss: 0.5091, Val Acc: 0.5091, Test MAE: 0.5267
2022-08-31 19:34:52,034:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 24/1000
2022-08-31 19:35:13,333:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.30s, LR: 0.00070, Train Loss: 0.4490, Train MAE: 0.4490,
                            Val Loss: 0.5536, Val Acc: 0.5536, Test MAE: 0.5715
2022-08-31 19:35:13,341:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 25/1000
2022-08-31 19:35:34,788:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.5208362974226475
2022-08-31 19:35:34,789:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.45s, LR: 0.00070, Train Loss: 0.4574, Train MAE: 0.4574,
                            Val Loss: 0.5033, Val Acc: 0.5033, Test MAE: 0.5208
2022-08-31 19:35:34,798:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 26/1000
2022-08-31 19:35:55,990:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.19s, LR: 0.00070, Train Loss: 0.4450, Train MAE: 0.4450,
                            Val Loss: 0.5488, Val Acc: 0.5488, Test MAE: 0.5578
2022-08-31 19:35:55,999:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 27/1000
2022-08-31 19:36:16,282:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.28s, LR: 0.00070, Train Loss: 0.4447, Train MAE: 0.4447,
                            Val Loss: 0.5402, Val Acc: 0.5402, Test MAE: 0.5620
2022-08-31 19:36:16,290:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 28/1000
2022-08-31 19:36:36,020:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.73s, LR: 0.00070, Train Loss: 0.4462, Train MAE: 0.4462,
                            Val Loss: 0.6125, Val Acc: 0.6125, Test MAE: 0.6435
2022-08-31 19:36:36,028:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 29/1000
2022-08-31 19:36:55,805:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.78s, LR: 0.00070, Train Loss: 0.4367, Train MAE: 0.4367,
                            Val Loss: 0.5050, Val Acc: 0.5050, Test MAE: 0.5223
2022-08-31 19:36:55,812:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 30/1000
2022-08-31 19:37:15,519:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.71s, LR: 0.00070, Train Loss: 0.4340, Train MAE: 0.4340,
                            Val Loss: 0.5690, Val Acc: 0.5690, Test MAE: 0.5718
2022-08-31 19:37:15,526:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 31/1000
2022-08-31 19:37:35,090:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4950888976454735
2022-08-31 19:37:35,090:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.56s, LR: 0.00070, Train Loss: 0.4371, Train MAE: 0.4371,
                            Val Loss: 0.4900, Val Acc: 0.4900, Test MAE: 0.4951
2022-08-31 19:37:35,099:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 32/1000
2022-08-31 19:37:54,867:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.77s, LR: 0.00070, Train Loss: 0.4221, Train MAE: 0.4221,
                            Val Loss: 0.5159, Val Acc: 0.5159, Test MAE: 0.5063
2022-08-31 19:37:54,875:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 33/1000
2022-08-31 19:38:14,640:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.77s, LR: 0.00070, Train Loss: 0.4155, Train MAE: 0.4155,
                            Val Loss: 0.5717, Val Acc: 0.5717, Test MAE: 0.6011
2022-08-31 19:38:14,648:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 34/1000
2022-08-31 19:38:34,647:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.00s, LR: 0.00070, Train Loss: 0.4356, Train MAE: 0.4356,
                            Val Loss: 0.6464, Val Acc: 0.6464, Test MAE: 0.6720
2022-08-31 19:38:34,655:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 35/1000
2022-08-31 19:38:54,384:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.73s, LR: 0.00070, Train Loss: 0.4368, Train MAE: 0.4368,
                            Val Loss: 0.4920, Val Acc: 0.4920, Test MAE: 0.5072
2022-08-31 19:38:54,392:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 36/1000
2022-08-31 19:39:14,249:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.86s, LR: 0.00070, Train Loss: 0.4177, Train MAE: 0.4177,
                            Val Loss: 0.6046, Val Acc: 0.6046, Test MAE: 0.5959
2022-08-31 19:39:14,257:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 37/1000
2022-08-31 19:39:34,664:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.41s, LR: 0.00070, Train Loss: 0.4125, Train MAE: 0.4125,
                            Val Loss: 0.6525, Val Acc: 0.6525, Test MAE: 0.6536
2022-08-31 19:39:34,672:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 38/1000
2022-08-31 19:39:55,753:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.493997547775507
2022-08-31 19:39:55,754:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.08s, LR: 0.00070, Train Loss: 0.4214, Train MAE: 0.4214,
                            Val Loss: 0.4868, Val Acc: 0.4868, Test MAE: 0.4940
2022-08-31 19:39:55,763:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 39/1000
2022-08-31 19:40:15,676:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.48792819306254387
2022-08-31 19:40:15,676:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.91s, LR: 0.00070, Train Loss: 0.3995, Train MAE: 0.3995,
                            Val Loss: 0.4893, Val Acc: 0.4893, Test MAE: 0.4879
2022-08-31 19:40:15,684:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 40/1000
2022-08-31 19:40:35,173:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.49s, LR: 0.00070, Train Loss: 0.4031, Train MAE: 0.4031,
                            Val Loss: 0.5374, Val Acc: 0.5374, Test MAE: 0.5523
2022-08-31 19:40:35,182:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 41/1000
2022-08-31 19:40:54,878:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.70s, LR: 0.00070, Train Loss: 0.3957, Train MAE: 0.3957,
                            Val Loss: 0.6972, Val Acc: 0.6972, Test MAE: 0.7023
2022-08-31 19:40:54,885:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 42/1000
2022-08-31 19:41:14,642:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.76s, LR: 0.00070, Train Loss: 0.3826, Train MAE: 0.3826,
                            Val Loss: 0.4981, Val Acc: 0.4981, Test MAE: 0.5064
2022-08-31 19:41:14,652:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 43/1000
2022-08-31 19:41:34,212:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4866706393659115
2022-08-31 19:41:34,212:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.56s, LR: 0.00070, Train Loss: 0.3879, Train MAE: 0.3879,
                            Val Loss: 0.4785, Val Acc: 0.4785, Test MAE: 0.4867
2022-08-31 19:41:34,221:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 44/1000
2022-08-31 19:41:54,186:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.96s, LR: 0.00070, Train Loss: 0.3815, Train MAE: 0.3815,
                            Val Loss: 0.6010, Val Acc: 0.6010, Test MAE: 0.6337
2022-08-31 19:41:54,193:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 45/1000
2022-08-31 19:42:14,293:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.10s, LR: 0.00070, Train Loss: 0.3852, Train MAE: 0.3852,
                            Val Loss: 0.4955, Val Acc: 0.4955, Test MAE: 0.5081
2022-08-31 19:42:14,302:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 46/1000
2022-08-31 19:42:34,267:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.97s, LR: 0.00070, Train Loss: 0.3840, Train MAE: 0.3840,
                            Val Loss: 0.5514, Val Acc: 0.5514, Test MAE: 0.5661
2022-08-31 19:42:34,279:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 47/1000
2022-08-31 19:42:54,128:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.85s, LR: 0.00070, Train Loss: 0.3869, Train MAE: 0.3869,
                            Val Loss: 0.5334, Val Acc: 0.5334, Test MAE: 0.5429
2022-08-31 19:42:54,137:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 48/1000
2022-08-31 19:43:13,842:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.47574859857559204
2022-08-31 19:43:13,842:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.71s, LR: 0.00070, Train Loss: 0.3685, Train MAE: 0.3685,
                            Val Loss: 0.4910, Val Acc: 0.4910, Test MAE: 0.4757
2022-08-31 19:43:13,851:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 49/1000
2022-08-31 19:43:33,517:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.67s, LR: 0.00070, Train Loss: 0.3696, Train MAE: 0.3696,
                            Val Loss: 0.6267, Val Acc: 0.6267, Test MAE: 0.6620
2022-08-31 19:43:33,527:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 50/1000
2022-08-31 19:43:53,281:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.75s, LR: 0.00070, Train Loss: 0.3551, Train MAE: 0.3551,
                            Val Loss: 0.5115, Val Acc: 0.5115, Test MAE: 0.5242
2022-08-31 19:43:53,289:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 51/1000
2022-08-31 19:44:13,018:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.73s, LR: 0.00070, Train Loss: 0.3511, Train MAE: 0.3511,
                            Val Loss: 0.5021, Val Acc: 0.5021, Test MAE: 0.5055
2022-08-31 19:44:13,027:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 52/1000
2022-08-31 19:44:32,724:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.70s, LR: 0.00070, Train Loss: 0.3716, Train MAE: 0.3716,
                            Val Loss: 0.5168, Val Acc: 0.5168, Test MAE: 0.5240
2022-08-31 19:44:32,732:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 53/1000
2022-08-31 19:44:52,717:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.99s, LR: 0.00070, Train Loss: 0.3460, Train MAE: 0.3460,
                            Val Loss: 0.5320, Val Acc: 0.5320, Test MAE: 0.5432
2022-08-31 19:44:52,726:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 54/1000
2022-08-31 19:45:12,579:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.85s, LR: 0.00070, Train Loss: 0.3483, Train MAE: 0.3483,
                            Val Loss: 0.5352, Val Acc: 0.5352, Test MAE: 0.5409
2022-08-31 19:45:12,586:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 55/1000
2022-08-31 19:45:32,129:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.54s, LR: 0.00070, Train Loss: 0.3488, Train MAE: 0.3488,
                            Val Loss: 0.5074, Val Acc: 0.5074, Test MAE: 0.5175
2022-08-31 19:45:32,136:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 56/1000
2022-08-31 19:45:51,797:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.66s, LR: 0.00070, Train Loss: 0.3477, Train MAE: 0.3477,
                            Val Loss: 0.4801, Val Acc: 0.4801, Test MAE: 0.4945
2022-08-31 19:45:51,805:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 57/1000
2022-08-31 19:46:11,472:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.67s, LR: 0.00070, Train Loss: 0.3477, Train MAE: 0.3477,
                            Val Loss: 0.5385, Val Acc: 0.5385, Test MAE: 0.5513
2022-08-31 19:46:11,481:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 58/1000
2022-08-31 19:46:31,213:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.73s, LR: 0.00070, Train Loss: 0.3418, Train MAE: 0.3418,
                            Val Loss: 0.6604, Val Acc: 0.6604, Test MAE: 0.6493
2022-08-31 19:46:31,221:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 59/1000
2022-08-31 19:46:51,159:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.46768004447221756
2022-08-31 19:46:51,160:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.94s, LR: 0.00070, Train Loss: 0.3510, Train MAE: 0.3510,
                            Val Loss: 0.4699, Val Acc: 0.4699, Test MAE: 0.4677
2022-08-31 19:46:51,168:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 60/1000
2022-08-31 19:47:11,188:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.02s, LR: 0.00070, Train Loss: 0.3513, Train MAE: 0.3513,
                            Val Loss: 0.5037, Val Acc: 0.5037, Test MAE: 0.5108
2022-08-31 19:47:11,195:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 61/1000
2022-08-31 19:47:30,830:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.63s, LR: 0.00070, Train Loss: 0.3264, Train MAE: 0.3264,
                            Val Loss: 0.4736, Val Acc: 0.4736, Test MAE: 0.4678
2022-08-31 19:47:30,837:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 62/1000
2022-08-31 19:47:50,786:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4586725942790508
2022-08-31 19:47:50,786:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.95s, LR: 0.00070, Train Loss: 0.3316, Train MAE: 0.3316,
                            Val Loss: 0.4645, Val Acc: 0.4645, Test MAE: 0.4587
2022-08-31 19:47:50,794:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 63/1000
2022-08-31 19:48:10,472:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.68s, LR: 0.00070, Train Loss: 0.3488, Train MAE: 0.3488,
                            Val Loss: 0.4906, Val Acc: 0.4906, Test MAE: 0.4909
2022-08-31 19:48:10,481:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 64/1000
2022-08-31 19:48:30,135:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.65s, LR: 0.00070, Train Loss: 0.3318, Train MAE: 0.3318,
                            Val Loss: 0.4979, Val Acc: 0.4979, Test MAE: 0.5016
2022-08-31 19:48:30,144:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 65/1000
2022-08-31 19:48:49,698:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.55s, LR: 0.00070, Train Loss: 0.3298, Train MAE: 0.3298,
                            Val Loss: 0.4661, Val Acc: 0.4661, Test MAE: 0.4681
2022-08-31 19:48:49,708:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 66/1000
2022-08-31 19:49:09,399:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.69s, LR: 0.00070, Train Loss: 0.3183, Train MAE: 0.3183,
                            Val Loss: 0.5699, Val Acc: 0.5699, Test MAE: 0.5809
2022-08-31 19:49:09,406:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 67/1000
2022-08-31 19:49:29,028:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.44905951246619225
2022-08-31 19:49:29,028:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.62s, LR: 0.00070, Train Loss: 0.3223, Train MAE: 0.3223,
                            Val Loss: 0.4565, Val Acc: 0.4565, Test MAE: 0.4491
2022-08-31 19:49:29,036:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 68/1000
2022-08-31 19:49:48,724:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.69s, LR: 0.00070, Train Loss: 0.3220, Train MAE: 0.3220,
                            Val Loss: 0.5249, Val Acc: 0.5249, Test MAE: 0.5280
2022-08-31 19:49:48,732:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 69/1000
2022-08-31 19:50:48,546:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 59.81s, LR: 0.00070, Train Loss: 0.3215, Train MAE: 0.3215,
                            Val Loss: 0.4946, Val Acc: 0.4946, Test MAE: 0.5016
2022-08-31 19:50:48,557:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 70/1000
2022-08-31 19:51:09,512:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.95s, LR: 0.00070, Train Loss: 0.3210, Train MAE: 0.3210,
                            Val Loss: 0.4581, Val Acc: 0.4581, Test MAE: 0.4671
2022-08-31 19:51:09,521:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 71/1000
2022-08-31 19:51:29,722:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4481310173869133
2022-08-31 19:51:29,722:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.20s, LR: 0.00070, Train Loss: 0.3136, Train MAE: 0.3136,
                            Val Loss: 0.4579, Val Acc: 0.4579, Test MAE: 0.4481
2022-08-31 19:51:29,731:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 72/1000
2022-08-31 19:51:49,448:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.72s, LR: 0.00070, Train Loss: 0.3208, Train MAE: 0.3208,
                            Val Loss: 0.4858, Val Acc: 0.4858, Test MAE: 0.4703
2022-08-31 19:51:49,456:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 73/1000
2022-08-31 19:52:09,501:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.04s, LR: 0.00070, Train Loss: 0.3219, Train MAE: 0.3219,
                            Val Loss: 0.4937, Val Acc: 0.4937, Test MAE: 0.4851
2022-08-31 19:52:09,508:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 74/1000
2022-08-31 19:52:29,420:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.91s, LR: 0.00070, Train Loss: 0.3117, Train MAE: 0.3117,
                            Val Loss: 0.4615, Val Acc: 0.4615, Test MAE: 0.4532
2022-08-31 19:52:29,428:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 75/1000
2022-08-31 19:52:49,049:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.62s, LR: 0.00070, Train Loss: 0.3012, Train MAE: 0.3012,
                            Val Loss: 0.5476, Val Acc: 0.5476, Test MAE: 0.5420
2022-08-31 19:52:49,056:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 76/1000
2022-08-31 19:53:08,900:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.84s, LR: 0.00070, Train Loss: 0.3035, Train MAE: 0.3035,
                            Val Loss: 0.4750, Val Acc: 0.4750, Test MAE: 0.4778
2022-08-31 19:53:08,909:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 77/1000
2022-08-31 19:53:28,865:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.96s, LR: 0.00070, Train Loss: 0.3075, Train MAE: 0.3075,
                            Val Loss: 0.5221, Val Acc: 0.5221, Test MAE: 0.5079
2022-08-31 19:53:28,872:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 78/1000
2022-08-31 19:53:48,754:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.88s, LR: 0.00070, Train Loss: 0.2944, Train MAE: 0.2944,
                            Val Loss: 0.4904, Val Acc: 0.4904, Test MAE: 0.4767
2022-08-31 19:53:48,762:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 79/1000
2022-08-31 19:54:08,485:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.72s, LR: 0.00070, Train Loss: 0.3070, Train MAE: 0.3070,
                            Val Loss: 0.4507, Val Acc: 0.4507, Test MAE: 0.4491
2022-08-31 19:54:08,493:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 80/1000
2022-08-31 19:54:28,248:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.75s, LR: 0.00070, Train Loss: 0.3103, Train MAE: 0.3103,
                            Val Loss: 0.4867, Val Acc: 0.4867, Test MAE: 0.4794
2022-08-31 19:54:28,257:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 81/1000
2022-08-31 19:54:47,964:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.71s, LR: 0.00070, Train Loss: 0.3036, Train MAE: 0.3036,
                            Val Loss: 0.4709, Val Acc: 0.4709, Test MAE: 0.4602
2022-08-31 19:54:47,972:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 82/1000
2022-08-31 19:55:07,804:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4455859363079071
2022-08-31 19:55:07,805:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.83s, LR: 0.00070, Train Loss: 0.3051, Train MAE: 0.3051,
                            Val Loss: 0.4510, Val Acc: 0.4510, Test MAE: 0.4456
2022-08-31 19:55:07,812:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 83/1000
2022-08-31 19:55:27,604:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.79s, LR: 0.00070, Train Loss: 0.3007, Train MAE: 0.3007,
                            Val Loss: 0.4680, Val Acc: 0.4680, Test MAE: 0.4694
2022-08-31 19:55:27,613:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 84/1000
2022-08-31 19:55:47,445:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.83s, LR: 0.00070, Train Loss: 0.2996, Train MAE: 0.2996,
                            Val Loss: 0.4698, Val Acc: 0.4698, Test MAE: 0.4778
2022-08-31 19:55:47,454:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 85/1000
2022-08-31 19:56:07,473:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.02s, LR: 0.00070, Train Loss: 0.2927, Train MAE: 0.2927,
                            Val Loss: 0.4626, Val Acc: 0.4626, Test MAE: 0.4531
2022-08-31 19:56:07,482:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 86/1000
2022-08-31 19:56:27,315:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.83s, LR: 0.00070, Train Loss: 0.2870, Train MAE: 0.2870,
                            Val Loss: 0.4922, Val Acc: 0.4922, Test MAE: 0.4712
2022-08-31 19:56:27,323:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 87/1000
2022-08-31 19:56:46,662:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.34s, LR: 0.00070, Train Loss: 0.2849, Train MAE: 0.2849,
                            Val Loss: 0.4527, Val Acc: 0.4527, Test MAE: 0.4600
2022-08-31 19:56:46,672:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 88/1000
2022-08-31 19:57:06,354:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.68s, LR: 0.00070, Train Loss: 0.2817, Train MAE: 0.2817,
                            Val Loss: 0.4643, Val Acc: 0.4643, Test MAE: 0.4609
2022-08-31 19:57:06,362:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 89/1000
2022-08-31 19:57:26,183:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.82s, LR: 0.00070, Train Loss: 0.2766, Train MAE: 0.2766,
                            Val Loss: 0.4700, Val Acc: 0.4700, Test MAE: 0.4788
2022-08-31 19:57:26,190:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 90/1000
2022-08-31 19:57:45,770:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.58s, LR: 0.00070, Train Loss: 0.2648, Train MAE: 0.2648,
                            Val Loss: 0.5086, Val Acc: 0.5086, Test MAE: 0.5143
2022-08-31 19:57:45,778:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 91/1000
2022-08-31 19:58:05,726:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.95s, LR: 0.00070, Train Loss: 0.2798, Train MAE: 0.2798,
                            Val Loss: 0.4804, Val Acc: 0.4804, Test MAE: 0.4983
2022-08-31 19:58:05,735:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 92/1000
2022-08-31 19:58:25,448:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.71s, LR: 0.00070, Train Loss: 0.2779, Train MAE: 0.2779,
                            Val Loss: 0.4815, Val Acc: 0.4815, Test MAE: 0.4574
2022-08-31 19:58:25,457:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 93/1000
2022-08-31 19:58:45,241:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.78s, LR: 0.00070, Train Loss: 0.2780, Train MAE: 0.2780,
                            Val Loss: 0.4662, Val Acc: 0.4662, Test MAE: 0.4554
2022-08-31 19:58:45,251:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 94/1000
2022-08-31 19:59:03,075:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4358437992632389
2022-08-31 19:59:03,076:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.83s, LR: 0.00070, Train Loss: 0.2795, Train MAE: 0.2795,
                            Val Loss: 0.4434, Val Acc: 0.4434, Test MAE: 0.4358
2022-08-31 19:59:03,083:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 95/1000
2022-08-31 19:59:20,626:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.54s, LR: 0.00070, Train Loss: 0.2679, Train MAE: 0.2679,
                            Val Loss: 0.4560, Val Acc: 0.4560, Test MAE: 0.4548
2022-08-31 19:59:20,633:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 96/1000
2022-08-31 19:59:38,383:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.75s, LR: 0.00070, Train Loss: 0.2817, Train MAE: 0.2817,
                            Val Loss: 0.4567, Val Acc: 0.4567, Test MAE: 0.4679
2022-08-31 19:59:38,391:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 97/1000
2022-08-31 19:59:55,862:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.47s, LR: 0.00070, Train Loss: 0.2710, Train MAE: 0.2710,
                            Val Loss: 0.4528, Val Acc: 0.4528, Test MAE: 0.4508
2022-08-31 19:59:55,871:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 98/1000
2022-08-31 20:00:13,299:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.43s, LR: 0.00070, Train Loss: 0.2733, Train MAE: 0.2733,
                            Val Loss: 0.4781, Val Acc: 0.4781, Test MAE: 0.4779
2022-08-31 20:00:13,308:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 99/1000
2022-08-31 20:00:30,802:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.49s, LR: 0.00070, Train Loss: 0.2742, Train MAE: 0.2742,
                            Val Loss: 0.4505, Val Acc: 0.4505, Test MAE: 0.4465
2022-08-31 20:00:30,809:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 100/1000
2022-08-31 20:00:48,658:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.85s, LR: 0.00070, Train Loss: 0.2820, Train MAE: 0.2820,
                            Val Loss: 0.4482, Val Acc: 0.4482, Test MAE: 0.4800
2022-08-31 20:00:48,667:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 101/1000
2022-08-31 20:01:06,132:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.47s, LR: 0.00070, Train Loss: 0.2706, Train MAE: 0.2706,
                            Val Loss: 0.4734, Val Acc: 0.4734, Test MAE: 0.4878
2022-08-31 20:01:06,140:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 102/1000
2022-08-31 20:01:24,062:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.92s, LR: 0.00070, Train Loss: 0.2834, Train MAE: 0.2834,
                            Val Loss: 0.4582, Val Acc: 0.4582, Test MAE: 0.4903
2022-08-31 20:01:24,069:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 103/1000
2022-08-31 20:14:58,200:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 814.13s, LR: 0.00070, Train Loss: 0.2820, Train MAE: 0.2820,
                            Val Loss: 0.4709, Val Acc: 0.4709, Test MAE: 0.4598
2022-08-31 20:14:58,208:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 104/1000
2022-08-31 20:15:16,782:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.57s, LR: 0.00070, Train Loss: 0.2875, Train MAE: 0.2875,
                            Val Loss: 0.4407, Val Acc: 0.4407, Test MAE: 0.4388
2022-08-31 20:15:16,789:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 105/1000
2022-08-31 20:15:34,912:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.12s, LR: 0.00070, Train Loss: 0.2559, Train MAE: 0.2559,
                            Val Loss: 0.4636, Val Acc: 0.4636, Test MAE: 0.4676
2022-08-31 20:15:34,920:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 106/1000
2022-08-31 20:15:52,114:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.19s, LR: 0.00070, Train Loss: 0.2978, Train MAE: 0.2978,
                            Val Loss: 0.4707, Val Acc: 0.4707, Test MAE: 0.4725
2022-08-31 20:15:52,120:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 107/1000
2022-08-31 20:16:09,503:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.38s, LR: 0.00070, Train Loss: 0.2650, Train MAE: 0.2650,
                            Val Loss: 0.4462, Val Acc: 0.4462, Test MAE: 0.4683
2022-08-31 20:16:09,510:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 108/1000
2022-08-31 20:16:27,007:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.50s, LR: 0.00070, Train Loss: 0.3112, Train MAE: 0.3112,
                            Val Loss: 0.4804, Val Acc: 0.4804, Test MAE: 0.4891
2022-08-31 20:16:27,014:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 109/1000
2022-08-31 20:16:44,423:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.41s, LR: 0.00070, Train Loss: 0.2874, Train MAE: 0.2874,
                            Val Loss: 0.4730, Val Acc: 0.4730, Test MAE: 0.4571
2022-08-31 20:16:44,430:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 110/1000
2022-08-31 20:17:01,922:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.49s, LR: 0.00070, Train Loss: 0.2844, Train MAE: 0.2844,
                            Val Loss: 0.4323, Val Acc: 0.4323, Test MAE: 0.4495
2022-08-31 20:17:01,929:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 111/1000
2022-08-31 20:17:19,452:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.52s, LR: 0.00070, Train Loss: 0.2533, Train MAE: 0.2533,
                            Val Loss: 0.4629, Val Acc: 0.4629, Test MAE: 0.4803
2022-08-31 20:17:19,460:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 112/1000
2022-08-31 20:17:36,823:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.36s, LR: 0.00070, Train Loss: 0.2473, Train MAE: 0.2473,
                            Val Loss: 0.4462, Val Acc: 0.4462, Test MAE: 0.4506
2022-08-31 20:17:36,831:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 113/1000
2022-08-31 20:17:54,278:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.45s, LR: 0.00070, Train Loss: 0.2447, Train MAE: 0.2447,
                            Val Loss: 0.4641, Val Acc: 0.4641, Test MAE: 0.4718
2022-08-31 20:17:54,285:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 114/1000
2022-08-31 20:18:11,721:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.44s, LR: 0.00070, Train Loss: 0.2419, Train MAE: 0.2419,
                            Val Loss: 0.4487, Val Acc: 0.4487, Test MAE: 0.4447
2022-08-31 20:18:11,728:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 115/1000
2022-08-31 20:18:29,439:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.71s, LR: 0.00070, Train Loss: 0.2342, Train MAE: 0.2342,
                            Val Loss: 0.4800, Val Acc: 0.4800, Test MAE: 0.4563
2022-08-31 20:18:29,447:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 116/1000
2022-08-31 20:18:46,866:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.42s, LR: 0.00070, Train Loss: 0.2493, Train MAE: 0.2493,
                            Val Loss: 0.4520, Val Acc: 0.4520, Test MAE: 0.4451
2022-08-31 20:18:46,873:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 117/1000
2022-08-31 20:19:04,233:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.42373503372073174
2022-08-31 20:19:04,233:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.36s, LR: 0.00070, Train Loss: 0.2405, Train MAE: 0.2405,
                            Val Loss: 0.4302, Val Acc: 0.4302, Test MAE: 0.4237
2022-08-31 20:19:04,241:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 118/1000
2022-08-31 20:19:21,629:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.39s, LR: 0.00070, Train Loss: 0.2374, Train MAE: 0.2374,
                            Val Loss: 0.4384, Val Acc: 0.4384, Test MAE: 0.4364
2022-08-31 20:19:21,637:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 119/1000
2022-08-31 20:19:38,992:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.35s, LR: 0.00070, Train Loss: 0.2399, Train MAE: 0.2399,
                            Val Loss: 0.4782, Val Acc: 0.4782, Test MAE: 0.4685
2022-08-31 20:19:38,999:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 120/1000
2022-08-31 20:19:56,536:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.54s, LR: 0.00070, Train Loss: 0.2557, Train MAE: 0.2557,
                            Val Loss: 0.4749, Val Acc: 0.4749, Test MAE: 0.4773
2022-08-31 20:19:56,545:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 121/1000
2022-08-31 20:20:13,927:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.38s, LR: 0.00070, Train Loss: 0.2594, Train MAE: 0.2594,
                            Val Loss: 0.4699, Val Acc: 0.4699, Test MAE: 0.4633
2022-08-31 20:20:13,934:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 122/1000
2022-08-31 20:20:31,679:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.75s, LR: 0.00070, Train Loss: 0.2581, Train MAE: 0.2581,
                            Val Loss: 0.4475, Val Acc: 0.4475, Test MAE: 0.4390
2022-08-31 20:20:31,687:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 123/1000
2022-08-31 20:20:48,946:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.26s, LR: 0.00070, Train Loss: 0.2520, Train MAE: 0.2520,
                            Val Loss: 0.4663, Val Acc: 0.4663, Test MAE: 0.4502
2022-08-31 20:20:48,954:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 124/1000
2022-08-31 20:21:06,557:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.60s, LR: 0.00070, Train Loss: 0.2448, Train MAE: 0.2448,
                            Val Loss: 0.4639, Val Acc: 0.4639, Test MAE: 0.4397
2022-08-31 20:21:06,565:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 125/1000
2022-08-31 20:21:24,173:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.61s, LR: 0.00070, Train Loss: 0.2678, Train MAE: 0.2678,
                            Val Loss: 0.4524, Val Acc: 0.4524, Test MAE: 0.4521
2022-08-31 20:21:24,180:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 126/1000
2022-08-31 20:21:41,616:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.44s, LR: 0.00070, Train Loss: 0.2456, Train MAE: 0.2456,
                            Val Loss: 0.4544, Val Acc: 0.4544, Test MAE: 0.4425
2022-08-31 20:21:41,624:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 127/1000
2022-08-31 20:21:59,177:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.55s, LR: 0.00070, Train Loss: 0.2479, Train MAE: 0.2479,
                            Val Loss: 0.4419, Val Acc: 0.4419, Test MAE: 0.4348
2022-08-31 20:21:59,184:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 128/1000
2022-08-31 20:22:16,640:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.46s, LR: 0.00070, Train Loss: 0.2420, Train MAE: 0.2420,
                            Val Loss: 0.4789, Val Acc: 0.4789, Test MAE: 0.4499
2022-08-31 20:22:16,647:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 129/1000
2022-08-31 20:22:34,128:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.48s, LR: 0.00070, Train Loss: 0.2314, Train MAE: 0.2314,
                            Val Loss: 0.4504, Val Acc: 0.4504, Test MAE: 0.4584
2022-08-31 20:22:34,136:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 130/1000
2022-08-31 20:22:51,586:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.45s, LR: 0.00070, Train Loss: 0.2349, Train MAE: 0.2349,
                            Val Loss: 0.4547, Val Acc: 0.4547, Test MAE: 0.4507
2022-08-31 20:22:51,593:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 131/1000
2022-08-31 20:23:09,339:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.75s, LR: 0.00070, Train Loss: 0.2175, Train MAE: 0.2175,
                            Val Loss: 0.4660, Val Acc: 0.4660, Test MAE: 0.4546
2022-08-31 20:23:09,346:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 132/1000
2022-08-31 20:23:26,828:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.48s, LR: 0.00070, Train Loss: 0.2277, Train MAE: 0.2277,
                            Val Loss: 0.4400, Val Acc: 0.4400, Test MAE: 0.4396
2022-08-31 20:23:26,837:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 133/1000
2022-08-31 20:23:44,237:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.40s, LR: 0.00070, Train Loss: 0.2285, Train MAE: 0.2285,
                            Val Loss: 0.4323, Val Acc: 0.4323, Test MAE: 0.4298
2022-08-31 20:23:44,244:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 134/1000
2022-08-31 20:24:01,668:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.42293742299079895
2022-08-31 20:24:01,668:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.42s, LR: 0.00035, Train Loss: 0.2023, Train MAE: 0.2023,
                            Val Loss: 0.4220, Val Acc: 0.4220, Test MAE: 0.4229
2022-08-31 20:24:01,677:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 135/1000
2022-08-31 20:24:19,193:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4187403880059719
2022-08-31 20:24:19,193:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.52s, LR: 0.00035, Train Loss: 0.1886, Train MAE: 0.1886,
                            Val Loss: 0.4370, Val Acc: 0.4370, Test MAE: 0.4187
2022-08-31 20:24:19,200:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 136/1000
2022-08-31 20:24:36,774:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.57s, LR: 0.00035, Train Loss: 0.1879, Train MAE: 0.1879,
                            Val Loss: 0.4455, Val Acc: 0.4455, Test MAE: 0.4326
2022-08-31 20:24:36,781:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 137/1000
2022-08-31 20:24:54,267:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.49s, LR: 0.00035, Train Loss: 0.1800, Train MAE: 0.1800,
                            Val Loss: 0.4242, Val Acc: 0.4242, Test MAE: 0.4223
2022-08-31 20:24:54,275:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 138/1000
2022-08-31 20:25:11,868:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.59s, LR: 0.00035, Train Loss: 0.1752, Train MAE: 0.1752,
                            Val Loss: 0.4306, Val Acc: 0.4306, Test MAE: 0.4263
2022-08-31 20:25:11,875:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 139/1000
2022-08-31 20:25:29,356:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.48s, LR: 0.00035, Train Loss: 0.1750, Train MAE: 0.1750,
                            Val Loss: 0.4279, Val Acc: 0.4279, Test MAE: 0.4254
2022-08-31 20:25:29,363:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 140/1000
2022-08-31 20:43:25,602:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 1076.24s, LR: 0.00035, Train Loss: 0.1717, Train MAE: 0.1717,
                            Val Loss: 0.4321, Val Acc: 0.4321, Test MAE: 0.4246
2022-08-31 20:43:25,611:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 141/1000
2022-08-31 20:43:42,837:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.23s, LR: 0.00035, Train Loss: 0.1667, Train MAE: 0.1667,
                            Val Loss: 0.4347, Val Acc: 0.4347, Test MAE: 0.4188
2022-08-31 20:43:42,844:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 142/1000
2022-08-31 20:43:59,965:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.12s, LR: 0.00035, Train Loss: 0.1633, Train MAE: 0.1633,
                            Val Loss: 0.4406, Val Acc: 0.4406, Test MAE: 0.4233
2022-08-31 20:43:59,972:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 143/1000
2022-08-31 20:59:16,383:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.41689568758010864
2022-08-31 20:59:16,384:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 916.41s, LR: 0.00035, Train Loss: 0.1697, Train MAE: 0.1697,
                            Val Loss: 0.4284, Val Acc: 0.4284, Test MAE: 0.4169
2022-08-31 20:59:16,391:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 144/1000
2022-08-31 20:59:33,789:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.40s, LR: 0.00035, Train Loss: 0.1563, Train MAE: 0.1563,
                            Val Loss: 0.4297, Val Acc: 0.4297, Test MAE: 0.4193
2022-08-31 20:59:33,796:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 145/1000
2022-08-31 20:59:51,048:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.25s, LR: 0.00035, Train Loss: 0.1637, Train MAE: 0.1637,
                            Val Loss: 0.4339, Val Acc: 0.4339, Test MAE: 0.4210
2022-08-31 20:59:51,055:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 146/1000
2022-08-31 21:00:08,254:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.20s, LR: 0.00035, Train Loss: 0.1645, Train MAE: 0.1645,
                            Val Loss: 0.4308, Val Acc: 0.4308, Test MAE: 0.4195
2022-08-31 21:00:08,263:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 147/1000
2022-08-31 21:00:25,555:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.29s, LR: 0.00035, Train Loss: 0.1581, Train MAE: 0.1581,
                            Val Loss: 0.4326, Val Acc: 0.4326, Test MAE: 0.4188
2022-08-31 21:00:25,563:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 148/1000
2022-08-31 21:00:42,966:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.41606898978352547
2022-08-31 21:00:42,968:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.40s, LR: 0.00035, Train Loss: 0.1645, Train MAE: 0.1645,
                            Val Loss: 0.4283, Val Acc: 0.4283, Test MAE: 0.4161
2022-08-31 21:00:42,975:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 149/1000
2022-08-31 21:01:00,299:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.32s, LR: 0.00035, Train Loss: 0.1736, Train MAE: 0.1736,
                            Val Loss: 0.4299, Val Acc: 0.4299, Test MAE: 0.4250
2022-08-31 21:01:00,306:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 150/1000
2022-08-31 21:01:17,529:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.22s, LR: 0.00035, Train Loss: 0.1643, Train MAE: 0.1643,
                            Val Loss: 0.4325, Val Acc: 0.4325, Test MAE: 0.4183
2022-08-31 21:01:17,537:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 151/1000
2022-08-31 21:01:34,883:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.40360287204384804
2022-08-31 21:01:34,884:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.35s, LR: 0.00017, Train Loss: 0.1512, Train MAE: 0.1512,
                            Val Loss: 0.4224, Val Acc: 0.4224, Test MAE: 0.4036
2022-08-31 21:01:34,892:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 152/1000
2022-08-31 21:01:52,285:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4029430001974106
2022-08-31 21:01:52,287:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.40s, LR: 0.00017, Train Loss: 0.1431, Train MAE: 0.1431,
                            Val Loss: 0.4199, Val Acc: 0.4199, Test MAE: 0.4029
2022-08-31 21:01:52,295:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 153/1000
2022-08-31 21:02:09,737:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.44s, LR: 0.00017, Train Loss: 0.1375, Train MAE: 0.1375,
                            Val Loss: 0.4304, Val Acc: 0.4304, Test MAE: 0.4110
2022-08-31 21:02:09,744:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 154/1000
2022-08-31 21:02:27,094:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.4003763124346733
2022-08-31 21:02:27,095:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.35s, LR: 0.00017, Train Loss: 0.1455, Train MAE: 0.1455,
                            Val Loss: 0.4221, Val Acc: 0.4221, Test MAE: 0.4004
2022-08-31 21:02:27,102:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 155/1000
2022-08-31 21:02:44,499:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.40s, LR: 0.00017, Train Loss: 0.1363, Train MAE: 0.1363,
                            Val Loss: 0.4339, Val Acc: 0.4339, Test MAE: 0.4083
2022-08-31 21:02:44,507:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 156/1000
2022-08-31 21:03:02,303:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.39928239956498146
2022-08-31 21:03:02,305:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.80s, LR: 0.00017, Train Loss: 0.1309, Train MAE: 0.1309,
                            Val Loss: 0.4233, Val Acc: 0.4233, Test MAE: 0.3993
2022-08-31 21:03:02,313:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 157/1000
2022-08-31 21:03:20,196:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.88s, LR: 0.00017, Train Loss: 0.1300, Train MAE: 0.1300,
                            Val Loss: 0.4269, Val Acc: 0.4269, Test MAE: 0.4080
2022-08-31 21:03:20,204:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 158/1000
2022-08-31 21:03:38,397:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.19s, LR: 0.00017, Train Loss: 0.1356, Train MAE: 0.1356,
                            Val Loss: 0.4254, Val Acc: 0.4254, Test MAE: 0.4045
2022-08-31 21:03:38,405:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 159/1000
2022-08-31 21:03:56,833:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.43s, LR: 0.00017, Train Loss: 0.1220, Train MAE: 0.1220,
                            Val Loss: 0.4311, Val Acc: 0.4311, Test MAE: 0.4161
2022-08-31 21:03:56,841:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 160/1000
2022-08-31 21:04:15,941:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.10s, LR: 0.00017, Train Loss: 0.1247, Train MAE: 0.1247,
                            Val Loss: 0.4285, Val Acc: 0.4285, Test MAE: 0.4111
2022-08-31 21:04:15,948:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 161/1000
2022-08-31 21:04:35,010:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.06s, LR: 0.00017, Train Loss: 0.1193, Train MAE: 0.1193,
                            Val Loss: 0.4269, Val Acc: 0.4269, Test MAE: 0.4145
2022-08-31 21:04:35,018:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 162/1000
2022-08-31 21:04:54,230:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.21s, LR: 0.00017, Train Loss: 0.1293, Train MAE: 0.1293,
                            Val Loss: 0.4234, Val Acc: 0.4234, Test MAE: 0.4125
2022-08-31 21:04:54,238:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 163/1000
2022-08-31 21:05:13,633:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.40s, LR: 0.00017, Train Loss: 0.1213, Train MAE: 0.1213,
                            Val Loss: 0.4148, Val Acc: 0.4148, Test MAE: 0.4059
2022-08-31 21:05:13,642:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 164/1000
2022-08-31 21:05:33,548:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 0.39555399119853973
2022-08-31 21:05:33,550:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.91s, LR: 0.00017, Train Loss: 0.1258, Train MAE: 0.1258,
                            Val Loss: 0.4168, Val Acc: 0.4168, Test MAE: 0.3956
2022-08-31 21:05:33,560:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 165/1000
2022-08-31 21:05:53,372:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.81s, LR: 0.00017, Train Loss: 0.1284, Train MAE: 0.1284,
                            Val Loss: 0.4828, Val Acc: 0.4828, Test MAE: 0.4353
2022-08-31 21:05:53,381:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 166/1000
2022-08-31 21:06:13,481:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.10s, LR: 0.00017, Train Loss: 0.1294, Train MAE: 0.1294,
                            Val Loss: 0.4262, Val Acc: 0.4262, Test MAE: 0.4152
2022-08-31 21:06:13,490:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 167/1000
2022-08-31 21:06:33,904:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.41s, LR: 0.00017, Train Loss: 0.1253, Train MAE: 0.1253,
                            Val Loss: 0.4255, Val Acc: 0.4255, Test MAE: 0.3994
2022-08-31 21:06:33,915:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 168/1000
2022-08-31 21:06:54,010:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.09s, LR: 0.00017, Train Loss: 0.1222, Train MAE: 0.1222,
                            Val Loss: 0.4359, Val Acc: 0.4359, Test MAE: 0.4048
2022-08-31 21:06:54,019:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 169/1000
2022-08-31 21:07:14,235:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.22s, LR: 0.00017, Train Loss: 0.1186, Train MAE: 0.1186,
                            Val Loss: 0.4300, Val Acc: 0.4300, Test MAE: 0.4134
2022-08-31 21:07:14,244:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 170/1000
2022-08-31 21:07:34,769:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.53s, LR: 0.00017, Train Loss: 0.1247, Train MAE: 0.1247,
                            Val Loss: 0.4252, Val Acc: 0.4252, Test MAE: 0.4104
2022-08-31 21:07:34,778:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 171/1000
2022-08-31 21:07:55,345:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.57s, LR: 0.00017, Train Loss: 0.1172, Train MAE: 0.1172,
                            Val Loss: 0.4273, Val Acc: 0.4273, Test MAE: 0.4124
2022-08-31 21:07:55,354:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 172/1000
2022-08-31 21:08:15,705:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.35s, LR: 0.00017, Train Loss: 0.1202, Train MAE: 0.1202,
                            Val Loss: 0.4258, Val Acc: 0.4258, Test MAE: 0.4105
2022-08-31 21:08:15,715:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 173/1000
2022-08-31 21:08:36,446:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.73s, LR: 0.00017, Train Loss: 0.1231, Train MAE: 0.1231,
                            Val Loss: 0.4367, Val Acc: 0.4367, Test MAE: 0.4066
2022-08-31 21:08:36,456:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 174/1000
2022-08-31 21:08:57,492:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.04s, LR: 0.00017, Train Loss: 0.1186, Train MAE: 0.1186,
                            Val Loss: 0.4253, Val Acc: 0.4253, Test MAE: 0.4076
2022-08-31 21:08:57,501:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 175/1000
2022-08-31 21:09:18,846:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.34s, LR: 0.00017, Train Loss: 0.1170, Train MAE: 0.1170,
                            Val Loss: 0.4283, Val Acc: 0.4283, Test MAE: 0.4096
2022-08-31 21:09:18,855:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 176/1000
2022-08-31 21:09:40,031:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.18s, LR: 0.00017, Train Loss: 0.1276, Train MAE: 0.1276,
                            Val Loss: 0.4295, Val Acc: 0.4295, Test MAE: 0.4133
2022-08-31 21:09:40,041:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 177/1000
2022-08-31 21:10:01,019:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00017, Train Loss: 0.1240, Train MAE: 0.1240,
                            Val Loss: 0.4306, Val Acc: 0.4306, Test MAE: 0.4126
2022-08-31 21:10:01,028:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 178/1000
2022-08-31 21:10:22,097:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.07s, LR: 0.00017, Train Loss: 0.1170, Train MAE: 0.1170,
                            Val Loss: 0.4280, Val Acc: 0.4280, Test MAE: 0.4109
2022-08-31 21:10:22,106:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 179/1000
2022-08-31 21:10:42,933:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.83s, LR: 0.00017, Train Loss: 0.1223, Train MAE: 0.1223,
                            Val Loss: 0.4299, Val Acc: 0.4299, Test MAE: 0.4069
2022-08-31 21:10:42,943:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 180/1000
2022-08-31 21:11:03,969:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.03s, LR: 0.00009, Train Loss: 0.1034, Train MAE: 0.1034,
                            Val Loss: 0.4205, Val Acc: 0.4205, Test MAE: 0.4032
2022-08-31 21:11:03,979:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 181/1000
2022-08-31 21:11:24,968:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.99s, LR: 0.00009, Train Loss: 0.1095, Train MAE: 0.1095,
                            Val Loss: 0.4271, Val Acc: 0.4271, Test MAE: 0.4092
2022-08-31 21:11:24,978:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 182/1000
2022-08-31 21:11:46,241:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.26s, LR: 0.00009, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.4216, Val Acc: 0.4216, Test MAE: 0.4044
2022-08-31 21:11:46,251:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 183/1000
2022-08-31 21:12:07,772:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.52s, LR: 0.00009, Train Loss: 0.1052, Train MAE: 0.1052,
                            Val Loss: 0.4283, Val Acc: 0.4283, Test MAE: 0.4098
2022-08-31 21:12:07,782:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 184/1000
2022-08-31 21:12:29,416:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 21.63s, LR: 0.00009, Train Loss: 0.0997, Train MAE: 0.0997,
                            Val Loss: 0.4241, Val Acc: 0.4241, Test MAE: 0.4072
2022-08-31 21:12:29,425:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 185/1000
2022-08-31 21:12:51,810:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 22.39s, LR: 0.00009, Train Loss: 0.1077, Train MAE: 0.1077,
                            Val Loss: 0.4313, Val Acc: 0.4313, Test MAE: 0.4061
2022-08-31 21:12:51,820:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 186/1000
2022-08-31 21:13:14,862:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.04s, LR: 0.00009, Train Loss: 0.1008, Train MAE: 0.1008,
                            Val Loss: 0.4275, Val Acc: 0.4275, Test MAE: 0.4041
2022-08-31 21:13:14,873:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 187/1000
2022-08-31 21:13:38,360:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 23.49s, LR: 0.00009, Train Loss: 0.1057, Train MAE: 0.1057,
                            Val Loss: 0.4321, Val Acc: 0.4321, Test MAE: 0.4099
2022-08-31 21:13:38,372:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 188/1000
2022-08-31 21:14:02,473:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00009, Train Loss: 0.0988, Train MAE: 0.0988,
                            Val Loss: 0.4269, Val Acc: 0.4269, Test MAE: 0.4042
2022-08-31 21:14:02,485:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 189/1000
2022-08-31 21:14:27,608:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.12s, LR: 0.00009, Train Loss: 0.0988, Train MAE: 0.0988,
                            Val Loss: 0.4257, Val Acc: 0.4257, Test MAE: 0.4050
2022-08-31 21:14:27,620:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 190/1000
2022-08-31 21:14:53,052:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.43s, LR: 0.00009, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.4264, Val Acc: 0.4264, Test MAE: 0.4018
2022-08-31 21:14:53,063:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 191/1000
2022-08-31 21:15:18,446:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.38s, LR: 0.00009, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.4346, Val Acc: 0.4346, Test MAE: 0.4070
2022-08-31 21:15:18,457:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 192/1000
2022-08-31 21:15:44,173:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.72s, LR: 0.00009, Train Loss: 0.0986, Train MAE: 0.0986,
                            Val Loss: 0.4275, Val Acc: 0.4275, Test MAE: 0.4072
2022-08-31 21:15:44,186:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 193/1000
2022-08-31 21:16:09,622:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.44s, LR: 0.00009, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.4278, Val Acc: 0.4278, Test MAE: 0.4091
2022-08-31 21:16:09,634:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 194/1000
2022-08-31 21:16:34,992:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.36s, LR: 0.00009, Train Loss: 0.1074, Train MAE: 0.1074,
                            Val Loss: 0.4305, Val Acc: 0.4305, Test MAE: 0.4080
2022-08-31 21:16:35,005:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 195/1000
2022-08-31 21:17:00,053:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.05s, LR: 0.00009, Train Loss: 0.0995, Train MAE: 0.0995,
                            Val Loss: 0.4291, Val Acc: 0.4291, Test MAE: 0.4040
2022-08-31 21:17:00,065:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 196/1000
2022-08-31 21:17:24,949:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 24.88s, LR: 0.00004, Train Loss: 0.0965, Train MAE: 0.0965,
                            Val Loss: 0.4306, Val Acc: 0.4306, Test MAE: 0.4084
2022-08-31 21:17:24,959:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 197/1000
2022-08-31 21:17:49,498:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 24.54s, LR: 0.00004, Train Loss: 0.0889, Train MAE: 0.0889,
                            Val Loss: 0.4254, Val Acc: 0.4254, Test MAE: 0.4007
2022-08-31 21:17:49,509:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 198/1000
2022-08-31 21:18:14,612:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.10s, LR: 0.00004, Train Loss: 0.0916, Train MAE: 0.0916,
                            Val Loss: 0.4262, Val Acc: 0.4262, Test MAE: 0.4044
2022-08-31 21:18:14,624:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 199/1000
2022-08-31 21:18:39,819:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.19s, LR: 0.00004, Train Loss: 0.0989, Train MAE: 0.0989,
                            Val Loss: 0.4261, Val Acc: 0.4261, Test MAE: 0.4057
2022-08-31 21:18:39,830:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 200/1000
2022-08-31 21:19:04,897:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.07s, LR: 0.00004, Train Loss: 0.1022, Train MAE: 0.1022,
                            Val Loss: 0.4243, Val Acc: 0.4243, Test MAE: 0.4044
2022-08-31 21:19:04,908:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 201/1000
2022-08-31 21:19:30,227:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.32s, LR: 0.00004, Train Loss: 0.0922, Train MAE: 0.0922,
                            Val Loss: 0.4266, Val Acc: 0.4266, Test MAE: 0.4017
2022-08-31 21:19:30,239:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 202/1000
2022-08-31 21:19:55,688:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.45s, LR: 0.00004, Train Loss: 0.1014, Train MAE: 0.1014,
                            Val Loss: 0.4271, Val Acc: 0.4271, Test MAE: 0.4071
2022-08-31 21:19:55,700:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 203/1000
2022-08-31 21:20:21,193:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.49s, LR: 0.00004, Train Loss: 0.0908, Train MAE: 0.0908,
                            Val Loss: 0.4310, Val Acc: 0.4310, Test MAE: 0.4114
2022-08-31 21:20:21,205:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 204/1000
2022-08-31 21:20:46,724:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.52s, LR: 0.00004, Train Loss: 0.0959, Train MAE: 0.0959,
                            Val Loss: 0.4313, Val Acc: 0.4313, Test MAE: 0.4048
2022-08-31 21:20:46,736:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 205/1000
2022-08-31 21:21:12,696:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.96s, LR: 0.00004, Train Loss: 0.0969, Train MAE: 0.0969,
                            Val Loss: 0.4283, Val Acc: 0.4283, Test MAE: 0.4037
2022-08-31 21:21:12,710:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 206/1000
2022-08-31 21:21:38,395:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.69s, LR: 0.00004, Train Loss: 0.0874, Train MAE: 0.0874,
                            Val Loss: 0.4285, Val Acc: 0.4285, Test MAE: 0.4061
2022-08-31 21:21:38,407:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 207/1000
2022-08-31 21:22:04,036:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.63s, LR: 0.00004, Train Loss: 0.0867, Train MAE: 0.0867,
                            Val Loss: 0.4296, Val Acc: 0.4296, Test MAE: 0.4068
2022-08-31 21:22:04,048:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 208/1000
2022-08-31 21:22:29,526:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.48s, LR: 0.00004, Train Loss: 0.0902, Train MAE: 0.0902,
                            Val Loss: 0.4301, Val Acc: 0.4301, Test MAE: 0.4044
2022-08-31 21:22:29,538:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 209/1000
2022-08-31 21:22:55,391:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.85s, LR: 0.00004, Train Loss: 0.0978, Train MAE: 0.0978,
                            Val Loss: 0.4288, Val Acc: 0.4288, Test MAE: 0.4036
2022-08-31 21:22:55,404:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 210/1000
2022-08-31 21:23:21,398:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.99s, LR: 0.00004, Train Loss: 0.0957, Train MAE: 0.0957,
                            Val Loss: 0.4302, Val Acc: 0.4302, Test MAE: 0.4076
2022-08-31 21:23:21,411:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 211/1000
2022-08-31 21:23:47,369:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 25.96s, LR: 0.00004, Train Loss: 0.0977, Train MAE: 0.0977,
                            Val Loss: 0.4244, Val Acc: 0.4244, Test MAE: 0.4046
2022-08-31 21:23:47,382:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 212/1000
2022-08-31 21:24:13,644:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 26.26s, LR: 0.00002, Train Loss: 0.0923, Train MAE: 0.0923,
                            Val Loss: 0.4256, Val Acc: 0.4256, Test MAE: 0.4035
2022-08-31 21:24:13,657:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 213/1000
2022-08-31 21:24:34,087:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 20.43s, LR: 0.00002, Train Loss: 0.0967, Train MAE: 0.0967,
                            Val Loss: 0.4314, Val Acc: 0.4314, Test MAE: 0.4043
2022-08-31 21:24:34,095:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 214/1000
2022-08-31 21:24:52,282:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.19s, LR: 0.00002, Train Loss: 0.0848, Train MAE: 0.0848,
                            Val Loss: 0.4293, Val Acc: 0.4293, Test MAE: 0.4056
2022-08-31 21:24:52,289:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 215/1000
2022-08-31 21:25:10,709:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.42s, LR: 0.00002, Train Loss: 0.0947, Train MAE: 0.0947,
                            Val Loss: 0.4300, Val Acc: 0.4300, Test MAE: 0.4069
2022-08-31 21:25:10,716:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 216/1000
2022-08-31 21:25:28,874:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.16s, LR: 0.00002, Train Loss: 0.0868, Train MAE: 0.0868,
                            Val Loss: 0.4298, Val Acc: 0.4298, Test MAE: 0.4085
2022-08-31 21:25:28,882:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 217/1000
2022-08-31 21:25:46,642:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.76s, LR: 0.00002, Train Loss: 0.0934, Train MAE: 0.0934,
                            Val Loss: 0.4273, Val Acc: 0.4273, Test MAE: 0.4040
2022-08-31 21:25:46,649:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 218/1000
2022-08-31 21:26:04,850:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.20s, LR: 0.00002, Train Loss: 0.0952, Train MAE: 0.0952,
                            Val Loss: 0.4310, Val Acc: 0.4310, Test MAE: 0.4104
2022-08-31 21:26:04,858:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 219/1000
2022-08-31 21:26:23,576:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.72s, LR: 0.00002, Train Loss: 0.0994, Train MAE: 0.0994,
                            Val Loss: 0.4275, Val Acc: 0.4275, Test MAE: 0.4059
2022-08-31 21:26:23,583:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 220/1000
2022-08-31 21:26:41,898:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.31s, LR: 0.00002, Train Loss: 0.0936, Train MAE: 0.0936,
                            Val Loss: 0.4288, Val Acc: 0.4288, Test MAE: 0.4073
2022-08-31 21:26:41,905:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 221/1000
2022-08-31 21:27:00,692:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.79s, LR: 0.00002, Train Loss: 0.0795, Train MAE: 0.0795,
                            Val Loss: 0.4279, Val Acc: 0.4279, Test MAE: 0.4074
2022-08-31 21:27:00,700:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 222/1000
2022-08-31 21:27:19,069:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.37s, LR: 0.00002, Train Loss: 0.0932, Train MAE: 0.0932,
                            Val Loss: 0.4359, Val Acc: 0.4359, Test MAE: 0.4138
2022-08-31 21:27:19,077:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 223/1000
2022-08-31 21:27:38,262:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 19.18s, LR: 0.00002, Train Loss: 0.0902, Train MAE: 0.0902,
                            Val Loss: 0.4267, Val Acc: 0.4267, Test MAE: 0.4037
2022-08-31 21:27:38,269:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 224/1000
2022-08-31 21:27:56,677:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.41s, LR: 0.00002, Train Loss: 0.0874, Train MAE: 0.0874,
                            Val Loss: 0.4262, Val Acc: 0.4262, Test MAE: 0.4024
2022-08-31 21:27:56,684:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 225/1000
2022-08-31 21:28:15,208:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.52s, LR: 0.00002, Train Loss: 0.0970, Train MAE: 0.0970,
                            Val Loss: 0.4292, Val Acc: 0.4292, Test MAE: 0.4077
2022-08-31 21:28:15,216:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 226/1000
2022-08-31 21:28:34,097:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.88s, LR: 0.00002, Train Loss: 0.0894, Train MAE: 0.0894,
                            Val Loss: 0.4300, Val Acc: 0.4300, Test MAE: 0.4096
2022-08-31 21:28:34,105:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 227/1000
2022-08-31 21:28:52,923:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.82s, LR: 0.00002, Train Loss: 0.0935, Train MAE: 0.0935,
                            Val Loss: 0.4303, Val Acc: 0.4303, Test MAE: 0.4060
2022-08-31 21:28:52,931:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 228/1000
2022-08-31 21:29:10,918:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.99s, LR: 0.00001, Train Loss: 0.0954, Train MAE: 0.0954,
                            Val Loss: 0.4256, Val Acc: 0.4256, Test MAE: 0.4026
2022-08-31 21:29:10,926:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 229/1000
2022-08-31 21:29:28,694:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.77s, LR: 0.00001, Train Loss: 0.0937, Train MAE: 0.0937,
                            Val Loss: 0.4265, Val Acc: 0.4265, Test MAE: 0.4027
2022-08-31 21:29:28,703:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 230/1000
2022-08-31 21:29:47,582:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.88s, LR: 0.00001, Train Loss: 0.0873, Train MAE: 0.0873,
                            Val Loss: 0.4302, Val Acc: 0.4302, Test MAE: 0.4038
2022-08-31 21:29:47,589:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 231/1000
2022-08-31 21:30:05,559:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.97s, LR: 0.00001, Train Loss: 0.0830, Train MAE: 0.0830,
                            Val Loss: 0.4274, Val Acc: 0.4274, Test MAE: 0.4034
2022-08-31 21:30:05,568:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 232/1000
2022-08-31 21:30:23,569:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.00s, LR: 0.00001, Train Loss: 0.0917, Train MAE: 0.0917,
                            Val Loss: 0.4294, Val Acc: 0.4294, Test MAE: 0.4048
2022-08-31 21:30:23,576:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 233/1000
2022-08-31 21:30:41,486:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.91s, LR: 0.00001, Train Loss: 0.0928, Train MAE: 0.0928,
                            Val Loss: 0.4278, Val Acc: 0.4278, Test MAE: 0.4027
2022-08-31 21:30:41,495:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 234/1000
2022-08-31 21:30:59,268:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.77s, LR: 0.00001, Train Loss: 0.0835, Train MAE: 0.0835,
                            Val Loss: 0.4324, Val Acc: 0.4324, Test MAE: 0.4068
2022-08-31 21:30:59,275:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 235/1000
2022-08-31 21:31:17,812:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.54s, LR: 0.00001, Train Loss: 0.0876, Train MAE: 0.0876,
                            Val Loss: 0.4289, Val Acc: 0.4289, Test MAE: 0.4074
2022-08-31 21:31:17,820:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 236/1000
2022-08-31 21:31:35,954:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.13s, LR: 0.00001, Train Loss: 0.0999, Train MAE: 0.0999,
                            Val Loss: 0.4318, Val Acc: 0.4318, Test MAE: 0.4103
2022-08-31 21:31:35,962:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 237/1000
2022-08-31 21:31:53,967:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.00s, LR: 0.00001, Train Loss: 0.0936, Train MAE: 0.0936,
                            Val Loss: 0.4276, Val Acc: 0.4276, Test MAE: 0.4058
2022-08-31 21:31:53,975:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 238/1000
2022-08-31 21:32:11,472:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.50s, LR: 0.00001, Train Loss: 0.0951, Train MAE: 0.0951,
                            Val Loss: 0.4270, Val Acc: 0.4270, Test MAE: 0.4036
2022-08-31 21:32:11,480:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 239/1000
2022-08-31 21:32:29,010:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.53s, LR: 0.00001, Train Loss: 0.0879, Train MAE: 0.0879,
                            Val Loss: 0.4278, Val Acc: 0.4278, Test MAE: 0.4028
2022-08-31 21:32:29,019:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 240/1000
2022-08-31 21:32:47,199:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.18s, LR: 0.00001, Train Loss: 0.0910, Train MAE: 0.0910,
                            Val Loss: 0.4294, Val Acc: 0.4294, Test MAE: 0.4071
2022-08-31 21:32:47,206:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 241/1000
2022-08-31 21:33:05,218:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.01s, LR: 0.00001, Train Loss: 0.0864, Train MAE: 0.0864,
                            Val Loss: 0.4273, Val Acc: 0.4273, Test MAE: 0.4048
2022-08-31 21:33:05,226:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 242/1000
2022-08-31 21:33:23,324:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 18.10s, LR: 0.00001, Train Loss: 0.0847, Train MAE: 0.0847,
                            Val Loss: 0.4303, Val Acc: 0.4303, Test MAE: 0.4077
2022-08-31 21:33:23,332:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 243/1000
2022-08-31 21:33:39,702:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.37s, LR: 0.00001, Train Loss: 0.0872, Train MAE: 0.0872,
                            Val Loss: 0.4273, Val Acc: 0.4273, Test MAE: 0.4038
2022-08-31 21:33:39,709:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 244/1000
2022-08-31 21:33:55,250:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.54s, LR: 0.00001, Train Loss: 0.0865, Train MAE: 0.0865,
                            Val Loss: 0.4274, Val Acc: 0.4274, Test MAE: 0.4042
2022-08-31 21:33:55,257:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 245/1000
2022-08-31 21:34:10,677:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.42s, LR: 0.00001, Train Loss: 0.0866, Train MAE: 0.0866,
                            Val Loss: 0.4322, Val Acc: 0.4322, Test MAE: 0.4072
2022-08-31 21:34:10,684:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 246/1000
2022-08-31 21:34:26,094:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.41s, LR: 0.00001, Train Loss: 0.0823, Train MAE: 0.0823,
                            Val Loss: 0.4292, Val Acc: 0.4292, Test MAE: 0.4056
2022-08-31 21:34:26,101:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 247/1000
2022-08-31 21:34:42,859:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.76s, LR: 0.00001, Train Loss: 0.0786, Train MAE: 0.0786,
                            Val Loss: 0.4294, Val Acc: 0.4294, Test MAE: 0.4075
2022-08-31 21:34:42,866:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 248/1000
2022-08-31 21:34:59,489:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.62s, LR: 0.00001, Train Loss: 0.0834, Train MAE: 0.0834,
                            Val Loss: 0.4285, Val Acc: 0.4285, Test MAE: 0.4080
2022-08-31 21:34:59,495:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 249/1000
2022-08-31 21:35:15,692:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00001, Train Loss: 0.0955, Train MAE: 0.0955,
                            Val Loss: 0.4277, Val Acc: 0.4277, Test MAE: 0.4034
2022-08-31 21:35:15,699:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 250/1000
2022-08-31 21:35:32,460:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.76s, LR: 0.00001, Train Loss: 0.0898, Train MAE: 0.0898,
                            Val Loss: 0.4343, Val Acc: 0.4343, Test MAE: 0.4071
2022-08-31 21:35:32,467:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 251/1000
2022-08-31 21:35:49,039:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.57s, LR: 0.00001, Train Loss: 0.0866, Train MAE: 0.0866,
                            Val Loss: 0.4303, Val Acc: 0.4303, Test MAE: 0.4055
2022-08-31 21:35:49,046:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 252/1000
2022-08-31 21:36:06,149:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.10s, LR: 0.00001, Train Loss: 0.0816, Train MAE: 0.0816,
                            Val Loss: 0.4332, Val Acc: 0.4332, Test MAE: 0.4091
2022-08-31 21:36:06,156:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 253/1000
2022-08-31 21:36:22,609:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.45s, LR: 0.00001, Train Loss: 0.0780, Train MAE: 0.0780,
                            Val Loss: 0.4330, Val Acc: 0.4330, Test MAE: 0.4060
2022-08-31 21:36:22,616:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 254/1000
2022-08-31 21:36:39,739:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.12s, LR: 0.00001, Train Loss: 0.0879, Train MAE: 0.0879,
                            Val Loss: 0.4315, Val Acc: 0.4315, Test MAE: 0.4059
2022-08-31 21:36:39,746:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 255/1000
2022-08-31 21:36:56,166:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.42s, LR: 0.00001, Train Loss: 0.0744, Train MAE: 0.0744,
                            Val Loss: 0.4305, Val Acc: 0.4305, Test MAE: 0.4052
2022-08-31 21:36:56,173:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 256/1000
2022-08-31 21:37:13,000:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.83s, LR: 0.00001, Train Loss: 0.0853, Train MAE: 0.0853,
                            Val Loss: 0.4308, Val Acc: 0.4308, Test MAE: 0.4062
2022-08-31 21:37:13,008:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 257/1000
2022-08-31 21:37:29,039:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.03s, LR: 0.00001, Train Loss: 0.0896, Train MAE: 0.0896,
                            Val Loss: 0.4286, Val Acc: 0.4286, Test MAE: 0.4049
2022-08-31 21:37:29,047:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 258/1000
2022-08-31 21:37:45,151:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00001, Train Loss: 0.0909, Train MAE: 0.0909,
                            Val Loss: 0.4282, Val Acc: 0.4282, Test MAE: 0.4054
2022-08-31 21:37:45,158:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 259/1000
2022-08-31 21:38:00,830:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.67s, LR: 0.00001, Train Loss: 0.0836, Train MAE: 0.0836,
                            Val Loss: 0.4297, Val Acc: 0.4297, Test MAE: 0.4051
2022-08-31 21:38:00,837:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 260/1000
2022-08-31 21:38:16,417:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.58s, LR: 0.00000, Train Loss: 0.0781, Train MAE: 0.0781,
                            Val Loss: 0.4280, Val Acc: 0.4280, Test MAE: 0.4057
2022-08-31 21:38:16,424:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 261/1000
2022-08-31 21:38:32,293:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.87s, LR: 0.00000, Train Loss: 0.0870, Train MAE: 0.0870,
                            Val Loss: 0.4290, Val Acc: 0.4290, Test MAE: 0.4080
2022-08-31 21:38:32,300:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 262/1000
2022-08-31 21:38:48,649:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.35s, LR: 0.00000, Train Loss: 0.0885, Train MAE: 0.0885,
                            Val Loss: 0.4296, Val Acc: 0.4296, Test MAE: 0.4047
2022-08-31 21:38:48,656:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 263/1000
2022-08-31 21:39:04,751:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00000, Train Loss: 0.0805, Train MAE: 0.0805,
                            Val Loss: 0.4304, Val Acc: 0.4304, Test MAE: 0.4077
2022-08-31 21:39:04,757:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 264/1000
2022-08-31 21:39:20,464:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.71s, LR: 0.00000, Train Loss: 0.0847, Train MAE: 0.0847,
                            Val Loss: 0.4352, Val Acc: 0.4352, Test MAE: 0.4147
2022-08-31 21:39:20,471:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 265/1000
2022-08-31 21:39:35,867:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.40s, LR: 0.00000, Train Loss: 0.0842, Train MAE: 0.0842,
                            Val Loss: 0.4312, Val Acc: 0.4312, Test MAE: 0.4052
2022-08-31 21:39:35,874:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 266/1000
2022-08-31 21:39:51,297:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.42s, LR: 0.00000, Train Loss: 0.0876, Train MAE: 0.0876,
                            Val Loss: 0.4341, Val Acc: 0.4341, Test MAE: 0.4115
2022-08-31 21:39:51,305:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 267/1000
2022-08-31 21:40:07,029:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.72s, LR: 0.00000, Train Loss: 0.0853, Train MAE: 0.0853,
                            Val Loss: 0.4297, Val Acc: 0.4297, Test MAE: 0.4069
2022-08-31 21:40:07,036:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 268/1000
2022-08-31 21:40:23,350:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.31s, LR: 0.00000, Train Loss: 0.0850, Train MAE: 0.0850,
                            Val Loss: 0.4280, Val Acc: 0.4280, Test MAE: 0.4049
2022-08-31 21:40:23,357:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 269/1000
2022-08-31 21:40:40,515:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.16s, LR: 0.00000, Train Loss: 0.0914, Train MAE: 0.0914,
                            Val Loss: 0.4322, Val Acc: 0.4322, Test MAE: 0.4084
2022-08-31 21:40:40,523:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 270/1000
2022-08-31 21:40:56,284:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.76s, LR: 0.00000, Train Loss: 0.0897, Train MAE: 0.0897,
                            Val Loss: 0.4286, Val Acc: 0.4286, Test MAE: 0.4023
2022-08-31 21:40:56,292:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 271/1000
2022-08-31 21:41:11,883:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.59s, LR: 0.00000, Train Loss: 0.0844, Train MAE: 0.0844,
                            Val Loss: 0.4299, Val Acc: 0.4299, Test MAE: 0.4041
2022-08-31 21:41:11,890:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 272/1000
2022-08-31 21:41:27,388:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.50s, LR: 0.00000, Train Loss: 0.0910, Train MAE: 0.0910,
                            Val Loss: 0.4280, Val Acc: 0.4280, Test MAE: 0.4059
2022-08-31 21:41:27,395:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 273/1000
2022-08-31 21:41:42,855:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.46s, LR: 0.00000, Train Loss: 0.0845, Train MAE: 0.0845,
                            Val Loss: 0.4281, Val Acc: 0.4281, Test MAE: 0.4041
2022-08-31 21:41:42,862:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 274/1000
2022-08-31 21:41:58,828:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.97s, LR: 0.00000, Train Loss: 0.0918, Train MAE: 0.0918,
                            Val Loss: 0.4291, Val Acc: 0.4291, Test MAE: 0.4062
2022-08-31 21:41:58,835:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 275/1000
2022-08-31 21:42:14,540:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.70s, LR: 0.00000, Train Loss: 0.0878, Train MAE: 0.0878,
                            Val Loss: 0.4288, Val Acc: 0.4288, Test MAE: 0.4053
2022-08-31 21:42:14,547:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 276/1000
2022-08-31 21:42:30,392:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.84s, LR: 0.00000, Train Loss: 0.0885, Train MAE: 0.0885,
                            Val Loss: 0.4286, Val Acc: 0.4286, Test MAE: 0.4046
2022-08-31 21:42:30,398:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 277/1000
2022-08-31 21:42:45,913:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.51s, LR: 0.00000, Train Loss: 0.0785, Train MAE: 0.0785,
                            Val Loss: 0.4296, Val Acc: 0.4296, Test MAE: 0.4083
2022-08-31 21:42:45,920:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 278/1000
2022-08-31 21:43:01,366:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.45s, LR: 0.00000, Train Loss: 0.0827, Train MAE: 0.0827,
                            Val Loss: 0.4277, Val Acc: 0.4277, Test MAE: 0.4036
2022-08-31 21:43:01,373:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 279/1000
2022-08-31 21:43:16,763:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.39s, LR: 0.00000, Train Loss: 0.0877, Train MAE: 0.0877,
                            Val Loss: 0.4303, Val Acc: 0.4303, Test MAE: 0.4041
2022-08-31 21:43:16,769:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 280/1000
2022-08-31 21:43:32,276:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.51s, LR: 0.00000, Train Loss: 0.0858, Train MAE: 0.0858,
                            Val Loss: 0.4277, Val Acc: 0.4277, Test MAE: 0.4049
2022-08-31 21:43:32,283:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 281/1000
2022-08-31 21:43:47,786:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.50s, LR: 0.00000, Train Loss: 0.0821, Train MAE: 0.0821,
                            Val Loss: 0.4287, Val Acc: 0.4287, Test MAE: 0.4070
2022-08-31 21:43:47,793:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 282/1000
2022-08-31 21:44:03,298:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.50s, LR: 0.00000, Train Loss: 0.0821, Train MAE: 0.0821,
                            Val Loss: 0.4284, Val Acc: 0.4284, Test MAE: 0.4048
2022-08-31 21:44:03,304:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 283/1000
2022-08-31 21:44:19,267:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.96s, LR: 0.00000, Train Loss: 0.0955, Train MAE: 0.0955,
                            Val Loss: 0.4315, Val Acc: 0.4315, Test MAE: 0.4081
2022-08-31 21:44:19,274:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 284/1000
2022-08-31 21:44:35,211:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.94s, LR: 0.00000, Train Loss: 0.0821, Train MAE: 0.0821,
                            Val Loss: 0.4256, Val Acc: 0.4256, Test MAE: 0.4022
2022-08-31 21:44:35,218:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 285/1000
2022-08-31 21:44:51,720:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 16.50s, LR: 0.00000, Train Loss: 0.0873, Train MAE: 0.0873,
                            Val Loss: 0.4308, Val Acc: 0.4308, Test MAE: 0.4069
2022-08-31 21:44:51,727:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 286/1000
2022-08-31 21:45:07,163:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.44s, LR: 0.00000, Train Loss: 0.0960, Train MAE: 0.0960,
                            Val Loss: 0.4310, Val Acc: 0.4310, Test MAE: 0.4042
2022-08-31 21:45:07,170:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 287/1000
2022-08-31 21:45:24,719:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 17.55s, LR: 0.00000, Train Loss: 0.0824, Train MAE: 0.0824,
                            Val Loss: 0.4307, Val Acc: 0.4307, Test MAE: 0.4049
2022-08-31 21:45:24,725:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 288/1000
2022-08-31 21:45:40,403:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.68s, LR: 0.00000, Train Loss: 0.0808, Train MAE: 0.0808,
                            Val Loss: 0.4261, Val Acc: 0.4261, Test MAE: 0.4019
2022-08-31 21:45:40,410:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 289/1000
2022-08-31 21:45:56,048:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.64s, LR: 0.00000, Train Loss: 0.0845, Train MAE: 0.0845,
                            Val Loss: 0.4295, Val Acc: 0.4295, Test MAE: 0.4039
2022-08-31 21:45:56,055:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 290/1000
2022-08-31 21:46:11,619:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.56s, LR: 0.00000, Train Loss: 0.0819, Train MAE: 0.0819,
                            Val Loss: 0.4275, Val Acc: 0.4275, Test MAE: 0.4044
2022-08-31 21:46:11,627:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 291/1000
2022-08-31 21:46:26,910:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 15.28s, LR: 0.00000, Train Loss: 0.0931, Train MAE: 0.0931,
                            Val Loss: 0.4270, Val Acc: 0.4270, Test MAE: 0.4049
2022-08-31 21:46:26,917:main_molecules_graph_regression.py:211 -   train_val_pipeline(): 
!! LR EQUAL TO MIN LR SET.
2022-08-31 21:46:35,745:main_molecules_graph_regression.py:230 -   train_val_pipeline(): Test MAE: 0.4049
2022-08-31 21:46:35,745:main_molecules_graph_regression.py:231 -   train_val_pipeline(): Best Test MAE: 0.3956
2022-08-31 21:46:35,745:main_molecules_graph_regression.py:232 -   train_val_pipeline(): Train MAE: 0.0344
2022-08-31 21:46:35,745:main_molecules_graph_regression.py:233 -   train_val_pipeline(): Best Train MAE Corresponding to Best Test MAE: 0.1258
2022-08-31 21:46:35,745:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Convergence Time (Epochs): 290.0000
2022-08-31 21:46:35,745:main_molecules_graph_regression.py:235 -   train_val_pipeline(): TOTAL TIME TAKEN: 8424.6589s
2022-08-31 21:46:35,745:main_molecules_graph_regression.py:236 -   train_val_pipeline(): AVG TIME PER EPOCH: 28.8627s
2022-09-01 00:00:35,951:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 00:00:40,852:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': 'DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-01 00:00:40,852:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-01 00:00:40,859:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 00:00:40,860:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 608678
2022-09-01 00:03:19,975:main_CYCLES_graph_classification.py:88 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-01 00:03:36,103:main_CYCLES_graph_classification.py:90 -   train_val_pipeline(): Time PE:175.24242687225342
2022-09-01 00:03:36,167:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-01 00:03:36,167:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-01 00:03:36,167:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-01 00:03:36,167:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-01 00:03:36,170:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 00:05:20,661:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5944 to out/CYCLES_graph_classification_b2-bnorm5-idc512-odc512-spd-512checkpoints/PseudoGraphormer_CYCLES_GPU0_1_1_00h00m40s_on_Sep_01_2022/MODELS_
2022-09-01 00:05:20,664:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 104.49s, LR: 0.00050, Train Loss: 0.6881, Train Acc: 0.5250,
                        Val Loss: 0.6775, Val Acc: 0.5730, Test Acc: 0.5944
2022-09-01 00:05:20,666:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 2/1000
2022-09-01 00:06:59,654:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.6034 to out/CYCLES_graph_classification_b2-bnorm5-idc512-odc512-spd-512checkpoints/PseudoGraphormer_CYCLES_GPU0_1_1_00h00m40s_on_Sep_01_2022/MODELS_
2022-09-01 00:06:59,656:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 98.99s, LR: 0.00050, Train Loss: 0.6540, Train Acc: 0.6300,
                        Val Loss: 0.6827, Val Acc: 0.5780, Test Acc: 0.6034
2022-09-01 00:06:59,656:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 3/1000
2022-09-01 00:08:44,290:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 104.63s, LR: 0.00050, Train Loss: 0.6384, Train Acc: 0.6600,
                        Val Loss: 0.6692, Val Acc: 0.5710, Test Acc: 0.6001
2022-09-01 00:08:44,291:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 4/1000
2022-09-01 00:10:29,415:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 105.12s, LR: 0.00050, Train Loss: 0.6259, Train Acc: 0.6550,
                        Val Loss: 0.6817, Val Acc: 0.5730, Test Acc: 0.5954
2022-09-01 00:10:29,416:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 5/1000
2022-09-01 00:12:15,625:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.6207 to out/CYCLES_graph_classification_b2-bnorm5-idc512-odc512-spd-512checkpoints/PseudoGraphormer_CYCLES_GPU0_1_1_00h00m40s_on_Sep_01_2022/MODELS_
2022-09-01 00:12:15,627:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 106.21s, LR: 0.00050, Train Loss: 0.6226, Train Acc: 0.6350,
                        Val Loss: 0.6846, Val Acc: 0.5980, Test Acc: 0.6207
2022-09-01 00:12:15,627:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 6/1000
2022-09-01 00:13:57,371:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.6245 to out/CYCLES_graph_classification_b2-bnorm5-idc512-odc512-spd-512checkpoints/PseudoGraphormer_CYCLES_GPU0_1_1_00h00m40s_on_Sep_01_2022/MODELS_
2022-09-01 00:13:57,374:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 101.75s, LR: 0.00050, Train Loss: 0.6187, Train Acc: 0.6500,
                        Val Loss: 0.6976, Val Acc: 0.6050, Test Acc: 0.6245
2022-09-01 00:13:57,375:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 7/1000
2022-09-01 00:15:38,458:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.6255 to out/CYCLES_graph_classification_b2-bnorm5-idc512-odc512-spd-512checkpoints/PseudoGraphormer_CYCLES_GPU0_1_1_00h00m40s_on_Sep_01_2022/MODELS_
2022-09-01 00:15:38,459:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 101.08s, LR: 0.00050, Train Loss: 0.6138, Train Acc: 0.6500,
                        Val Loss: 0.6923, Val Acc: 0.6050, Test Acc: 0.6255
2022-09-01 00:15:38,459:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 8/1000
2022-09-01 00:17:16,053:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 97.59s, LR: 0.00050, Train Loss: 0.6182, Train Acc: 0.6150,
                        Val Loss: 0.6736, Val Acc: 0.5800, Test Acc: 0.5992
2022-09-01 00:17:16,054:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 9/1000
2022-09-01 00:18:55,165:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 99.11s, LR: 0.00050, Train Loss: 0.6207, Train Acc: 0.6200,
                        Val Loss: 0.6668, Val Acc: 0.6060, Test Acc: 0.6207
2022-09-01 00:18:55,166:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 10/1000
2022-09-01 00:20:33,218:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 98.05s, LR: 0.00050, Train Loss: 0.6327, Train Acc: 0.6400,
                        Val Loss: 0.6801, Val Acc: 0.5800, Test Acc: 0.6002
2022-09-01 00:20:33,219:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 11/1000
2022-09-01 00:22:12,504:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 99.28s, LR: 0.00050, Train Loss: 0.6276, Train Acc: 0.6450,
                        Val Loss: 0.6674, Val Acc: 0.6070, Test Acc: 0.6195
2022-09-01 00:22:12,505:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 12/1000
2022-09-01 00:23:55,177:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 102.67s, LR: 0.00050, Train Loss: 0.6352, Train Acc: 0.6350,
                        Val Loss: 0.6769, Val Acc: 0.5950, Test Acc: 0.5950
2022-09-01 00:23:55,178:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 13/1000
2022-09-01 00:25:35,247:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 100.07s, LR: 0.00050, Train Loss: 0.6226, Train Acc: 0.6250,
                        Val Loss: 0.6693, Val Acc: 0.5700, Test Acc: 0.5935
2022-09-01 00:25:35,248:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 14/1000
2022-09-01 00:27:14,961:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 99.71s, LR: 0.00050, Train Loss: 0.6075, Train Acc: 0.6050,
                        Val Loss: 0.6759, Val Acc: 0.5930, Test Acc: 0.6000
2022-09-01 00:27:14,963:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 15/1000
2022-09-01 00:28:54,909:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 99.95s, LR: 0.00050, Train Loss: 0.6244, Train Acc: 0.6200,
                        Val Loss: 0.6782, Val Acc: 0.5730, Test Acc: 0.5954
2022-09-01 00:28:54,911:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 16/1000
2022-09-01 00:30:34,177:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 99.27s, LR: 0.00050, Train Loss: 0.6194, Train Acc: 0.6400,
                        Val Loss: 0.6792, Val Acc: 0.5700, Test Acc: 0.5935
2022-09-01 00:30:34,179:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 17/1000
2022-09-01 00:32:16,036:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 101.86s, LR: 0.00050, Train Loss: 0.6100, Train Acc: 0.6450,
                        Val Loss: 0.6737, Val Acc: 0.5680, Test Acc: 0.5982
2022-09-01 00:32:16,037:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 18/1000
2022-09-01 00:33:50,228:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 94.19s, LR: 0.00050, Train Loss: 0.6137, Train Acc: 0.6400,
                        Val Loss: 0.6742, Val Acc: 0.5680, Test Acc: 0.5982
2022-09-01 00:33:50,229:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 19/1000
2022-09-01 00:35:31,769:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 101.54s, LR: 0.00050, Train Loss: 0.6211, Train Acc: 0.6150,
                        Val Loss: 0.6759, Val Acc: 0.5690, Test Acc: 0.5983
2022-09-01 00:35:31,773:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 20/1000
2022-09-01 00:37:13,451:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 101.68s, LR: 0.00050, Train Loss: 0.6089, Train Acc: 0.6450,
                        Val Loss: 0.6763, Val Acc: 0.5950, Test Acc: 0.6188
2022-09-01 00:37:13,452:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 21/1000
2022-09-01 00:38:53,714:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 100.26s, LR: 0.00025, Train Loss: 0.6071, Train Acc: 0.6450,
                        Val Loss: 0.6711, Val Acc: 0.5980, Test Acc: 0.6207
2022-09-01 00:38:53,715:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 22/1000
2022-09-01 03:49:48,692:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 03:49:52,086:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 03:49:52,086:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-noedge', 'job_num': 8}
2022-09-01 03:49:52,096:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:49:52,097:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:49:52,097:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:49:52,105:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 03:49:52,107:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 409113
2022-09-01 03:49:52,108:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:49:52,108:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:49:52,108:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:49:52,118:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 03:50:02,317:main_molecules_graph_regression.py:87 -   train_val_pipeline(): Time PE:10.210243940353394
2022-09-01 03:50:02,333:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-01 03:50:02,333:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-01 03:50:02,333:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-01 03:50:02,335:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 03:50:15,775:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 03:50:19,029:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 70, 'out_dim': 70, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 03:50:19,030:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-noedge', 'job_num': 8}
2022-09-01 03:50:19,031:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:50:19,031:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:50:19,031:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:50:19,038:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 03:50:19,039:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 461977
2022-09-01 03:50:19,041:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:50:19,041:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:50:19,041:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:50:19,048:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 03:50:37,362:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 03:50:40,680:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 03:50:40,680:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-noedge', 'job_num': 8}
2022-09-01 03:50:40,681:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:50:40,682:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:50:40,682:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:50:40,689:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 03:50:40,690:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 596633
2022-09-01 03:50:40,691:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:50:40,691:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:50:40,691:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:50:40,697:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 03:50:57,612:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 03:51:00,920:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 76, 'out_dim': 76, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 03:51:00,920:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-noedge', 'job_num': 8}
2022-09-01 03:51:00,922:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:51:00,922:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:51:00,922:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:51:00,929:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 03:51:00,931:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 536763
2022-09-01 03:51:00,932:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:51:00,932:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:51:00,932:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:51:00,939:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 03:51:11,457:main_molecules_graph_regression.py:87 -   train_val_pipeline(): Time PE:10.525961875915527
2022-09-01 03:51:11,471:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-01 03:51:11,471:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-01 03:51:11,471:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-01 03:51:11,473:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 03:51:31,599:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 03:51:34,758:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 03:51:34,758:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-noedge', 'job_num': 8}
2022-09-01 03:51:34,760:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:51:34,760:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:51:34,760:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:51:34,767:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 03:51:34,768:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 497713
2022-09-01 03:51:34,770:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 03:51:34,770:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 03:51:34,770:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 03:51:34,777:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 03:51:44,875:main_molecules_graph_regression.py:87 -   train_val_pipeline(): Time PE:10.106422901153564
2022-09-01 03:51:44,890:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-01 03:51:44,890:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-01 03:51:44,890:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-01 03:51:44,892:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 13:59:17,167:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 13:59:19,258:main_molecules_graph_regression.py:335 -                 main(): {'num_train_data': 7000, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'edge_feat': True, 'rand_pos_enc': True, 'adj_enc': False, 'dataset': 'AQSOL', 'matrix_type': 'A', 'pow_of_mat': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 65, 'num_bond_type': 5}
2022-09-01 13:59:19,258:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-01 13:59:19,266:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 13:59:19,273:pe_layer.py:122 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 13:59:19,273:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 13:59:19,273:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 13:59:19,282:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 13:59:19,284:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 924562
2022-09-01 13:59:26,214:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 13:59:28,357:main_molecules_graph_regression.py:335 -                 main(): {'num_train_data': 7000, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'edge_feat': True, 'rand_pos_enc': True, 'adj_enc': False, 'dataset': 'AQSOL', 'matrix_type': 'A', 'pow_of_mat': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 65, 'num_bond_type': 5}
2022-09-01 13:59:28,357:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16, 'save_name': 'save'}
2022-09-01 13:59:28,359:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 13:59:28,360:pe_layer.py:122 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 13:59:28,360:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 13:59:28,360:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 13:59:28,368:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 13:59:28,369:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 924562
2022-09-01 13:59:28,371:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 13:59:28,372:pe_layer.py:122 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 13:59:28,372:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 13:59:28,372:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 13:59:28,383:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-01 14:00:01,845:main_molecules_graph_regression.py:74 -   train_val_pipeline(): Time PE:33.47503423690796
2022-09-01 14:00:01,861:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 7831
2022-09-01 14:00:01,861:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 996
2022-09-01 14:00:01,861:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 996
2022-09-01 14:00:01,864:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 14:00:15,697:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 2.961081802845001
2022-09-01 14:00:15,698:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 13.83s, LR: 0.00070, Train Loss: 1.4953, Train MAE: 1.4953,
                            Val Loss: 1.6592, Val Acc: 1.6592, Test MAE: 2.9611
2022-09-01 14:00:15,708:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-09-01 14:00:23,008:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-01 14:00:23,008:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-01 14:00:57,233:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 14:00:59,386:main_molecules_graph_regression.py:335 -                 main(): {'num_train_data': 7000, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'edge_feat': False, 'rand_pos_enc': True, 'adj_enc': False, 'dataset': 'AQSOL', 'matrix_type': 'A', 'pow_of_mat': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 65, 'num_bond_type': 5}
2022-09-01 14:00:59,387:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16, 'save_name': 'save'}
2022-09-01 14:00:59,388:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 14:00:59,389:pe_layer.py:122 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 14:00:59,389:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 14:00:59,389:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 14:00:59,395:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 14:00:59,396:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 533762
2022-09-01 14:00:59,397:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 14:00:59,397:pe_layer.py:122 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 14:00:59,397:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 14:00:59,397:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 14:00:59,403:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-01 14:01:32,952:main_molecules_graph_regression.py:74 -   train_val_pipeline(): Time PE:33.556122064590454
2022-09-01 14:01:32,968:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 7831
2022-09-01 14:01:32,968:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 996
2022-09-01 14:01:32,968:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 996
2022-09-01 14:01:32,971:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 14:01:42,144:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 9.17s, LR: 0.00070, Train Loss: nan, Train MAE: nan,
                            Val Loss: nan, Val Acc: nan, Test MAE: nan
2022-09-01 14:01:42,150:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-09-01 14:01:51,116:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 8.97s, LR: 0.00070, Train Loss: nan, Train MAE: nan,
                            Val Loss: nan, Val Acc: nan, Test MAE: nan
2022-09-01 14:01:51,121:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-09-01 14:06:02,852:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 14:06:06,143:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 56, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 14:06:06,143:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 56}
2022-09-01 14:06:06,146:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 14:06:06,147:pe_layer.py:122 -             __init__(): Using 56 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 14:06:06,147:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 14:06:06,147:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 14:06:06,153:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 14:06:06,154:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 565802
2022-09-01 14:06:06,155:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 14:06:06,156:pe_layer.py:122 -             __init__(): Using 56 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 14:06:06,156:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 14:06:06,156:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 14:06:06,162:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (56).
2022-09-01 14:07:04,597:main_molecules_graph_regression.py:74 -   train_val_pipeline(): Time PE:58.44252586364746
2022-09-01 14:07:04,615:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-01 14:07:04,615:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-01 14:07:04,615:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-01 14:07:04,618:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 14:07:19,513:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.0254428088665009
2022-09-01 14:07:19,514:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.90s, LR: 0.00070, Train Loss: 0.9666, Train MAE: 0.9666,
                            Val Loss: 0.9903, Val Acc: 0.9903, Test MAE: 1.0254
2022-09-01 14:07:19,522:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-09-01 14:08:55,331:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 14:08:58,648:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 56, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 14:08:58,648:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 56}
2022-09-01 14:08:58,649:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 14:08:58,650:pe_layer.py:122 -             __init__(): Using 56 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 14:08:58,651:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 14:08:58,651:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 14:08:58,657:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 14:08:58,658:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 565802
2022-09-01 14:08:58,659:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 14:08:58,660:pe_layer.py:122 -             __init__(): Using 56 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 14:08:58,660:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 14:08:58,660:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 14:08:58,666:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (56).
2022-09-01 22:43:57,866:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:44:01,314:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:44:01,315:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-noedge', 'job_num': 8}
2022-09-01 22:44:01,324:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:44:01,325:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:44:01,325:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:44:01,335:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:44:01,337:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 596633
2022-09-01 22:44:01,339:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:44:01,339:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:44:01,339:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:44:01,348:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:44:16,190:main_molecules_graph_regression.py:87 -   train_val_pipeline(): Time PE:14.85294222831726
2022-09-01 22:44:16,208:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-01 22:44:16,209:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-01 22:44:16,209:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-01 22:44:16,211:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 22:44:23,027:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-01 22:44:23,027:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-01 22:46:39,351:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:46:42,594:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:46:42,595:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-noedge', 'job_num': 8}
2022-09-01 22:46:42,596:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:46:42,596:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:46:42,596:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:46:42,604:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:46:42,605:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 532857
2022-09-01 22:46:42,607:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:46:42,607:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:46:42,607:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:46:42,614:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:46:52,481:main_molecules_graph_regression.py:87 -   train_val_pipeline(): Time PE:9.875722885131836
2022-09-01 22:46:52,497:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-01 22:46:52,498:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-01 22:46:52,498:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-01 22:46:52,500:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 22:49:56,302:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:49:59,590:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': True, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:49:59,590:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 8}
2022-09-01 22:49:59,591:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:49:59,592:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:49:59,592:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:49:59,601:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:49:59,602:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 523697
2022-09-01 22:49:59,604:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:49:59,604:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:49:59,604:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:49:59,613:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:50:22,744:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:50:26,069:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:50:26,070:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 8}
2022-09-01 22:50:26,071:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:50:26,071:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:50:26,071:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:50:26,078:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:50:26,079:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 330833
2022-09-01 22:50:26,080:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:50:26,081:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:50:26,081:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:50:26,087:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:50:39,507:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:50:42,701:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:50:42,701:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 8}
2022-09-01 22:50:42,702:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:50:42,702:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:50:42,702:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:50:42,709:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:50:42,710:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 497713
2022-09-01 22:50:42,711:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:50:42,711:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:50:42,711:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:50:42,718:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:50:55,250:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:50:58,462:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:50:58,462:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 8}
2022-09-01 22:50:58,464:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:50:58,464:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:50:58,464:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:50:58,470:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:50:58,471:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 532857
2022-09-01 22:50:58,473:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:50:58,473:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:50:58,473:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:50:58,479:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:58:22,123:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:58:25,643:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:58:25,643:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 16}
2022-09-01 22:58:25,645:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:58:25,645:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:58:25,645:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:58:25,652:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:58:25,653:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 567433
2022-09-01 22:58:25,654:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:58:25,654:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:58:25,654:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:58:25,661:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:59:05,647:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:59:08,927:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:59:08,927:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 32}
2022-09-01 22:59:08,929:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:08,929:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:08,929:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:08,937:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:59:08,938:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 850521
2022-09-01 22:59:08,940:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:08,940:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:08,940:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:08,948:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:59:19,558:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:59:22,744:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:59:22,744:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 32}
2022-09-01 22:59:22,745:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:22,745:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:22,745:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:22,752:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:59:22,753:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 713017
2022-09-01 22:59:22,755:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:22,755:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:22,755:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:22,762:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:59:41,395:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:59:44,598:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:59:44,598:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 32}
2022-09-01 22:59:44,600:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:44,600:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:44,600:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:44,606:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:59:44,607:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 624417
2022-09-01 22:59:44,609:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:44,609:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:44,609:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:44,614:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 22:59:55,887:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 22:59:59,011:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 22:59:59,012:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 32}
2022-09-01 22:59:59,013:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:59,013:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:59,013:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:59,020:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 22:59:59,021:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 546137
2022-09-01 22:59:59,022:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 22:59:59,022:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 22:59:59,022:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 22:59:59,028:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 23:00:51,462:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 23:00:54,697:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 23:00:54,697:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 16}
2022-09-01 23:00:54,699:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 23:00:54,699:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 23:00:54,699:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 23:00:54,705:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 23:00:54,706:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 567433
2022-09-01 23:00:54,707:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 23:00:54,707:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 23:00:54,707:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 23:00:54,713:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 23:01:02,378:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 23:01:05,619:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'edge_feat': False, 'gpu_id': 0, 'batch_size': 32, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-01 23:01:05,620:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b32-noedge', 'job_num': 32}
2022-09-01 23:01:05,621:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 23:01:05,621:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 23:01:05,621:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 23:01:05,628:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 23:01:05,629:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 546137
2022-09-01 23:01:05,630:pe_layer.py:65 -             __init__(): no_pe
2022-09-01 23:01:05,630:pe_layer.py:127 -             __init__(): Using matrix: A
2022-09-01 23:01:05,630:pe_layer.py:128 -             __init__(): Matrix power: 1
2022-09-01 23:01:05,636:main_molecules_graph_regression.py:85 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-01 23:40:27,306:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 23:40:32,413:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-01 23:40:32,414:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-01 23:40:32,421:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:40:32,431:pe_layer.py:125 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:40:32,431:pe_layer.py:130 -             __init__(): Using matrix: A
2022-09-01 23:40:32,431:pe_layer.py:131 -             __init__(): Matrix power: 1
2022-09-01 23:40:32,437:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 23:40:32,438:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-01 23:40:32,439:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:40:32,440:pe_layer.py:125 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:40:32,441:pe_layer.py:130 -             __init__(): Using matrix: A
2022-09-01 23:40:32,441:pe_layer.py:131 -             __init__(): Matrix power: 1
2022-09-01 23:40:32,447:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-01 23:40:32,447:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-01 23:54:21,469:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 23:54:26,080:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-01 23:54:26,080:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-01 23:54:26,082:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:54:26,083:pe_layer.py:125 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:54:26,083:pe_layer.py:130 -             __init__(): Using matrix: A
2022-09-01 23:54:26,083:pe_layer.py:131 -             __init__(): Matrix power: 1
2022-09-01 23:54:26,088:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 23:54:26,089:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-01 23:54:26,090:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:54:26,091:pe_layer.py:125 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:54:26,091:pe_layer.py:130 -             __init__(): Using matrix: A
2022-09-01 23:54:26,091:pe_layer.py:131 -             __init__(): Matrix power: 1
2022-09-01 23:54:26,345:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-01 23:54:26,345:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-01 23:54:59,056:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:32.959518909454346
2022-09-01 23:54:59,058:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-01 23:54:59,058:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-01 23:54:59,058:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-01 23:54:59,058:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-01 23:54:59,061:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 23:56:02,399:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 23:56:06,551:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-01 23:56:06,551:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-01 23:56:06,553:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:56:06,554:pe_layer.py:125 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:56:06,554:pe_layer.py:130 -             __init__(): Using matrix: A
2022-09-01 23:56:06,554:pe_layer.py:131 -             __init__(): Matrix power: 1
2022-09-01 23:56:06,559:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 23:56:06,560:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-01 23:56:06,561:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:56:06,562:pe_layer.py:125 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:56:06,562:pe_layer.py:130 -             __init__(): Using matrix: A
2022-09-01 23:56:06,562:pe_layer.py:131 -             __init__(): Matrix power: 1
2022-09-01 23:56:06,842:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-01 23:56:06,843:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-01 23:56:39,687:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:33.120030879974365
2022-09-01 23:56:39,689:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-01 23:56:39,689:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-01 23:56:39,690:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-01 23:56:39,690:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-01 23:56:39,691:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-01 23:59:33,733:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-01 23:59:38,136:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-01 23:59:38,136:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-01 23:59:38,137:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:59:38,139:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:59:38,139:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-01 23:59:38,139:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-01 23:59:38,144:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-01 23:59:38,145:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-01 23:59:38,146:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-01 23:59:38,148:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-01 23:59:38,148:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-01 23:59:38,148:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-01 23:59:38,450:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-01 23:59:38,450:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 00:00:11,445:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:33.2896409034729
2022-09-02 00:00:11,448:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 00:00:11,448:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 00:00:11,448:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 00:00:11,448:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 00:00:11,449:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 00:00:40,804:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 00:00:44,961:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 00:00:44,961:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 00:00:44,963:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:00:44,964:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:00:44,964:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:00:44,964:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:00:44,969:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 00:00:44,970:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 00:00:44,971:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:00:44,972:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:00:44,973:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:00:44,973:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:00:45,217:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 00:00:45,217:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 00:01:17,717:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:32.7392098903656
2022-09-02 00:01:17,720:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 00:01:17,720:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 00:01:17,720:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 00:01:17,720:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 00:01:17,721:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 00:01:18,404:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:18,404:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.8038, Train Acc: 16.5372,
                        Val Loss: 1.8783, Val Acc: 16.5933, Test Acc: 16.6667
2022-09-02 00:01:18,404:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 00:01:19,030:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7771, Train Acc: 19.5704,
                        Val Loss: 1.8756, Val Acc: 16.9704, Test Acc: 16.6667
2022-09-02 00:01:19,030:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 00:01:19,771:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 18.2649 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:19,771:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.74s, LR: 0.00050, Train Loss: 1.7597, Train Acc: 22.7480,
                        Val Loss: 1.8754, Val Acc: 18.4403, Test Acc: 18.2649
2022-09-02 00:01:19,771:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 00:01:20,418:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 18.6073 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:20,418:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7468, Train Acc: 25.2191,
                        Val Loss: 1.8748, Val Acc: 18.5475, Test Acc: 18.6073
2022-09-02 00:01:20,418:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 00:01:21,070:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 18.9504 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:21,071:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7358, Train Acc: 27.3283,
                        Val Loss: 1.8729, Val Acc: 18.6072, Test Acc: 18.9504
2022-09-02 00:01:21,071:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 00:01:21,725:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.3006 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:21,725:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7256, Train Acc: 28.2315,
                        Val Loss: 1.8728, Val Acc: 19.4477, Test Acc: 19.3006
2022-09-02 00:01:21,725:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-02 00:01:22,361:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.5169 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:22,361:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7162, Train Acc: 29.3428,
                        Val Loss: 1.8722, Val Acc: 20.0265, Test Acc: 19.5169
2022-09-02 00:01:22,361:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-02 00:01:22,991:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 20.0987 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:22,991:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7075, Train Acc: 29.2046,
                        Val Loss: 1.8723, Val Acc: 20.2556, Test Acc: 20.0987
2022-09-02 00:01:22,992:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-02 00:01:23,624:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 20.2990 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:23,624:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6989, Train Acc: 30.6254,
                        Val Loss: 1.8737, Val Acc: 20.4528, Test Acc: 20.2990
2022-09-02 00:01:23,624:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-02 00:01:24,236:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 21.5749 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:24,236:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.6904, Train Acc: 32.4986,
                        Val Loss: 1.8770, Val Acc: 20.9080, Test Acc: 21.5749
2022-09-02 00:01:24,236:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-02 00:01:24,876:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 22.0552 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:24,876:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6818, Train Acc: 33.0434,
                        Val Loss: 1.8801, Val Acc: 21.3510, Test Acc: 22.0552
2022-09-02 00:01:24,876:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-02 00:01:25,494:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 23.0310 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:25,494:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.6728, Train Acc: 34.2542,
                        Val Loss: 1.8823, Val Acc: 21.8637, Test Acc: 23.0310
2022-09-02 00:01:25,494:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-02 00:01:26,106:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 23.6405 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:26,106:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.6632, Train Acc: 34.9493,
                        Val Loss: 1.8907, Val Acc: 23.1457, Test Acc: 23.6405
2022-09-02 00:01:26,106:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-02 00:01:26,748:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 25.9832 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:26,748:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6528, Train Acc: 35.9530,
                        Val Loss: 1.8965, Val Acc: 24.3614, Test Acc: 25.9832
2022-09-02 00:01:26,748:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-02 00:01:27,356:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.6415, Train Acc: 37.6511,
                        Val Loss: 1.9174, Val Acc: 22.8115, Test Acc: 23.9688
2022-09-02 00:01:27,356:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-02 00:01:27,984:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6294, Train Acc: 38.6048,
                        Val Loss: 1.9488, Val Acc: 20.8639, Test Acc: 22.5164
2022-09-02 00:01:27,984:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-02 00:01:28,592:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.6165, Train Acc: 40.0234,
                        Val Loss: 1.9721, Val Acc: 20.5182, Test Acc: 21.7380
2022-09-02 00:01:28,592:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-02 00:01:29,244:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6035, Train Acc: 41.1178,
                        Val Loss: 2.0132, Val Acc: 20.1550, Test Acc: 21.9985
2022-09-02 00:01:29,245:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-02 00:01:29,877:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.5905, Train Acc: 40.5157,
                        Val Loss: 2.0180, Val Acc: 20.7381, Test Acc: 23.3818
2022-09-02 00:01:29,878:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-02 00:01:30,522:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.5837, Train Acc: 40.8655,
                        Val Loss: 1.9973, Val Acc: 22.2512, Test Acc: 24.9473
2022-09-02 00:01:30,522:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-02 00:01:31,162:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 28.0266 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:31,162:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.5764, Train Acc: 41.0756,
                        Val Loss: 1.9553, Val Acc: 24.7436, Test Acc: 28.0266
2022-09-02 00:01:31,162:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-02 00:01:31,812:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.7556 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:31,812:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.5689, Train Acc: 41.8228,
                        Val Loss: 1.9308, Val Acc: 27.2999, Test Acc: 32.7556
2022-09-02 00:01:31,812:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-02 00:01:32,430:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 34.9998 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:32,430:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.5612, Train Acc: 42.1178,
                        Val Loss: 1.9212, Val Acc: 30.9881, Test Acc: 34.9998
2022-09-02 00:01:32,430:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-02 00:01:33,066:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 35.0062 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:33,066:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.5532, Train Acc: 42.6270,
                        Val Loss: 1.9220, Val Acc: 31.7186, Test Acc: 35.0062
2022-09-02 00:01:33,066:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-02 00:01:33,686:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 35.1737 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:33,686:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.5451, Train Acc: 42.9751,
                        Val Loss: 1.9316, Val Acc: 32.3774, Test Acc: 35.1737
2022-09-02 00:01:33,687:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-02 00:01:34,314:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.5369, Train Acc: 43.4518,
                        Val Loss: 1.9418, Val Acc: 32.3878, Test Acc: 34.7167
2022-09-02 00:01:34,314:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-02 00:01:34,955:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 35.6951 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_00h00m44s_on_Sep_02_2022/MODELS_
2022-09-02 00:01:34,955:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.5286, Train Acc: 43.7546,
                        Val Loss: 1.9780, Val Acc: 33.3985, Test Acc: 35.6951
2022-09-02 00:01:34,955:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
2022-09-02 00:01:35,590:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.5201, Train Acc: 43.8490,
                        Val Loss: 1.9883, Val Acc: 34.1421, Test Acc: 34.7116
2022-09-02 00:01:35,591:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 29/1000
2022-09-02 00:01:36,210:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.5113, Train Acc: 43.8893,
                        Val Loss: 2.0126, Val Acc: 32.7754, Test Acc: 34.1798
2022-09-02 00:01:36,210:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 30/1000
2022-09-02 00:01:36,839:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.5024, Train Acc: 43.8478,
                        Val Loss: 2.0431, Val Acc: 32.6261, Test Acc: 32.7096
2022-09-02 00:01:36,839:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 31/1000
2022-09-02 00:01:37,457:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.4978, Train Acc: 44.2723,
                        Val Loss: 2.0894, Val Acc: 31.9297, Test Acc: 33.1898
2022-09-02 00:01:37,457:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 32/1000
2022-09-02 00:01:38,098:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.4930, Train Acc: 44.7023,
                        Val Loss: 2.1050, Val Acc: 32.3140, Test Acc: 33.4648
2022-09-02 00:01:38,099:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 33/1000
2022-09-02 00:01:38,722:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.4880, Train Acc: 45.0869,
                        Val Loss: 2.1511, Val Acc: 32.0015, Test Acc: 33.6969
2022-09-02 00:01:38,722:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 34/1000
2022-09-02 00:01:39,368:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.4829, Train Acc: 45.5041,
                        Val Loss: 2.2011, Val Acc: 32.1197, Test Acc: 33.1976
2022-09-02 00:01:39,368:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 35/1000
2022-09-02 00:01:39,986:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.4776, Train Acc: 45.7898,
                        Val Loss: 2.2460, Val Acc: 32.5480, Test Acc: 33.9745
2022-09-02 00:01:39,986:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 36/1000
2022-09-02 00:01:40,613:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.4722, Train Acc: 46.3270,
                        Val Loss: 2.2626, Val Acc: 32.8839, Test Acc: 34.1789
2022-09-02 00:01:40,613:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 37/1000
2022-09-02 00:01:41,230:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.4667, Train Acc: 47.2360,
                        Val Loss: 2.2850, Val Acc: 34.1448, Test Acc: 34.2309
2022-09-02 00:01:41,230:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 38/1000
2022-09-02 00:01:41,853:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.4611, Train Acc: 47.5875,
                        Val Loss: 2.3403, Val Acc: 33.1478, Test Acc: 33.6402
2022-09-02 00:01:41,853:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 39/1000
2022-09-02 00:01:42,494:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.4553, Train Acc: 47.6241,
                        Val Loss: 2.3901, Val Acc: 32.8733, Test Acc: 33.9826
2022-09-02 00:01:42,494:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 40/1000
2022-09-02 00:01:43,130:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.4495, Train Acc: 47.9620,
                        Val Loss: 2.3941, Val Acc: 32.1414, Test Acc: 33.9043
2022-09-02 00:01:43,130:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 41/1000
2022-09-02 00:01:43,747:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.4435, Train Acc: 48.1175,
                        Val Loss: 2.4103, Val Acc: 32.3359, Test Acc: 33.3599
2022-09-02 00:01:43,747:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 42/1000
2022-09-02 00:01:44,357:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00006, Train Loss: 1.4404, Train Acc: 48.1833,
                        Val Loss: 2.4405, Val Acc: 32.4547, Test Acc: 33.1262
2022-09-02 00:01:44,357:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 43/1000
2022-09-02 00:01:44,980:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.4373, Train Acc: 48.1618,
                        Val Loss: 2.4616, Val Acc: 32.3531, Test Acc: 33.3111
2022-09-02 00:01:44,980:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 44/1000
2022-09-02 00:01:45,622:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.4341, Train Acc: 48.2570,
                        Val Loss: 2.4369, Val Acc: 32.5689, Test Acc: 32.9539
2022-09-02 00:01:45,622:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 45/1000
2022-09-02 00:01:46,238:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.4308, Train Acc: 48.0681,
                        Val Loss: 2.4646, Val Acc: 32.2322, Test Acc: 32.6076
2022-09-02 00:01:46,238:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 46/1000
2022-09-02 00:01:46,855:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.4275, Train Acc: 48.0562,
                        Val Loss: 2.5063, Val Acc: 32.1414, Test Acc: 32.9134
2022-09-02 00:01:46,855:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 47/1000
2022-09-02 00:01:47,489:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.4242, Train Acc: 48.1450,
                        Val Loss: 2.5441, Val Acc: 31.5581, Test Acc: 33.2151
2022-09-02 00:01:47,489:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 48/1000
2022-09-02 00:01:48,102:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00006, Train Loss: 1.4208, Train Acc: 48.5822,
                        Val Loss: 2.5572, Val Acc: 31.3132, Test Acc: 32.8170
2022-09-02 00:01:48,102:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 49/1000
2022-09-02 00:01:48,740:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.4174, Train Acc: 48.7963,
                        Val Loss: 2.5836, Val Acc: 31.3649, Test Acc: 32.4828
2022-09-02 00:01:48,740:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 50/1000
2022-09-02 00:01:49,352:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00006, Train Loss: 1.4139, Train Acc: 49.3794,
                        Val Loss: 2.6429, Val Acc: 31.4374, Test Acc: 32.6690
2022-09-02 00:01:49,352:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 51/1000
2022-09-02 00:01:49,999:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00006, Train Loss: 1.4104, Train Acc: 49.2176,
                        Val Loss: 2.6646, Val Acc: 31.5235, Test Acc: 32.6422
2022-09-02 00:01:49,999:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 52/1000
2022-09-02 00:01:50,629:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.4069, Train Acc: 49.5468,
                        Val Loss: 2.6488, Val Acc: 30.8434, Test Acc: 32.7298
2022-09-02 00:01:50,629:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 53/1000
2022-09-02 00:01:51,255:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.4051, Train Acc: 49.6189,
                        Val Loss: 2.6618, Val Acc: 30.7256, Test Acc: 32.6038
2022-09-02 00:01:51,255:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 54/1000
2022-09-02 00:01:51,869:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00003, Train Loss: 1.4033, Train Acc: 49.6189,
                        Val Loss: 2.6785, Val Acc: 30.7454, Test Acc: 32.9950
2022-09-02 00:01:51,870:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 55/1000
2022-09-02 00:01:52,485:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.4014, Train Acc: 50.0022,
                        Val Loss: 2.6797, Val Acc: 30.9278, Test Acc: 32.8635
2022-09-02 00:01:52,485:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 56/1000
2022-09-02 00:01:53,090:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00003, Train Loss: 1.3996, Train Acc: 50.0038,
                        Val Loss: 2.6895, Val Acc: 31.0128, Test Acc: 32.5784
2022-09-02 00:01:53,090:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 57/1000
2022-09-02 00:01:53,681:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.59s, LR: 0.00003, Train Loss: 1.3977, Train Acc: 50.2577,
                        Val Loss: 2.6870, Val Acc: 30.9113, Test Acc: 32.8920
2022-09-02 00:01:53,681:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 58/1000
2022-09-02 00:01:54,274:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.59s, LR: 0.00003, Train Loss: 1.3959, Train Acc: 50.4179,
                        Val Loss: 2.7159, Val Acc: 31.1034, Test Acc: 32.9669
2022-09-02 00:01:54,275:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 59/1000
2022-09-02 00:01:54,895:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.3940, Train Acc: 50.7662,
                        Val Loss: 2.7425, Val Acc: 31.0133, Test Acc: 32.8512
2022-09-02 00:01:54,895:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 60/1000
2022-09-02 00:01:55,502:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00003, Train Loss: 1.3921, Train Acc: 50.8535,
                        Val Loss: 2.7407, Val Acc: 31.1828, Test Acc: 32.6084
2022-09-02 00:01:55,503:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 61/1000
2022-09-02 00:01:56,139:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.3902, Train Acc: 50.7734,
                        Val Loss: 2.7478, Val Acc: 31.2922, Test Acc: 32.6182
2022-09-02 00:01:56,139:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 62/1000
2022-09-02 00:01:56,757:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.3883, Train Acc: 50.8399,
                        Val Loss: 2.7741, Val Acc: 31.0320, Test Acc: 32.5671
2022-09-02 00:01:56,757:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 63/1000
2022-09-02 00:01:57,385:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.3863, Train Acc: 50.9938,
                        Val Loss: 2.7861, Val Acc: 31.2916, Test Acc: 32.7036
2022-09-02 00:01:57,385:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 64/1000
2022-09-02 00:01:58,003:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00002, Train Loss: 1.3853, Train Acc: 50.9938,
                        Val Loss: 2.7858, Val Acc: 31.6664, Test Acc: 33.0109
2022-09-02 00:01:58,003:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 65/1000
2022-09-02 00:01:58,603:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00002, Train Loss: 1.3844, Train Acc: 50.9938,
                        Val Loss: 2.7839, Val Acc: 31.5242, Test Acc: 33.5377
2022-09-02 00:01:58,603:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 66/1000
2022-09-02 00:01:59,209:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.3834, Train Acc: 50.9137,
                        Val Loss: 2.7945, Val Acc: 31.5904, Test Acc: 33.5025
2022-09-02 00:01:59,209:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 67/1000
2022-09-02 00:01:59,839:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.3824, Train Acc: 50.9137,
                        Val Loss: 2.8193, Val Acc: 32.0808, Test Acc: 33.8477
2022-09-02 00:01:59,839:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 68/1000
2022-09-02 00:02:00,484:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00002, Train Loss: 1.3814, Train Acc: 51.0811,
                        Val Loss: 2.8294, Val Acc: 32.2316, Test Acc: 34.1774
2022-09-02 00:02:00,484:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 69/1000
2022-09-02 00:02:01,085:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00002, Train Loss: 1.3804, Train Acc: 51.3246,
                        Val Loss: 2.8437, Val Acc: 32.1409, Test Acc: 34.0575
2022-09-02 00:02:01,085:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 70/1000
2022-09-02 00:02:01,678:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.59s, LR: 0.00002, Train Loss: 1.3794, Train Acc: 51.4936,
                        Val Loss: 2.8513, Val Acc: 31.7243, Test Acc: 34.3463
2022-09-02 00:02:01,678:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 71/1000
2022-09-02 00:02:02,295:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00002, Train Loss: 1.3783, Train Acc: 51.6610,
                        Val Loss: 2.8715, Val Acc: 32.0859, Test Acc: 34.6401
2022-09-02 00:02:02,296:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 72/1000
2022-09-02 00:02:02,907:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.3773, Train Acc: 51.7546,
                        Val Loss: 2.8770, Val Acc: 32.2667, Test Acc: 34.4878
2022-09-02 00:02:02,907:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 73/1000
2022-09-02 00:02:03,500:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.59s, LR: 0.00002, Train Loss: 1.3763, Train Acc: 51.8482,
                        Val Loss: 2.8798, Val Acc: 31.9085, Test Acc: 34.5596
2022-09-02 00:02:03,501:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 74/1000
2022-09-02 00:02:04,113:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00001, Train Loss: 1.3753, Train Acc: 51.8482,
                        Val Loss: 2.8831, Val Acc: 31.7237, Test Acc: 34.7448
2022-09-02 00:02:04,113:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 75/1000
2022-09-02 00:02:04,717:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00001, Train Loss: 1.3748, Train Acc: 51.8482,
                        Val Loss: 2.8850, Val Acc: 31.7589, Test Acc: 34.9092
2022-09-02 00:02:04,717:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 76/1000
2022-09-02 00:02:05,319:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00001, Train Loss: 1.3743, Train Acc: 51.8482,
                        Val Loss: 2.8906, Val Acc: 31.7839, Test Acc: 35.0018
2022-09-02 00:02:05,319:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 77/1000
2022-09-02 00:02:05,917:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00001, Train Loss: 1.3738, Train Acc: 51.8482,
                        Val Loss: 2.8951, Val Acc: 31.6961, Test Acc: 35.0386
2022-09-02 00:02:05,917:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 78/1000
2022-09-02 00:02:06,524:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00001, Train Loss: 1.3733, Train Acc: 51.8482,
                        Val Loss: 2.9029, Val Acc: 31.7816, Test Acc: 35.0825
2022-09-02 00:02:06,524:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 79/1000
2022-09-02 00:02:07,116:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.59s, LR: 0.00001, Train Loss: 1.3727, Train Acc: 51.9355,
                        Val Loss: 2.9135, Val Acc: 31.3327, Test Acc: 35.0688
2022-09-02 00:02:07,116:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 80/1000
2022-09-02 00:02:07,709:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.59s, LR: 0.00001, Train Loss: 1.3722, Train Acc: 52.0156,
                        Val Loss: 2.9178, Val Acc: 31.3060, Test Acc: 35.3297
2022-09-02 00:02:07,709:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 81/1000
2022-09-02 00:02:08,309:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00001, Train Loss: 1.3717, Train Acc: 52.0156,
                        Val Loss: 2.9208, Val Acc: 31.2130, Test Acc: 35.2299
2022-09-02 00:02:08,309:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 82/1000
2022-09-02 00:02:08,921:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00001, Train Loss: 1.3712, Train Acc: 52.0156,
                        Val Loss: 2.9196, Val Acc: 31.4215, Test Acc: 35.1301
2022-09-02 00:02:08,921:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 83/1000
2022-09-02 00:02:09,621:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00001, Train Loss: 1.3707, Train Acc: 52.0894,
                        Val Loss: 2.9122, Val Acc: 30.9517, Test Acc: 34.9448
2022-09-02 00:02:09,621:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 84/1000
2022-09-02 00:02:10,248:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00001, Train Loss: 1.3702, Train Acc: 52.1766,
                        Val Loss: 2.9226, Val Acc: 31.0096, Test Acc: 34.8450
2022-09-02 00:02:10,248:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 85/1000
2022-09-02 00:02:10,853:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00000, Train Loss: 1.3697, Train Acc: 52.0949,
                        Val Loss: 2.9303, Val Acc: 30.8095, Test Acc: 34.8164
2022-09-02 00:02:10,853:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 86/1000
2022-09-02 00:02:11,478:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00000, Train Loss: 1.3694, Train Acc: 52.0949,
                        Val Loss: 2.9367, Val Acc: 31.3592, Test Acc: 34.3188
2022-09-02 00:02:11,478:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 87/1000
2022-09-02 00:02:12,212:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.73s, LR: 0.00000, Train Loss: 1.3691, Train Acc: 52.0949,
                        Val Loss: 2.9433, Val Acc: 31.3428, Test Acc: 34.1989
2022-09-02 00:02:12,212:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 88/1000
2022-09-02 00:02:12,953:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.74s, LR: 0.00000, Train Loss: 1.3689, Train Acc: 52.1822,
                        Val Loss: 2.9461, Val Acc: 31.0179, Test Acc: 34.3096
2022-09-02 00:02:12,953:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 89/1000
2022-09-02 00:02:13,607:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00000, Train Loss: 1.3686, Train Acc: 52.1822,
                        Val Loss: 2.9473, Val Acc: 30.9947, Test Acc: 34.1853
2022-09-02 00:02:13,607:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 90/1000
2022-09-02 00:02:14,224:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00000, Train Loss: 1.3684, Train Acc: 52.2639,
                        Val Loss: 2.9491, Val Acc: 31.0145, Test Acc: 34.4280
2022-09-02 00:02:14,224:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 91/1000
2022-09-02 00:02:14,828:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.60s, LR: 0.00000, Train Loss: 1.3681, Train Acc: 52.2639,
                        Val Loss: 2.9491, Val Acc: 31.0928, Test Acc: 34.5206
2022-09-02 00:02:14,828:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 92/1000
2022-09-02 00:02:15,435:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00000, Train Loss: 1.3679, Train Acc: 52.2639,
                        Val Loss: 2.9480, Val Acc: 31.1732, Test Acc: 34.5063
2022-09-02 00:02:15,435:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 93/1000
2022-09-02 00:02:16,153:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00000, Train Loss: 1.3676, Train Acc: 52.2639,
                        Val Loss: 2.9485, Val Acc: 31.3614, Test Acc: 34.5063
2022-09-02 00:02:16,153:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 94/1000
2022-09-02 00:02:16,884:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.73s, LR: 0.00000, Train Loss: 1.3673, Train Acc: 52.2639,
                        Val Loss: 2.9483, Val Acc: 31.5613, Test Acc: 34.9297
2022-09-02 00:02:16,884:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 95/1000
2022-09-02 00:02:17,541:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00000, Train Loss: 1.3671, Train Acc: 52.3511,
                        Val Loss: 2.9489, Val Acc: 31.3777, Test Acc: 34.9297
2022-09-02 00:02:17,541:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 96/1000
2022-09-02 00:02:18,211:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00000, Train Loss: 1.3668, Train Acc: 52.3511,
                        Val Loss: 2.9503, Val Acc: 31.3658, Test Acc: 34.9297
2022-09-02 00:02:18,211:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 97/1000
2022-09-02 00:02:18,852:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00000, Train Loss: 1.3667, Train Acc: 52.3511,
                        Val Loss: 2.9565, Val Acc: 31.2678, Test Acc: 34.9369
2022-09-02 00:02:18,852:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 98/1000
2022-09-02 00:02:19,479:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00000, Train Loss: 1.3666, Train Acc: 52.3511,
                        Val Loss: 2.9584, Val Acc: 31.1692, Test Acc: 34.9369
2022-09-02 00:02:19,479:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 99/1000
2022-09-02 00:02:20,173:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00000, Train Loss: 1.3664, Train Acc: 52.5114,
                        Val Loss: 2.9590, Val Acc: 31.1692, Test Acc: 35.1286
2022-09-02 00:02:20,173:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 100/1000
2022-09-02 00:02:20,835:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00000, Train Loss: 1.3663, Train Acc: 52.5114,
                        Val Loss: 2.9594, Val Acc: 31.1692, Test Acc: 35.1286
2022-09-02 00:02:20,835:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 101/1000
2022-09-02 00:02:21,468:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00000, Train Loss: 1.3662, Train Acc: 52.5114,
                        Val Loss: 2.9613, Val Acc: 31.1692, Test Acc: 35.2212
2022-09-02 00:02:21,468:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 102/1000
2022-09-02 00:02:22,115:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00000, Train Loss: 1.3661, Train Acc: 52.5114,
                        Val Loss: 2.9633, Val Acc: 31.1771, Test Acc: 35.2212
2022-09-02 00:02:22,115:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 103/1000
2022-09-02 00:02:22,830:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00000, Train Loss: 1.3659, Train Acc: 52.5114,
                        Val Loss: 2.9657, Val Acc: 31.0723, Test Acc: 35.1357
2022-09-02 00:02:22,830:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 104/1000
2022-09-02 00:02:23,518:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00000, Train Loss: 1.3658, Train Acc: 52.5114,
                        Val Loss: 2.9687, Val Acc: 31.0723, Test Acc: 35.1357
2022-09-02 00:02:23,518:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 105/1000
2022-09-02 00:02:24,169:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00000, Train Loss: 1.3657, Train Acc: 52.5114,
                        Val Loss: 2.9690, Val Acc: 31.0723, Test Acc: 35.1357
2022-09-02 00:02:24,169:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 106/1000
2022-09-02 00:02:24,820:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00000, Train Loss: 1.3656, Train Acc: 52.5114,
                        Val Loss: 2.9697, Val Acc: 30.9641, Test Acc: 35.1357
2022-09-02 00:02:24,820:main_SBMs_node_classification.py:233 -   train_val_pipeline(): 
!! LR SMALLER OR EQUAL TO MIN LR THRESHOLD.
2022-09-02 00:02:25,128:main_SBMs_node_classification.py:249 -   train_val_pipeline(): Test Accuracy: 35.1357
2022-09-02 00:02:25,128:main_SBMs_node_classification.py:250 -   train_val_pipeline(): Best Test Accuracy: 35.6951
2022-09-02 00:02:25,128:main_SBMs_node_classification.py:251 -   train_val_pipeline(): Train Accuracy: 53.2899
2022-09-02 00:02:25,128:main_SBMs_node_classification.py:252 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 43.7546
2022-09-02 00:02:25,128:main_SBMs_node_classification.py:253 -   train_val_pipeline(): Convergence Time (Epochs): 105.0000
2022-09-02 00:02:25,128:main_SBMs_node_classification.py:254 -   train_val_pipeline(): TOTAL TIME TAKEN: 100.1502s
2022-09-02 00:02:25,128:main_SBMs_node_classification.py:255 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.6330s
2022-09-02 00:17:34,325:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 00:17:37,511:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 4, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-02 00:17:37,511:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 4}
2022-09-02 00:17:37,513:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:17:37,514:pe_layer.py:126 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:17:37,514:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:17:37,514:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:17:37,520:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 00:17:37,521:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526761
2022-09-02 00:17:37,522:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:17:37,522:pe_layer.py:126 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:17:37,522:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:17:37,522:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:17:37,527:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (4).
2022-09-02 00:17:37,528:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 00:20:12,833:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-02 00:20:12,833:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-02 00:20:12,833:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-02 00:20:12,835:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 00:20:27,350:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5520304441452026
2022-09-02 00:20:27,351:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.52s, LR: 0.00070, Train Loss: 1.4850, Train MAE: 1.4850,
                            Val Loss: 1.4358, Val Acc: 1.4358, Test MAE: 1.5520
2022-09-02 00:20:27,358:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 00:20:42,018:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.66s, LR: 0.00070, Train Loss: 1.4604, Train MAE: 1.4604,
                            Val Loss: 1.4635, Val Acc: 1.4635, Test MAE: 1.5701
2022-09-02 00:20:42,025:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 00:20:44,038:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 00:20:44,039:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 00:20:51,396:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 00:20:54,702:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 4, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-02 00:20:54,702:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 4}
2022-09-02 00:20:54,704:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:20:54,704:pe_layer.py:126 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:20:54,705:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:20:54,705:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:20:54,710:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 00:20:54,711:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526761
2022-09-02 00:20:54,712:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:20:54,713:pe_layer.py:126 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:20:54,713:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:20:54,713:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:20:54,719:main_molecules_graph_regression.py:68 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (4).
2022-09-02 00:20:54,719:main_molecules_graph_regression.py:70 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 00:21:04,149:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-02 00:21:04,150:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-02 00:21:04,150:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-02 00:21:04,152:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 00:21:18,690:main_molecules_graph_regression.py:166 -   train_val_pipeline(): Best model with MAE 1.5594889223575592
2022-09-02 00:21:18,691:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.54s, LR: 0.00070, Train Loss: 1.4955, Train MAE: 1.4955,
                            Val Loss: 1.4427, Val Acc: 1.4427, Test MAE: 1.5595
2022-09-02 00:21:18,698:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 00:21:33,274:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.58s, LR: 0.00070, Train Loss: 1.4718, Train MAE: 1.4718,
                            Val Loss: 1.4439, Val Acc: 1.4439, Test MAE: 1.5629
2022-09-02 00:21:33,281:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 00:21:47,465:main_molecules_graph_regression.py:189 -   train_val_pipeline(): 	Time: 14.18s, LR: 0.00070, Train Loss: 1.4755, Train MAE: 1.4755,
                            Val Loss: 1.4414, Val Acc: 1.4414, Test MAE: 1.5600
2022-09-02 00:21:47,472:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 00:21:49,497:main_molecules_graph_regression.py:221 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 00:21:49,497:main_molecules_graph_regression.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 00:39:46,333:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 00:39:51,349:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 00:39:51,349:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 00:39:51,354:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:39:51,363:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:39:51,363:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:39:51,363:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:39:51,370:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 00:39:51,371:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 00:39:51,373:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:39:51,374:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:39:51,374:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:39:51,374:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:39:51,380:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 00:39:51,380:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 00:39:57,872:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 00:40:02,369:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 00:40:02,370:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 00:40:02,371:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:40:02,372:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:40:02,372:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:40:02,372:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:40:02,379:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 00:40:02,380:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 00:40:02,381:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 00:40:02,382:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 00:40:02,382:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 00:40:02,382:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 00:40:02,390:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 00:40:02,390:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 01:02:26,346:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 01:02:30,847:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 01:02:30,847:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 01:02:30,850:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:02:30,850:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:02:30,850:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:02:30,851:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:02:30,855:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 01:02:30,856:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 529227
2022-09-02 01:02:30,858:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:02:30,858:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:02:30,858:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:02:30,858:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:02:30,863:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 01:09:49,817:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 01:09:53,037:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 01:09:57,801:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 01:09:57,801:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 01:09:57,802:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:09:57,804:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:09:57,804:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:09:57,804:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:09:57,809:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 01:09:57,810:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 01:09:57,811:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:09:57,812:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:09:57,812:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:09:57,812:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:09:58,083:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 01:09:58,083:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 01:10:04,139:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:6.32241415977478
2022-09-02 01:10:04,142:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 01:10:04,142:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 01:10:04,142:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 01:10:04,142:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 01:10:04,144:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 01:10:04,953:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 17.1657 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:04,953:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.81s, LR: 0.00050, Train Loss: 1.7999, Train Acc: 15.8684,
                        Val Loss: 1.8042, Val Acc: 17.1598, Test Acc: 17.1657
2022-09-02 01:10:04,953:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 01:10:05,601:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 17.5649 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:05,601:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7799, Train Acc: 19.7652,
                        Val Loss: 1.8020, Val Acc: 17.6529, Test Acc: 17.5649
2022-09-02 01:10:05,601:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 01:10:06,315:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 17.6647 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:06,315:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00050, Train Loss: 1.7659, Train Acc: 23.3801,
                        Val Loss: 1.7994, Val Acc: 17.6529, Test Acc: 17.6647
2022-09-02 01:10:06,315:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 01:10:06,997:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.7541, Train Acc: 25.3992,
                        Val Loss: 1.7961, Val Acc: 17.6529, Test Acc: 17.6647
2022-09-02 01:10:06,997:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 01:10:07,689:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 17.7846 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:07,689:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.7431, Train Acc: 26.3216,
                        Val Loss: 1.7924, Val Acc: 17.6529, Test Acc: 17.7846
2022-09-02 01:10:07,689:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 01:10:08,325:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 18.7165 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:08,325:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7329, Train Acc: 27.9581,
                        Val Loss: 1.7889, Val Acc: 18.3571, Test Acc: 18.7165
2022-09-02 01:10:08,325:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-02 01:10:08,955:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.0489 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:08,955:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7229, Train Acc: 28.1794,
                        Val Loss: 1.7857, Val Acc: 18.6512, Test Acc: 19.0489
2022-09-02 01:10:08,956:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-02 01:10:09,577:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7129, Train Acc: 28.3078,
                        Val Loss: 1.7835, Val Acc: 18.8275, Test Acc: 19.0489
2022-09-02 01:10:09,577:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-02 01:10:10,203:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7029, Train Acc: 28.5235,
                        Val Loss: 1.7827, Val Acc: 18.6314, Test Acc: 19.0489
2022-09-02 01:10:10,203:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-02 01:10:10,832:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.1733 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:10,832:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6928, Train Acc: 29.1302,
                        Val Loss: 1.7889, Val Acc: 18.7034, Test Acc: 19.1733
2022-09-02 01:10:10,832:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-02 01:10:11,480:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.7952 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:11,480:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6820, Train Acc: 29.4275,
                        Val Loss: 1.8044, Val Acc: 19.2136, Test Acc: 19.7952
2022-09-02 01:10:11,480:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-02 01:10:12,136:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 20.2609 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:12,136:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6707, Train Acc: 30.1279,
                        Val Loss: 1.8260, Val Acc: 19.3837, Test Acc: 20.2609
2022-09-02 01:10:12,136:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-02 01:10:12,839:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.6588, Train Acc: 31.0796,
                        Val Loss: 1.8488, Val Acc: 19.2136, Test Acc: 20.2609
2022-09-02 01:10:12,839:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-02 01:10:13,493:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6465, Train Acc: 32.7295,
                        Val Loss: 1.8728, Val Acc: 19.1207, Test Acc: 20.2609
2022-09-02 01:10:13,493:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-02 01:10:14,126:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6337, Train Acc: 33.5887,
                        Val Loss: 1.8962, Val Acc: 19.1207, Test Acc: 20.2466
2022-09-02 01:10:14,127:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-02 01:10:14,765:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 20.4318 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:14,766:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6208, Train Acc: 35.2791,
                        Val Loss: 1.9164, Val Acc: 19.3989, Test Acc: 20.4318
2022-09-02 01:10:14,766:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-02 01:10:15,416:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 20.7880 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:15,416:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6082, Train Acc: 36.1391,
                        Val Loss: 1.9352, Val Acc: 19.7667, Test Acc: 20.7880
2022-09-02 01:10:15,416:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-02 01:10:16,065:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 21.0773 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:16,065:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.5956, Train Acc: 36.0376,
                        Val Loss: 1.9396, Val Acc: 20.4910, Test Acc: 21.0773
2022-09-02 01:10:16,065:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-02 01:10:16,726:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 22.3602 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:16,726:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.5827, Train Acc: 36.8609,
                        Val Loss: 1.9002, Val Acc: 21.4221, Test Acc: 22.3602
2022-09-02 01:10:16,726:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-02 01:10:17,408:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 23.5391 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:17,408:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.5693, Train Acc: 37.2363,
                        Val Loss: 1.8231, Val Acc: 21.9787, Test Acc: 23.5391
2022-09-02 01:10:17,408:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-02 01:10:18,064:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 25.5568 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:18,065:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.5554, Train Acc: 37.8432,
                        Val Loss: 1.7649, Val Acc: 22.6890, Test Acc: 25.5568
2022-09-02 01:10:18,065:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-02 01:10:18,744:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 27.1021 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:18,744:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.5478, Train Acc: 38.0170,
                        Val Loss: 1.7191, Val Acc: 23.6567, Test Acc: 27.1021
2022-09-02 01:10:18,744:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-02 01:10:19,391:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 29.3285 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:19,391:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.5398, Train Acc: 38.7286,
                        Val Loss: 1.6948, Val Acc: 26.3063, Test Acc: 29.3285
2022-09-02 01:10:19,391:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-02 01:10:20,061:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 30.9550 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:20,061:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.5312, Train Acc: 38.8087,
                        Val Loss: 1.6836, Val Acc: 28.4601, Test Acc: 30.9550
2022-09-02 01:10:20,061:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-02 01:10:20,709:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 31.2055 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:20,709:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.5224, Train Acc: 39.1989,
                        Val Loss: 1.6836, Val Acc: 30.7591, Test Acc: 31.2055
2022-09-02 01:10:20,709:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-02 01:10:21,362:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.5133, Train Acc: 39.6408,
                        Val Loss: 1.6966, Val Acc: 29.8077, Test Acc: 29.9446
2022-09-02 01:10:21,362:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-02 01:10:22,016:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.5037, Train Acc: 40.4493,
                        Val Loss: 1.7245, Val Acc: 27.3151, Test Acc: 28.4906
2022-09-02 01:10:22,016:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
2022-09-02 01:10:22,664:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.4937, Train Acc: 41.2490,
                        Val Loss: 1.7660, Val Acc: 25.6324, Test Acc: 26.6504
2022-09-02 01:10:22,664:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 29/1000
2022-09-02 01:10:23,328:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.4831, Train Acc: 41.9631,
                        Val Loss: 1.8110, Val Acc: 24.6213, Test Acc: 25.7825
2022-09-02 01:10:23,328:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 30/1000
2022-09-02 01:10:23,979:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.4721, Train Acc: 42.7326,
                        Val Loss: 1.8645, Val Acc: 23.7312, Test Acc: 25.4773
2022-09-02 01:10:23,979:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 31/1000
2022-09-02 01:10:24,631:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.4607, Train Acc: 43.8719,
                        Val Loss: 1.8876, Val Acc: 23.6100, Test Acc: 25.8981
2022-09-02 01:10:24,631:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 32/1000
2022-09-02 01:10:25,269:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.4488, Train Acc: 44.4772,
                        Val Loss: 1.9341, Val Acc: 23.0709, Test Acc: 25.5276
2022-09-02 01:10:25,269:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 33/1000
2022-09-02 01:10:25,931:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.4368, Train Acc: 45.0976,
                        Val Loss: 1.9565, Val Acc: 23.3460, Test Acc: 26.1673
2022-09-02 01:10:25,931:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 34/1000
2022-09-02 01:10:26,573:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.4244, Train Acc: 45.5910,
                        Val Loss: 2.0243, Val Acc: 23.5428, Test Acc: 26.2563
2022-09-02 01:10:26,573:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 35/1000
2022-09-02 01:10:27,241:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.4122, Train Acc: 46.0464,
                        Val Loss: 2.0334, Val Acc: 23.6790, Test Acc: 26.2510
2022-09-02 01:10:27,241:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 36/1000
2022-09-02 01:10:27,894:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.4002, Train Acc: 46.7635,
                        Val Loss: 2.0287, Val Acc: 23.7572, Test Acc: 27.0164
2022-09-02 01:10:27,894:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 37/1000
2022-09-02 01:10:28,547:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.3920, Train Acc: 47.2316,
                        Val Loss: 2.0303, Val Acc: 24.0702, Test Acc: 27.4028
2022-09-02 01:10:28,547:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 38/1000
2022-09-02 01:10:29,207:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00013, Train Loss: 1.3869, Train Acc: 46.8263,
                        Val Loss: 2.0094, Val Acc: 24.5708, Test Acc: 27.6650
2022-09-02 01:10:29,207:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 39/1000
2022-09-02 01:10:29,868:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00013, Train Loss: 1.3785, Train Acc: 47.7250,
                        Val Loss: 1.9865, Val Acc: 25.2232, Test Acc: 28.3119
2022-09-02 01:10:29,869:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 40/1000
2022-09-02 01:10:30,509:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.3731, Train Acc: 48.3659,
                        Val Loss: 1.9649, Val Acc: 25.6307, Test Acc: 29.3380
2022-09-02 01:10:30,509:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 41/1000
2022-09-02 01:10:31,137:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.3646, Train Acc: 48.5088,
                        Val Loss: 1.9383, Val Acc: 26.2153, Test Acc: 29.7717
2022-09-02 01:10:31,137:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 42/1000
2022-09-02 01:10:31,774:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.3590, Train Acc: 48.5017,
                        Val Loss: 1.9091, Val Acc: 27.5906, Test Acc: 30.5428
2022-09-02 01:10:31,774:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 43/1000
2022-09-02 01:10:32,419:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.3504, Train Acc: 49.3306,
                        Val Loss: 1.8957, Val Acc: 27.9463, Test Acc: 30.6684
2022-09-02 01:10:32,419:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 44/1000
2022-09-02 01:10:33,083:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00013, Train Loss: 1.3448, Train Acc: 49.6758,
                        Val Loss: 1.8963, Val Acc: 27.8216, Test Acc: 31.1065
2022-09-02 01:10:33,083:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 45/1000
2022-09-02 01:10:33,765:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 31.5133 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:33,766:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00013, Train Loss: 1.3361, Train Acc: 50.2009,
                        Val Loss: 1.8969, Val Acc: 27.8529, Test Acc: 31.5133
2022-09-02 01:10:33,766:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 46/1000
2022-09-02 01:10:34,416:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.1349 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:34,416:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.3302, Train Acc: 50.3255,
                        Val Loss: 1.8917, Val Acc: 28.4790, Test Acc: 32.1349
2022-09-02 01:10:34,416:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 47/1000
2022-09-02 01:10:35,085:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00006, Train Loss: 1.3215, Train Acc: 51.0625,
                        Val Loss: 1.8834, Val Acc: 28.5670, Test Acc: 31.9654
2022-09-02 01:10:35,085:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 48/1000
2022-09-02 01:10:35,744:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.4304 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:35,744:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00006, Train Loss: 1.3182, Train Acc: 51.2442,
                        Val Loss: 1.8762, Val Acc: 28.5024, Test Acc: 32.4304
2022-09-02 01:10:35,744:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 49/1000
2022-09-02 01:10:36,413:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.4928 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:36,413:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00006, Train Loss: 1.3139, Train Acc: 51.5749,
                        Val Loss: 1.8703, Val Acc: 28.6427, Test Acc: 32.4928
2022-09-02 01:10:36,413:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 50/1000
2022-09-02 01:10:37,067:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.6179 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:37,067:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00006, Train Loss: 1.3102, Train Acc: 51.2505,
                        Val Loss: 1.8665, Val Acc: 28.6174, Test Acc: 32.6179
2022-09-02 01:10:37,067:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 51/1000
2022-09-02 01:10:37,730:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 33.0927 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h09m57s_on_Sep_02_2022/MODELS_
2022-09-02 01:10:37,730:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00006, Train Loss: 1.3063, Train Acc: 51.6789,
                        Val Loss: 1.8665, Val Acc: 28.7138, Test Acc: 33.0927
2022-09-02 01:10:37,730:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 52/1000
2022-09-02 01:10:38,375:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.3021, Train Acc: 51.8423,
                        Val Loss: 1.8691, Val Acc: 28.4492, Test Acc: 33.0567
2022-09-02 01:10:38,376:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 53/1000
2022-09-02 01:10:39,011:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.2984, Train Acc: 52.0994,
                        Val Loss: 1.8714, Val Acc: 28.3506, Test Acc: 32.6269
2022-09-02 01:10:39,011:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 54/1000
2022-09-02 01:10:39,672:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00006, Train Loss: 1.2940, Train Acc: 52.2564,
                        Val Loss: 1.8745, Val Acc: 28.1183, Test Acc: 32.4266
2022-09-02 01:10:39,672:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 55/1000
2022-09-02 01:10:40,311:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.2902, Train Acc: 52.6261,
                        Val Loss: 1.8821, Val Acc: 27.9971, Test Acc: 31.6036
2022-09-02 01:10:40,311:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 56/1000
2022-09-02 01:10:40,963:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00006, Train Loss: 1.2860, Train Acc: 53.1434,
                        Val Loss: 1.8914, Val Acc: 28.0731, Test Acc: 31.1159
2022-09-02 01:10:40,963:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 57/1000
2022-09-02 01:10:41,630:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00006, Train Loss: 1.2820, Train Acc: 53.5639,
                        Val Loss: 1.8970, Val Acc: 28.2606, Test Acc: 30.9983
2022-09-02 01:10:41,630:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 58/1000
2022-09-02 01:10:42,288:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00003, Train Loss: 1.2779, Train Acc: 53.9281,
                        Val Loss: 1.8959, Val Acc: 27.8956, Test Acc: 30.5209
2022-09-02 01:10:42,288:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 59/1000
2022-09-02 01:10:42,951:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00003, Train Loss: 1.2756, Train Acc: 53.8328,
                        Val Loss: 1.8949, Val Acc: 27.9857, Test Acc: 30.2867
2022-09-02 01:10:42,952:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 60/1000
2022-09-02 01:10:43,591:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.2736, Train Acc: 54.0699,
                        Val Loss: 1.8961, Val Acc: 27.8292, Test Acc: 30.2867
2022-09-02 01:10:43,591:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 61/1000
2022-09-02 01:10:44,255:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00003, Train Loss: 1.2716, Train Acc: 54.0699,
                        Val Loss: 1.9006, Val Acc: 27.3797, Test Acc: 30.3306
2022-09-02 01:10:44,255:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 62/1000
2022-09-02 01:10:44,901:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.2693, Train Acc: 54.2747,
                        Val Loss: 1.9065, Val Acc: 27.3292, Test Acc: 30.1015
2022-09-02 01:10:44,901:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 63/1000
2022-09-02 01:10:45,558:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00003, Train Loss: 1.2673, Train Acc: 53.9249,
                        Val Loss: 1.9101, Val Acc: 27.2306, Test Acc: 30.2659
2022-09-02 01:10:45,558:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 64/1000
2022-09-02 01:10:46,203:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.2652, Train Acc: 54.1018,
                        Val Loss: 1.9108, Val Acc: 26.9444, Test Acc: 30.1180
2022-09-02 01:10:46,203:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 65/1000
2022-09-02 01:10:46,856:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.2629, Train Acc: 54.6508,
                        Val Loss: 1.9112, Val Acc: 26.7029, Test Acc: 29.9055
2022-09-02 01:10:46,857:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 66/1000
2022-09-02 01:10:47,500:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.2608, Train Acc: 54.6095,
                        Val Loss: 1.9138, Val Acc: 26.9518, Test Acc: 29.8740
2022-09-02 01:10:47,500:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 67/1000
2022-09-02 01:10:48,157:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00003, Train Loss: 1.2587, Train Acc: 54.7166,
                        Val Loss: 1.9184, Val Acc: 26.9483, Test Acc: 29.6982
2022-09-02 01:10:48,157:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 68/1000
2022-09-02 01:10:48,807:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.2564, Train Acc: 55.1745,
                        Val Loss: 1.9231, Val Acc: 26.7488, Test Acc: 29.8626
2022-09-02 01:10:48,807:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 69/1000
2022-09-02 01:10:49,474:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00002, Train Loss: 1.2543, Train Acc: 55.1135,
                        Val Loss: 1.9235, Val Acc: 26.7488, Test Acc: 29.9345
2022-09-02 01:10:49,474:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 70/1000
2022-09-02 01:10:50,122:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00002, Train Loss: 1.2532, Train Acc: 55.1135,
                        Val Loss: 1.9230, Val Acc: 26.8389, Test Acc: 29.9065
2022-09-02 01:10:50,122:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 71/1000
2022-09-02 01:10:50,773:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00002, Train Loss: 1.2521, Train Acc: 55.0071,
                        Val Loss: 1.9224, Val Acc: 26.8616, Test Acc: 29.8139
2022-09-02 01:10:50,773:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 72/1000
2022-09-02 01:10:51,431:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00002, Train Loss: 1.2510, Train Acc: 54.9792,
                        Val Loss: 1.9226, Val Acc: 26.4886, Test Acc: 29.6661
2022-09-02 01:10:51,431:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 73/1000
2022-09-02 01:10:52,077:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00002, Train Loss: 1.2499, Train Acc: 54.8840,
                        Val Loss: 1.9240, Val Acc: 26.5867, Test Acc: 29.6661
2022-09-02 01:10:52,077:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 74/1000
2022-09-02 01:10:52,739:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00002, Train Loss: 1.2488, Train Acc: 54.9776,
                        Val Loss: 1.9266, Val Acc: 26.4886, Test Acc: 29.6661
2022-09-02 01:10:52,739:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 75/1000
2022-09-02 01:10:53,377:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.2477, Train Acc: 55.1665,
                        Val Loss: 1.9293, Val Acc: 26.5838, Test Acc: 29.6381
2022-09-02 01:10:53,377:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 76/1000
2022-09-02 01:10:54,031:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00002, Train Loss: 1.2466, Train Acc: 55.2546,
                        Val Loss: 1.9316, Val Acc: 26.4858, Test Acc: 29.5663
2022-09-02 01:10:54,031:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 77/1000
2022-09-02 01:10:54,710:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00002, Train Loss: 1.2455, Train Acc: 55.3363,
                        Val Loss: 1.9327, Val Acc: 26.5844, Test Acc: 29.4665
2022-09-02 01:10:54,710:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 78/1000
2022-09-02 01:10:55,387:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00002, Train Loss: 1.2443, Train Acc: 55.4220,
                        Val Loss: 1.9333, Val Acc: 26.5090, Test Acc: 29.3020
2022-09-02 01:10:55,387:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 79/1000
2022-09-02 01:10:56,043:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00002, Train Loss: 1.2432, Train Acc: 55.3338,
                        Val Loss: 1.9345, Val Acc: 26.5090, Test Acc: 29.2302
2022-09-02 01:10:56,044:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 80/1000
2022-09-02 01:10:56,709:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00001, Train Loss: 1.2421, Train Acc: 55.5147,
                        Val Loss: 1.9354, Val Acc: 26.5090, Test Acc: 29.2302
2022-09-02 01:10:56,709:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 81/1000
2022-09-02 01:10:57,341:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00001, Train Loss: 1.2416, Train Acc: 55.5147,
                        Val Loss: 1.9367, Val Acc: 26.5090, Test Acc: 29.1447
2022-09-02 01:10:57,341:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 82/1000
2022-09-02 01:10:58,011:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00001, Train Loss: 1.2410, Train Acc: 55.5147,
                        Val Loss: 1.9382, Val Acc: 26.4110, Test Acc: 29.1447
2022-09-02 01:10:58,011:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 83/1000
2022-09-02 01:10:58,693:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00001, Train Loss: 1.2405, Train Acc: 55.5147,
                        Val Loss: 1.9396, Val Acc: 26.4110, Test Acc: 29.1447
2022-09-02 01:10:58,694:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 84/1000
2022-09-02 01:10:59,401:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00001, Train Loss: 1.2399, Train Acc: 55.5227,
                        Val Loss: 1.9408, Val Acc: 26.4110, Test Acc: 29.1447
2022-09-02 01:10:59,401:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 85/1000
2022-09-02 01:11:00,056:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00001, Train Loss: 1.2394, Train Acc: 55.5227,
                        Val Loss: 1.9415, Val Acc: 26.3129, Test Acc: 29.0248
2022-09-02 01:11:00,056:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 86/1000
2022-09-02 01:11:00,715:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00001, Train Loss: 1.2388, Train Acc: 55.6100,
                        Val Loss: 1.9419, Val Acc: 26.3883, Test Acc: 29.0248
2022-09-02 01:11:00,715:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 87/1000
2022-09-02 01:11:01,414:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00001, Train Loss: 1.2382, Train Acc: 55.6100,
                        Val Loss: 1.9423, Val Acc: 26.3101, Test Acc: 29.0248
2022-09-02 01:11:01,414:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 88/1000
2022-09-02 01:11:02,063:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00001, Train Loss: 1.2377, Train Acc: 55.6917,
                        Val Loss: 1.9428, Val Acc: 26.3101, Test Acc: 29.0248
2022-09-02 01:11:02,063:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 89/1000
2022-09-02 01:11:02,697:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00001, Train Loss: 1.2371, Train Acc: 55.6917,
                        Val Loss: 1.9436, Val Acc: 26.2318, Test Acc: 28.9049
2022-09-02 01:11:02,697:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 90/1000
2022-09-02 01:11:03,329:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00001, Train Loss: 1.2366, Train Acc: 55.6917,
                        Val Loss: 1.9447, Val Acc: 26.2318, Test Acc: 28.9049
2022-09-02 01:11:03,329:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 91/1000
2022-09-02 01:11:03,806:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 01:11:03,806:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 01:11:13,291:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 01:11:17,813:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 01:11:17,813:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 01:11:17,814:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:11:17,815:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:11:17,816:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:11:17,816:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:11:17,820:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 01:11:17,821:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 01:11:17,822:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:11:17,823:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:11:17,823:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:11:17,823:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:11:18,071:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 01:11:18,071:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 01:11:50,407:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:32.57880091667175
2022-09-02 01:11:50,409:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 01:11:50,409:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 01:11:50,409:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 01:11:50,409:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 01:11:50,411:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 01:11:51,061:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 16.8376 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:51,062:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7957, Train Acc: 16.8032,
                        Val Loss: 1.7936, Val Acc: 16.7568, Test Acc: 16.8376
2022-09-02 01:11:51,062:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 01:11:51,702:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 18.7204 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:51,702:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7751, Train Acc: 22.0832,
                        Val Loss: 1.7882, Val Acc: 18.1935, Test Acc: 18.7204
2022-09-02 01:11:51,702:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 01:11:52,424:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.5188 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:52,424:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.7602, Train Acc: 23.6648,
                        Val Loss: 1.7842, Val Acc: 19.1390, Test Acc: 19.5188
2022-09-02 01:11:52,424:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 01:11:53,149:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.5940 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:53,149:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.7483, Train Acc: 25.3900,
                        Val Loss: 1.7799, Val Acc: 19.2320, Test Acc: 19.5940
2022-09-02 01:11:53,149:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 01:11:53,845:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.6133 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:53,845:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.7382, Train Acc: 26.5300,
                        Val Loss: 1.7750, Val Acc: 19.3074, Test Acc: 19.6133
2022-09-02 01:11:53,845:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 01:11:54,489:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.7481 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:54,489:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7289, Train Acc: 27.5512,
                        Val Loss: 1.7700, Val Acc: 19.4859, Test Acc: 19.7481
2022-09-02 01:11:54,489:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-02 01:11:55,104:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 20.8100 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:55,104:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.7200, Train Acc: 28.8039,
                        Val Loss: 1.7647, Val Acc: 20.1326, Test Acc: 20.8100
2022-09-02 01:11:55,104:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-02 01:11:55,727:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 21.5761 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:55,727:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7111, Train Acc: 29.7583,
                        Val Loss: 1.7589, Val Acc: 20.9743, Test Acc: 21.5761
2022-09-02 01:11:55,727:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-02 01:11:56,357:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 22.6139 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:56,358:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7025, Train Acc: 31.3974,
                        Val Loss: 1.7530, Val Acc: 21.5838, Test Acc: 22.6139
2022-09-02 01:11:56,358:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-02 01:11:56,993:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 23.8352 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:56,993:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6940, Train Acc: 31.9582,
                        Val Loss: 1.7474, Val Acc: 22.1388, Test Acc: 23.8352
2022-09-02 01:11:56,993:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-02 01:11:57,624:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 25.5079 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:57,625:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6855, Train Acc: 32.9253,
                        Val Loss: 1.7422, Val Acc: 23.6317, Test Acc: 25.5079
2022-09-02 01:11:57,625:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-02 01:11:58,244:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 26.5379 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:58,244:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.6768, Train Acc: 33.7376,
                        Val Loss: 1.7373, Val Acc: 24.9262, Test Acc: 26.5379
2022-09-02 01:11:58,244:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-02 01:11:58,892:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 28.0118 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:58,893:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6679, Train Acc: 34.7292,
                        Val Loss: 1.7329, Val Acc: 26.4552, Test Acc: 28.0118
2022-09-02 01:11:58,893:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-02 01:11:59,521:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 28.8110 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:11:59,521:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6586, Train Acc: 35.4724,
                        Val Loss: 1.7287, Val Acc: 27.9415, Test Acc: 28.8110
2022-09-02 01:11:59,521:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-02 01:12:00,158:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 29.8287 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:12:00,158:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6488, Train Acc: 36.4733,
                        Val Loss: 1.7245, Val Acc: 28.0792, Test Acc: 29.8287
2022-09-02 01:12:00,158:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-02 01:12:00,796:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 30.5706 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:12:00,796:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6385, Train Acc: 37.9532,
                        Val Loss: 1.7194, Val Acc: 28.7478, Test Acc: 30.5706
2022-09-02 01:12:00,796:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-02 01:12:01,425:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 30.8779 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h11m17s_on_Sep_02_2022/MODELS_
2022-09-02 01:12:01,425:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6275, Train Acc: 38.6201,
                        Val Loss: 1.7134, Val Acc: 28.1478, Test Acc: 30.8779
2022-09-02 01:12:01,425:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-02 01:12:02,075:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6159, Train Acc: 39.9128,
                        Val Loss: 1.7093, Val Acc: 27.3993, Test Acc: 30.3144
2022-09-02 01:12:02,076:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-02 01:12:02,751:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.6036, Train Acc: 40.3323,
                        Val Loss: 1.7108, Val Acc: 25.6046, Test Acc: 28.6346
2022-09-02 01:12:02,751:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-02 01:12:03,399:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.5908, Train Acc: 41.6135,
                        Val Loss: 1.7261, Val Acc: 24.5826, Test Acc: 27.4282
2022-09-02 01:12:03,400:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-02 01:12:04,041:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.5773, Train Acc: 42.4156,
                        Val Loss: 1.7664, Val Acc: 23.9286, Test Acc: 26.4576
2022-09-02 01:12:04,041:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-02 01:12:04,663:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.5630, Train Acc: 42.9374,
                        Val Loss: 1.8297, Val Acc: 24.1442, Test Acc: 26.3962
2022-09-02 01:12:04,663:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-02 01:12:05,285:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.5479, Train Acc: 43.1871,
                        Val Loss: 1.9006, Val Acc: 24.2088, Test Acc: 25.8112
2022-09-02 01:12:05,285:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-02 01:12:05,913:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.5322, Train Acc: 44.6021,
                        Val Loss: 1.9838, Val Acc: 24.1760, Test Acc: 25.9141
2022-09-02 01:12:05,913:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-02 01:12:06,541:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.5162, Train Acc: 44.9353,
                        Val Loss: 2.0973, Val Acc: 23.6076, Test Acc: 25.3655
2022-09-02 01:12:06,542:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-02 01:12:07,163:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.4995, Train Acc: 46.3243,
                        Val Loss: 2.2342, Val Acc: 23.7750, Test Acc: 25.1931
2022-09-02 01:12:07,163:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-02 01:12:07,814:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.4817, Train Acc: 46.3243,
                        Val Loss: 2.4175, Val Acc: 23.3235, Test Acc: 25.0345
2022-09-02 01:12:07,814:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
2022-09-02 01:12:08,485:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.4634, Train Acc: 47.3848,
                        Val Loss: 2.6367, Val Acc: 22.8820, Test Acc: 24.9120
2022-09-02 01:12:08,485:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 29/1000
2022-09-02 01:12:09,136:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.4448, Train Acc: 48.5723,
                        Val Loss: 2.9826, Val Acc: 23.1519, Test Acc: 24.0761
2022-09-02 01:12:09,136:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 30/1000
2022-09-02 01:12:09,763:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.4256, Train Acc: 49.6695,
                        Val Loss: 2.9989, Val Acc: 23.3641, Test Acc: 24.2910
2022-09-02 01:12:09,763:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 31/1000
2022-09-02 01:12:10,446:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.4146, Train Acc: 49.8631,
                        Val Loss: 2.9322, Val Acc: 23.9080, Test Acc: 25.2713
2022-09-02 01:12:10,446:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 32/1000
2022-09-02 01:12:11,125:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.4032, Train Acc: 50.2732,
                        Val Loss: 2.8502, Val Acc: 24.2570, Test Acc: 25.3059
2022-09-02 01:12:11,125:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 33/1000
2022-09-02 01:12:11,787:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.3915, Train Acc: 50.8379,
                        Val Loss: 2.8252, Val Acc: 24.6179, Test Acc: 25.5342
2022-09-02 01:12:11,787:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 34/1000
2022-09-02 01:12:12,420:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3789, Train Acc: 51.2489,
                        Val Loss: 2.8716, Val Acc: 25.0806, Test Acc: 25.8889
2022-09-02 01:12:12,421:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 35/1000
2022-09-02 01:12:13,065:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.3670, Train Acc: 51.1198,
                        Val Loss: 2.9468, Val Acc: 25.1606, Test Acc: 25.4858
2022-09-02 01:12:13,065:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 36/1000
2022-09-02 01:12:13,694:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3543, Train Acc: 51.5670,
                        Val Loss: 2.9614, Val Acc: 25.2214, Test Acc: 25.4858
2022-09-02 01:12:13,694:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 37/1000
2022-09-02 01:12:14,373:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.3418, Train Acc: 52.1039,
                        Val Loss: 2.9526, Val Acc: 25.9607, Test Acc: 25.3465
2022-09-02 01:12:14,373:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 38/1000
2022-09-02 01:12:15,055:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.3292, Train Acc: 53.0727,
                        Val Loss: 3.0141, Val Acc: 25.8251, Test Acc: 25.3638
2022-09-02 01:12:15,055:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 39/1000
2022-09-02 01:12:15,697:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.3159, Train Acc: 53.5637,
                        Val Loss: 3.0886, Val Acc: 25.5924, Test Acc: 25.3715
2022-09-02 01:12:15,697:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 40/1000
2022-09-02 01:12:16,349:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.3024, Train Acc: 53.9675,
                        Val Loss: 3.1178, Val Acc: 25.8873, Test Acc: 25.4944
2022-09-02 01:12:16,349:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 41/1000
2022-09-02 01:12:17,007:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00013, Train Loss: 1.2887, Train Acc: 54.3920,
                        Val Loss: 3.0680, Val Acc: 26.2380, Test Acc: 25.7119
2022-09-02 01:12:17,007:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 42/1000
2022-09-02 01:12:17,649:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2812, Train Acc: 54.7117,
                        Val Loss: 3.0254, Val Acc: 26.6114, Test Acc: 26.1835
2022-09-02 01:12:17,649:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 43/1000
2022-09-02 01:12:18,300:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2736, Train Acc: 54.7568,
                        Val Loss: 2.9752, Val Acc: 26.5410, Test Acc: 25.8027
2022-09-02 01:12:18,301:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 44/1000
2022-09-02 01:12:18,949:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2657, Train Acc: 55.8849,
                        Val Loss: 2.9323, Val Acc: 26.4244, Test Acc: 26.1078
2022-09-02 01:12:18,949:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 45/1000
2022-09-02 01:12:19,595:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2575, Train Acc: 56.6386,
                        Val Loss: 2.9146, Val Acc: 26.5612, Test Acc: 26.0760
2022-09-02 01:12:19,595:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 46/1000
2022-09-02 01:12:20,231:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2492, Train Acc: 56.8821,
                        Val Loss: 2.9015, Val Acc: 25.9177, Test Acc: 26.6684
2022-09-02 01:12:20,231:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 47/1000
2022-09-02 01:12:20,881:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2408, Train Acc: 57.2264,
                        Val Loss: 2.8757, Val Acc: 26.1226, Test Acc: 26.9136
2022-09-02 01:12:20,881:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 48/1000
2022-09-02 01:12:21,525:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2323, Train Acc: 57.5588,
                        Val Loss: 2.8431, Val Acc: 26.2183, Test Acc: 26.2872
2022-09-02 01:12:21,525:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 49/1000
2022-09-02 01:12:22,175:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2237, Train Acc: 57.6127,
                        Val Loss: 2.8561, Val Acc: 26.1535, Test Acc: 26.0689
2022-09-02 01:12:22,176:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 50/1000
2022-09-02 01:12:22,829:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2150, Train Acc: 57.4199,
                        Val Loss: 2.8516, Val Acc: 26.4192, Test Acc: 26.2316
2022-09-02 01:12:22,829:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 51/1000
2022-09-02 01:12:23,459:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.2063, Train Acc: 57.9181,
                        Val Loss: 2.8266, Val Acc: 26.7434, Test Acc: 25.8634
2022-09-02 01:12:23,459:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 52/1000
2022-09-02 01:12:24,106:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00006, Train Loss: 1.1974, Train Acc: 58.6479,
                        Val Loss: 2.7821, Val Acc: 27.0919, Test Acc: 25.8124
2022-09-02 01:12:24,106:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 53/1000
2022-09-02 01:12:24,741:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.1928, Train Acc: 58.7296,
                        Val Loss: 2.7505, Val Acc: 27.0823, Test Acc: 26.2739
2022-09-02 01:12:24,742:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 54/1000
2022-09-02 01:12:25,373:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.1882, Train Acc: 58.8192,
                        Val Loss: 2.7253, Val Acc: 27.1571, Test Acc: 25.7067
2022-09-02 01:12:25,373:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 55/1000
2022-09-02 01:12:26,003:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.1834, Train Acc: 59.1318,
                        Val Loss: 2.6928, Val Acc: 27.0484, Test Acc: 25.8323
2022-09-02 01:12:26,003:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 56/1000
2022-09-02 01:12:26,660:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00006, Train Loss: 1.1787, Train Acc: 59.7909,
                        Val Loss: 2.6622, Val Acc: 27.1828, Test Acc: 25.1094
2022-09-02 01:12:26,661:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 57/1000
2022-09-02 01:12:27,281:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.1737, Train Acc: 60.2360,
                        Val Loss: 2.6386, Val Acc: 27.3309, Test Acc: 25.5510
2022-09-02 01:12:27,281:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 58/1000
2022-09-02 01:12:27,896:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00006, Train Loss: 1.1688, Train Acc: 60.4329,
                        Val Loss: 2.6223, Val Acc: 27.4000, Test Acc: 25.6017
2022-09-02 01:12:27,896:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 59/1000
2022-09-02 01:12:28,516:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.1638, Train Acc: 60.8812,
                        Val Loss: 2.6138, Val Acc: 27.8882, Test Acc: 26.0979
2022-09-02 01:12:28,516:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 60/1000
2022-09-02 01:12:29,154:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.1589, Train Acc: 61.0793,
                        Val Loss: 2.6164, Val Acc: 28.1229, Test Acc: 26.5575
2022-09-02 01:12:29,154:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 61/1000
2022-09-02 01:12:29,777:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.1537, Train Acc: 61.4650,
                        Val Loss: 2.6184, Val Acc: 28.2080, Test Acc: 26.9859
2022-09-02 01:12:29,778:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 62/1000
2022-09-02 01:12:30,418:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.1486, Train Acc: 61.8704,
                        Val Loss: 2.6155, Val Acc: 28.5600, Test Acc: 27.5388
2022-09-02 01:12:30,418:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 63/1000
2022-09-02 01:12:31,061:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.1433, Train Acc: 62.5462,
                        Val Loss: 2.6046, Val Acc: 28.8798, Test Acc: 27.8713
2022-09-02 01:12:31,061:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 64/1000
2022-09-02 01:12:31,707:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.1406, Train Acc: 62.4669,
                        Val Loss: 2.5957, Val Acc: 29.2841, Test Acc: 27.6668
2022-09-02 01:12:31,707:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 65/1000
2022-09-02 01:12:32,334:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.1379, Train Acc: 62.3821,
                        Val Loss: 2.5886, Val Acc: 28.9973, Test Acc: 27.6389
2022-09-02 01:12:32,334:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 66/1000
2022-09-02 01:12:32,979:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.1352, Train Acc: 62.6327,
                        Val Loss: 2.5826, Val Acc: 29.1810, Test Acc: 27.9505
2022-09-02 01:12:32,979:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 67/1000
2022-09-02 01:12:33,623:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.1326, Train Acc: 62.8969,
                        Val Loss: 2.5736, Val Acc: 29.4872, Test Acc: 27.7543
2022-09-02 01:12:33,623:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 68/1000
2022-09-02 01:12:34,279:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00003, Train Loss: 1.1299, Train Acc: 62.9691,
                        Val Loss: 2.5645, Val Acc: 29.9957, Test Acc: 28.6709
2022-09-02 01:12:34,280:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 69/1000
2022-09-02 01:12:34,909:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.1272, Train Acc: 62.9691,
                        Val Loss: 2.5538, Val Acc: 30.2401, Test Acc: 28.6154
2022-09-02 01:12:34,909:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 70/1000
2022-09-02 01:12:35,562:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.1245, Train Acc: 63.1436,
                        Val Loss: 2.5449, Val Acc: 30.9475, Test Acc: 28.8436
2022-09-02 01:12:35,562:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 71/1000
2022-09-02 01:12:36,208:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.1218, Train Acc: 63.3872,
                        Val Loss: 2.5424, Val Acc: 31.5235, Test Acc: 28.5412
2022-09-02 01:12:36,208:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 72/1000
2022-09-02 01:12:36,853:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.1191, Train Acc: 63.2999,
                        Val Loss: 2.5477, Val Acc: 31.7872, Test Acc: 28.4557
2022-09-02 01:12:36,853:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 73/1000
2022-09-02 01:12:37,510:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00003, Train Loss: 1.1163, Train Acc: 63.7307,
                        Val Loss: 2.5527, Val Acc: 31.8563, Test Acc: 28.1849
2022-09-02 01:12:37,511:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 74/1000
2022-09-02 01:12:38,141:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.1136, Train Acc: 64.1392,
                        Val Loss: 2.5498, Val Acc: 32.0713, Test Acc: 28.1849
2022-09-02 01:12:38,141:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 75/1000
2022-09-02 01:12:38,780:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1122, Train Acc: 64.1336,
                        Val Loss: 2.5450, Val Acc: 31.9490, Test Acc: 28.3433
2022-09-02 01:12:38,781:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 76/1000
2022-09-02 01:12:39,420:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1108, Train Acc: 63.9520,
                        Val Loss: 2.5424, Val Acc: 32.3538, Test Acc: 28.2533
2022-09-02 01:12:39,421:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 77/1000
2022-09-02 01:12:40,063:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1095, Train Acc: 64.1812,
                        Val Loss: 2.5447, Val Acc: 32.5103, Test Acc: 28.4730
2022-09-02 01:12:40,063:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 78/1000
2022-09-02 01:12:40,695:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.1081, Train Acc: 64.3286,
                        Val Loss: 2.5505, Val Acc: 32.5103, Test Acc: 28.6363
2022-09-02 01:12:40,695:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 79/1000
2022-09-02 01:12:41,347:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00002, Train Loss: 1.1067, Train Acc: 64.3072,
                        Val Loss: 2.5573, Val Acc: 32.4202, Test Acc: 28.7471
2022-09-02 01:12:41,347:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 80/1000
2022-09-02 01:12:41,989:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1053, Train Acc: 64.6157,
                        Val Loss: 2.5616, Val Acc: 32.5189, Test Acc: 28.7860
2022-09-02 01:12:41,989:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 81/1000
2022-09-02 01:12:42,630:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1039, Train Acc: 64.7093,
                        Val Loss: 2.5631, Val Acc: 32.1817, Test Acc: 28.6079
2022-09-02 01:12:42,630:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 82/1000
2022-09-02 01:12:43,270:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1025, Train Acc: 64.6958,
                        Val Loss: 2.5632, Val Acc: 32.1699, Test Acc: 28.4370
2022-09-02 01:12:43,270:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 83/1000
2022-09-02 01:12:43,908:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1011, Train Acc: 64.6958,
                        Val Loss: 2.5644, Val Acc: 32.4131, Test Acc: 28.4714
2022-09-02 01:12:43,908:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 84/1000
2022-09-02 01:12:44,566:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00002, Train Loss: 1.0997, Train Acc: 64.6958,
                        Val Loss: 2.5683, Val Acc: 32.5032, Test Acc: 28.4714
2022-09-02 01:12:44,566:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 85/1000
2022-09-02 01:12:45,196:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00001, Train Loss: 1.0983, Train Acc: 64.9513,
                        Val Loss: 2.5715, Val Acc: 32.5032, Test Acc: 28.4714
2022-09-02 01:12:45,196:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 86/1000
2022-09-02 01:12:45,826:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00001, Train Loss: 1.0976, Train Acc: 65.0465,
                        Val Loss: 2.5747, Val Acc: 32.4947, Test Acc: 28.6424
2022-09-02 01:12:45,826:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 87/1000
2022-09-02 01:12:46,449:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00001, Train Loss: 1.0969, Train Acc: 65.1401,
                        Val Loss: 2.5777, Val Acc: 32.3116, Test Acc: 28.6424
2022-09-02 01:12:46,449:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 88/1000
2022-09-02 01:12:47,072:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00001, Train Loss: 1.0962, Train Acc: 65.1401,
                        Val Loss: 2.5804, Val Acc: 32.3116, Test Acc: 28.5180
2022-09-02 01:12:47,072:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 89/1000
2022-09-02 01:12:47,724:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00001, Train Loss: 1.0955, Train Acc: 65.2139,
                        Val Loss: 2.5832, Val Acc: 32.3116, Test Acc: 28.5180
2022-09-02 01:12:47,724:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 90/1000
2022-09-02 01:12:48,392:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00001, Train Loss: 1.0948, Train Acc: 65.2139,
                        Val Loss: 2.5858, Val Acc: 32.3116, Test Acc: 28.4791
2022-09-02 01:12:48,392:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 91/1000
2022-09-02 01:12:49,035:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00001, Train Loss: 1.0941, Train Acc: 65.3091,
                        Val Loss: 2.5886, Val Acc: 32.3116, Test Acc: 28.4791
2022-09-02 01:12:49,035:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 92/1000
2022-09-02 01:12:49,758:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00001, Train Loss: 1.0934, Train Acc: 65.3829,
                        Val Loss: 2.5916, Val Acc: 32.2362, Test Acc: 28.5717
2022-09-02 01:12:49,758:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 93/1000
2022-09-02 01:12:50,438:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00001, Train Loss: 1.0927, Train Acc: 65.3829,
                        Val Loss: 2.5949, Val Acc: 32.2480, Test Acc: 28.5717
2022-09-02 01:12:50,438:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 94/1000
2022-09-02 01:12:51,114:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00001, Train Loss: 1.0920, Train Acc: 65.3829,
                        Val Loss: 2.5980, Val Acc: 32.2480, Test Acc: 28.5717
2022-09-02 01:12:51,114:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 95/1000
2022-09-02 01:12:51,520:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 01:12:51,520:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 01:13:04,030:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 01:13:08,507:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 01:13:08,507:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 01:13:08,509:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:13:08,510:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:13:08,510:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:13:08,510:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:13:08,515:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 01:13:08,516:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 01:13:08,517:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-02 01:13:08,518:pe_layer.py:126 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 01:13:08,518:pe_layer.py:131 -             __init__(): Using matrix: A
2022-09-02 01:13:08,518:pe_layer.py:132 -             __init__(): Matrix power: 1
2022-09-02 01:13:08,793:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 01:13:08,793:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 01:13:15,087:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:6.563652753829956
2022-09-02 01:13:15,090:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 01:13:15,090:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 01:13:15,090:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 01:13:15,090:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 01:13:15,092:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 01:13:15,835:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 17.2650 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:15,835:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.74s, LR: 0.00050, Train Loss: 1.7971, Train Acc: 18.0273,
                        Val Loss: 1.7998, Val Acc: 17.3433, Test Acc: 17.2650
2022-09-02 01:13:15,836:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 01:13:16,456:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 17.8669 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:16,456:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7750, Train Acc: 22.1002,
                        Val Loss: 1.7949, Val Acc: 18.4839, Test Acc: 17.8669
2022-09-02 01:13:16,456:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 01:13:17,148:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 18.4249 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:17,148:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.7599, Train Acc: 24.1310,
                        Val Loss: 1.7897, Val Acc: 18.8110, Test Acc: 18.4249
2022-09-02 01:13:17,148:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 01:13:17,816:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.1858 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:17,816:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7465, Train Acc: 25.5558,
                        Val Loss: 1.7837, Val Acc: 20.0778, Test Acc: 19.1858
2022-09-02 01:13:17,816:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 01:13:18,536:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.2305 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:18,536:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.7346, Train Acc: 26.3291,
                        Val Loss: 1.7779, Val Acc: 20.0506, Test Acc: 19.2305
2022-09-02 01:13:18,536:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 01:13:19,177:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.5991 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:19,177:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7237, Train Acc: 26.8439,
                        Val Loss: 1.7724, Val Acc: 19.9520, Test Acc: 19.5991
2022-09-02 01:13:19,177:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-02 01:13:19,793:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 19.8568 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:19,793:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7136, Train Acc: 27.4238,
                        Val Loss: 1.7685, Val Acc: 20.3057, Test Acc: 19.8568
2022-09-02 01:13:19,793:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-02 01:13:20,412:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7040, Train Acc: 27.8655,
                        Val Loss: 1.7656, Val Acc: 20.4111, Test Acc: 19.6844
2022-09-02 01:13:20,412:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-02 01:13:21,040:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 20.9282 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:21,041:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6947, Train Acc: 28.9499,
                        Val Loss: 1.7626, Val Acc: 20.8634, Test Acc: 20.9282
2022-09-02 01:13:21,041:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-02 01:13:21,666:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 21.3013 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:21,666:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6853, Train Acc: 29.5564,
                        Val Loss: 1.7596, Val Acc: 21.1117, Test Acc: 21.3013
2022-09-02 01:13:21,666:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-02 01:13:22,287:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 21.4257 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:22,287:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.6756, Train Acc: 30.4461,
                        Val Loss: 1.7569, Val Acc: 21.4722, Test Acc: 21.4257
2022-09-02 01:13:22,287:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-02 01:13:22,918:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 21.8234 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:22,918:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6654, Train Acc: 32.0587,
                        Val Loss: 1.7547, Val Acc: 21.6287, Test Acc: 21.8234
2022-09-02 01:13:22,918:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-02 01:13:23,549:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 23.2438 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:23,549:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6547, Train Acc: 33.3476,
                        Val Loss: 1.7537, Val Acc: 21.9316, Test Acc: 23.2438
2022-09-02 01:13:23,549:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-02 01:13:24,164:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 25.2584 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:24,164:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.6436, Train Acc: 34.8930,
                        Val Loss: 1.7553, Val Acc: 24.2328, Test Acc: 25.2584
2022-09-02 01:13:24,164:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-02 01:13:24,820:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 26.2939 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:24,821:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6321, Train Acc: 36.0202,
                        Val Loss: 1.7586, Val Acc: 25.8680, Test Acc: 26.2939
2022-09-02 01:13:24,821:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-02 01:13:25,460:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 27.7372 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:25,460:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6200, Train Acc: 37.3784,
                        Val Loss: 1.7571, Val Acc: 27.7301, Test Acc: 27.7372
2022-09-02 01:13:25,460:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-02 01:13:26,103:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 27.9931 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:26,104:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6074, Train Acc: 38.8367,
                        Val Loss: 1.7523, Val Acc: 28.0235, Test Acc: 27.9931
2022-09-02 01:13:26,104:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-02 01:13:26,749:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 29.0685 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:26,749:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.5945, Train Acc: 39.9407,
                        Val Loss: 1.7501, Val Acc: 28.2567, Test Acc: 29.0685
2022-09-02 01:13:26,749:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-02 01:13:27,410:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.5812, Train Acc: 41.2429,
                        Val Loss: 1.7559, Val Acc: 28.7946, Test Acc: 28.7129
2022-09-02 01:13:27,410:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-02 01:13:28,065:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.5678, Train Acc: 41.5128,
                        Val Loss: 1.7819, Val Acc: 29.3883, Test Acc: 28.5672
2022-09-02 01:13:28,065:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 21/1000
2022-09-02 01:13:28,700:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.5540, Train Acc: 43.3456,
                        Val Loss: 1.8263, Val Acc: 28.1852, Test Acc: 28.5035
2022-09-02 01:13:28,700:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 22/1000
2022-09-02 01:13:29,326:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.5396, Train Acc: 43.9224,
                        Val Loss: 1.8701, Val Acc: 27.2030, Test Acc: 27.9173
2022-09-02 01:13:29,326:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 23/1000
2022-09-02 01:13:29,971:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.5241, Train Acc: 44.6697,
                        Val Loss: 1.9374, Val Acc: 26.3002, Test Acc: 27.6709
2022-09-02 01:13:29,971:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 24/1000
2022-09-02 01:13:30,596:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.5077, Train Acc: 46.1287,
                        Val Loss: 2.0038, Val Acc: 24.6051, Test Acc: 25.9800
2022-09-02 01:13:30,596:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 25/1000
2022-09-02 01:13:31,237:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.4911, Train Acc: 46.5326,
                        Val Loss: 2.1223, Val Acc: 23.9045, Test Acc: 25.8066
2022-09-02 01:13:31,237:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 26/1000
2022-09-02 01:13:31,871:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.4737, Train Acc: 47.2617,
                        Val Loss: 2.2343, Val Acc: 24.4114, Test Acc: 25.9147
2022-09-02 01:13:31,871:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 27/1000
2022-09-02 01:13:32,512:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.4559, Train Acc: 48.1860,
                        Val Loss: 2.4893, Val Acc: 23.3267, Test Acc: 22.9244
2022-09-02 01:13:32,512:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 28/1000
2022-09-02 01:13:33,146:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.4372, Train Acc: 48.4335,
                        Val Loss: 2.5993, Val Acc: 23.6633, Test Acc: 24.1842
2022-09-02 01:13:33,146:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 29/1000
2022-09-02 01:13:33,774:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.4178, Train Acc: 50.5690,
                        Val Loss: 2.9600, Val Acc: 20.2745, Test Acc: 21.9615
2022-09-02 01:13:33,774:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 30/1000
2022-09-02 01:13:34,407:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.4037, Train Acc: 50.8071,
                        Val Loss: 2.6608, Val Acc: 22.8290, Test Acc: 24.5308
2022-09-02 01:13:34,408:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 31/1000
2022-09-02 01:13:35,039:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3876, Train Acc: 52.1366,
                        Val Loss: 2.5697, Val Acc: 24.5273, Test Acc: 26.1862
2022-09-02 01:13:35,039:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 32/1000
2022-09-02 01:13:35,672:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3829, Train Acc: 51.7383,
                        Val Loss: 2.7445, Val Acc: 23.0852, Test Acc: 24.6695
2022-09-02 01:13:35,673:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 33/1000
2022-09-02 01:13:36,307:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3665, Train Acc: 52.6041,
                        Val Loss: 2.8630, Val Acc: 22.2166, Test Acc: 24.2582
2022-09-02 01:13:36,307:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 34/1000
2022-09-02 01:13:36,932:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3614, Train Acc: 53.4046,
                        Val Loss: 2.6277, Val Acc: 24.5388, Test Acc: 27.1337
2022-09-02 01:13:36,932:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 35/1000
2022-09-02 01:13:37,569:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.3458, Train Acc: 53.3560,
                        Val Loss: 2.4520, Val Acc: 25.4765, Test Acc: 28.8841
2022-09-02 01:13:37,569:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 36/1000
2022-09-02 01:13:38,202:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3376, Train Acc: 53.0427,
                        Val Loss: 2.5883, Val Acc: 24.9473, Test Acc: 27.8036
2022-09-02 01:13:38,203:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 37/1000
2022-09-02 01:13:38,838:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.3239, Train Acc: 53.2219,
                        Val Loss: 2.6909, Val Acc: 23.7608, Test Acc: 26.6728
2022-09-02 01:13:38,838:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 38/1000
2022-09-02 01:13:39,457:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.3141, Train Acc: 54.3805,
                        Val Loss: 2.4804, Val Acc: 25.2812, Test Acc: 28.7505
2022-09-02 01:13:39,457:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 39/1000
2022-09-02 01:13:40,103:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 30.6036 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:40,103:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.3007, Train Acc: 54.6843,
                        Val Loss: 2.2920, Val Acc: 29.1952, Test Acc: 30.6036
2022-09-02 01:13:40,103:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 40/1000
2022-09-02 01:13:40,744:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.2903, Train Acc: 54.1605,
                        Val Loss: 2.4348, Val Acc: 26.8876, Test Acc: 29.0466
2022-09-02 01:13:40,744:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 41/1000
2022-09-02 01:13:41,376:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.2752, Train Acc: 55.7550,
                        Val Loss: 2.4418, Val Acc: 26.3906, Test Acc: 29.3310
2022-09-02 01:13:41,376:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 42/1000
2022-09-02 01:13:42,008:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.2691, Train Acc: 56.1828,
                        Val Loss: 2.3631, Val Acc: 27.8937, Test Acc: 29.4679
2022-09-02 01:13:42,008:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 43/1000
2022-09-02 01:13:42,643:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2624, Train Acc: 56.5802,
                        Val Loss: 2.2372, Val Acc: 30.2906, Test Acc: 30.2958
2022-09-02 01:13:42,643:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 44/1000
2022-09-02 01:13:43,269:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 31.6122 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:43,269:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.2548, Train Acc: 56.8159,
                        Val Loss: 2.1850, Val Acc: 31.2331, Test Acc: 31.6122
2022-09-02 01:13:43,269:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 45/1000
2022-09-02 01:13:43,906:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2487, Train Acc: 56.6666,
                        Val Loss: 2.2173, Val Acc: 30.6851, Test Acc: 31.1451
2022-09-02 01:13:43,906:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 46/1000
2022-09-02 01:13:44,536:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.2404, Train Acc: 57.4211,
                        Val Loss: 2.2766, Val Acc: 30.3869, Test Acc: 30.8539
2022-09-02 01:13:44,536:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 47/1000
2022-09-02 01:13:45,176:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2337, Train Acc: 57.6916,
                        Val Loss: 2.2643, Val Acc: 30.6713, Test Acc: 30.9727
2022-09-02 01:13:45,176:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 48/1000
2022-09-02 01:13:45,813:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2257, Train Acc: 58.1296,
                        Val Loss: 2.2221, Val Acc: 32.3567, Test Acc: 31.5894
2022-09-02 01:13:45,813:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 49/1000
2022-09-02 01:13:46,453:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 31.7240 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:46,453:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2179, Train Acc: 58.5120,
                        Val Loss: 2.2355, Val Acc: 32.2590, Test Acc: 31.7240
2022-09-02 01:13:46,453:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 50/1000
2022-09-02 01:13:47,096:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2100, Train Acc: 59.3657,
                        Val Loss: 2.3039, Val Acc: 31.4077, Test Acc: 30.8129
2022-09-02 01:13:47,096:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 51/1000
2022-09-02 01:13:47,742:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2021, Train Acc: 60.0598,
                        Val Loss: 2.3434, Val Acc: 31.5623, Test Acc: 30.4003
2022-09-02 01:13:47,742:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 52/1000
2022-09-02 01:13:48,390:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00006, Train Loss: 1.1937, Train Acc: 60.7644,
                        Val Loss: 2.3302, Val Acc: 31.8774, Test Acc: 31.1026
2022-09-02 01:13:48,390:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 53/1000
2022-09-02 01:13:49,028:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.1895, Train Acc: 60.8644,
                        Val Loss: 2.3205, Val Acc: 32.1585, Test Acc: 30.7187
2022-09-02 01:13:49,028:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 54/1000
2022-09-02 01:13:49,655:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.1852, Train Acc: 60.5812,
                        Val Loss: 2.3232, Val Acc: 31.5357, Test Acc: 30.9140
2022-09-02 01:13:49,655:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 55/1000
2022-09-02 01:13:50,273:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.1812, Train Acc: 60.6875,
                        Val Loss: 2.3415, Val Acc: 31.0415, Test Acc: 31.0817
2022-09-02 01:13:50,273:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 56/1000
2022-09-02 01:13:50,909:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.1767, Train Acc: 61.0446,
                        Val Loss: 2.3672, Val Acc: 30.8624, Test Acc: 30.6730
2022-09-02 01:13:50,909:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 57/1000
2022-09-02 01:13:51,560:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00006, Train Loss: 1.1723, Train Acc: 61.2366,
                        Val Loss: 2.3837, Val Acc: 30.5684, Test Acc: 31.0707
2022-09-02 01:13:51,560:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 58/1000
2022-09-02 01:13:52,197:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.1681, Train Acc: 61.4841,
                        Val Loss: 2.3903, Val Acc: 30.2861, Test Acc: 31.0110
2022-09-02 01:13:52,197:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 59/1000
2022-09-02 01:13:52,821:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.1634, Train Acc: 61.7197,
                        Val Loss: 2.3917, Val Acc: 29.9240, Test Acc: 30.4748
2022-09-02 01:13:52,821:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 60/1000
2022-09-02 01:13:53,456:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.1590, Train Acc: 61.3897,
                        Val Loss: 2.4058, Val Acc: 29.8097, Test Acc: 31.0218
2022-09-02 01:13:53,457:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 61/1000
2022-09-02 01:13:54,082:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.1545, Train Acc: 61.5317,
                        Val Loss: 2.4349, Val Acc: 29.3902, Test Acc: 30.8180
2022-09-02 01:13:54,082:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 62/1000
2022-09-02 01:13:54,714:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.1498, Train Acc: 61.8911,
                        Val Loss: 2.4639, Val Acc: 29.1452, Test Acc: 30.8309
2022-09-02 01:13:54,715:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 63/1000
2022-09-02 01:13:55,337:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 31.8226 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:55,337:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.1453, Train Acc: 62.3782,
                        Val Loss: 2.4674, Val Acc: 28.9152, Test Acc: 31.8226
2022-09-02 01:13:55,337:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 64/1000
2022-09-02 01:13:55,980:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.3307 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:55,980:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.1429, Train Acc: 62.7018,
                        Val Loss: 2.4699, Val Acc: 28.4165, Test Acc: 32.3307
2022-09-02 01:13:55,980:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 65/1000
2022-09-02 01:13:56,617:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.1405, Train Acc: 62.9629,
                        Val Loss: 2.4754, Val Acc: 28.0469, Test Acc: 31.8914
2022-09-02 01:13:56,617:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 66/1000
2022-09-02 01:13:57,258:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.1382, Train Acc: 63.0780,
                        Val Loss: 2.4844, Val Acc: 28.0402, Test Acc: 32.3281
2022-09-02 01:13:57,258:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 67/1000
2022-09-02 01:13:57,886:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.4106 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:13:57,886:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.1359, Train Acc: 63.2454,
                        Val Loss: 2.4968, Val Acc: 27.7664, Test Acc: 32.4106
2022-09-02 01:13:57,886:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 68/1000
2022-09-02 01:13:58,531:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.1335, Train Acc: 63.3937,
                        Val Loss: 2.5107, Val Acc: 27.4893, Test Acc: 32.1889
2022-09-02 01:13:58,531:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 69/1000
2022-09-02 01:13:59,159:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.1311, Train Acc: 63.5492,
                        Val Loss: 2.5244, Val Acc: 27.6401, Test Acc: 32.0438
2022-09-02 01:13:59,159:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 70/1000
2022-09-02 01:13:59,774:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.1287, Train Acc: 63.2168,
                        Val Loss: 2.5355, Val Acc: 27.5319, Test Acc: 32.2690
2022-09-02 01:13:59,775:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 71/1000
2022-09-02 01:14:00,405:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.1263, Train Acc: 63.2367,
                        Val Loss: 2.5458, Val Acc: 27.4463, Test Acc: 32.3091
2022-09-02 01:14:00,406:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 72/1000
2022-09-02 01:14:01,030:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 32.4290 to out/SBMs_node_classification_b32-bnorm-alt-ngape3checkpoints/GraphTransformer_SBM_CLUSTER_GPU0_16_16_01h13m08s_on_Sep_02_2022/MODELS_
2022-09-02 01:14:01,031:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.1238, Train Acc: 63.2311,
                        Val Loss: 2.5579, Val Acc: 27.2830, Test Acc: 32.4290
2022-09-02 01:14:01,031:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 73/1000
2022-09-02 01:14:01,658:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.1214, Train Acc: 63.3866,
                        Val Loss: 2.5728, Val Acc: 27.1612, Test Acc: 32.4290
2022-09-02 01:14:01,658:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 74/1000
2022-09-02 01:14:02,283:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00002, Train Loss: 1.1189, Train Acc: 63.4818,
                        Val Loss: 2.5777, Val Acc: 27.1419, Test Acc: 32.1523
2022-09-02 01:14:02,283:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 75/1000
2022-09-02 01:14:02,910:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.1177, Train Acc: 63.4739,
                        Val Loss: 2.5827, Val Acc: 27.1272, Test Acc: 32.0487
2022-09-02 01:14:02,910:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 76/1000
2022-09-02 01:14:03,548:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1164, Train Acc: 63.6627,
                        Val Loss: 2.5875, Val Acc: 27.0139, Test Acc: 32.0487
2022-09-02 01:14:03,548:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 77/1000
2022-09-02 01:14:04,182:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.1152, Train Acc: 63.6627,
                        Val Loss: 2.5918, Val Acc: 26.9092, Test Acc: 32.2117
2022-09-02 01:14:04,183:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 78/1000
2022-09-02 01:14:04,789:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.1139, Train Acc: 63.7500,
                        Val Loss: 2.5955, Val Acc: 26.8747, Test Acc: 31.6260
2022-09-02 01:14:04,789:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 79/1000
2022-09-02 01:14:05,400:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.1126, Train Acc: 63.6429,
                        Val Loss: 2.5991, Val Acc: 26.7931, Test Acc: 31.8529
2022-09-02 01:14:05,400:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 80/1000
2022-09-02 01:14:06,025:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00002, Train Loss: 1.1114, Train Acc: 63.7301,
                        Val Loss: 2.6031, Val Acc: 26.6293, Test Acc: 31.7724
2022-09-02 01:14:06,025:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 81/1000
2022-09-02 01:14:06,692:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00002, Train Loss: 1.1101, Train Acc: 63.9046,
                        Val Loss: 2.6075, Val Acc: 26.6293, Test Acc: 31.5656
2022-09-02 01:14:06,693:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 82/1000
2022-09-02 01:14:07,349:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00002, Train Loss: 1.1089, Train Acc: 63.8238,
                        Val Loss: 2.6130, Val Acc: 26.4609, Test Acc: 31.5857
2022-09-02 01:14:07,349:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 83/1000
2022-09-02 01:14:07,984:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.1076, Train Acc: 63.8238,
                        Val Loss: 2.6195, Val Acc: 26.4609, Test Acc: 31.4820
2022-09-02 01:14:07,984:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 84/1000
2022-09-02 01:14:08,623:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.1063, Train Acc: 63.8238,
                        Val Loss: 2.6268, Val Acc: 26.5364, Test Acc: 31.4677
2022-09-02 01:14:08,623:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 85/1000
2022-09-02 01:14:09,242:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00001, Train Loss: 1.1051, Train Acc: 64.0514,
                        Val Loss: 2.6291, Val Acc: 26.4513, Test Acc: 31.4152
2022-09-02 01:14:09,242:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 86/1000
2022-09-02 01:14:09,859:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00001, Train Loss: 1.1044, Train Acc: 64.0442,
                        Val Loss: 2.6313, Val Acc: 26.3612, Test Acc: 31.2514
2022-09-02 01:14:09,859:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 87/1000
2022-09-02 01:14:10,478:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00001, Train Loss: 1.1038, Train Acc: 64.0442,
                        Val Loss: 2.6333, Val Acc: 26.2762, Test Acc: 31.1516
2022-09-02 01:14:10,478:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 88/1000
2022-09-02 01:14:11,111:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00001, Train Loss: 1.1031, Train Acc: 64.0442,
                        Val Loss: 2.6353, Val Acc: 26.1714, Test Acc: 31.1516
2022-09-02 01:14:11,111:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 89/1000
2022-09-02 01:14:11,722:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00001, Train Loss: 1.1025, Train Acc: 64.1244,
                        Val Loss: 2.6372, Val Acc: 25.9878, Test Acc: 31.1516
2022-09-02 01:14:11,722:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 90/1000
2022-09-02 01:14:12,361:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00001, Train Loss: 1.1019, Train Acc: 64.3069,
                        Val Loss: 2.6392, Val Acc: 25.9878, Test Acc: 31.1516
2022-09-02 01:14:12,361:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 91/1000
2022-09-02 01:14:13,015:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00001, Train Loss: 1.1012, Train Acc: 64.4743,
                        Val Loss: 2.6415, Val Acc: 25.8892, Test Acc: 31.0317
2022-09-02 01:14:13,015:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 92/1000
2022-09-02 01:14:13,653:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00001, Train Loss: 1.1006, Train Acc: 64.4005,
                        Val Loss: 2.6442, Val Acc: 25.7991, Test Acc: 31.0317
2022-09-02 01:14:13,653:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 93/1000
2022-09-02 01:14:13,847:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 01:14:13,847:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 12:15:47,049:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:15:51,769:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:15:51,769:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:15:51,777:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:15:51,796:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:15:51,797:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:15:51,797:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:15:51,809:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:15:51,811:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:15:51,812:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:15:51,814:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:15:51,814:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:15:51,814:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:15:52,067:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:15:52,068:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:17:29,325:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:17:33,597:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:17:33,597:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:17:33,599:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:17:33,601:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:17:33,601:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:17:33,601:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:17:33,606:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:17:33,607:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:17:33,608:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:17:33,610:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:17:33,610:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:17:33,610:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:17:33,871:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:17:33,871:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:20:03,278:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:20:07,302:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:20:07,302:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:20:07,303:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:20:07,306:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:20:07,306:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:20:07,306:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:20:07,310:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:20:07,311:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:20:07,312:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:20:07,315:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:20:07,315:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:20:07,315:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:20:07,571:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:20:07,571:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:20:27,922:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:20:32,012:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:20:32,012:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:20:32,014:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:20:32,016:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:20:32,016:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:20:32,016:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:20:32,021:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:20:32,022:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:20:32,024:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:20:32,028:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:20:32,028:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:20:32,028:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:20:32,289:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:20:32,289:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:20:47,034:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:20:51,066:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:20:51,067:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:20:51,068:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:20:51,070:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:20:51,070:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:20:51,070:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:20:51,074:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:20:51,075:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:20:51,077:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:20:51,078:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:20:51,078:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:20:51,079:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:20:51,324:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:20:51,324:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:21:26,400:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:21:30,431:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:21:30,431:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:21:30,433:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:21:30,435:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:21:30,435:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:21:30,435:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:21:30,440:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:21:30,441:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:21:30,443:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:21:30,445:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:21:30,445:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:21:30,445:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:21:30,744:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:21:30,744:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:22:07,012:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:22:10,917:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:22:10,917:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:22:10,919:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:22:10,921:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:22:10,921:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:22:10,921:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:22:10,925:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:22:10,926:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:22:10,928:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:22:10,929:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:22:10,929:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:22:10,929:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:22:11,171:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:22:11,172:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:22:45,161:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:22:49,128:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:22:49,128:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:22:49,129:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:22:49,131:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:22:49,131:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:22:49,131:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:22:49,136:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:22:49,137:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:22:49,138:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:22:49,141:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:22:49,141:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:22:49,141:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:22:49,407:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:22:49,407:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:23:18,667:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:23:22,712:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:23:22,712:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:23:22,713:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:23:22,715:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:23:22,715:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:23:22,715:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:23:22,720:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:23:22,721:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:23:22,722:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:23:22,723:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:23:22,723:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:23:22,723:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:23:23,006:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:23:23,006:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:23:43,669:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:23:47,754:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:23:47,754:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:23:47,756:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:23:47,758:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:23:47,758:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:23:47,758:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:23:47,763:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:23:47,764:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:23:47,765:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:23:47,767:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:23:47,767:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:23:47,767:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:23:48,012:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:23:48,012:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:24:08,309:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:24:12,234:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:24:12,234:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:24:12,235:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:24:12,237:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:24:12,237:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:24:12,237:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:24:12,242:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:24:12,243:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:24:12,244:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:24:12,246:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:24:12,246:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:24:12,246:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:24:12,494:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:24:12,495:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:24:44,718:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:24:48,822:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:24:48,822:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:24:48,823:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:24:48,825:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:24:48,826:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:24:48,826:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:24:48,831:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:24:48,832:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:24:48,833:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:24:48,835:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:24:48,836:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:24:48,836:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:24:49,105:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:24:49,105:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:24:49,771:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-02 12:25:52,936:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:25:56,848:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:25:56,848:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:25:56,850:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:25:56,851:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:25:56,851:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:25:56,851:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:25:56,856:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:25:56,857:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:25:56,858:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:25:56,860:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:25:56,860:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:25:56,860:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:25:57,111:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:25:57,111:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:25:57,749:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-02 12:26:31,827:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:26:35,950:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:26:35,950:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:26:35,951:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:26:35,953:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:26:35,953:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:26:35,953:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:26:35,958:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:26:35,959:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:26:35,960:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:26:35,962:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:26:35,962:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:26:35,962:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:26:36,223:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:26:36,223:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:26:36,869:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.901587963104248
2022-09-02 12:26:36,874:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:26:36,874:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:26:36,875:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:26:36,875:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:26:36,876:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:27:22,305:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:27:26,321:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:27:26,321:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:27:26,322:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:27:26,324:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:27:26,324:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:27:26,324:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:27:26,329:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:27:26,330:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:27:26,332:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:27:26,336:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:27:26,336:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:27:26,337:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:27:26,578:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:27:26,578:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:27:27,210:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.8669240474700928
2022-09-02 12:27:27,215:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:27:27,215:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:27:27,215:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:27:27,215:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:27:27,216:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:27:45,009:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:27:49,110:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:27:49,110:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:27:49,111:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:27:49,113:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:27:49,113:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:27:49,113:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:27:49,118:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:27:49,119:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:27:49,120:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:27:49,122:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:27:49,122:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:27:49,122:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:27:49,358:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:27:49,359:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:27:50,102:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.9744699001312256
2022-09-02 12:27:50,107:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:27:50,107:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:27:50,107:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:27:50,107:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:27:50,109:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:28:17,393:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:28:21,309:main_SBMs_node_classification.py:347 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:28:21,309:main_SBMs_node_classification.py:348 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:28:21,310:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:28:21,312:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:28:21,312:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:28:21,312:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:28:21,317:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:28:21,318:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:28:21,320:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:28:21,321:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:28:21,321:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:28:21,321:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:28:21,573:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:28:21,574:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:28:22,317:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.990440845489502
2022-09-02 12:28:22,321:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:28:22,321:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:28:22,321:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:28:22,321:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:28:22,322:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:29:07,630:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:29:11,647:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:29:11,647:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:29:11,649:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:29:11,650:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:29:11,650:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:29:11,651:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:29:11,655:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:29:11,656:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:29:11,658:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:29:11,661:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:29:11,661:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:29:11,661:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:29:11,901:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:29:11,901:main_SBMs_node_classification.py:94 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:29:12,555:main_SBMs_node_classification.py:101 -   train_val_pipeline(): Time PE:0.8881340026855469
2022-09-02 12:29:12,560:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:29:12,560:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:29:12,560:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:29:12,560:main_SBMs_node_classification.py:140 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:29:12,562:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:29:26,371:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:29:30,402:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:29:30,403:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:29:30,404:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:29:30,406:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:29:30,406:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:29:30,406:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:29:30,411:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:29:30,412:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:29:30,414:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:29:30,415:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:29:30,415:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:29:30,415:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:29:30,653:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:29:30,653:main_SBMs_node_classification.py:94 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:29:31,338:main_SBMs_node_classification.py:101 -   train_val_pipeline(): Time PE:0.916419267654419
2022-09-02 12:29:31,344:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:29:31,344:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:29:31,344:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:29:31,344:main_SBMs_node_classification.py:140 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:29:31,345:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:30:19,008:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:30:22,955:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:30:22,955:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:30:22,957:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:30:22,958:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:30:22,958:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:30:22,958:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:30:22,963:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:30:22,964:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:30:22,965:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:30:22,967:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:30:22,967:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:30:22,967:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:30:23,213:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:30:23,213:main_SBMs_node_classification.py:94 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:30:23,833:main_SBMs_node_classification.py:101 -   train_val_pipeline(): Time PE:0.8598160743713379
2022-09-02 12:30:23,838:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:30:23,838:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:30:23,838:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:30:23,838:main_SBMs_node_classification.py:140 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:30:23,841:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:30:45,774:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:30:49,901:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:30:49,901:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:30:49,902:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:30:49,904:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:30:49,904:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:30:49,904:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:30:49,910:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:30:49,911:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:30:49,912:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:30:49,914:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:30:49,914:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:30:49,914:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:30:50,200:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:30:50,200:main_SBMs_node_classification.py:94 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:30:51,054:main_SBMs_node_classification.py:101 -   train_val_pipeline(): Time PE:1.1335790157318115
2022-09-02 12:30:51,056:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:30:51,056:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:30:51,056:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:30:51,056:main_SBMs_node_classification.py:140 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:30:51,057:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:30:51,919:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 16.5809 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h30m49s_on_Sep_02_2022/MODELS_
2022-09-02 12:30:51,919:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.86s, LR: 0.00050, Train Loss: 1.7909, Train Acc: 16.0861,
                        Val Loss: 1.8436, Val Acc: 15.5364, Test Acc: 16.5809
2022-09-02 12:30:51,919:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 12:30:52,553:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7847, Train Acc: 19.5527,
                        Val Loss: 1.8029, Val Acc: 16.6669, Test Acc: 15.9278
2022-09-02 12:30:52,553:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 12:30:53,239:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 17.3973 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h30m49s_on_Sep_02_2022/MODELS_
2022-09-02 12:30:53,239:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.7809, Train Acc: 19.6789,
                        Val Loss: 1.7977, Val Acc: 16.2783, Test Acc: 17.3973
2022-09-02 12:30:53,239:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 12:30:53,932:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 17.8486 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h30m49s_on_Sep_02_2022/MODELS_
2022-09-02 12:30:53,932:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.7765, Train Acc: 19.5503,
                        Val Loss: 1.7959, Val Acc: 17.2105, Test Acc: 17.8486
2022-09-02 12:30:53,932:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 12:30:54,648:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.7736, Train Acc: 21.0880,
                        Val Loss: 1.7959, Val Acc: 16.3460, Test Acc: 16.9733
2022-09-02 12:30:54,648:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 12:30:55,309:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7705, Train Acc: 20.7970,
                        Val Loss: 1.7963, Val Acc: 15.9635, Test Acc: 16.9893
2022-09-02 12:30:55,309:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 7/1000
2022-09-02 12:30:55,979:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7680, Train Acc: 20.5335,
                        Val Loss: 1.7956, Val Acc: 16.1014, Test Acc: 17.5587
2022-09-02 12:30:55,979:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 8/1000
2022-09-02 12:30:56,601:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7662, Train Acc: 21.1809,
                        Val Loss: 1.7953, Val Acc: 15.9025, Test Acc: 17.3060
2022-09-02 12:30:56,601:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 9/1000
2022-09-02 12:30:57,230:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7619, Train Acc: 22.2486,
                        Val Loss: 1.7945, Val Acc: 16.4593, Test Acc: 17.5568
2022-09-02 12:30:57,230:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 10/1000
2022-09-02 12:30:57,852:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 18.2250 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h30m49s_on_Sep_02_2022/MODELS_
2022-09-02 12:30:57,852:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7587, Train Acc: 21.6393,
                        Val Loss: 1.7939, Val Acc: 16.8844, Test Acc: 18.2250
2022-09-02 12:30:57,852:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 11/1000
2022-09-02 12:30:58,473:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 18.2843 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h30m49s_on_Sep_02_2022/MODELS_
2022-09-02 12:30:58,474:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7553, Train Acc: 22.0398,
                        Val Loss: 1.7937, Val Acc: 16.4031, Test Acc: 18.2843
2022-09-02 12:30:58,474:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 12/1000
2022-09-02 12:30:59,089:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7510, Train Acc: 22.7377,
                        Val Loss: 1.7937, Val Acc: 16.3277, Test Acc: 18.0713
2022-09-02 12:30:59,089:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 13/1000
2022-09-02 12:30:59,735:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7471, Train Acc: 23.2383,
                        Val Loss: 1.7936, Val Acc: 16.5347, Test Acc: 17.2199
2022-09-02 12:30:59,736:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 14/1000
2022-09-02 12:31:00,376:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7433, Train Acc: 22.3016,
                        Val Loss: 1.7930, Val Acc: 16.7638, Test Acc: 17.7853
2022-09-02 12:31:00,376:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 15/1000
2022-09-02 12:31:01,015:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7398, Train Acc: 21.7117,
                        Val Loss: 1.7946, Val Acc: 16.3948, Test Acc: 16.6907
2022-09-02 12:31:01,015:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 16/1000
2022-09-02 12:31:01,670:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7375, Train Acc: 22.4883,
                        Val Loss: 1.7929, Val Acc: 16.9948, Test Acc: 17.8039
2022-09-02 12:31:01,670:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 17/1000
2022-09-02 12:31:02,306:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7376, Train Acc: 20.2069,
                        Val Loss: 1.7941, Val Acc: 16.9804, Test Acc: 16.6670
2022-09-02 12:31:02,306:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 18/1000
2022-09-02 12:31:02,965:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7294, Train Acc: 21.5002,
                        Val Loss: 1.7973, Val Acc: 16.5139, Test Acc: 15.7100
2022-09-02 12:31:02,965:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 19/1000
2022-09-02 12:31:03,622:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7294, Train Acc: 21.8256,
                        Val Loss: 1.7944, Val Acc: 16.5825, Test Acc: 16.0701
2022-09-02 12:31:03,622:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 20/1000
2022-09-02 12:31:04,293:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7231, Train Acc: 22.2517,
                        Val Loss: 1.7939, Val Acc: 16.7955, Test Acc: 17.7769
2022-09-02 12:31:04,293:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 21/1000
2022-09-02 12:31:04,931:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7212, Train Acc: 23.1417,
                        Val Loss: 1.7929, Val Acc: 16.7231, Test Acc: 17.2549
2022-09-02 12:31:04,931:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 22/1000
2022-09-02 12:31:05,586:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7175, Train Acc: 23.8914,
                        Val Loss: 1.7978, Val Acc: 16.7128, Test Acc: 16.3298
2022-09-02 12:31:05,586:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 23/1000
2022-09-02 12:31:06,239:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7182, Train Acc: 22.5785,
                        Val Loss: 1.7976, Val Acc: 16.9021, Test Acc: 16.6911
2022-09-02 12:31:06,239:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 24/1000
2022-09-02 12:31:06,895:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 19.3013 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h30m49s_on_Sep_02_2022/MODELS_
2022-09-02 12:31:06,895:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7102, Train Acc: 23.8316,
                        Val Loss: 1.7952, Val Acc: 18.2662, Test Acc: 19.3013
2022-09-02 12:31:06,895:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 25/1000
2022-09-02 12:31:07,535:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7085, Train Acc: 24.2034,
                        Val Loss: 1.8033, Val Acc: 16.3454, Test Acc: 16.4902
2022-09-02 12:31:07,535:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 26/1000
2022-09-02 12:31:08,187:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.7080, Train Acc: 24.7361,
                        Val Loss: 1.7991, Val Acc: 18.0976, Test Acc: 16.1864
2022-09-02 12:31:08,187:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 27/1000
2022-09-02 12:31:08,835:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.7002, Train Acc: 24.0803,
                        Val Loss: 1.7954, Val Acc: 18.3512, Test Acc: 18.8542
2022-09-02 12:31:08,835:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 28/1000
2022-09-02 12:31:09,481:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.6987, Train Acc: 24.6293,
                        Val Loss: 1.7966, Val Acc: 17.1765, Test Acc: 17.4258
2022-09-02 12:31:09,481:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 29/1000
2022-09-02 12:31:10,120:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.6955, Train Acc: 24.8523,
                        Val Loss: 1.7997, Val Acc: 16.6678, Test Acc: 17.0062
2022-09-02 12:31:10,120:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 30/1000
2022-09-02 12:31:10,775:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.6928, Train Acc: 24.6846,
                        Val Loss: 1.7976, Val Acc: 16.7159, Test Acc: 16.9181
2022-09-02 12:31:10,775:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 31/1000
2022-09-02 12:31:11,434:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 19.9267 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h30m49s_on_Sep_02_2022/MODELS_
2022-09-02 12:31:11,434:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.6895, Train Acc: 25.2889,
                        Val Loss: 1.7935, Val Acc: 17.7733, Test Acc: 19.9267
2022-09-02 12:31:11,434:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 32/1000
2022-09-02 12:31:12,076:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.6871, Train Acc: 26.2576,
                        Val Loss: 1.7936, Val Acc: 16.1059, Test Acc: 16.7709
2022-09-02 12:31:12,076:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 33/1000
2022-09-02 12:31:12,717:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.6821, Train Acc: 26.0825,
                        Val Loss: 1.7996, Val Acc: 15.5937, Test Acc: 14.7255
2022-09-02 12:31:12,717:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 34/1000
2022-09-02 12:31:13,360:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.6803, Train Acc: 26.4586,
                        Val Loss: 1.7972, Val Acc: 16.4895, Test Acc: 16.8939
2022-09-02 12:31:13,360:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 35/1000
2022-09-02 12:31:14,011:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.6747, Train Acc: 26.2334,
                        Val Loss: 1.7983, Val Acc: 16.6886, Test Acc: 17.2787
2022-09-02 12:31:14,011:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 36/1000
2022-09-02 12:31:14,642:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.6711, Train Acc: 26.4008,
                        Val Loss: 1.8035, Val Acc: 16.7432, Test Acc: 16.9830
2022-09-02 12:31:14,642:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 37/1000
2022-09-02 12:31:15,305:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00013, Train Loss: 1.6684, Train Acc: 27.5621,
                        Val Loss: 1.8008, Val Acc: 17.9033, Test Acc: 16.8219
2022-09-02 12:31:15,305:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 38/1000
2022-09-02 12:31:15,944:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.6650, Train Acc: 27.4582,
                        Val Loss: 1.8021, Val Acc: 17.5070, Test Acc: 16.4324
2022-09-02 12:31:15,944:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 39/1000
2022-09-02 12:31:16,576:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.6631, Train Acc: 27.1615,
                        Val Loss: 1.8085, Val Acc: 16.6888, Test Acc: 16.8658
2022-09-02 12:31:16,576:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 40/1000
2022-09-02 12:31:17,197:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.6610, Train Acc: 28.1572,
                        Val Loss: 1.8058, Val Acc: 16.7755, Test Acc: 16.8357
2022-09-02 12:31:17,197:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 41/1000
2022-09-02 12:31:17,843:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.6575, Train Acc: 28.1572,
                        Val Loss: 1.8008, Val Acc: 18.0734, Test Acc: 18.2144
2022-09-02 12:31:17,843:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 42/1000
2022-09-02 12:31:18,482:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.6570, Train Acc: 27.7929,
                        Val Loss: 1.8066, Val Acc: 16.2555, Test Acc: 16.4910
2022-09-02 12:31:18,482:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 43/1000
2022-09-02 12:31:19,123:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.6538, Train Acc: 28.5182,
                        Val Loss: 1.8078, Val Acc: 15.9754, Test Acc: 16.4937
2022-09-02 12:31:19,124:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 44/1000
2022-09-02 12:31:19,762:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.6514, Train Acc: 28.6514,
                        Val Loss: 1.8041, Val Acc: 16.9891, Test Acc: 16.5589
2022-09-02 12:31:19,762:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 45/1000
2022-09-02 12:31:20,405:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.6499, Train Acc: 28.5815,
                        Val Loss: 1.8083, Val Acc: 16.2673, Test Acc: 16.3520
2022-09-02 12:31:20,405:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 46/1000
2022-09-02 12:31:21,032:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.6469, Train Acc: 29.4361,
                        Val Loss: 1.8094, Val Acc: 16.2577, Test Acc: 16.1478
2022-09-02 12:31:21,032:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 47/1000
2022-09-02 12:31:21,653:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.6449, Train Acc: 29.3830,
                        Val Loss: 1.8044, Val Acc: 17.7579, Test Acc: 16.8460
2022-09-02 12:31:21,653:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 48/1000
2022-09-02 12:31:22,283:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.6433, Train Acc: 29.0274,
                        Val Loss: 1.8081, Val Acc: 16.4049, Test Acc: 15.9284
2022-09-02 12:31:22,283:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 49/1000
2022-09-02 12:31:22,913:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.6410, Train Acc: 29.5433,
                        Val Loss: 1.8105, Val Acc: 16.2573, Test Acc: 16.0693
2022-09-02 12:31:22,913:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 50/1000
2022-09-02 12:31:23,537:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.6407, Train Acc: 30.0860,
                        Val Loss: 1.8075, Val Acc: 16.3469, Test Acc: 16.0692
2022-09-02 12:31:23,537:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 51/1000
2022-09-02 12:31:24,181:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.6387, Train Acc: 30.0860,
                        Val Loss: 1.8031, Val Acc: 16.8903, Test Acc: 16.9029
2022-09-02 12:31:24,181:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 52/1000
2022-09-02 12:31:24,821:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.6383, Train Acc: 29.6907,
                        Val Loss: 1.8052, Val Acc: 16.7082, Test Acc: 16.4739
2022-09-02 12:31:24,821:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 53/1000
2022-09-02 12:31:25,489:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00006, Train Loss: 1.6364, Train Acc: 29.8780,
                        Val Loss: 1.8095, Val Acc: 15.7072, Test Acc: 16.0445
2022-09-02 12:31:25,489:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 54/1000
2022-09-02 12:31:26,137:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00006, Train Loss: 1.6358, Train Acc: 30.5024,
                        Val Loss: 1.8082, Val Acc: 15.8539, Test Acc: 17.1428
2022-09-02 12:31:26,137:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 55/1000
2022-09-02 12:31:26,757:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.6340, Train Acc: 30.5913,
                        Val Loss: 1.8047, Val Acc: 16.2882, Test Acc: 18.0341
2022-09-02 12:31:26,757:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 56/1000
2022-09-02 12:31:27,414:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00006, Train Loss: 1.6331, Train Acc: 30.3984,
                        Val Loss: 1.8071, Val Acc: 15.7965, Test Acc: 18.2101
2022-09-02 12:31:27,414:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 57/1000
2022-09-02 12:31:28,038:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.6315, Train Acc: 30.4318,
                        Val Loss: 1.8108, Val Acc: 15.9607, Test Acc: 18.5979
2022-09-02 12:31:28,039:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 58/1000
2022-09-02 12:31:28,679:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.6305, Train Acc: 30.8714,
                        Val Loss: 1.8088, Val Acc: 15.8503, Test Acc: 17.7597
2022-09-02 12:31:28,679:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 59/1000
2022-09-02 12:31:29,325:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.6290, Train Acc: 30.9094,
                        Val Loss: 1.8082, Val Acc: 15.5862, Test Acc: 17.7869
2022-09-02 12:31:29,325:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 60/1000
2022-09-02 12:31:29,971:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.6283, Train Acc: 30.4231,
                        Val Loss: 1.8093, Val Acc: 15.7227, Test Acc: 17.9426
2022-09-02 12:31:29,971:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 61/1000
2022-09-02 12:31:30,605:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.6276, Train Acc: 31.0356,
                        Val Loss: 1.8117, Val Acc: 15.7928, Test Acc: 18.1263
2022-09-02 12:31:30,605:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 62/1000
2022-09-02 12:31:31,250:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.6270, Train Acc: 30.9619,
                        Val Loss: 1.8131, Val Acc: 15.9293, Test Acc: 18.8548
2022-09-02 12:31:31,250:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 63/1000
2022-09-02 12:31:31,889:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.6263, Train Acc: 30.7478,
                        Val Loss: 1.8120, Val Acc: 15.7406, Test Acc: 18.4719
2022-09-02 12:31:31,889:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 64/1000
2022-09-02 12:31:32,509:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.6255, Train Acc: 30.9937,
                        Val Loss: 1.8101, Val Acc: 15.3875, Test Acc: 18.0047
2022-09-02 12:31:32,510:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 65/1000
2022-09-02 12:31:33,164:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00003, Train Loss: 1.6249, Train Acc: 31.3014,
                        Val Loss: 1.8094, Val Acc: 15.2844, Test Acc: 18.3726
2022-09-02 12:31:33,164:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 66/1000
2022-09-02 12:31:33,791:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.6243, Train Acc: 31.3624,
                        Val Loss: 1.8113, Val Acc: 15.5926, Test Acc: 18.3547
2022-09-02 12:31:33,791:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 67/1000
2022-09-02 12:31:34,421:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.6235, Train Acc: 31.3887,
                        Val Loss: 1.8136, Val Acc: 15.5871, Test Acc: 19.2756
2022-09-02 12:31:34,421:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 68/1000
2022-09-02 12:31:35,056:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.6229, Train Acc: 31.2967,
                        Val Loss: 1.8144, Val Acc: 15.5168, Test Acc: 19.3754
2022-09-02 12:31:35,056:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 69/1000
2022-09-02 12:31:35,688:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.6222, Train Acc: 31.5744,
                        Val Loss: 1.8138, Val Acc: 15.3582, Test Acc: 18.6069
2022-09-02 12:31:35,688:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 70/1000
2022-09-02 12:31:36,187:main_SBMs_node_classification.py:247 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 12:31:36,187:main_SBMs_node_classification.py:248 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 12:31:38,639:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:31:42,794:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': True, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:31:42,794:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:31:42,796:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:31:42,798:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:31:42,798:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:31:42,798:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:31:42,803:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:31:42,804:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:31:42,805:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:31:42,807:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:31:42,807:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:31:42,807:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:31:43,050:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:31:43,051:main_SBMs_node_classification.py:94 -   train_val_pipeline(): [!] Stacking automata PEs
2022-09-02 12:31:43,668:main_SBMs_node_classification.py:101 -   train_val_pipeline(): Time PE:0.8547420501708984
2022-09-02 12:31:43,672:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:31:43,672:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:31:43,672:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:31:43,672:main_SBMs_node_classification.py:140 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:31:43,673:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:31:44,491:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 19.1342 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h31m42s_on_Sep_02_2022/MODELS_
2022-09-02 12:31:44,491:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.82s, LR: 0.00050, Train Loss: 1.7994, Train Acc: 17.6110,
                        Val Loss: 1.7988, Val Acc: 16.4565, Test Acc: 19.1342
2022-09-02 12:31:44,491:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 12:31:45,130:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 19.2612 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h31m42s_on_Sep_02_2022/MODELS_
2022-09-02 12:31:45,130:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7931, Train Acc: 19.3266,
                        Val Loss: 1.7913, Val Acc: 15.4970, Test Acc: 19.2612
2022-09-02 12:31:45,130:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 12:31:45,830:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.7889, Train Acc: 20.2000,
                        Val Loss: 1.7922, Val Acc: 15.7224, Test Acc: 17.0560
2022-09-02 12:31:45,830:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 12:31:46,536:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00050, Train Loss: 1.7866, Train Acc: 20.0168,
                        Val Loss: 1.7926, Val Acc: 17.3446, Test Acc: 16.1538
2022-09-02 12:31:46,536:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 12:31:47,202:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7829, Train Acc: 20.0594,
                        Val Loss: 1.7938, Val Acc: 16.9845, Test Acc: 18.6496
2022-09-02 12:31:47,202:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 12:31:47,844:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7807, Train Acc: 19.8640,
                        Val Loss: 1.7945, Val Acc: 17.1034, Test Acc: 19.2389
2022-09-02 12:31:47,844:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 7/1000
2022-09-02 12:31:48,461:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7787, Train Acc: 20.0010,
                        Val Loss: 1.7950, Val Acc: 17.4477, Test Acc: 18.3483
2022-09-02 12:31:48,461:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 8/1000
2022-09-02 12:31:49,107:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7769, Train Acc: 19.4545,
                        Val Loss: 1.7955, Val Acc: 17.1893, Test Acc: 18.0939
2022-09-02 12:31:49,107:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 9/1000
2022-09-02 12:31:49,751:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7743, Train Acc: 19.3376,
                        Val Loss: 1.7955, Val Acc: 17.5623, Test Acc: 18.1793
2022-09-02 12:31:49,751:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 10/1000
2022-09-02 12:31:50,385:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7718, Train Acc: 19.1352,
                        Val Loss: 1.7957, Val Acc: 17.0784, Test Acc: 18.0757
2022-09-02 12:31:50,385:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 11/1000
2022-09-02 12:31:51,036:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.7695, Train Acc: 20.1298,
                        Val Loss: 1.7962, Val Acc: 16.9716, Test Acc: 18.0407
2022-09-02 12:31:51,036:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 12/1000
2022-09-02 12:31:51,670:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7674, Train Acc: 20.3524,
                        Val Loss: 1.7958, Val Acc: 16.3116, Test Acc: 17.8154
2022-09-02 12:31:51,670:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 13/1000
2022-09-02 12:31:52,293:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7648, Train Acc: 20.3833,
                        Val Loss: 1.7951, Val Acc: 15.6076, Test Acc: 17.9605
2022-09-02 12:31:52,293:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 14/1000
2022-09-02 12:31:52,933:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.7621, Train Acc: 20.6437,
                        Val Loss: 1.7965, Val Acc: 15.6683, Test Acc: 17.0200
2022-09-02 12:31:52,933:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 15/1000
2022-09-02 12:31:53,578:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.7607, Train Acc: 21.1059,
                        Val Loss: 1.7967, Val Acc: 15.7018, Test Acc: 16.5790
2022-09-02 12:31:53,578:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 16/1000
2022-09-02 12:31:54,227:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.7589, Train Acc: 21.2016,
                        Val Loss: 1.7961, Val Acc: 15.3964, Test Acc: 16.0253
2022-09-02 12:31:54,227:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 17/1000
2022-09-02 12:31:54,867:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.7579, Train Acc: 22.0427,
                        Val Loss: 1.7990, Val Acc: 15.5530, Test Acc: 16.7499
2022-09-02 12:31:54,867:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 18/1000
2022-09-02 12:31:55,516:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.7563, Train Acc: 22.2840,
                        Val Loss: 1.8005, Val Acc: 15.3442, Test Acc: 16.9345
2022-09-02 12:31:55,516:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 19/1000
2022-09-02 12:31:56,183:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.7541, Train Acc: 22.3773,
                        Val Loss: 1.7995, Val Acc: 15.6235, Test Acc: 16.7227
2022-09-02 12:31:56,183:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 20/1000
2022-09-02 12:31:56,840:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.7529, Train Acc: 22.9269,
                        Val Loss: 1.7963, Val Acc: 15.7820, Test Acc: 16.7117
2022-09-02 12:31:56,840:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 21/1000
2022-09-02 12:31:57,492:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.7509, Train Acc: 22.9594,
                        Val Loss: 1.7969, Val Acc: 15.8664, Test Acc: 16.4759
2022-09-02 12:31:57,492:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 22/1000
2022-09-02 12:31:57,658:main_SBMs_node_classification.py:247 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 12:31:57,658:main_SBMs_node_classification.py:248 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 12:32:03,619:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:32:07,756:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:32:07,756:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:32:07,758:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:32:07,760:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:32:07,760:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:32:07,760:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:32:07,765:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:32:07,766:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:32:07,767:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:32:07,768:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:32:07,768:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:32:07,768:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:32:07,997:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:32:51,635:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:32:55,709:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': False, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:32:55,709:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:32:55,711:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:32:55,713:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:32:55,713:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:32:55,713:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:32:55,717:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:32:55,718:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:32:55,720:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:32:55,721:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:32:55,721:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:32:55,721:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:32:55,960:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:32:55,960:main_SBMs_node_classification.py:97 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-02 12:33:22,426:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:33:26,512:main_SBMs_node_classification.py:348 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'gape_stack_automata': False, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:33:26,512:main_SBMs_node_classification.py:349 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-02 12:33:26,513:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:33:26,515:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:33:26,515:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:33:26,515:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:33:26,520:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:33:26,521:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 531235
2022-09-02 12:33:26,522:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:33:26,524:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:33:26,524:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:33:26,524:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:33:26,809:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-02 12:33:26,809:main_SBMs_node_classification.py:97 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-02 12:33:30,578:main_SBMs_node_classification.py:101 -   train_val_pipeline(): Time PE:4.048837184906006
2022-09-02 12:33:30,580:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 12:33:30,580:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 12:33:30,580:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 12:33:30,580:main_SBMs_node_classification.py:140 -   train_val_pipeline(): Number of Classes: 6
2022-09-02 12:33:30,582:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 12:33:31,263:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 16.7910 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:31,263:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.8081, Train Acc: 16.6297,
                        Val Loss: 1.8537, Val Acc: 16.8796, Test Acc: 16.7910
2022-09-02 12:33:31,264:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 12:33:31,919:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 17.1642 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:31,919:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7898, Train Acc: 17.3466,
                        Val Loss: 1.8478, Val Acc: 17.1516, Test Acc: 17.1642
2022-09-02 12:33:31,919:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 12:33:32,623:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 17.7816 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:32,623:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.7760, Train Acc: 18.9683,
                        Val Loss: 1.8396, Val Acc: 17.6364, Test Acc: 17.7816
2022-09-02 12:33:32,623:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 12:33:33,284:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 19.1854 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:33,284:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7651, Train Acc: 20.5862,
                        Val Loss: 1.8281, Val Acc: 18.9944, Test Acc: 19.1854
2022-09-02 12:33:33,284:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 12:33:33,972:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 20.4405 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:33,972:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.7552, Train Acc: 21.5247,
                        Val Loss: 1.8289, Val Acc: 19.3844, Test Acc: 20.4405
2022-09-02 12:33:33,972:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 12:33:34,603:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 20.6602 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:34,603:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7457, Train Acc: 22.0393,
                        Val Loss: 1.8290, Val Acc: 20.0323, Test Acc: 20.6602
2022-09-02 12:33:34,603:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 7/1000
2022-09-02 12:33:35,223:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 20.9013 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:35,223:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7359, Train Acc: 23.8343,
                        Val Loss: 1.8315, Val Acc: 20.1973, Test Acc: 20.9013
2022-09-02 12:33:35,223:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 8/1000
2022-09-02 12:33:35,830:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 20.9402 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:35,830:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.7259, Train Acc: 25.2389,
                        Val Loss: 1.8385, Val Acc: 20.0222, Test Acc: 20.9402
2022-09-02 12:33:35,830:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 9/1000
2022-09-02 12:33:36,438:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 21.1035 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:36,438:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.7166, Train Acc: 27.1909,
                        Val Loss: 1.8435, Val Acc: 20.1072, Test Acc: 21.1035
2022-09-02 12:33:36,438:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 10/1000
2022-09-02 12:33:37,043:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 21.9034 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:37,043:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.7077, Train Acc: 27.4875,
                        Val Loss: 1.8481, Val Acc: 20.0120, Test Acc: 21.9034
2022-09-02 12:33:37,043:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 11/1000
2022-09-02 12:33:37,658:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 22.0591 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:37,658:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00050, Train Loss: 1.6989, Train Acc: 28.2678,
                        Val Loss: 1.8527, Val Acc: 20.1771, Test Acc: 22.0591
2022-09-02 12:33:37,658:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 12/1000
2022-09-02 12:33:38,290:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 22.9445 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:38,290:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6904, Train Acc: 29.3394,
                        Val Loss: 1.8594, Val Acc: 20.2570, Test Acc: 22.9445
2022-09-02 12:33:38,290:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 13/1000
2022-09-02 12:33:38,918:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.6822, Train Acc: 30.7065,
                        Val Loss: 1.8663, Val Acc: 20.6423, Test Acc: 22.7824
2022-09-02 12:33:38,918:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 14/1000
2022-09-02 12:33:39,555:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 23.3112 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:39,555:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6729, Train Acc: 31.8380,
                        Val Loss: 1.8713, Val Acc: 20.9521, Test Acc: 23.3112
2022-09-02 12:33:39,555:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 15/1000
2022-09-02 12:33:40,194:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 24.0256 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:40,194:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6635, Train Acc: 32.7819,
                        Val Loss: 1.8650, Val Acc: 21.3417, Test Acc: 24.0256
2022-09-02 12:33:40,194:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 16/1000
2022-09-02 12:33:40,824:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 24.4746 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:40,824:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.6550, Train Acc: 33.5638,
                        Val Loss: 1.8636, Val Acc: 21.9931, Test Acc: 24.4746
2022-09-02 12:33:40,824:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 17/1000
2022-09-02 12:33:41,452:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 24.5732 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:41,452:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.6498, Train Acc: 34.1487,
                        Val Loss: 1.8656, Val Acc: 22.3918, Test Acc: 24.5732
2022-09-02 12:33:41,452:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 18/1000
2022-09-02 12:33:42,087:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 25.1646 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:42,087:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.6451, Train Acc: 34.1185,
                        Val Loss: 1.8656, Val Acc: 23.0269, Test Acc: 25.1646
2022-09-02 12:33:42,087:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 19/1000
2022-09-02 12:33:42,726:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 25.6423 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:42,726:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.6402, Train Acc: 34.5546,
                        Val Loss: 1.8734, Val Acc: 23.4993, Test Acc: 25.6423
2022-09-02 12:33:42,726:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 20/1000
2022-09-02 12:33:43,362:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.6349, Train Acc: 35.1828,
                        Val Loss: 1.8895, Val Acc: 23.9691, Test Acc: 25.1070
2022-09-02 12:33:43,362:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 21/1000
2022-09-02 12:33:43,988:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.6298, Train Acc: 36.0089,
                        Val Loss: 1.9040, Val Acc: 24.8994, Test Acc: 25.0929
2022-09-02 12:33:43,988:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 22/1000
2022-09-02 12:33:44,628:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.6242, Train Acc: 36.8171,
                        Val Loss: 1.9201, Val Acc: 24.7893, Test Acc: 25.0470
2022-09-02 12:33:44,628:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 23/1000
2022-09-02 12:33:45,244:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.6189, Train Acc: 37.6983,
                        Val Loss: 1.9284, Val Acc: 24.3919, Test Acc: 25.1784
2022-09-02 12:33:45,244:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 24/1000
2022-09-02 12:33:45,861:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.6130, Train Acc: 38.9448,
                        Val Loss: 1.9436, Val Acc: 24.4344, Test Acc: 25.5680
2022-09-02 12:33:45,861:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 25/1000
2022-09-02 12:33:46,490:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 25.7285 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:46,490:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.6073, Train Acc: 40.2214,
                        Val Loss: 1.9646, Val Acc: 23.9948, Test Acc: 25.7285
2022-09-02 12:33:46,490:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 26/1000
2022-09-02 12:33:47,118:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 26.2038 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:47,118:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.6015, Train Acc: 40.9914,
                        Val Loss: 1.9783, Val Acc: 23.0485, Test Acc: 26.2038
2022-09-02 12:33:47,118:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 27/1000
2022-09-02 12:33:47,749:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 26.5520 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:47,749:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.5952, Train Acc: 41.3105,
                        Val Loss: 1.9845, Val Acc: 23.3751, Test Acc: 26.5520
2022-09-02 12:33:47,749:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 28/1000
2022-09-02 12:33:48,376:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 26.6609 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:48,376:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.5921, Train Acc: 41.3105,
                        Val Loss: 1.9964, Val Acc: 23.8156, Test Acc: 26.6609
2022-09-02 12:33:48,376:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 29/1000
2022-09-02 12:33:48,999:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 27.1010 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:48,999:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.5889, Train Acc: 41.7302,
                        Val Loss: 1.9993, Val Acc: 24.1474, Test Acc: 27.1010
2022-09-02 12:33:48,999:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 30/1000
2022-09-02 12:33:49,622:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 27.3918 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:49,622:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.5855, Train Acc: 41.9127,
                        Val Loss: 2.0090, Val Acc: 24.4706, Test Acc: 27.3918
2022-09-02 12:33:49,622:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 31/1000
2022-09-02 12:33:50,257:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 27.6129 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:50,257:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.5821, Train Acc: 41.9182,
                        Val Loss: 2.0223, Val Acc: 24.7496, Test Acc: 27.6129
2022-09-02 12:33:50,257:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 32/1000
2022-09-02 12:33:50,899:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 28.4402 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:50,899:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.5786, Train Acc: 42.1371,
                        Val Loss: 2.0284, Val Acc: 24.5746, Test Acc: 28.4402
2022-09-02 12:33:50,899:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 33/1000
2022-09-02 12:33:51,529:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 28.5011 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:51,529:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.5751, Train Acc: 42.3353,
                        Val Loss: 2.0328, Val Acc: 25.1580, Test Acc: 28.5011
2022-09-02 12:33:51,529:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 34/1000
2022-09-02 12:33:52,165:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 28.7307 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:52,165:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.5713, Train Acc: 42.7250,
                        Val Loss: 2.0432, Val Acc: 25.3985, Test Acc: 28.7307
2022-09-02 12:33:52,165:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 35/1000
2022-09-02 12:33:52,793:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 29.0197 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:52,793:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.5676, Train Acc: 42.7987,
                        Val Loss: 2.0513, Val Acc: 25.5618, Test Acc: 29.0197
2022-09-02 12:33:52,793:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 36/1000
2022-09-02 12:33:53,428:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 29.2595 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:53,428:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.5638, Train Acc: 42.9366,
                        Val Loss: 2.0588, Val Acc: 25.8681, Test Acc: 29.2595
2022-09-02 12:33:53,428:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 37/1000
2022-09-02 12:33:54,044:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.5600, Train Acc: 43.1311,
                        Val Loss: 2.0721, Val Acc: 26.0185, Test Acc: 28.9214
2022-09-02 12:33:54,044:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 38/1000
2022-09-02 12:33:54,678:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 29.6509 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:54,678:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.5562, Train Acc: 43.5918,
                        Val Loss: 2.0756, Val Acc: 26.3093, Test Acc: 29.6509
2022-09-02 12:33:54,678:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 39/1000
2022-09-02 12:33:55,305:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 30.4572 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:55,305:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.5541, Train Acc: 43.5101,
                        Val Loss: 2.0835, Val Acc: 26.9512, Test Acc: 30.4572
2022-09-02 12:33:55,305:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 40/1000
2022-09-02 12:33:55,937:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.5522, Train Acc: 43.3769,
                        Val Loss: 2.0858, Val Acc: 27.4681, Test Acc: 30.2222
2022-09-02 12:33:55,937:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 41/1000
2022-09-02 12:33:56,554:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.5500, Train Acc: 43.6974,
                        Val Loss: 2.0865, Val Acc: 28.2655, Test Acc: 30.1307
2022-09-02 12:33:56,554:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 42/1000
2022-09-02 12:33:57,174:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.5480, Train Acc: 43.8441,
                        Val Loss: 2.0960, Val Acc: 28.4102, Test Acc: 30.3428
2022-09-02 12:33:57,174:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 43/1000
2022-09-02 12:33:57,800:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00006, Train Loss: 1.5458, Train Acc: 44.0330,
                        Val Loss: 2.1049, Val Acc: 28.8404, Test Acc: 30.4018
2022-09-02 12:33:57,800:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 44/1000
2022-09-02 12:33:58,421:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.5438, Train Acc: 44.2956,
                        Val Loss: 2.1088, Val Acc: 29.3590, Test Acc: 30.3145
2022-09-02 12:33:58,421:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 45/1000
2022-09-02 12:33:59,044:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.5416, Train Acc: 44.2630,
                        Val Loss: 2.1120, Val Acc: 29.5949, Test Acc: 30.3352
2022-09-02 12:33:59,044:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 46/1000
2022-09-02 12:33:59,681:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 30.5795 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:33:59,681:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.5395, Train Acc: 44.7977,
                        Val Loss: 2.1122, Val Acc: 29.8268, Test Acc: 30.5795
2022-09-02 12:33:59,681:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 47/1000
2022-09-02 12:34:00,317:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 30.6650 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:34:00,317:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00006, Train Loss: 1.5373, Train Acc: 45.0271,
                        Val Loss: 2.1134, Val Acc: 30.1273, Test Acc: 30.6650
2022-09-02 12:34:00,317:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 48/1000
2022-09-02 12:34:00,941:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 30.9599 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:34:00,941:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00006, Train Loss: 1.5351, Train Acc: 45.0271,
                        Val Loss: 2.1311, Val Acc: 29.9963, Test Acc: 30.9599
2022-09-02 12:34:00,941:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 49/1000
2022-09-02 12:34:01,576:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 31.4995 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:34:01,576:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.5329, Train Acc: 45.2865,
                        Val Loss: 2.1305, Val Acc: 30.4728, Test Acc: 31.4995
2022-09-02 12:34:01,576:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 50/1000
2022-09-02 12:34:02,202:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 31.6195 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:34:02,202:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.5317, Train Acc: 45.3602,
                        Val Loss: 2.1340, Val Acc: 30.5561, Test Acc: 31.6195
2022-09-02 12:34:02,202:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 51/1000
2022-09-02 12:34:02,839:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 31.8159 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:34:02,839:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.5306, Train Acc: 45.6427,
                        Val Loss: 2.1353, Val Acc: 30.3911, Test Acc: 31.8159
2022-09-02 12:34:02,839:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 52/1000
2022-09-02 12:34:03,461:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 32.0038 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:34:03,461:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.5295, Train Acc: 45.5324,
                        Val Loss: 2.1322, Val Acc: 30.9947, Test Acc: 32.0038
2022-09-02 12:34:03,461:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 53/1000
2022-09-02 12:34:04,101:main_SBMs_node_classification.py:194 -   train_val_pipeline(): Saving best model with test accuracy: 32.1573 to out/SBMs_node_classification_b32-bnorm-alt-ngape8-lincombcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_8_8_12h33m26s_on_Sep_02_2022/MODELS_
2022-09-02 12:34:04,101:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00003, Train Loss: 1.5283, Train Acc: 45.6862,
                        Val Loss: 2.1319, Val Acc: 31.1001, Test Acc: 32.1573
2022-09-02 12:34:04,101:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 54/1000
2022-09-02 12:34:04,713:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00003, Train Loss: 1.5272, Train Acc: 45.8584,
                        Val Loss: 2.1308, Val Acc: 31.5501, Test Acc: 32.1528
2022-09-02 12:34:04,713:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 55/1000
2022-09-02 12:34:05,336:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.5260, Train Acc: 46.1258,
                        Val Loss: 2.1187, Val Acc: 31.5614, Test Acc: 32.0240
2022-09-02 12:34:05,336:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 56/1000
2022-09-02 12:34:05,958:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00003, Train Loss: 1.5249, Train Acc: 46.2948,
                        Val Loss: 2.1228, Val Acc: 31.6543, Test Acc: 32.0705
2022-09-02 12:34:05,958:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 57/1000
2022-09-02 12:34:06,568:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00003, Train Loss: 1.5237, Train Acc: 46.3820,
                        Val Loss: 2.1245, Val Acc: 31.8430, Test Acc: 32.1560
2022-09-02 12:34:06,568:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 58/1000
2022-09-02 12:34:07,182:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00003, Train Loss: 1.5225, Train Acc: 46.5565,
                        Val Loss: 2.1225, Val Acc: 31.8498, Test Acc: 31.9390
2022-09-02 12:34:07,182:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 59/1000
2022-09-02 12:34:07,808:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00003, Train Loss: 1.5213, Train Acc: 46.4693,
                        Val Loss: 2.1166, Val Acc: 31.7444, Test Acc: 32.0200
2022-09-02 12:34:07,808:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 60/1000
2022-09-02 12:34:08,428:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00002, Train Loss: 1.5202, Train Acc: 46.2939,
                        Val Loss: 2.1189, Val Acc: 31.6577, Test Acc: 31.9766
2022-09-02 12:34:08,428:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 61/1000
2022-09-02 12:34:09,062:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00002, Train Loss: 1.5196, Train Acc: 46.3677,
                        Val Loss: 2.1145, Val Acc: 31.8277, Test Acc: 31.8178
2022-09-02 12:34:09,062:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 62/1000
2022-09-02 12:34:09,707:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00002, Train Loss: 1.5190, Train Acc: 46.3677,
                        Val Loss: 2.1093, Val Acc: 31.7658, Test Acc: 31.9033
2022-09-02 12:34:09,707:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 63/1000
2022-09-02 12:34:10,324:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00002, Train Loss: 1.5183, Train Acc: 46.2804,
                        Val Loss: 2.1124, Val Acc: 31.5039, Test Acc: 32.0232
2022-09-02 12:34:10,325:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 64/1000
2022-09-02 12:34:10,939:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.5177, Train Acc: 46.3740,
                        Val Loss: 2.1140, Val Acc: 31.5090, Test Acc: 31.9843
2022-09-02 12:34:10,939:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 65/1000
2022-09-02 12:34:11,545:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.5171, Train Acc: 46.3589,
                        Val Loss: 2.1153, Val Acc: 31.2589, Test Acc: 31.9525
2022-09-02 12:34:11,545:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 66/1000
2022-09-02 12:34:12,151:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.5165, Train Acc: 46.3589,
                        Val Loss: 2.1044, Val Acc: 31.2579, Test Acc: 31.7997
2022-09-02 12:34:12,151:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 67/1000
2022-09-02 12:34:12,762:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.5159, Train Acc: 46.3589,
                        Val Loss: 2.1018, Val Acc: 31.1610, Test Acc: 31.8852
2022-09-02 12:34:12,762:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 68/1000
2022-09-02 12:34:13,385:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00002, Train Loss: 1.5153, Train Acc: 46.3589,
                        Val Loss: 2.1037, Val Acc: 31.1711, Test Acc: 31.9850
2022-09-02 12:34:13,386:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 69/1000
2022-09-02 12:34:13,995:main_SBMs_node_classification.py:216 -   train_val_pipeline(): 	Time: 0.61s, LR: 0.00002, Train Loss: 1.5147, Train Acc: 46.4526,
                        Val Loss: 2.1004, Val Acc: 31.0010, Test Acc: 32.0776
2022-09-02 12:34:13,996:main_SBMs_node_classification.py:174 -   train_val_pipeline(): Epoch 70/1000
2022-09-02 12:34:14,103:main_SBMs_node_classification.py:247 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 12:34:14,103:main_SBMs_node_classification.py:248 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 12:41:37,611:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:41:41,838:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'R', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:41:41,838:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 12:41:41,839:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:41:41,841:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:41:41,841:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:41:41,841:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:41:41,846:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:41:41,846:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 12:41:41,848:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:41:41,848:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:41:41,848:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:41:41,848:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:41:42,109:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 12:41:42,109:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 12:42:06,717:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:42:10,721:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'R', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:42:10,721:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 12:42:10,722:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:42:10,723:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:42:10,723:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:42:10,723:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:42:10,728:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:42:10,729:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 12:42:10,730:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:42:10,731:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:42:10,732:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:42:10,732:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:42:10,989:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 12:42:10,989:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 12:42:38,028:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:42:41,949:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'R', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:42:41,949:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 12:42:41,951:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:42:41,951:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:42:41,952:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:42:41,952:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:42:41,956:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:42:41,957:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 12:42:41,959:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:42:41,961:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:42:41,961:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:42:41,961:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:42:42,208:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 12:42:42,208:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 12:43:38,009:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:43:41,943:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:43:41,943:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 12:43:41,944:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:43:41,945:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:43:41,945:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:43:41,945:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:43:41,950:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:43:41,951:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 12:43:41,953:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:43:41,953:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:43:41,954:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-02 12:43:41,954:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:43:42,198:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 12:43:42,198:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 12:44:07,400:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 12:44:11,516:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'R', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-02 12:44:11,516:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 12:44:11,518:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:44:11,519:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:44:11,519:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:44:11,519:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:44:11,524:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 12:44:11,525:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532494
2022-09-02 12:44:11,526:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-02 12:44:11,527:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-02 12:44:11,527:pe_layer.py:134 -             __init__(): Using matrix: R
2022-09-02 12:44:11,527:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-02 12:44:11,821:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-02 12:44:11,821:main_SBMs_node_classification.py:93 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-02 22:39:43,527:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:39:49,785:main_SBMs_node_classification.py:344 -                 main(): {'L': 6, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:39:49,785:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 22:39:49,803:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:39:49,804:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 521638
2022-09-02 22:39:50,333:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:39:51,435:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:1.6239128112792969
2022-09-02 22:39:51,437:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:39:51,437:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:39:51,437:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:39:51,437:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:39:51,439:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:39:53,635:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b16-sparsecheckpoints/SAGraphTransformer_SBM_PATTERN_GPU0_16_16_22h39m49s_on_Sep_02_2022/MODELS_
2022-09-02 22:39:53,635:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 2.20s, LR: 0.00050, Train Loss: 0.7030, Train Acc: 52.7144,
                        Val Loss: 0.8603, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-02 22:39:53,635:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 22:39:55,571:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 1.94s, LR: 0.00050, Train Loss: 0.6879, Train Acc: 56.7401,
                        Val Loss: 0.7325, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-02 22:39:55,572:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 22:39:56,856:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 22:39:56,856:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 22:40:07,514:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:40:12,918:main_SBMs_node_classification.py:344 -                 main(): {'L': 10, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:40:12,919:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 22:40:12,925:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:40:12,926:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 728998
2022-09-02 22:40:13,434:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:40:13,867:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.9339268207550049
2022-09-02 22:40:13,869:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:40:13,869:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:40:13,869:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:40:13,870:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:40:13,871:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:40:15,454:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 22:40:15,454:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 22:40:40,099:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:40:45,132:main_SBMs_node_classification.py:344 -                 main(): {'L': 7, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:40:45,132:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 22:40:45,138:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:40:45,139:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 573478
2022-09-02 22:40:45,665:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:40:45,845:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.7003028392791748
2022-09-02 22:40:45,847:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:40:45,847:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:40:45,847:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:40:45,847:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:40:45,848:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:40:47,918:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b16-sparsecheckpoints/SAGraphTransformer_SBM_PATTERN_GPU0_16_16_22h40m45s_on_Sep_02_2022/MODELS_
2022-09-02 22:40:47,918:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 2.07s, LR: 0.00050, Train Loss: 0.7035, Train Acc: 49.4156,
                        Val Loss: 0.8129, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-02 22:40:47,918:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-02 22:40:49,944:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 2.03s, LR: 0.00050, Train Loss: 0.6841, Train Acc: 57.7974,
                        Val Loss: 1.1354, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-02 22:40:49,944:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-02 22:40:51,941:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 2.00s, LR: 0.00050, Train Loss: 0.6721, Train Acc: 61.9420,
                        Val Loss: 1.2151, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-02 22:40:51,941:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-02 22:40:53,880:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 1.94s, LR: 0.00050, Train Loss: 0.6626, Train Acc: 61.9420,
                        Val Loss: 1.1105, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-02 22:40:53,880:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-02 22:40:55,841:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 1.96s, LR: 0.00050, Train Loss: 0.6579, Train Acc: 61.9420,
                        Val Loss: 1.0629, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-02 22:40:55,841:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-02 22:40:55,883:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 22:40:55,883:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 22:41:18,272:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:41:23,435:main_SBMs_node_classification.py:344 -                 main(): {'L': 6, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 4, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:41:23,435:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 22:41:23,442:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:41:23,442:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 590390
2022-09-02 22:41:24,096:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:41:24,397:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.9493229389190674
2022-09-02 22:41:24,399:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:41:24,399:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:41:24,399:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:41:24,400:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:41:24,401:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:41:26,117:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 22:41:26,117:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 22:41:42,932:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:41:47,989:main_SBMs_node_classification.py:344 -                 main(): {'L': 6, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 5, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:41:47,989:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-02 22:43:21,982:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:43:27,239:main_SBMs_node_classification.py:344 -                 main(): {'L': 5, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 20, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:43:27,239:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 20}
2022-09-02 22:43:27,245:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:43:27,245:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 520786
2022-09-02 22:43:27,834:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:43:28,266:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:1.015406847000122
2022-09-02 22:43:28,276:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:43:28,276:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:43:28,276:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:43:28,276:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:43:28,278:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:43:34,629:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:43:39,718:main_SBMs_node_classification.py:344 -                 main(): {'L': 6, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 20, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:43:39,718:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 20}
2022-09-02 22:43:39,725:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:43:39,726:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 572626
2022-09-02 22:43:40,281:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:43:40,512:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.7805740833282471
2022-09-02 22:43:40,516:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:43:40,516:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:43:40,516:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:43:40,516:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:43:40,518:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:43:42,122:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 22:43:42,122:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 22:44:18,825:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:44:23,822:main_SBMs_node_classification.py:344 -                 main(): {'L': 5, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:44:23,822:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-09-02 22:44:23,827:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:44:23,828:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 676054
2022-09-02 22:44:24,410:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:44:24,715:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.8828742504119873
2022-09-02 22:44:24,718:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:44:24,718:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:44:24,718:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:44:24,718:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:44:24,720:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:44:27,350:main_SBMs_node_classification.py:243 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-02 22:44:27,350:main_SBMs_node_classification.py:244 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-02 22:44:31,270:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:44:36,524:main_SBMs_node_classification.py:344 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:44:36,524:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-09-02 22:44:36,529:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:44:36,530:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 624214
2022-09-02 22:44:37,043:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:44:37,208:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.6734557151794434
2022-09-02 22:44:37,211:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:44:37,211:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:44:37,211:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:44:37,211:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:44:37,212:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:45:00,568:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:45:05,687:main_SBMs_node_classification.py:344 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:45:05,688:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-09-02 22:45:05,692:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:45:05,693:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 582524
2022-09-02 22:45:06,224:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:45:06,391:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.6939809322357178
2022-09-02 22:45:06,393:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:45:06,393:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:45:06,393:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:45:06,393:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:45:06,394:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-02 22:45:14,604:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-02 22:45:19,687:main_SBMs_node_classification.py:344 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 3, 'pos_enc_dim': 32, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 3, 'n_classes': 2}
2022-09-02 22:45:19,687:main_SBMs_node_classification.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 32}
2022-09-02 22:45:19,691:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-02 22:45:19,692:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 545394
2022-09-02 22:45:20,127:main_SBMs_node_classification.py:100 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-02 22:45:20,419:main_SBMs_node_classification.py:102 -   train_val_pipeline(): Time PE:0.7223339080810547
2022-09-02 22:45:20,422:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-02 22:45:20,422:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-02 22:45:20,422:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-02 22:45:20,422:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-02 22:45:20,423:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:28:41,016:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:28:44,360:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:28:44,360:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 13:29:05,733:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:29:09,009:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:29:09,009:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 13:29:32,563:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:29:35,834:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:29:35,834:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 13:29:35,850:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:29:35,851:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:29:47,270:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:29:50,427:main_molecules_graph_regression.py:335 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:29:50,428:main_molecules_graph_regression.py:336 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:29:50,434:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:29:50,435:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:29:50,462:main_molecules_graph_regression.py:107 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:29:50,462:main_molecules_graph_regression.py:108 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:29:50,462:main_molecules_graph_regression.py:109 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:29:50,464:main_molecules_graph_regression.py:147 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:30:49,636:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:30:52,941:main_molecules_graph_regression.py:339 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:30:52,941:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:30:52,947:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:30:52,948:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:30:52,955:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:30:56,781:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.8325517177581787
2022-09-03 13:30:56,795:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:30:56,795:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:30:56,795:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:30:56,797:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:32:08,929:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:32:12,157:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:32:12,157:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:32:12,163:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:32:12,164:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:32:12,170:main_molecules_graph_regression.py:91 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:32:15,849:main_molecules_graph_regression.py:93 -   train_val_pipeline(): Time PE:3.6844470500946045
2022-09-03 13:32:15,863:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:32:15,863:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:32:15,863:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:32:15,865:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:32:42,840:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:32:46,131:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:32:46,131:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:32:46,138:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:32:46,139:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:32:46,146:main_molecules_graph_regression.py:91 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:32:49,993:main_molecules_graph_regression.py:93 -   train_val_pipeline(): Time PE:3.853379249572754
2022-09-03 13:32:50,007:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:32:50,007:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:32:50,007:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:32:50,009:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:33:11,680:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:33:14,967:main_molecules_graph_regression.py:339 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:33:14,967:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:33:14,973:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:33:14,974:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:33:14,981:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:33:18,651:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.676527261734009
2022-09-03 13:33:18,665:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:33:18,665:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:33:18,665:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:33:18,667:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:34:41,529:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:34:57,482:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:35:00,741:main_molecules_graph_regression.py:339 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:35:00,742:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:35:00,748:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:35:00,749:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:35:00,756:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:35:04,546:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.797363042831421
2022-09-03 13:35:04,561:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:35:04,561:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:35:04,561:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:35:04,563:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:35:51,764:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:35:54,893:main_molecules_graph_regression.py:339 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:35:54,893:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:35:54,900:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:35:54,900:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610817
2022-09-03 13:35:54,907:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:35:58,698:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.797553062438965
2022-09-03 13:35:58,712:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:35:58,713:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:35:58,713:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:35:58,716:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:36:34,189:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:36:37,448:main_molecules_graph_regression.py:339 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:36:37,448:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:36:37,455:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:36:37,455:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610737
2022-09-03 13:36:37,462:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:36:41,209:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.753491163253784
2022-09-03 13:36:41,223:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:36:41,223:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:36:41,223:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:36:41,225:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:37:27,987:main_molecules_graph_regression.py:170 -   train_val_pipeline(): Best model with MAE 1.5054543763399124
2022-09-03 13:37:27,988:main_molecules_graph_regression.py:193 -   train_val_pipeline(): 	Time: 46.76s, LR: 0.00070, Train Loss: 1.4464, Train MAE: 1.4464,
                            Val Loss: 1.4074, Val Acc: 1.4074, Test MAE: 1.5055
2022-09-03 13:37:27,995:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 2/1000
2022-09-03 13:37:58,368:main_molecules_graph_regression.py:225 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-03 13:37:58,368:main_molecules_graph_regression.py:226 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-03 13:38:06,434:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:38:09,818:main_molecules_graph_regression.py:339 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:38:09,818:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:38:09,825:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:38:09,826:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 610737
2022-09-03 13:38:09,834:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:38:25,458:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:38:32,155:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:38:35,394:main_molecules_graph_regression.py:339 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:38:35,394:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:38:35,400:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:38:35,401:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 503633
2022-09-03 13:38:35,407:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:38:39,111:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.7104930877685547
2022-09-03 13:38:39,126:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:38:39,126:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:38:39,126:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:38:39,128:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:38:43,009:main_molecules_graph_regression.py:225 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-03 13:38:43,009:main_molecules_graph_regression.py:226 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-03 13:38:49,570:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:38:52,919:main_molecules_graph_regression.py:339 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 512, 'out_deg_centrality': 512, 'spd_len': 512, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:38:52,919:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:38:52,926:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:38:52,927:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 558897
2022-09-03 13:38:52,933:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:45:31,591:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:45:35,100:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:45:38,403:main_molecules_graph_regression.py:339 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 128, 'out_deg_centrality': 128, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:45:38,403:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:45:38,409:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:45:38,410:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 494385
2022-09-03 13:45:38,416:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:45:42,143:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.732588052749634
2022-09-03 13:45:42,158:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:45:42,158:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:45:42,158:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:45:42,160:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:45:57,180:main_molecules_graph_regression.py:225 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-03 13:45:57,180:main_molecules_graph_regression.py:226 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-03 13:46:09,813:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:46:13,133:main_molecules_graph_regression.py:339 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:46:13,133:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:46:13,138:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:46:13,138:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 13:46:13,144:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:46:16,897:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time PE:3.7587976455688477
2022-09-03 13:46:16,913:main_molecules_graph_regression.py:111 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 13:46:16,913:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 13:46:16,913:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 13:46:16,916:main_molecules_graph_regression.py:151 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 13:46:21,786:main_molecules_graph_regression.py:225 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-03 13:46:21,786:main_molecules_graph_regression.py:226 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-03 13:46:34,379:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:46:37,559:main_molecules_graph_regression.py:339 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 13:46:37,559:main_molecules_graph_regression.py:340 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-03 13:46:37,564:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:46:37,564:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 13:46:37,570:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 13:54:36,124:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 13:54:36,190:main_CSL_graph_classification.py:321 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 13:54:36,190:main_CSL_graph_classification.py:322 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'job_num': 1, 'seed_array': [41]}
2022-09-03 13:54:36,191:pe_layer.py:68 -             __init__(): no_pe
2022-09-03 13:54:36,191:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-03 13:54:36,191:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-03 13:54:36,194:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 13:54:36,195:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 321654
2022-09-03 13:54:36,310:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-03 13:54:36,312:pe_layer.py:68 -             __init__(): no_pe
2022-09-03 13:54:36,313:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-03 13:54:36,313:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-03 13:54:36,316:main_CSL_graph_classification.py:95 -   train_val_pipeline(): Training Graphs: 90
2022-09-03 13:54:36,316:main_CSL_graph_classification.py:96 -   train_val_pipeline(): Validation Graphs: 30
2022-09-03 13:54:36,316:main_CSL_graph_classification.py:97 -   train_val_pipeline(): Test Graphs: 30
2022-09-03 13:54:36,316:main_CSL_graph_classification.py:98 -   train_val_pipeline(): Number of Classes: 10
2022-09-03 13:54:36,318:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 0
2022-09-03 13:54:37,186:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 2.3080, Train Acc: 0.0778,
                            Val Loss: 81392.7292, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-03 13:54:37,190:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 1
2022-09-03 13:54:38,011:main_CSL_graph_classification.py:174 -   train_val_pipeline(): 	Time: 0.82s, LR: 0.00050, Train Loss: 2.3064, Train Acc: 0.1000,
                            Val Loss: 966760309.3333, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-03 13:54:38,016:main_CSL_graph_classification.py:136 -   train_val_pipeline(): Epoch 2
2022-09-03 13:54:38,562:main_CSL_graph_classification.py:221 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-03 13:54:38,562:main_CSL_graph_classification.py:222 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-03 13:54:38,562:main_CSL_graph_classification.py:225 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0007hrs
2022-09-03 13:54:38,562:main_CSL_graph_classification.py:226 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.8450s
2022-09-03 13:54:38,566:main_CSL_graph_classification.py:229 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-03 13:54:38,566:main_CSL_graph_classification.py:230 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-03 13:54:38,566:main_CSL_graph_classification.py:231 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-03 13:54:38,566:main_CSL_graph_classification.py:232 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-03 14:05:19,940:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:05:20,002:main_CSL_graph_classification.py:325 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:05:20,002:main_CSL_graph_classification.py:326 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:06:51,214:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:06:51,278:main_CSL_graph_classification.py:325 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:06:51,278:main_CSL_graph_classification.py:326 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:07:31,570:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:07:31,631:main_CSL_graph_classification.py:325 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:07:31,631:main_CSL_graph_classification.py:326 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:07:31,636:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 14:07:31,637:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 534014
2022-09-03 14:07:43,739:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:07:43,805:main_CSL_graph_classification.py:325 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:07:43,805:main_CSL_graph_classification.py:326 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:07:43,810:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 14:07:43,811:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 534014
2022-09-03 14:07:43,914:main_CSL_graph_classification.py:53 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 14:07:44,462:main_CSL_graph_classification.py:81 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-03 14:07:44,469:main_CSL_graph_classification.py:99 -   train_val_pipeline(): Training Graphs: 90
2022-09-03 14:07:44,469:main_CSL_graph_classification.py:100 -   train_val_pipeline(): Validation Graphs: 30
2022-09-03 14:07:44,469:main_CSL_graph_classification.py:101 -   train_val_pipeline(): Test Graphs: 30
2022-09-03 14:07:44,469:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Number of Classes: 10
2022-09-03 14:07:44,473:main_CSL_graph_classification.py:140 -   train_val_pipeline(): Epoch 0
2022-09-03 14:17:58,892:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:17:58,959:main_CSL_graph_classification.py:328 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:17:58,959:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:17:58,964:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 14:17:58,965:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 534014
2022-09-03 14:17:59,092:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-03 14:17:59,100:main_CSL_graph_classification.py:96 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 14:17:59,217:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-03 14:17:59,217:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-03 14:17:59,217:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-03 14:17:59,217:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-03 14:17:59,222:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-03 14:18:51,804:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:18:51,870:main_CSL_graph_classification.py:328 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:18:51,870:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:18:51,875:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 14:18:51,876:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 534014
2022-09-03 14:18:51,997:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-03 14:18:52,004:main_CSL_graph_classification.py:96 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 14:18:52,105:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-03 14:18:52,105:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-03 14:18:52,105:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-03 14:18:52,105:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-03 14:18:52,107:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-03 14:19:04,775:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:19:04,835:main_CSL_graph_classification.py:328 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:19:04,835:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:19:04,841:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 14:19:04,841:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 534014
2022-09-03 14:19:04,959:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-03 14:19:04,966:main_CSL_graph_classification.py:96 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 14:19:05,067:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-03 14:19:05,067:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-03 14:19:05,067:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-03 14:19:05,067:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-03 14:19:05,070:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-03 14:19:22,513:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:19:22,576:main_CSL_graph_classification.py:328 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:19:22,576:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:19:22,581:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 14:19:22,582:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 534014
2022-09-03 14:19:22,692:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-03 14:19:22,698:main_CSL_graph_classification.py:96 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 14:19:22,799:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-03 14:19:22,799:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-03 14:19:22,799:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-03 14:19:22,799:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-03 14:19:22,801:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-03 14:19:39,633:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 14:19:39,694:main_CSL_graph_classification.py:328 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-03 14:19:39,695:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-03 14:19:39,700:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 14:19:39,701:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 534014
2022-09-03 14:19:39,808:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-03 14:19:39,814:main_CSL_graph_classification.py:96 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 14:19:39,920:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-03 14:19:39,920:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-03 14:19:39,920:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-03 14:19:39,920:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-03 14:19:39,923:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-03 20:57:42,554:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 20:57:45,939:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 20:57:45,939:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-03 20:57:45,953:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 20:57:45,956:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 20:57:45,964:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 20:57:49,853:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.897143602371216
2022-09-03 23:34:45,248:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:34:48,477:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:34:48,477:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-03 23:34:48,491:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:34:48,492:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:34:54,476:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:34:57,657:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:34:57,657:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:34:57,662:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:34:57,663:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:34:57,669:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:35:01,367:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.703914165496826
2022-09-03 23:35:01,382:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:35:01,383:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:35:01,383:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:35:01,385:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:41:13,540:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:41:16,749:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:41:16,751:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:41:16,756:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:41:16,756:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:41:16,761:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:41:20,613:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.856598138809204
2022-09-03 23:41:20,628:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:41:20,629:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:41:20,629:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:41:20,631:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:42:09,641:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:42:12,906:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:42:12,906:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:42:12,911:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:42:12,912:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:42:12,917:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:42:16,820:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.907724142074585
2022-09-03 23:42:16,835:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:42:16,835:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:42:16,835:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:42:16,837:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:42:50,328:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:42:53,468:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:42:53,468:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:42:53,473:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:42:53,474:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:42:53,479:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:42:57,010:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.535604953765869
2022-09-03 23:42:57,024:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:42:57,024:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:42:57,024:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:42:57,026:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:44:05,923:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:44:09,364:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:44:09,364:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:44:09,372:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:44:09,373:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:44:09,378:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:44:13,235:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.8622629642486572
2022-09-03 23:44:13,251:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:44:13,251:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:44:13,251:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:44:13,253:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:44:44,864:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:44:48,118:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:44:48,118:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:44:48,123:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:44:48,124:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:44:48,129:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:44:51,732:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.608433961868286
2022-09-03 23:44:51,747:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:44:51,747:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:44:51,747:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:44:51,749:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:49:58,391:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:50:01,610:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:50:01,610:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:50:01,615:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:50:01,616:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:50:01,621:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:50:05,297:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.680655002593994
2022-09-03 23:50:05,311:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:50:05,312:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:50:05,312:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:50:05,314:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:50:21,710:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:50:24,847:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:50:24,847:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:50:24,852:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:50:24,853:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:50:24,858:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:50:28,398:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.54467511177063
2022-09-03 23:50:28,412:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:50:28,412:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:50:28,412:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:50:28,414:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:50:37,106:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:50:40,271:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:50:40,271:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:50:40,276:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:50:40,277:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:50:40,282:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:50:43,988:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.710676908493042
2022-09-03 23:50:44,002:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:50:44,002:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:50:44,002:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:50:44,003:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:51:16,304:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:51:19,551:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:51:19,551:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:51:19,556:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:51:19,557:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:51:19,563:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:51:23,348:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.7908620834350586
2022-09-03 23:51:23,364:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:51:23,364:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:51:23,364:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:51:23,366:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:51:49,029:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:51:52,178:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:51:52,178:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:51:52,183:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:51:52,184:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:51:52,189:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:51:56,072:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.8879878520965576
2022-09-03 23:51:56,086:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:51:56,087:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:51:56,087:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:51:56,089:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:53:02,345:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:53:05,623:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:53:05,623:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:53:05,628:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:53:05,629:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:53:05,634:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:53:09,444:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.8152589797973633
2022-09-03 23:53:09,460:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:53:09,460:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:53:09,460:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:53:09,462:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:53:46,967:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:53:50,107:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:53:50,107:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:53:50,112:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:53:50,113:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:53:50,117:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:53:53,768:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.654792070388794
2022-09-03 23:53:53,781:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:53:53,781:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:53:53,781:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:53:53,783:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:54:07,386:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:54:10,535:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:54:10,535:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:54:10,540:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:54:10,541:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:54:10,546:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:54:14,188:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.6469838619232178
2022-09-03 23:54:14,202:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:54:14,202:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:54:14,202:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:54:14,204:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:54:53,550:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:54:56,683:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:54:56,683:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:54:56,688:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:54:56,689:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:54:56,694:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:55:00,344:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.655441999435425
2022-09-03 23:55:00,359:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:55:00,359:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:55:00,359:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:55:00,361:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:55:13,823:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:55:17,024:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:55:17,024:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:55:17,030:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:55:17,030:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:55:17,035:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:55:20,564:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.5338737964630127
2022-09-03 23:55:20,579:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:55:20,579:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:55:20,579:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:55:20,581:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:55:54,785:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:55:58,033:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:55:58,033:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:55:58,038:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:55:58,038:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:55:58,044:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:56:01,730:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.6911461353302
2022-09-03 23:56:01,744:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:56:01,744:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:56:01,744:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:56:01,746:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:56:40,180:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:56:43,313:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:56:43,314:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:56:43,319:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:56:43,319:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:56:43,324:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:56:46,996:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.676529884338379
2022-09-03 23:56:47,011:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:56:47,011:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:56:47,011:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:56:47,013:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:57:21,971:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:57:25,248:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:57:25,248:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:57:25,253:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:57:25,253:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:57:25,259:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:57:28,782:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.5283069610595703
2022-09-03 23:57:28,807:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:57:28,808:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:57:28,808:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:57:28,810:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:58:14,959:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:58:18,114:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:58:18,114:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:58:18,119:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:58:18,120:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:58:18,125:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:58:21,681:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.5607879161834717
2022-09-03 23:58:21,694:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:58:21,694:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:58:21,694:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:58:21,697:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:58:49,817:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:58:52,968:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:58:52,968:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:58:52,973:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:58:52,974:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:58:52,979:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:58:56,525:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.55138897895813
2022-09-03 23:58:56,541:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:58:56,541:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:58:56,541:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:58:56,544:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:59:25,606:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:59:28,844:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:59:28,845:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:59:28,851:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:59:28,852:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:59:28,857:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:59:32,518:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.6661150455474854
2022-09-03 23:59:32,534:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:59:32,534:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:59:32,534:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:59:32,536:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-03 23:59:50,775:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-03 23:59:54,079:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-03 23:59:54,079:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-03 23:59:54,084:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-03 23:59:54,085:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-03 23:59:54,090:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-03 23:59:57,786:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.7010090351104736
2022-09-03 23:59:57,802:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-03 23:59:57,802:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-03 23:59:57,802:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-03 23:59:57,804:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 00:00:49,801:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 00:00:53,001:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 00:00:53,001:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 00:00:53,015:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 00:00:53,016:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 00:00:53,022:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 00:00:56,675:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.6590731143951416
2022-09-04 00:00:56,691:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 00:00:56,691:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 00:00:56,691:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 00:00:56,693:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 00:01:29,793:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 00:01:32,943:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 00:01:32,944:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 00:01:32,948:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 00:01:32,949:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 00:01:32,954:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 00:01:36,693:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.743704080581665
2022-09-04 00:01:36,709:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 00:01:36,709:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 00:01:36,709:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 00:01:36,711:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 00:01:50,730:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 00:01:53,923:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 00:01:53,923:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 00:01:53,928:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 00:01:53,929:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 00:01:53,935:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 00:01:57,829:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.899740219116211
2022-09-04 00:01:57,844:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 00:01:57,844:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 00:01:57,844:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 00:01:57,845:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 00:03:20,238:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 00:03:23,461:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 2, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 00:03:23,461:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 2, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 00:03:23,474:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 00:03:23,475:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 00:03:23,481:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 00:03:27,110:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.6343066692352295
2022-09-04 00:03:27,126:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 00:03:27,127:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 00:03:27,127:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 00:03:27,129:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 00:03:48,855:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 00:03:52,023:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 2, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 00:03:52,023:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 2, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 00:03:52,028:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 00:03:52,029:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 00:03:52,034:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 00:03:55,726:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.6967031955718994
2022-09-04 00:03:55,744:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 00:03:55,744:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 00:03:55,744:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 00:03:55,747:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 00:04:13,699:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 00:04:16,859:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 2, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 00:04:16,860:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 2, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 00:04:16,865:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 00:04:16,865:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 00:04:16,871:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 00:04:20,566:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.7007339000701904
2022-09-04 00:04:20,581:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 00:04:20,581:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 00:04:20,581:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 00:04:20,584:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:17:06,390:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:17:09,675:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 2, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:17:09,675:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 2, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:17:09,688:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:17:09,689:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 02:17:09,695:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:17:13,250:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.5608599185943604
2022-09-04 02:17:13,266:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:17:13,266:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:17:13,267:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:17:13,269:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:17:37,374:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:17:40,584:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 2, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:17:40,584:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 2, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:17:40,589:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:17:40,590:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 02:17:40,594:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:17:44,288:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.698500156402588
2022-09-04 02:17:44,303:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:17:44,304:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:17:44,304:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:17:44,305:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:18:06,104:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:18:09,440:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 2, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:18:09,440:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 2, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:18:09,445:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:18:09,446:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 02:18:09,451:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:18:13,171:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:3.724970817565918
2022-09-04 02:18:13,184:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:18:13,184:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:18:13,184:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:18:13,186:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:19:46,765:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:19:50,009:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 2, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:19:50,009:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 2, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:19:50,014:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:19:50,015:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 02:19:50,020:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:19:57,234:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:20:00,536:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:20:00,536:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:20:00,541:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:20:00,542:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 02:20:00,547:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:20:31,179:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:20:34,499:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:20:34,499:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:20:34,504:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:20:34,505:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 487217
2022-09-04 02:20:34,510:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:20:49,925:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.420035123825073
2022-09-04 02:20:49,940:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:20:49,940:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:20:49,940:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:20:49,942:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:21:33,394:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4777961373329163
2022-09-04 02:21:33,396:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.45s, LR: 0.00070, Train Loss: 1.4495, Train MAE: 1.4495,
                            Val Loss: 1.3879, Val Acc: 1.3879, Test MAE: 1.4778
2022-09-04 02:21:33,403:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 02:21:43,601:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 02:21:43,602:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 02:21:52,384:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:21:55,560:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:21:55,560:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:21:55,565:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:21:55,566:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 487217
2022-09-04 02:21:55,571:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:22:10,777:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.210848093032837
2022-09-04 02:22:10,777:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-04 02:22:31,763:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 20.985692977905273
2022-09-04 02:22:31,779:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:22:31,779:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:22:31,779:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:22:31,782:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:23:41,766:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4632043689489365
2022-09-04 02:23:41,768:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 69.99s, LR: 0.00070, Train Loss: 1.4320, Train MAE: 1.4320,
                            Val Loss: 1.3800, Val Acc: 1.3800, Test MAE: 1.4632
2022-09-04 02:23:41,775:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 02:23:50,153:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 02:23:50,153:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 02:37:15,317:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:37:18,716:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:37:18,717:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:37:18,722:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:37:18,722:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 487217
2022-09-04 02:37:18,728:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:37:30,819:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:37:34,117:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:37:34,117:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:37:34,122:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:37:34,123:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 487217
2022-09-04 02:37:34,128:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:37:49,411:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.287932872772217
2022-09-04 02:37:49,426:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:37:49,426:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:37:49,426:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:37:49,428:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:37:51,695:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 02:37:51,695:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 02:38:32,463:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:38:35,671:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:38:35,671:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:38:35,676:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:38:35,677:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 487217
2022-09-04 02:38:35,682:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:38:50,946:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.268872261047363
2022-09-04 02:38:50,960:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:38:50,960:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:38:50,960:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:38:50,962:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:38:52,916:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 02:38:52,916:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 02:40:15,299:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 02:40:18,442:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 02:40:18,442:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 02:40:18,447:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 02:40:18,448:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 487217
2022-09-04 02:40:18,452:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 02:40:33,660:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.21279788017273
2022-09-04 02:40:33,675:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 02:40:33,675:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 02:40:33,675:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 02:40:33,676:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 02:40:35,370:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 02:40:35,370:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 03:04:12,122:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 03:04:15,464:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 512, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 03:04:15,464:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 03:04:15,479:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 03:04:15,479:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 487217
2022-09-04 03:04:15,486:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 03:04:30,754:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.274298906326294
2022-09-04 03:04:30,770:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 03:04:30,771:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 03:04:30,771:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 03:04:30,773:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 03:05:19,204:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.515069380402565
2022-09-04 03:05:19,207:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 48.43s, LR: 0.00070, Train Loss: 1.4503, Train MAE: 1.4503,
                            Val Loss: 1.4143, Val Acc: 1.4143, Test MAE: 1.5151
2022-09-04 03:05:19,213:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 03:06:07,162:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4488088935613632
2022-09-04 03:06:07,162:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 47.95s, LR: 0.00070, Train Loss: 1.3950, Train MAE: 1.3950,
                            Val Loss: 1.3611, Val Acc: 1.3611, Test MAE: 1.4488
2022-09-04 03:06:07,168:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-04 03:06:53,347:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4402289688587189
2022-09-04 03:06:53,348:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 46.18s, LR: 0.00070, Train Loss: 1.3929, Train MAE: 1.3929,
                            Val Loss: 1.3620, Val Acc: 1.3620, Test MAE: 1.4402
2022-09-04 03:06:53,354:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-04 03:07:39,013:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 45.66s, LR: 0.00070, Train Loss: 1.3810, Train MAE: 1.3810,
                            Val Loss: 1.3809, Val Acc: 1.3809, Test MAE: 1.4660
2022-09-04 03:07:39,018:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-04 03:08:24,834:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 45.82s, LR: 0.00070, Train Loss: 1.3698, Train MAE: 1.3698,
                            Val Loss: 1.3820, Val Acc: 1.3820, Test MAE: 1.4730
2022-09-04 03:08:24,840:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-04 03:09:09,582:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.74s, LR: 0.00070, Train Loss: 1.3543, Train MAE: 1.3543,
                            Val Loss: 1.4430, Val Acc: 1.4430, Test MAE: 1.5044
2022-09-04 03:09:09,587:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-04 03:09:55,287:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4359167516231537
2022-09-04 03:09:55,287:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 45.70s, LR: 0.00070, Train Loss: 1.3716, Train MAE: 1.3716,
                            Val Loss: 1.3636, Val Acc: 1.3636, Test MAE: 1.4359
2022-09-04 03:09:55,293:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 8/1000
2022-09-04 03:10:40,895:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3978606313467026
2022-09-04 03:10:40,896:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 45.60s, LR: 0.00070, Train Loss: 1.3240, Train MAE: 1.3240,
                            Val Loss: 1.3396, Val Acc: 1.3396, Test MAE: 1.3979
2022-09-04 03:10:40,901:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 9/1000
2022-09-04 03:11:26,864:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3571882098913193
2022-09-04 03:11:26,864:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 45.96s, LR: 0.00070, Train Loss: 1.2995, Train MAE: 1.2995,
                            Val Loss: 1.3039, Val Acc: 1.3039, Test MAE: 1.3572
2022-09-04 03:11:26,870:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 10/1000
2022-09-04 03:11:37,332:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 03:11:37,332:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 03:13:00,445:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 03:13:03,813:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 03:13:03,813:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 03:13:03,815:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:13:03,815:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:13:03,815:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:13:03,820:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 03:13:03,821:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 339025
2022-09-04 03:13:03,822:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:13:03,822:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:13:03,822:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:13:03,842:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 03:13:03,842:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 03:13:03,842:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 03:13:03,845:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 03:13:23,390:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 03:13:26,706:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 03:13:26,706:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 03:13:26,707:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:13:26,707:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:13:26,707:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:13:26,712:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 03:13:26,713:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 339025
2022-09-04 03:13:26,714:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:13:26,714:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:13:26,714:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:13:26,736:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 03:13:26,736:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 03:13:26,736:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 03:13:26,738:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 03:13:35,370:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 03:13:38,652:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 03:13:38,652:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 03:13:38,653:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:13:38,654:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:13:38,654:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:13:38,658:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 03:13:38,659:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 339025
2022-09-04 03:13:38,660:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:13:38,660:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:13:38,660:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:13:38,679:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 03:13:38,679:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 03:13:38,679:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 03:13:38,681:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 03:14:00,558:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 03:14:03,854:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 03:14:03,854:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 03:14:03,855:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:14:03,855:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:14:03,855:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:14:03,860:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 03:14:03,860:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 339025
2022-09-04 03:14:03,862:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:14:03,862:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:14:03,862:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:14:03,880:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 03:14:03,881:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 03:14:03,881:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 03:14:03,885:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 03:14:15,283:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 03:14:15,284:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 03:14:22,950:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 03:14:29,528:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 03:14:32,815:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 03:14:32,815:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 03:14:32,816:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:14:32,817:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:14:32,817:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:14:32,822:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 03:14:32,822:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526545
2022-09-04 03:14:32,824:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 03:14:32,824:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 03:14:32,824:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 03:14:32,830:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-04 03:14:53,925:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 21.094956874847412
2022-09-04 03:14:53,940:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 03:14:53,940:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 03:14:53,940:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 03:14:53,942:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 03:15:37,240:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.7131694778800011
2022-09-04 03:15:37,242:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.30s, LR: 0.00070, Train Loss: 0.8149, Train MAE: 0.8149,
                            Val Loss: 0.6687, Val Acc: 0.6687, Test MAE: 0.7132
2022-09-04 03:15:37,248:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 03:16:20,127:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.88s, LR: 0.00070, Train Loss: 0.6874, Train MAE: 0.6874,
                            Val Loss: 0.7288, Val Acc: 0.7288, Test MAE: 0.7925
2022-09-04 03:16:20,134:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-04 03:17:02,969:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.83s, LR: 0.00070, Train Loss: 0.6794, Train MAE: 0.6794,
                            Val Loss: 0.6712, Val Acc: 0.6712, Test MAE: 0.7143
2022-09-04 03:17:02,976:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-04 03:17:46,470:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.49s, LR: 0.00070, Train Loss: 0.6809, Train MAE: 0.6809,
                            Val Loss: 0.6718, Val Acc: 0.6718, Test MAE: 0.7136
2022-09-04 03:17:46,477:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-04 03:18:30,301:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.82s, LR: 0.00070, Train Loss: 0.6794, Train MAE: 0.6794,
                            Val Loss: 0.6967, Val Acc: 0.6967, Test MAE: 0.7407
2022-09-04 03:18:30,308:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-04 03:19:14,824:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.52s, LR: 0.00070, Train Loss: 0.6671, Train MAE: 0.6671,
                            Val Loss: 0.6778, Val Acc: 0.6778, Test MAE: 0.7270
2022-09-04 03:19:14,830:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-04 03:19:58,348:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.7053285539150238
2022-09-04 03:19:58,349:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.52s, LR: 0.00070, Train Loss: 0.6923, Train MAE: 0.6923,
                            Val Loss: 0.6416, Val Acc: 0.6416, Test MAE: 0.7053
2022-09-04 03:19:58,355:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 8/1000
2022-09-04 03:20:41,823:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6893707513809204
2022-09-04 03:20:41,823:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.47s, LR: 0.00070, Train Loss: 0.6582, Train MAE: 0.6582,
                            Val Loss: 0.6547, Val Acc: 0.6547, Test MAE: 0.6894
2022-09-04 03:20:41,829:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 9/1000
2022-09-04 03:21:24,853:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.02s, LR: 0.00070, Train Loss: 0.6539, Train MAE: 0.6539,
                            Val Loss: 0.6852, Val Acc: 0.6852, Test MAE: 0.7244
2022-09-04 03:21:24,860:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 10/1000
2022-09-04 03:22:07,837:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.98s, LR: 0.00070, Train Loss: 0.6487, Train MAE: 0.6487,
                            Val Loss: 0.6983, Val Acc: 0.6983, Test MAE: 0.7240
2022-09-04 03:22:07,844:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 11/1000
2022-09-04 03:22:50,465:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.62s, LR: 0.00070, Train Loss: 0.6530, Train MAE: 0.6530,
                            Val Loss: 0.6845, Val Acc: 0.6845, Test MAE: 0.7207
2022-09-04 03:22:50,472:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 12/1000
2022-09-04 03:23:33,073:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6888817697763443
2022-09-04 03:23:33,073:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.60s, LR: 0.00070, Train Loss: 0.6506, Train MAE: 0.6506,
                            Val Loss: 0.6546, Val Acc: 0.6546, Test MAE: 0.6889
2022-09-04 03:23:33,081:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 13/1000
2022-09-04 03:25:51,699:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 138.62s, LR: 0.00070, Train Loss: 0.6476, Train MAE: 0.6476,
                            Val Loss: 0.6635, Val Acc: 0.6635, Test MAE: 0.7178
2022-09-04 03:25:51,711:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 14/1000
2022-09-04 03:26:34,912:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.20s, LR: 0.00070, Train Loss: 0.6465, Train MAE: 0.6465,
                            Val Loss: 0.7019, Val Acc: 0.7019, Test MAE: 0.7360
2022-09-04 03:26:34,920:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 15/1000
2022-09-04 03:27:17,600:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.68s, LR: 0.00070, Train Loss: 0.6523, Train MAE: 0.6523,
                            Val Loss: 0.7062, Val Acc: 0.7062, Test MAE: 0.7519
2022-09-04 03:27:17,607:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 16/1000
2022-09-04 03:28:00,404:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6788427755236626
2022-09-04 03:28:00,404:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.80s, LR: 0.00070, Train Loss: 0.6428, Train MAE: 0.6428,
                            Val Loss: 0.6311, Val Acc: 0.6311, Test MAE: 0.6788
2022-09-04 03:28:00,413:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 17/1000
2022-09-04 03:29:48,819:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 108.41s, LR: 0.00070, Train Loss: 0.6458, Train MAE: 0.6458,
                            Val Loss: 0.6455, Val Acc: 0.6455, Test MAE: 0.6965
2022-09-04 03:29:48,827:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 18/1000
2022-09-04 03:30:32,732:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.91s, LR: 0.00070, Train Loss: 0.6496, Train MAE: 0.6496,
                            Val Loss: 0.6528, Val Acc: 0.6528, Test MAE: 0.6942
2022-09-04 03:30:32,740:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 19/1000
2022-09-04 03:31:17,456:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.72s, LR: 0.00070, Train Loss: 0.6461, Train MAE: 0.6461,
                            Val Loss: 0.6386, Val Acc: 0.6386, Test MAE: 0.6857
2022-09-04 03:31:17,463:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 20/1000
2022-09-04 03:32:01,714:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.25s, LR: 0.00070, Train Loss: 0.6389, Train MAE: 0.6389,
                            Val Loss: 0.7006, Val Acc: 0.7006, Test MAE: 0.7265
2022-09-04 03:32:01,722:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 21/1000
2022-09-04 03:32:46,016:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.29s, LR: 0.00070, Train Loss: 0.6513, Train MAE: 0.6513,
                            Val Loss: 0.6892, Val Acc: 0.6892, Test MAE: 0.7242
2022-09-04 03:32:46,023:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 22/1000
2022-09-04 03:33:29,246:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.22s, LR: 0.00070, Train Loss: 0.6395, Train MAE: 0.6395,
                            Val Loss: 0.7116, Val Acc: 0.7116, Test MAE: 0.7670
2022-09-04 03:33:29,253:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 23/1000
2022-09-04 03:34:12,682:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.43s, LR: 0.00070, Train Loss: 0.6382, Train MAE: 0.6382,
                            Val Loss: 0.6926, Val Acc: 0.6926, Test MAE: 0.7401
2022-09-04 03:34:12,688:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 24/1000
2022-09-04 03:34:56,647:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.96s, LR: 0.00070, Train Loss: 0.6410, Train MAE: 0.6410,
                            Val Loss: 0.6507, Val Acc: 0.6507, Test MAE: 0.6927
2022-09-04 03:34:56,655:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 25/1000
2022-09-04 03:35:40,500:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.85s, LR: 0.00070, Train Loss: 0.6459, Train MAE: 0.6459,
                            Val Loss: 0.6464, Val Acc: 0.6464, Test MAE: 0.6965
2022-09-04 03:35:40,507:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 26/1000
2022-09-04 03:36:24,228:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.72s, LR: 0.00070, Train Loss: 0.6419, Train MAE: 0.6419,
                            Val Loss: 0.6601, Val Acc: 0.6601, Test MAE: 0.7112
2022-09-04 03:36:24,236:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 27/1000
2022-09-04 03:37:07,954:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.72s, LR: 0.00070, Train Loss: 0.6437, Train MAE: 0.6437,
                            Val Loss: 0.6761, Val Acc: 0.6761, Test MAE: 0.7302
2022-09-04 03:37:07,962:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 28/1000
2022-09-04 03:37:50,738:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.78s, LR: 0.00070, Train Loss: 0.6404, Train MAE: 0.6404,
                            Val Loss: 0.6562, Val Acc: 0.6562, Test MAE: 0.6853
2022-09-04 03:37:50,745:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 29/1000
2022-09-04 03:38:33,320:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6782595217227936
2022-09-04 03:38:33,320:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.58s, LR: 0.00070, Train Loss: 0.6363, Train MAE: 0.6363,
                            Val Loss: 0.6341, Val Acc: 0.6341, Test MAE: 0.6783
2022-09-04 03:38:33,327:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 30/1000
2022-09-04 03:39:16,171:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.84s, LR: 0.00070, Train Loss: 0.6366, Train MAE: 0.6366,
                            Val Loss: 0.6407, Val Acc: 0.6407, Test MAE: 0.6874
2022-09-04 03:39:16,178:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 31/1000
2022-09-04 03:53:28,727:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 852.55s, LR: 0.00070, Train Loss: 0.6358, Train MAE: 0.6358,
                            Val Loss: 0.6365, Val Acc: 0.6365, Test MAE: 0.6817
2022-09-04 03:53:28,734:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 32/1000
2022-09-04 03:54:12,486:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.75s, LR: 0.00070, Train Loss: 0.6344, Train MAE: 0.6344,
                            Val Loss: 0.6656, Val Acc: 0.6656, Test MAE: 0.7074
2022-09-04 03:54:12,493:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 33/1000
2022-09-04 03:54:56,496:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.00s, LR: 0.00035, Train Loss: 0.6293, Train MAE: 0.6293,
                            Val Loss: 0.6465, Val Acc: 0.6465, Test MAE: 0.6897
2022-09-04 03:54:56,504:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 34/1000
2022-09-04 03:55:39,874:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.37s, LR: 0.00035, Train Loss: 0.6377, Train MAE: 0.6377,
                            Val Loss: 0.6420, Val Acc: 0.6420, Test MAE: 0.6848
2022-09-04 03:55:39,882:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 35/1000
2022-09-04 03:56:23,361:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.48s, LR: 0.00035, Train Loss: 0.6390, Train MAE: 0.6390,
                            Val Loss: 0.6566, Val Acc: 0.6566, Test MAE: 0.7087
2022-09-04 03:56:23,367:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 36/1000
2022-09-04 03:57:06,146:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.78s, LR: 0.00035, Train Loss: 0.6261, Train MAE: 0.6261,
                            Val Loss: 0.6365, Val Acc: 0.6365, Test MAE: 0.6785
2022-09-04 03:57:06,153:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 37/1000
2022-09-04 03:57:48,960:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.81s, LR: 0.00035, Train Loss: 0.6236, Train MAE: 0.6236,
                            Val Loss: 0.6492, Val Acc: 0.6492, Test MAE: 0.6905
2022-09-04 03:57:48,968:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 38/1000
2022-09-04 03:59:26,187:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 97.22s, LR: 0.00035, Train Loss: 0.6298, Train MAE: 0.6298,
                            Val Loss: 0.6424, Val Acc: 0.6424, Test MAE: 0.6926
2022-09-04 03:59:26,195:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 39/1000
2022-09-04 04:00:11,263:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6769422888755798
2022-09-04 04:00:11,264:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 45.07s, LR: 0.00035, Train Loss: 0.6309, Train MAE: 0.6309,
                            Val Loss: 0.6333, Val Acc: 0.6333, Test MAE: 0.6769
2022-09-04 04:00:11,271:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 40/1000
2022-09-04 04:00:53,895:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.62s, LR: 0.00035, Train Loss: 0.6196, Train MAE: 0.6196,
                            Val Loss: 0.6446, Val Acc: 0.6446, Test MAE: 0.6918
2022-09-04 04:00:53,903:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 41/1000
2022-09-04 04:01:36,584:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.68s, LR: 0.00035, Train Loss: 0.6182, Train MAE: 0.6182,
                            Val Loss: 0.6410, Val Acc: 0.6410, Test MAE: 0.6875
2022-09-04 04:01:36,592:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 42/1000
2022-09-04 04:02:19,411:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.82s, LR: 0.00035, Train Loss: 0.6158, Train MAE: 0.6158,
                            Val Loss: 0.6465, Val Acc: 0.6465, Test MAE: 0.7013
2022-09-04 04:02:19,418:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 43/1000
2022-09-04 04:03:02,234:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.82s, LR: 0.00035, Train Loss: 0.6273, Train MAE: 0.6273,
                            Val Loss: 0.6357, Val Acc: 0.6357, Test MAE: 0.6889
2022-09-04 04:03:02,240:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 44/1000
2022-09-04 04:03:45,064:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.82s, LR: 0.00035, Train Loss: 0.6265, Train MAE: 0.6265,
                            Val Loss: 0.6597, Val Acc: 0.6597, Test MAE: 0.7018
2022-09-04 04:03:45,072:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 45/1000
2022-09-04 04:04:27,654:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.58s, LR: 0.00035, Train Loss: 0.6210, Train MAE: 0.6210,
                            Val Loss: 0.6531, Val Acc: 0.6531, Test MAE: 0.6943
2022-09-04 04:04:27,660:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 46/1000
2022-09-04 04:05:10,249:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.59s, LR: 0.00035, Train Loss: 0.6211, Train MAE: 0.6211,
                            Val Loss: 0.6648, Val Acc: 0.6648, Test MAE: 0.7079
2022-09-04 04:05:10,256:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 47/1000
2022-09-04 04:05:52,595:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.34s, LR: 0.00035, Train Loss: 0.6254, Train MAE: 0.6254,
                            Val Loss: 0.6539, Val Acc: 0.6539, Test MAE: 0.7074
2022-09-04 04:05:52,602:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 48/1000
2022-09-04 04:06:34,758:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.16s, LR: 0.00035, Train Loss: 0.6237, Train MAE: 0.6237,
                            Val Loss: 0.6417, Val Acc: 0.6417, Test MAE: 0.6878
2022-09-04 04:06:34,765:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 49/1000
2022-09-04 04:07:17,023:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.26s, LR: 0.00017, Train Loss: 0.6175, Train MAE: 0.6175,
                            Val Loss: 0.6520, Val Acc: 0.6520, Test MAE: 0.6975
2022-09-04 04:07:17,029:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 50/1000
2022-09-04 04:07:59,820:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.79s, LR: 0.00017, Train Loss: 0.6125, Train MAE: 0.6125,
                            Val Loss: 0.6450, Val Acc: 0.6450, Test MAE: 0.6894
2022-09-04 04:07:59,829:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 51/1000
2022-09-04 04:08:42,409:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.58s, LR: 0.00017, Train Loss: 0.6120, Train MAE: 0.6120,
                            Val Loss: 0.6323, Val Acc: 0.6323, Test MAE: 0.6801
2022-09-04 04:08:42,417:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 52/1000
2022-09-04 04:09:25,025:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.61s, LR: 0.00017, Train Loss: 0.6159, Train MAE: 0.6159,
                            Val Loss: 0.6421, Val Acc: 0.6421, Test MAE: 0.6842
2022-09-04 04:09:25,032:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 53/1000
2022-09-04 04:10:07,447:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.41s, LR: 0.00017, Train Loss: 0.6061, Train MAE: 0.6061,
                            Val Loss: 0.6564, Val Acc: 0.6564, Test MAE: 0.6992
2022-09-04 04:10:07,453:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 54/1000
2022-09-04 04:10:50,008:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.55s, LR: 0.00017, Train Loss: 0.6054, Train MAE: 0.6054,
                            Val Loss: 0.6304, Val Acc: 0.6304, Test MAE: 0.6811
2022-09-04 04:10:50,016:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 55/1000
2022-09-04 04:15:13,415:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 04:15:13,417:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 19:57:39,062:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 19:57:42,379:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': True, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 19:57:42,379:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 19:57:42,387:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 19:57:42,388:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 19:57:42,388:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 19:57:42,397:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 19:57:42,399:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 590161
2022-09-04 19:57:42,400:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 19:57:42,400:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 19:57:42,400:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 19:57:42,426:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 19:57:42,426:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 19:57:42,426:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 19:57:42,428:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 19:57:48,300:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 19:57:48,300:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:05:43,821:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:05:47,111:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': True, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:05:47,111:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 20:05:47,113:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 20:05:47,113:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 20:05:47,113:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 20:05:47,120:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:05:47,122:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 590161
2022-09-04 20:05:47,123:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 20:05:47,123:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 20:05:47,123:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 20:05:47,143:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:05:47,143:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:05:47,143:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:05:47,146:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:06:06,935:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.8701018691062927
2022-09-04 20:06:06,936:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.79s, LR: 0.00070, Train Loss: 0.9040, Train MAE: 0.9040,
                            Val Loss: 0.8164, Val Acc: 0.8164, Test MAE: 0.8701
2022-09-04 20:06:06,947:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 20:06:27,016:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6728567704558372
2022-09-04 20:06:27,017:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 20.07s, LR: 0.00070, Train Loss: 0.5937, Train MAE: 0.5937,
                            Val Loss: 0.6370, Val Acc: 0.6370, Test MAE: 0.6729
2022-09-04 20:06:27,027:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-04 20:06:46,675:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6361156776547432
2022-09-04 20:06:46,675:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.65s, LR: 0.00070, Train Loss: 0.5672, Train MAE: 0.5672,
                            Val Loss: 0.5904, Val Acc: 0.5904, Test MAE: 0.6361
2022-09-04 20:06:46,686:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-04 20:07:06,219:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6064362749457359
2022-09-04 20:07:06,219:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.53s, LR: 0.00070, Train Loss: 0.5471, Train MAE: 0.5471,
                            Val Loss: 0.5633, Val Acc: 0.5633, Test MAE: 0.6064
2022-09-04 20:07:06,230:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-04 20:07:25,785:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.56s, LR: 0.00070, Train Loss: 0.5317, Train MAE: 0.5317,
                            Val Loss: 0.5778, Val Acc: 0.5778, Test MAE: 0.6320
2022-09-04 20:07:25,797:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-04 20:07:46,077:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5764768570661545
2022-09-04 20:07:46,078:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 20.28s, LR: 0.00070, Train Loss: 0.5112, Train MAE: 0.5112,
                            Val Loss: 0.5291, Val Acc: 0.5291, Test MAE: 0.5765
2022-09-04 20:07:46,087:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-04 20:08:05,729:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5505077019333839
2022-09-04 20:08:05,730:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.64s, LR: 0.00070, Train Loss: 0.5231, Train MAE: 0.5231,
                            Val Loss: 0.5239, Val Acc: 0.5239, Test MAE: 0.5505
2022-09-04 20:08:05,740:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 8/1000
2022-09-04 20:08:25,208:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.47s, LR: 0.00070, Train Loss: 0.4820, Train MAE: 0.4820,
                            Val Loss: 0.5550, Val Acc: 0.5550, Test MAE: 0.5892
2022-09-04 20:08:25,218:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 9/1000
2022-09-04 20:08:44,618:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5259315744042397
2022-09-04 20:08:44,619:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.40s, LR: 0.00070, Train Loss: 0.4818, Train MAE: 0.4818,
                            Val Loss: 0.4806, Val Acc: 0.4806, Test MAE: 0.5259
2022-09-04 20:08:44,628:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 10/1000
2022-09-04 20:09:03,650:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.02s, LR: 0.00070, Train Loss: 0.4611, Train MAE: 0.4611,
                            Val Loss: 0.5116, Val Acc: 0.5116, Test MAE: 0.5507
2022-09-04 20:09:03,661:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 11/1000
2022-09-04 20:09:21,558:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5220943167805672
2022-09-04 20:09:21,558:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.90s, LR: 0.00070, Train Loss: 0.4551, Train MAE: 0.4551,
                            Val Loss: 0.4701, Val Acc: 0.4701, Test MAE: 0.5221
2022-09-04 20:09:21,568:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 12/1000
2022-09-04 20:09:39,052:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.48s, LR: 0.00070, Train Loss: 0.4501, Train MAE: 0.4501,
                            Val Loss: 0.5143, Val Acc: 0.5143, Test MAE: 0.5561
2022-09-04 20:09:39,062:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 13/1000
2022-09-04 20:09:56,374:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.31s, LR: 0.00070, Train Loss: 0.4441, Train MAE: 0.4441,
                            Val Loss: 0.5885, Val Acc: 0.5885, Test MAE: 0.6351
2022-09-04 20:09:56,383:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 14/1000
2022-09-04 20:10:13,590:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.505284558981657
2022-09-04 20:10:13,591:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.21s, LR: 0.00070, Train Loss: 0.4413, Train MAE: 0.4413,
                            Val Loss: 0.4724, Val Acc: 0.4724, Test MAE: 0.5053
2022-09-04 20:10:13,601:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 15/1000
2022-09-04 20:10:32,528:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 18.93s, LR: 0.00070, Train Loss: 0.4465, Train MAE: 0.4465,
                            Val Loss: 0.7567, Val Acc: 0.7567, Test MAE: 0.7867
2022-09-04 20:10:32,538:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 16/1000
2022-09-04 20:10:50,161:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.62s, LR: 0.00070, Train Loss: 0.4370, Train MAE: 0.4370,
                            Val Loss: 0.5800, Val Acc: 0.5800, Test MAE: 0.6140
2022-09-04 20:10:50,170:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 17/1000
2022-09-04 20:11:07,768:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4781503938138485
2022-09-04 20:11:07,768:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.60s, LR: 0.00070, Train Loss: 0.4466, Train MAE: 0.4466,
                            Val Loss: 0.4365, Val Acc: 0.4365, Test MAE: 0.4782
2022-09-04 20:11:07,778:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 18/1000
2022-09-04 20:11:25,084:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.31s, LR: 0.00070, Train Loss: 0.4494, Train MAE: 0.4494,
                            Val Loss: 0.4677, Val Acc: 0.4677, Test MAE: 0.4970
2022-09-04 20:11:25,093:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 19/1000
2022-09-04 20:11:42,449:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.36s, LR: 0.00070, Train Loss: 0.4305, Train MAE: 0.4305,
                            Val Loss: 0.4410, Val Acc: 0.4410, Test MAE: 0.4792
2022-09-04 20:11:42,460:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 20/1000
2022-09-04 20:11:59,821:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.36s, LR: 0.00070, Train Loss: 0.4215, Train MAE: 0.4215,
                            Val Loss: 0.5459, Val Acc: 0.5459, Test MAE: 0.5718
2022-09-04 20:11:59,830:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 21/1000
2022-09-04 20:12:17,236:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.41s, LR: 0.00070, Train Loss: 0.4238, Train MAE: 0.4238,
                            Val Loss: 0.4881, Val Acc: 0.4881, Test MAE: 0.5246
2022-09-04 20:12:17,246:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 22/1000
2022-09-04 20:12:34,557:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.47069478407502174
2022-09-04 20:12:34,558:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.31s, LR: 0.00070, Train Loss: 0.4059, Train MAE: 0.4059,
                            Val Loss: 0.4154, Val Acc: 0.4154, Test MAE: 0.4707
2022-09-04 20:12:34,568:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 23/1000
2022-09-04 20:12:51,919:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.35s, LR: 0.00070, Train Loss: 0.4105, Train MAE: 0.4105,
                            Val Loss: 0.4704, Val Acc: 0.4704, Test MAE: 0.5139
2022-09-04 20:12:51,929:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 24/1000
2022-09-04 20:13:09,425:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.45043299347162247
2022-09-04 20:13:09,426:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.50s, LR: 0.00070, Train Loss: 0.4082, Train MAE: 0.4082,
                            Val Loss: 0.4087, Val Acc: 0.4087, Test MAE: 0.4504
2022-09-04 20:13:09,435:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 25/1000
2022-09-04 20:13:27,508:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 18.07s, LR: 0.00070, Train Loss: 0.4126, Train MAE: 0.4126,
                            Val Loss: 0.4033, Val Acc: 0.4033, Test MAE: 0.4522
2022-09-04 20:13:27,518:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 26/1000
2022-09-04 20:13:46,384:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 18.87s, LR: 0.00070, Train Loss: 0.4043, Train MAE: 0.4043,
                            Val Loss: 0.4428, Val Acc: 0.4428, Test MAE: 0.4797
2022-09-04 20:13:46,395:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 27/1000
2022-09-04 20:14:05,553:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.16s, LR: 0.00070, Train Loss: 0.4060, Train MAE: 0.4060,
                            Val Loss: 0.4327, Val Acc: 0.4327, Test MAE: 0.4965
2022-09-04 20:14:05,563:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 28/1000
2022-09-04 20:14:24,561:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 19.00s, LR: 0.00070, Train Loss: 0.3944, Train MAE: 0.3944,
                            Val Loss: 0.4413, Val Acc: 0.4413, Test MAE: 0.4879
2022-09-04 20:14:24,571:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 29/1000
2022-09-04 20:14:30,315:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:14:30,315:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:18:11,036:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:18:15,127:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:18:15,128:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'sav'}
2022-09-04 20:18:15,148:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:18:15,149:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:18:15,156:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:18:43,052:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:27.903053045272827
2022-09-04 20:18:43,087:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:18:43,087:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:18:43,087:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:18:43,092:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:19:23,726:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:19:27,635:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:19:27,635:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'sav'}
2022-09-04 20:19:27,642:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:19:27,643:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:19:27,650:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:19:55,195:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:27.55139398574829
2022-09-04 20:19:55,220:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:19:55,220:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:19:55,220:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:19:55,223:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:20:10,695:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:20:14,707:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:20:14,708:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'sav'}
2022-09-04 20:20:14,715:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:20:14,716:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:20:14,723:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:20:42,266:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:27.54917883872986
2022-09-04 20:20:42,289:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:20:42,290:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:20:42,290:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:20:42,293:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:20:58,929:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:21:02,869:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 64, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:21:02,869:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 64, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'sav'}
2022-09-04 20:21:02,876:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:21:02,877:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:21:02,883:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:21:24,329:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:21.452038764953613
2022-09-04 20:21:24,351:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:21:24,353:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:21:24,353:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:21:24,356:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:21:33,553:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:21:37,523:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 1, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:21:37,523:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 1, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'sav'}
2022-09-04 20:21:37,530:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:21:37,531:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:21:37,538:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:21:59,132:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:21.60025405883789
2022-09-04 20:21:59,156:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:21:59,157:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:21:59,158:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:21:59,161:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:22:11,140:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:22:14,315:main_molecules_graph_regression.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': True, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:22:14,315:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'save'}
2022-09-04 20:22:14,324:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 20:22:14,325:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 20:22:14,325:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 20:22:14,334:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:22:14,336:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 590161
2022-09-04 20:22:14,337:pe_layer.py:68 -             __init__(): no_pe
2022-09-04 20:22:14,337:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-04 20:22:14,337:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-04 20:22:14,361:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:22:14,361:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:22:14,362:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:22:14,364:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:22:21,465:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:22:21,465:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:22:52,729:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:22:55,913:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:22:55,913:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:22:55,918:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:22:55,919:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:22:55,924:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:23:11,318:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.39981198310852
2022-09-04 20:23:11,333:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:23:11,333:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:23:11,333:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:23:11,334:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:23:35,615:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:23:38,812:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:23:38,812:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:23:38,817:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:23:38,818:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:23:38,822:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:23:53,911:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.09325623512268
2022-09-04 20:23:53,926:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:23:53,926:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:23:53,927:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:23:53,930:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:24:10,043:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:24:13,242:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:24:13,242:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:24:13,247:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:24:13,248:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:24:13,253:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:24:28,294:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.04521894454956
2022-09-04 20:24:28,308:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:24:28,308:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:24:28,308:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:24:28,310:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:24:43,857:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.465291053056717
2022-09-04 20:24:43,858:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.55s, LR: 0.00070, Train Loss: 1.4478, Train MAE: 1.4478,
                            Val Loss: 1.3804, Val Acc: 1.3804, Test MAE: 1.4653
2022-09-04 20:24:43,866:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 20:24:59,388:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4435663670301437
2022-09-04 20:24:59,389:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.52s, LR: 0.00070, Train Loss: 1.3921, Train MAE: 1.3921,
                            Val Loss: 1.3529, Val Acc: 1.3529, Test MAE: 1.4436
2022-09-04 20:24:59,394:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-04 20:25:15,054:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4155022650957108
2022-09-04 20:25:15,054:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.66s, LR: 0.00070, Train Loss: 1.3800, Train MAE: 1.3800,
                            Val Loss: 1.3342, Val Acc: 1.3342, Test MAE: 1.4155
2022-09-04 20:25:15,060:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-04 20:25:30,642:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.58s, LR: 0.00070, Train Loss: 1.3558, Train MAE: 1.3558,
                            Val Loss: 1.4041, Val Acc: 1.4041, Test MAE: 1.4793
2022-09-04 20:25:30,648:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-04 20:25:46,218:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3840893507003784
2022-09-04 20:25:46,218:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.57s, LR: 0.00070, Train Loss: 1.3414, Train MAE: 1.3414,
                            Val Loss: 1.3350, Val Acc: 1.3350, Test MAE: 1.3841
2022-09-04 20:25:46,226:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-04 20:25:52,806:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:25:52,807:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:25:55,314:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:25:58,648:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:25:58,648:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:25:58,653:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:25:58,654:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:25:58,659:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:26:14,214:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.559467792510986
2022-09-04 20:26:14,229:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:26:14,229:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:26:14,229:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:26:14,231:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:26:30,106:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4880936592817307
2022-09-04 20:26:30,108:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.88s, LR: 0.00070, Train Loss: 1.4330, Train MAE: 1.4330,
                            Val Loss: 1.4032, Val Acc: 1.4032, Test MAE: 1.4881
2022-09-04 20:26:30,114:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 20:26:30,865:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:26:30,865:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:32:03,626:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:32:06,767:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:32:06,767:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:32:06,772:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:32:06,773:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:32:06,778:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:32:23,276:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:16.50282883644104
2022-09-04 20:32:23,292:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:32:23,293:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:32:23,293:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:32:23,295:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:32:25,137:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:32:25,137:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:33:09,389:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:33:12,605:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:33:12,605:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:33:12,610:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:33:12,611:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:33:12,616:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:33:27,684:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.072556018829346
2022-09-04 20:33:27,697:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:33:27,698:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:33:27,698:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:33:27,701:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:33:43,580:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.484168902039528
2022-09-04 20:33:43,582:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.88s, LR: 0.00070, Train Loss: 1.4604, Train MAE: 1.4604,
                            Val Loss: 1.3848, Val Acc: 1.3848, Test MAE: 1.4842
2022-09-04 20:33:43,587:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 20:33:46,783:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:33:46,783:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:33:53,940:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:33:57,124:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:33:57,124:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:33:57,129:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:33:57,130:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:33:57,135:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:34:12,108:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.97815203666687
2022-09-04 20:34:12,123:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:34:12,123:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:34:12,123:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:34:12,127:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:34:14,605:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:34:14,605:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 20:34:30,422:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 20:34:33,588:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 20:34:33,588:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 20:34:33,593:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 20:34:33,594:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 20:34:33,599:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 20:34:48,588:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.993796110153198
2022-09-04 20:34:48,602:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 20:34:48,602:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 20:34:48,602:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 20:34:48,605:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 20:34:52,732:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 20:34:52,732:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 21:45:52,092:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:45:55,288:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:45:55,288:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:45:55,301:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:45:55,301:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:45:55,307:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:46:10,477:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.175107717514038
2022-09-04 21:46:10,494:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:46:10,494:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:46:10,494:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:46:10,499:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:46:25,993:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4640635401010513
2022-09-04 21:46:25,994:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.49s, LR: 0.00070, Train Loss: 1.4465, Train MAE: 1.4465,
                            Val Loss: 1.3796, Val Acc: 1.3796, Test MAE: 1.4641
2022-09-04 21:46:26,000:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 21:46:30,675:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 21:46:30,675:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 21:46:49,224:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:46:52,412:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:46:52,412:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:46:52,417:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:46:52,418:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:46:52,423:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:47:07,414:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.995660781860352
2022-09-04 21:47:07,427:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:47:07,427:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:47:07,427:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:47:07,429:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:47:10,489:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 21:47:10,490:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 21:48:05,104:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:48:08,311:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:48:08,311:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:48:08,316:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:48:08,317:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:48:08,322:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:48:23,333:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.015681982040405
2022-09-04 21:48:23,346:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:48:23,346:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:48:23,346:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:48:23,348:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:48:25,094:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 21:48:25,094:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 21:48:45,960:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:48:49,123:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:48:49,123:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:48:49,128:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:48:49,129:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:48:49,133:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:49:04,125:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.996179819107056
2022-09-04 21:49:04,140:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:49:04,140:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:49:04,140:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:49:04,142:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:49:05,723:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 21:49:05,723:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 21:50:13,680:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:50:16,855:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:50:16,855:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:50:16,860:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:50:16,861:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:50:16,866:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:50:31,990:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.129515886306763
2022-09-04 21:50:32,004:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:50:32,004:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:50:32,004:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:50:32,006:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:50:33,696:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 21:50:33,696:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 21:50:46,595:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:50:49,785:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:50:49,785:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:50:49,790:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:50:49,790:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:50:49,795:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:51:04,952:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.160933017730713
2022-09-04 21:51:04,965:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:51:04,965:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:51:04,965:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:51:04,967:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:51:07,075:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 21:51:07,075:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 21:51:34,502:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:51:37,826:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:51:37,826:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:51:37,831:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:51:37,831:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:51:37,837:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:51:53,223:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.391372203826904
2022-09-04 21:51:53,237:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:51:53,237:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:51:53,237:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:51:53,239:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:52:56,994:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:53:00,155:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:53:00,156:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:53:00,161:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:53:00,162:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:53:00,167:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:53:15,909:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.747262001037598
2022-09-04 21:53:15,924:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:53:15,924:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:53:15,924:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:53:15,926:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:56:20,609:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:56:23,779:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:56:23,779:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:56:23,784:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:56:23,785:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:56:23,790:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:56:38,755:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.96984314918518
2022-09-04 21:56:38,768:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:56:38,768:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:56:38,768:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:56:38,770:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 21:57:20,146:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 21:57:23,434:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 21:57:23,435:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 21:57:23,439:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 21:57:23,440:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 21:57:23,445:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 21:57:38,550:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.109447956085205
2022-09-04 21:57:38,564:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 21:57:38,564:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 21:57:38,564:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 21:57:38,566:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:01:36,394:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 22:01:39,586:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 22:01:39,586:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 22:01:39,591:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 22:01:39,591:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 22:01:39,596:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 22:01:54,660:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.06840968132019
2022-09-04 22:01:54,674:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 22:01:54,674:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 22:01:54,674:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 22:01:54,676:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:02:01,502:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 22:02:01,502:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 22:02:22,509:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 22:02:25,745:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 22:02:25,745:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 22:02:25,750:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 22:02:25,751:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 22:02:25,756:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 22:02:40,741:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.990229845046997
2022-09-04 22:02:40,756:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 22:02:40,756:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 22:02:40,756:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 22:02:40,758:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:02:44,777:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 22:02:44,777:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 22:02:52,749:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 22:02:55,967:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 22:02:55,967:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 22:02:55,972:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 22:02:55,973:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 22:02:55,978:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 22:03:11,506:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.533339023590088
2022-09-04 22:03:11,523:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 22:03:11,523:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 22:03:11,523:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 22:03:11,525:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:03:53,938:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4593064934015274
2022-09-04 22:03:53,939:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.41s, LR: 0.00070, Train Loss: 1.4347, Train MAE: 1.4347,
                            Val Loss: 1.3697, Val Acc: 1.3697, Test MAE: 1.4593
2022-09-04 22:03:53,945:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 22:04:36,483:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4408935010433197
2022-09-04 22:04:36,483:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.54s, LR: 0.00070, Train Loss: 1.3912, Train MAE: 1.3912,
                            Val Loss: 1.3589, Val Acc: 1.3589, Test MAE: 1.4409
2022-09-04 22:04:36,489:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-04 22:05:19,069:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.58s, LR: 0.00070, Train Loss: 1.3839, Train MAE: 1.3839,
                            Val Loss: 1.3971, Val Acc: 1.3971, Test MAE: 1.4741
2022-09-04 22:05:19,075:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-04 22:06:00,697:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.435899704694748
2022-09-04 22:06:00,698:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.62s, LR: 0.00070, Train Loss: 1.3787, Train MAE: 1.3787,
                            Val Loss: 1.3690, Val Acc: 1.3690, Test MAE: 1.4359
2022-09-04 22:06:00,703:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-04 22:06:42,018:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4155939668416977
2022-09-04 22:06:42,019:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.32s, LR: 0.00070, Train Loss: 1.3604, Train MAE: 1.3604,
                            Val Loss: 1.3458, Val Acc: 1.3458, Test MAE: 1.4156
2022-09-04 22:06:42,024:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-04 22:07:23,986:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.96s, LR: 0.00070, Train Loss: 1.3394, Train MAE: 1.3394,
                            Val Loss: 1.3634, Val Acc: 1.3634, Test MAE: 1.4373
2022-09-04 22:07:23,991:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-04 22:08:08,985:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3709962666034698
2022-09-04 22:08:08,985:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.99s, LR: 0.00070, Train Loss: 1.3613, Train MAE: 1.3613,
                            Val Loss: 1.3067, Val Acc: 1.3067, Test MAE: 1.3710
2022-09-04 22:08:08,991:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 8/1000
2022-09-04 22:08:51,212:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3685062676668167
2022-09-04 22:08:51,212:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.22s, LR: 0.00070, Train Loss: 1.3051, Train MAE: 1.3051,
                            Val Loss: 1.2935, Val Acc: 1.2935, Test MAE: 1.3685
2022-09-04 22:08:51,218:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 9/1000
2022-09-04 22:09:33,609:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.39s, LR: 0.00070, Train Loss: 1.2944, Train MAE: 1.2944,
                            Val Loss: 1.3036, Val Acc: 1.3036, Test MAE: 1.3855
2022-09-04 22:09:33,614:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 10/1000
2022-09-04 22:10:15,482:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3659293353557587
2022-09-04 22:10:15,483:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.87s, LR: 0.00070, Train Loss: 1.2924, Train MAE: 1.2924,
                            Val Loss: 1.3007, Val Acc: 1.3007, Test MAE: 1.3659
2022-09-04 22:10:15,488:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 11/1000
2022-09-04 22:10:57,258:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3353416174650192
2022-09-04 22:10:57,258:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.77s, LR: 0.00070, Train Loss: 1.2855, Train MAE: 1.2855,
                            Val Loss: 1.2902, Val Acc: 1.2902, Test MAE: 1.3353
2022-09-04 22:10:57,264:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 12/1000
2022-09-04 22:11:39,317:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3225348144769669
2022-09-04 22:11:39,318:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.05s, LR: 0.00070, Train Loss: 1.2923, Train MAE: 1.2923,
                            Val Loss: 1.2633, Val Acc: 1.2633, Test MAE: 1.3225
2022-09-04 22:11:39,323:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 13/1000
2022-09-04 22:12:21,429:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.11s, LR: 0.00070, Train Loss: 1.2724, Train MAE: 1.2724,
                            Val Loss: 1.3274, Val Acc: 1.3274, Test MAE: 1.3660
2022-09-04 22:12:21,435:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 14/1000
2022-09-04 22:13:03,441:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.01s, LR: 0.00070, Train Loss: 1.2797, Train MAE: 1.2797,
                            Val Loss: 1.2851, Val Acc: 1.2851, Test MAE: 1.3298
2022-09-04 22:13:03,447:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 15/1000
2022-09-04 22:13:46,020:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.3026692122220993
2022-09-04 22:13:46,020:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.57s, LR: 0.00070, Train Loss: 1.2559, Train MAE: 1.2559,
                            Val Loss: 1.2734, Val Acc: 1.2734, Test MAE: 1.3027
2022-09-04 22:13:46,026:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 16/1000
2022-09-04 22:14:28,196:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.17s, LR: 0.00070, Train Loss: 1.2684, Train MAE: 1.2684,
                            Val Loss: 1.2532, Val Acc: 1.2532, Test MAE: 1.3029
2022-09-04 22:14:28,202:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 17/1000
2022-09-04 22:15:10,490:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.29s, LR: 0.00070, Train Loss: 1.2738, Train MAE: 1.2738,
                            Val Loss: 1.3181, Val Acc: 1.3181, Test MAE: 1.3592
2022-09-04 22:15:10,496:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 18/1000
2022-09-04 22:15:52,484:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.99s, LR: 0.00070, Train Loss: 1.2758, Train MAE: 1.2758,
                            Val Loss: 1.2816, Val Acc: 1.2816, Test MAE: 1.3234
2022-09-04 22:15:52,490:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 19/1000
2022-09-04 22:16:34,621:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.298151820898056
2022-09-04 22:16:34,622:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.13s, LR: 0.00070, Train Loss: 1.2674, Train MAE: 1.2674,
                            Val Loss: 1.2561, Val Acc: 1.2561, Test MAE: 1.2982
2022-09-04 22:16:34,627:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 20/1000
2022-09-04 22:17:16,211:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.58s, LR: 0.00070, Train Loss: 1.2543, Train MAE: 1.2543,
                            Val Loss: 1.3041, Val Acc: 1.3041, Test MAE: 1.3216
2022-09-04 22:17:16,217:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 21/1000
2022-09-04 22:17:58,191:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.2924308478832245
2022-09-04 22:17:58,192:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.97s, LR: 0.00070, Train Loss: 1.2624, Train MAE: 1.2624,
                            Val Loss: 1.2641, Val Acc: 1.2641, Test MAE: 1.2924
2022-09-04 22:17:58,197:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 22/1000
2022-09-04 22:18:40,143:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.2899418771266937
2022-09-04 22:18:40,144:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.95s, LR: 0.00070, Train Loss: 1.2638, Train MAE: 1.2638,
                            Val Loss: 1.2648, Val Acc: 1.2648, Test MAE: 1.2899
2022-09-04 22:18:40,149:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 23/1000
2022-09-04 22:19:22,149:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.00s, LR: 0.00070, Train Loss: 1.2746, Train MAE: 1.2746,
                            Val Loss: 1.4441, Val Acc: 1.4441, Test MAE: 1.4861
2022-09-04 22:19:22,155:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 24/1000
2022-09-04 22:20:03,894:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.74s, LR: 0.00070, Train Loss: 1.2810, Train MAE: 1.2810,
                            Val Loss: 1.3055, Val Acc: 1.3055, Test MAE: 1.3530
2022-09-04 22:20:03,900:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 25/1000
2022-09-04 22:20:45,859:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.96s, LR: 0.00070, Train Loss: 1.2690, Train MAE: 1.2690,
                            Val Loss: 1.2689, Val Acc: 1.2689, Test MAE: 1.2957
2022-09-04 22:20:45,865:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 26/1000
2022-09-04 22:21:27,563:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.70s, LR: 0.00070, Train Loss: 1.2652, Train MAE: 1.2652,
                            Val Loss: 1.2800, Val Acc: 1.2800, Test MAE: 1.3130
2022-09-04 22:21:27,569:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 27/1000
2022-09-04 22:22:09,080:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.51s, LR: 0.00070, Train Loss: 1.2570, Train MAE: 1.2570,
                            Val Loss: 1.2610, Val Acc: 1.2610, Test MAE: 1.2983
2022-09-04 22:22:09,086:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 28/1000
2022-09-04 22:22:50,995:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.2874029725790024
2022-09-04 22:22:50,995:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.91s, LR: 0.00035, Train Loss: 1.2347, Train MAE: 1.2347,
                            Val Loss: 1.2419, Val Acc: 1.2419, Test MAE: 1.2874
2022-09-04 22:22:51,001:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 29/1000
2022-09-04 22:23:32,851:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.263063833117485
2022-09-04 22:23:32,852:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.85s, LR: 0.00035, Train Loss: 1.2272, Train MAE: 1.2272,
                            Val Loss: 1.2289, Val Acc: 1.2289, Test MAE: 1.2631
2022-09-04 22:23:32,857:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 30/1000
2022-09-04 22:24:14,790:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.2582636028528214
2022-09-04 22:24:14,791:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.93s, LR: 0.00035, Train Loss: 1.2257, Train MAE: 1.2257,
                            Val Loss: 1.2376, Val Acc: 1.2376, Test MAE: 1.2583
2022-09-04 22:24:14,796:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 31/1000
2022-09-04 22:24:56,525:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 41.73s, LR: 0.00035, Train Loss: 1.2225, Train MAE: 1.2225,
                            Val Loss: 1.2434, Val Acc: 1.2434, Test MAE: 1.2732
2022-09-04 22:24:56,531:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 32/1000
2022-09-04 22:25:38,768:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.24s, LR: 0.00035, Train Loss: 1.2148, Train MAE: 1.2148,
                            Val Loss: 1.2466, Val Acc: 1.2466, Test MAE: 1.2700
2022-09-04 22:25:38,773:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 33/1000
2022-09-04 22:26:21,718:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.94s, LR: 0.00035, Train Loss: 1.2149, Train MAE: 1.2149,
                            Val Loss: 1.2445, Val Acc: 1.2445, Test MAE: 1.2715
2022-09-04 22:26:21,724:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 34/1000
2022-09-04 22:27:05,008:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.28s, LR: 0.00035, Train Loss: 1.2108, Train MAE: 1.2108,
                            Val Loss: 1.2366, Val Acc: 1.2366, Test MAE: 1.2797
2022-09-04 22:27:05,013:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 35/1000
2022-09-04 22:27:49,682:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 44.67s, LR: 0.00035, Train Loss: 1.2127, Train MAE: 1.2127,
                            Val Loss: 1.2385, Val Acc: 1.2385, Test MAE: 1.2907
2022-09-04 22:27:49,687:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 36/1000
2022-09-04 22:28:33,338:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 43.65s, LR: 0.00035, Train Loss: 1.2009, Train MAE: 1.2009,
                            Val Loss: 1.2517, Val Acc: 1.2517, Test MAE: 1.2966
2022-09-04 22:28:33,344:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 37/1000
2022-09-04 22:29:16,127:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.78s, LR: 0.00035, Train Loss: 1.2088, Train MAE: 1.2088,
                            Val Loss: 1.2504, Val Acc: 1.2504, Test MAE: 1.2742
2022-09-04 22:29:16,133:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 38/1000
2022-09-04 22:29:58,376:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.251023143529892
2022-09-04 22:29:58,376:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.24s, LR: 0.00035, Train Loss: 1.1986, Train MAE: 1.1986,
                            Val Loss: 1.2226, Val Acc: 1.2226, Test MAE: 1.2510
2022-09-04 22:29:58,382:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 39/1000
2022-09-04 22:30:40,789:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.41s, LR: 0.00035, Train Loss: 1.2074, Train MAE: 1.2074,
                            Val Loss: 1.2241, Val Acc: 1.2241, Test MAE: 1.2778
2022-09-04 22:30:40,795:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 40/1000
2022-09-04 22:31:23,360:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.57s, LR: 0.00035, Train Loss: 1.2020, Train MAE: 1.2020,
                            Val Loss: 1.2464, Val Acc: 1.2464, Test MAE: 1.2703
2022-09-04 22:31:23,366:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 41/1000
2022-09-04 22:32:06,113:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.75s, LR: 0.00035, Train Loss: 1.2076, Train MAE: 1.2076,
                            Val Loss: 1.2272, Val Acc: 1.2272, Test MAE: 1.2778
2022-09-04 22:32:06,118:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 42/1000
2022-09-04 22:32:48,976:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.86s, LR: 0.00035, Train Loss: 1.2007, Train MAE: 1.2007,
                            Val Loss: 1.2283, Val Acc: 1.2283, Test MAE: 1.2754
2022-09-04 22:32:48,982:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 43/1000
2022-09-04 22:33:19,522:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 22:33:19,522:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 22:35:07,286:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 22:35:10,424:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 22:35:10,424:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 22:35:10,429:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 22:35:10,429:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 22:35:10,434:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 22:35:25,380:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.95058822631836
2022-09-04 22:35:25,395:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 22:35:25,395:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 22:35:25,395:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 22:35:25,397:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:35:26,713:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 22:35:26,713:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 22:37:00,446:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 22:37:03,583:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 22:37:03,583:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 22:37:03,588:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 22:37:03,589:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 22:37:03,594:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 22:37:18,878:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.289631128311157
2022-09-04 22:37:18,893:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 22:37:18,893:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 22:37:18,894:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 22:37:18,895:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:37:24,811:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 22:37:24,811:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 22:37:33,593:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 22:37:36,735:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 22:37:36,735:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 22:37:36,740:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 22:37:36,741:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 22:37:36,746:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 22:37:51,682:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.940173149108887
2022-09-04 22:37:51,696:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 22:37:51,696:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 22:37:51,696:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 22:37:51,697:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:38:34,065:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4754641354084015
2022-09-04 22:38:34,067:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 42.37s, LR: 0.00070, Train Loss: 1.4382, Train MAE: 1.4382,
                            Val Loss: 1.3757, Val Acc: 1.3757, Test MAE: 1.4755
2022-09-04 22:38:34,072:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-04 22:38:42,951:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 22:38:42,951:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-04 22:56:27,247:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-04 22:56:30,421:main_molecules_graph_regression.py:340 -                 main(): {'L': 9, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': False, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-04 22:56:30,421:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1, 'save_name': 'save'}
2022-09-04 22:56:30,426:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-04 22:56:30,427:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 484145
2022-09-04 22:56:30,432:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-04 22:56:45,404:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.97688913345337
2022-09-04 22:56:45,420:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-04 22:56:45,420:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-04 22:56:45,420:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-04 22:56:45,422:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-04 22:56:48,664:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-04 22:56:48,664:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 01:49:01,532:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:49:07,607:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:49:07,607:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 01:49:07,611:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:49:07,628:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:49:07,628:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:49:07,628:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:49:07,639:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:49:07,641:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526866
2022-09-05 01:49:07,644:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:49:07,645:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:49:07,645:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:49:07,645:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:49:08,161:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 01:49:08,162:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:49:08,950:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:1.2900540828704834
2022-09-05 01:49:08,952:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 10
2022-09-05 01:49:08,952:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 10
2022-09-05 01:49:08,952:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 10
2022-09-05 01:49:08,953:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 01:49:08,956:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 01:49:09,970:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 45.8354 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:09,970:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.01s, LR: 0.00050, Train Loss: 0.6952, Train Acc: 50.3013,
                        Val Loss: 0.7025, Val Acc: 45.0420, Test Acc: 45.8354
2022-09-05 01:49:09,970:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 01:49:10,917:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 56.2928 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:10,917:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.95s, LR: 0.00050, Train Loss: 0.6684, Train Acc: 63.2868,
                        Val Loss: 0.6902, Val Acc: 55.3908, Test Acc: 56.2928
2022-09-05 01:49:10,917:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 01:49:11,889:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.97s, LR: 0.00050, Train Loss: 0.6532, Train Acc: 64.0994,
                        Val Loss: 0.6779, Val Acc: 55.9690, Test Acc: 56.2504
2022-09-05 01:49:11,889:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 01:49:12,818:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 58.8226 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:12,818:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.6425, Train Acc: 64.7405,
                        Val Loss: 0.6678, Val Acc: 57.9813, Test Acc: 58.8226
2022-09-05 01:49:12,819:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 01:49:13,714:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 62.6497 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:13,715:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.6344, Train Acc: 64.1636,
                        Val Loss: 0.6603, Val Acc: 61.8249, Test Acc: 62.6497
2022-09-05 01:49:13,715:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 01:49:14,646:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 66.9310 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:14,646:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.6274, Train Acc: 65.2390,
                        Val Loss: 0.6545, Val Acc: 61.1693, Test Acc: 66.9310
2022-09-05 01:49:14,646:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 01:49:15,628:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 67.7643 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:15,628:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.98s, LR: 0.00050, Train Loss: 0.6208, Train Acc: 66.4354,
                        Val Loss: 0.6503, Val Acc: 63.4561, Test Acc: 67.7643
2022-09-05 01:49:15,628:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 01:49:16,540:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 69.1367 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:16,540:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.6136, Train Acc: 66.9979,
                        Val Loss: 0.6465, Val Acc: 63.7016, Test Acc: 69.1367
2022-09-05 01:49:16,540:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 01:49:17,498:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 70.2214 to out/SBMs_node_classification_b26-bnorm-alt-ngape3-lincomb-nosoftmaxcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_8_8_01h49m07s_on_Sep_05_2022/MODELS_
2022-09-05 01:49:17,498:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.6055, Train Acc: 67.5889,
                        Val Loss: 0.6425, Val Acc: 63.5853, Test Acc: 70.2214
2022-09-05 01:49:17,498:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 01:49:18,402:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.5968, Train Acc: 68.9562,
                        Val Loss: 0.6382, Val Acc: 64.0730, Test Acc: 69.5545
2022-09-05 01:49:18,403:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 01:49:19,344:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.5876, Train Acc: 70.2238,
                        Val Loss: 0.6332, Val Acc: 65.5491, Test Acc: 69.3550
2022-09-05 01:49:19,344:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 01:49:20,303:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.5776, Train Acc: 71.7406,
                        Val Loss: 0.6276, Val Acc: 66.7345, Test Acc: 69.8582
2022-09-05 01:49:20,303:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 01:49:21,216:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.5669, Train Acc: 72.9085,
                        Val Loss: 0.6205, Val Acc: 67.4354, Test Acc: 69.3451
2022-09-05 01:49:21,216:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 01:49:22,153:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.5555, Train Acc: 73.2788,
                        Val Loss: 0.6128, Val Acc: 67.3385, Test Acc: 69.0182
2022-09-05 01:49:22,153:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 01:49:23,085:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.5435, Train Acc: 74.7244,
                        Val Loss: 0.6064, Val Acc: 68.0652, Test Acc: 68.5018
2022-09-05 01:49:23,085:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 01:49:24,044:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.5309, Train Acc: 75.3154,
                        Val Loss: 0.6021, Val Acc: 69.5284, Test Acc: 68.7697
2022-09-05 01:49:24,044:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 01:49:25,001:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.5177, Train Acc: 76.2911,
                        Val Loss: 0.6026, Val Acc: 68.9503, Test Acc: 68.3839
2022-09-05 01:49:25,001:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 01:49:25,910:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.5036, Train Acc: 77.8722,
                        Val Loss: 0.6085, Val Acc: 68.2138, Test Acc: 67.2171
2022-09-05 01:49:25,910:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 01:49:26,841:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.4887, Train Acc: 79.5530,
                        Val Loss: 0.6216, Val Acc: 67.9845, Test Acc: 66.6092
2022-09-05 01:49:26,841:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 01:49:27,741:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4727, Train Acc: 81.0059,
                        Val Loss: 0.6389, Val Acc: 69.3023, Test Acc: 66.5602
2022-09-05 01:49:27,741:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 01:49:28,266:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 01:49:28,266:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 01:50:22,024:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:50:27,764:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:50:27,765:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 01:50:27,767:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:50:27,768:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:50:27,768:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:50:27,770:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:50:27,778:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:50:27,779:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532090
2022-09-05 01:50:27,780:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:50:27,781:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:50:27,781:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:50:27,781:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:50:28,221:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 01:50:28,221:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:50:35,842:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:50:41,449:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 32, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:50:41,449:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 01:50:41,450:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:50:41,452:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:50:41,452:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:50:41,452:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:50:41,457:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:50:41,458:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 546762
2022-09-05 01:50:41,459:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:50:41,460:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:50:41,460:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:50:41,460:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:50:42,085:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 01:50:42,085:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:50:48,022:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:50:53,193:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:50:53,193:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 01:50:53,194:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:50:53,197:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:50:53,197:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:50:53,197:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:50:53,202:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:50:53,203:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 593002
2022-09-05 01:50:53,204:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:50:53,205:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:50:53,205:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:50:53,205:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:50:53,841:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:50:53,842:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:51:17,096:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:51:22,379:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:51:22,379:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 01:51:22,381:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:51:22,383:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:51:22,383:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:51:22,383:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:51:22,387:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:51:22,388:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 492728
2022-09-05 01:51:22,390:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:51:22,391:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:51:22,391:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:51:22,391:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:51:22,958:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:51:22,959:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:51:30,925:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:51:35,953:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:51:35,953:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 01:51:35,955:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:51:35,956:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:51:35,956:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:51:35,956:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:51:35,961:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:51:35,962:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 501370
2022-09-05 01:51:35,963:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:51:35,965:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:51:35,965:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:51:35,965:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:51:36,549:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:51:36,549:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:52:35,872:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:52:41,080:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:52:41,080:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:52:41,085:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:52:41,092:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:52:41,092:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:52:41,092:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:52:41,097:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:52:41,098:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 779899
2022-09-05 01:52:41,100:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:52:41,103:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:52:41,103:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:52:41,103:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:52:41,578:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:52:41,578:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 01:52:59,214:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:53:04,314:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:53:04,314:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:53:04,316:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:53:04,319:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:53:04,319:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:53:04,319:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:53:04,323:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:53:04,324:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 677057
2022-09-05 01:53:04,326:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:53:04,329:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:53:04,329:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:53:04,329:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:53:04,842:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:53:04,842:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 01:53:15,253:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:53:20,442:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:53:20,442:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:53:20,444:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:53:20,447:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:53:20,448:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:53:20,448:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:53:20,452:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:53:20,453:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 584535
2022-09-05 01:53:20,454:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:53:20,458:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:53:20,458:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:53:20,458:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:53:20,976:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:53:20,976:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 01:54:03,034:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:54:08,083:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:54:08,083:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:54:08,084:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:54:08,086:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:54:08,086:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:54:08,086:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:54:08,091:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:54:08,092:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 411095
2022-09-05 01:54:08,093:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:54:08,095:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:54:08,095:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:54:08,095:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:54:08,621:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:54:08,621:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 01:54:21,239:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:54:26,310:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:54:26,311:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:54:26,312:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:54:26,314:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:54:26,314:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:54:26,314:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:54:26,319:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:54:26,319:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 602363
2022-09-05 01:54:26,321:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:54:26,322:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:54:26,323:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:54:26,323:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:54:26,881:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:54:26,881:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 01:54:36,340:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:54:41,264:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:54:41,264:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:54:41,265:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:54:41,267:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:54:41,267:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:54:41,267:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:54:41,272:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:54:41,273:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 501569
2022-09-05 01:54:41,274:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:54:41,275:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:54:41,275:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:54:41,275:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:54:41,797:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:54:41,797:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 01:55:12,425:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:55:17,380:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 32, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:55:17,380:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:55:17,382:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:55:17,383:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:55:17,383:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:55:17,383:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:55:17,388:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:55:17,389:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 550459
2022-09-05 01:55:17,390:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:55:17,391:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:55:17,391:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:55:17,391:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:55:18,035:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 01:55:18,035:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 01:55:41,987:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:55:47,234:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:55:47,234:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:55:47,236:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:55:47,239:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:55:47,239:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:55:47,239:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:55:47,244:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:55:47,245:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 753066
2022-09-05 01:55:47,246:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:55:47,249:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:55:47,249:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:55:47,249:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:55:47,827:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:55:47,827:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:55:59,809:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:56:04,586:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:56:04,586:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:56:04,588:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:56:04,591:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:56:04,591:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:56:04,591:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:56:04,596:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:56:04,597:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 559766
2022-09-05 01:56:04,598:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:56:04,601:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:56:04,601:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:56:04,601:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:56:05,140:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:56:05,140:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 01:57:27,115:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:57:32,229:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:57:32,229:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:57:32,231:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:57:32,237:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:57:32,237:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:57:32,237:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:57:32,242:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:57:32,243:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 887231
2022-09-05 01:57:32,245:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:57:32,250:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:57:32,251:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:57:32,251:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:57:32,767:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:57:32,768:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 01:57:43,042:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:57:47,968:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:57:47,968:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:57:47,969:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:57:47,975:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:57:47,975:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:57:47,975:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:57:47,979:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:57:47,980:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 683611
2022-09-05 01:57:47,982:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:57:47,987:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:57:47,988:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:57:47,988:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:57:48,499:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:57:48,499:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 01:58:04,602:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:58:09,600:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 58, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:58:09,600:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:58:09,602:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:58:09,607:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:58:09,607:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:58:09,607:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:58:09,612:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:58:09,613:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 598566
2022-09-05 01:58:09,614:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:58:09,622:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:58:09,622:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:58:09,622:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:58:10,170:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:58:10,171:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 01:58:30,629:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:58:35,627:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:58:35,627:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 01:58:35,628:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:58:35,634:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:58:35,634:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:58:35,634:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:58:35,638:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:58:35,639:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 597281
2022-09-05 01:58:35,641:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:58:35,646:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:58:35,647:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:58:35,647:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:58:36,200:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 01:58:36,200:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 01:59:04,882:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:59:09,890:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:59:09,890:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 01:59:09,892:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:59:09,895:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:59:09,895:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:59:09,895:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:59:09,900:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:59:09,901:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 444379
2022-09-05 01:59:09,902:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:59:09,905:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:59:09,905:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:59:09,905:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:59:10,450:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:59:10,450:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 01:59:18,784:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:59:23,572:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 01:59:28,686:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 01:59:28,687:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 01:59:28,688:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:59:28,691:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:59:28,691:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:59:28,691:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:59:28,696:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 01:59:28,696:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536933
2022-09-05 01:59:28,698:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 01:59:28,700:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 01:59:28,700:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 01:59:28,701:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 01:59:29,266:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 01:59:29,266:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:02:51,987:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:02:56,855:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 64, 'in_dim': 3, 'n_classes': 2}
2022-09-05 02:02:56,855:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 02:02:56,856:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:02:56,858:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:02:56,858:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:02:56,858:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:02:56,863:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:02:56,864:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 602363
2022-09-05 02:02:56,866:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:02:56,867:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:02:56,867:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:02:56,867:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:02:57,357:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 02:02:57,357:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 02:03:21,968:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:03:27,109:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 02:03:27,109:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:03:27,111:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:03:27,114:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:03:27,114:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:03:27,114:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:03:27,118:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:03:27,119:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 584535
2022-09-05 02:03:27,123:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:03:27,126:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:03:27,126:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:03:27,126:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:03:27,751:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:03:27,751:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 02:11:26,879:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:11:32,116:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'in_dim': 3, 'n_classes': 2}
2022-09-05 02:11:32,116:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:11:32,120:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:11:32,126:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:11:32,126:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:11:32,126:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:11:32,130:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:11:32,131:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 597281
2022-09-05 02:11:32,133:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:11:32,140:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:11:32,140:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:11:32,140:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:11:32,730:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:11:32,730:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:22:21,580:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:22:26,072:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:22:26,072:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:22:26,074:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:22:26,075:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:22:26,075:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:22:26,075:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:22:26,080:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:22:26,081:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:22:26,082:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:22:26,083:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:22:26,083:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:22:26,083:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:22:26,088:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:22:26,088:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:22:43,794:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:17.71343421936035
2022-09-05 02:22:43,810:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 02:22:43,811:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 02:22:43,811:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 02:22:43,811:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 02:22:43,813:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 02:23:17,068:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:23:21,651:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:23:21,651:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:23:21,653:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:23:21,654:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:23:21,654:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:23:21,654:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:23:21,659:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:23:21,660:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:23:21,661:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:23:21,662:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:23:21,662:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:23:21,662:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:23:21,668:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:23:21,668:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:23:39,689:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:18.029401779174805
2022-09-05 02:23:39,704:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 02:23:39,704:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 02:23:39,704:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 02:23:39,704:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 02:23:39,706:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 02:24:43,054:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:24:47,352:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:24:47,352:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:24:47,353:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:24:47,354:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:24:47,354:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:24:47,354:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:24:47,359:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:24:47,360:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:24:47,362:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:24:47,362:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:24:47,362:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:24:47,362:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:24:47,368:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:24:47,368:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:25:04,554:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:17.193648099899292
2022-09-05 02:25:04,571:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 02:25:04,571:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 02:25:04,571:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 02:25:04,571:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 02:25:04,574:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 02:25:46,464:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:25:50,796:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:25:50,796:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:25:50,798:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:25:50,799:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:25:50,799:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:25:50,799:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:25:50,803:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:25:50,804:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:25:50,806:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:25:50,806:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:25:50,806:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:25:50,806:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:25:50,812:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:25:50,812:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:26:08,702:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:17.89741277694702
2022-09-05 02:26:40,649:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:26:44,979:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:26:44,979:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:26:44,981:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:26:44,982:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:26:44,982:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:26:44,982:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:26:44,987:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:26:44,987:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:26:44,989:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:26:44,989:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:26:44,989:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:26:44,989:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:26:44,994:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:26:44,994:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:27:02,339:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:17.35170316696167
2022-09-05 02:27:21,486:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:27:25,905:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:27:25,905:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:27:25,906:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:27:25,907:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:27:25,908:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:27:25,908:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:27:25,912:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:27:25,913:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:27:25,914:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:27:25,915:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:27:25,915:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:27:25,915:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:27:25,920:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:27:25,920:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:27:43,323:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:17.40998387336731
2022-09-05 02:27:43,338:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 02:27:43,338:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 02:27:43,338:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 02:27:43,338:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 02:27:43,340:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 02:28:18,363:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:28:22,672:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:28:22,672:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:28:22,674:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:28:22,675:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:28:22,675:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:28:22,675:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:28:22,680:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:28:22,681:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:28:22,682:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:28:22,683:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:28:22,683:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:28:22,683:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:28:22,688:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:28:22,688:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:28:39,959:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:17.278156042099
2022-09-05 02:28:39,974:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 02:28:39,974:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 02:28:39,974:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 02:28:39,974:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 02:28:39,976:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 02:29:33,375:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:29:37,965:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:29:37,966:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:29:37,967:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:29:37,968:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:29:37,968:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:29:37,968:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:29:37,973:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:29:37,974:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525993
2022-09-05 02:29:37,975:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:29:37,976:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:29:37,976:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:29:37,976:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:29:37,982:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 02:29:37,982:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:29:56,155:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:18.1804461479187
2022-09-05 02:29:56,170:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 02:29:56,170:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 02:29:56,170:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 02:29:56,170:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 02:29:56,172:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 02:29:58,882:main_CYCLES_graph_classification.py:211 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 02:29:58,882:main_CYCLES_graph_classification.py:212 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 02:30:07,149:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:30:11,726:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:30:11,726:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:30:11,727:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:30:11,728:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:30:11,728:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:30:11,728:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:30:11,733:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:30:11,734:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 530377
2022-09-05 02:30:11,735:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:30:11,736:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:30:11,736:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:30:11,736:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:30:11,741:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 02:30:11,741:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:30:30,825:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:30:35,275:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:30:35,275:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:30:35,277:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:30:35,279:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:30:35,279:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:30:35,279:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:30:35,284:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:30:35,284:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 726153
2022-09-05 02:30:35,286:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:30:35,288:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:30:35,288:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:30:35,288:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:30:35,293:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:30:35,293:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:30:46,273:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:30:50,697:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:30:50,697:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-05 02:30:50,699:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:30:50,701:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:30:50,701:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:30:50,701:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:30:50,705:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:30:50,706:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 534933
2022-09-05 02:30:50,708:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:30:50,710:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:30:50,710:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:30:50,710:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:30:50,715:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:30:50,715:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:31:22,545:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:31:27,067:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 2, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:31:27,067:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 02:31:27,069:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:31:27,070:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:31:27,070:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:31:27,070:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:31:27,075:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:31:27,076:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 583561
2022-09-05 02:31:27,077:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:31:27,078:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:31:27,078:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:31:27,078:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:31:27,084:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 02:31:27,084:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 2 random automata.
2022-09-05 02:32:26,130:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:32:30,558:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:32:30,558:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:32:30,560:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:32:30,563:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:32:30,563:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:32:30,563:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:32:30,568:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:32:30,569:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 779819
2022-09-05 02:32:30,571:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:32:30,574:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:32:30,574:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:32:30,574:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:32:30,579:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:32:30,579:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 02:32:44,966:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:32:49,259:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 4, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:32:49,260:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:32:49,261:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:32:49,265:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:32:49,265:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:32:49,265:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:32:49,269:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:32:49,270:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 584471
2022-09-05 02:32:49,272:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:32:49,274:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:32:49,275:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:32:49,275:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:32:49,280:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:32:49,280:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 4 random automata.
2022-09-05 02:33:45,104:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:33:49,521:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:33:49,521:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:33:49,523:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:33:49,529:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:33:49,529:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:33:49,529:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:33:49,534:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:33:49,535:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 887151
2022-09-05 02:33:49,536:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:33:49,541:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:33:49,541:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:33:49,541:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:33:49,547:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:33:49,547:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:34:01,602:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:34:06,000:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:34:06,000:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:34:06,002:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:34:06,008:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:34:06,008:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:34:06,008:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:34:06,012:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:34:06,013:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 597225
2022-09-05 02:34:06,015:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:34:06,020:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:34:06,020:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:34:06,020:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:34:06,025:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:34:06,025:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:34:26,531:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:34:31,062:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:34:31,062:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 02:34:31,064:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:34:31,067:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:34:31,067:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:34:31,067:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:34:31,072:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:34:31,073:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 639727
2022-09-05 02:34:31,075:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:34:31,077:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:34:31,077:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:34:31,077:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:34:31,082:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 02:34:31,082:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:34:41,855:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:34:46,305:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:34:46,305:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-05 02:34:46,307:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:34:46,310:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:34:46,310:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:34:46,310:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:34:46,315:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:34:46,316:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 536861
2022-09-05 02:34:46,318:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:34:46,321:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:34:46,321:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:34:46,321:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:34:46,326:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 02:34:46,326:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:35:35,457:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:35:39,927:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:35:39,927:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:35:39,929:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:35:39,935:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:35:39,935:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:35:39,935:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:35:39,940:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:35:39,941:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 887151
2022-09-05 02:35:39,943:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:35:39,949:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:35:39,949:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:35:39,949:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:35:39,954:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:35:39,954:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:35:55,745:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:36:00,816:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:36:05,302:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:36:05,302:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:36:05,303:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:36:05,309:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:36:05,309:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:36:05,309:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:36:05,313:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:36:05,314:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 597225
2022-09-05 02:36:05,316:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:36:05,321:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:36:05,321:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 02:36:05,321:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 02:36:05,326:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:36:05,326:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 02:38:09,233:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 02:38:14,009:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 56, 'out_dim': 56, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 8, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 02:38:14,009:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 128}
2022-09-05 02:38:14,011:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:38:14,016:pe_layer.py:132 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:38:14,016:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 02:38:14,016:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 02:38:14,020:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 02:38:14,021:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 546657
2022-09-05 02:38:14,023:pe_layer.py:68 -             __init__(): rand_pos_enc
2022-09-05 02:38:14,028:pe_layer.py:132 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 02:38:14,028:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-05 02:38:14,028:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-05 02:38:14,033:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 02:38:14,033:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 8 random automata.
2022-09-05 14:29:55,028:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:30:01,606:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:30:01,606:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:33:25,228:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:33:31,138:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:33:31,139:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:33:31,139:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:33:31,143:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:33:31,143:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:33:31,143:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:33:31,150:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:33:31,151:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522823
2022-09-05 14:33:31,152:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:33:31,153:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:33:31,153:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:33:31,153:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:33:31,167:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (0).
2022-09-05 14:33:49,814:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:33:55,401:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:33:55,401:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:33:55,402:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:33:55,405:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:33:55,405:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:33:55,405:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:33:55,410:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:33:55,411:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522823
2022-09-05 14:33:55,411:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:33:55,411:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:33:55,411:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:33:55,411:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:33:55,416:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (0).
2022-09-05 14:34:13,437:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:34:18,864:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:34:18,864:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:34:18,865:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:34:18,868:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:34:18,868:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:34:18,868:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:34:18,873:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:34:18,874:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522823
2022-09-05 14:34:18,874:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:34:18,874:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:34:18,874:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:34:18,874:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:34:18,880:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (0).
2022-09-05 14:34:46,586:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:34:52,183:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:34:52,183:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:34:52,183:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:34:52,186:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:34:52,186:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:34:52,186:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:34:52,191:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:34:52,192:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522823
2022-09-05 14:34:52,192:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:34:52,192:pe_layer.py:129 -             __init__(): Using 0 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:34:52,192:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:34:52,192:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:34:52,199:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (0).
2022-09-05 14:35:01,719:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:35:07,136:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 64, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:35:07,136:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:35:07,136:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:35:07,143:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:35:07,143:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:35:07,144:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:35:07,148:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:35:07,149:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532103
2022-09-05 14:35:07,150:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:35:07,150:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:35:07,150:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:35:07,150:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:35:07,156:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 14:35:45,497:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:35:51,002:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:35:51,003:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:35:51,003:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:35:51,004:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:35:51,004:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:35:51,004:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:35:51,010:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:35:51,010:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:35:51,011:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:35:51,011:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:35:51,011:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:35:51,011:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:35:51,016:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:36:19,124:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:36:24,607:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:36:24,608:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:36:24,608:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:36:24,609:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:36:24,609:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:36:24,609:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:36:24,615:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:36:24,615:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:36:24,616:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:36:24,616:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:36:24,616:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:36:24,616:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:36:25,162:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:36:31,399:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:6.776808023452759
2022-09-05 14:36:31,402:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 10
2022-09-05 14:36:31,402:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 10
2022-09-05 14:36:31,402:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 10
2022-09-05 14:36:31,402:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:36:31,403:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:36:32,536:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h36m24s_on_Sep_05_2022/MODELS_
2022-09-05 14:36:32,536:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.13s, LR: 0.00050, Train Loss: 0.6607, Train Acc: 50.0000,
                        Val Loss: 13.6305, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:32,536:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:36:33,598:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.06s, LR: 0.00050, Train Loss: 0.5938, Train Acc: 50.0000,
                        Val Loss: 11.7249, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:33,598:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:36:34,582:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.98s, LR: 0.00050, Train Loss: 0.5637, Train Acc: 50.0000,
                        Val Loss: 9.5474, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:34,582:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:36:35,577:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.99s, LR: 0.00050, Train Loss: 0.5453, Train Acc: 50.0000,
                        Val Loss: 8.2181, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:35,577:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:36:36,490:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.5323, Train Acc: 50.0000,
                        Val Loss: 6.7408, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:36,490:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:36:37,387:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.5225, Train Acc: 50.8475,
                        Val Loss: 5.1157, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:37,387:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:36:38,307:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.5148, Train Acc: 53.5394,
                        Val Loss: 3.9163, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:38,307:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:36:39,207:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.5087, Train Acc: 56.7797,
                        Val Loss: 3.2990, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:39,207:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:36:40,103:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.5036, Train Acc: 58.7737,
                        Val Loss: 3.0056, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:40,103:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:36:41,029:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.4991, Train Acc: 61.2662,
                        Val Loss: 2.9733, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:41,029:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:36:41,925:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4950, Train Acc: 62.9611,
                        Val Loss: 2.9588, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:41,925:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:36:42,836:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4910, Train Acc: 64.4068,
                        Val Loss: 2.9149, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:42,837:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:36:43,748:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4874, Train Acc: 67.8179,
                        Val Loss: 2.9514, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:43,749:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:36:44,678:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.4838, Train Acc: 73.4652,
                        Val Loss: 2.9950, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:44,678:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:36:45,563:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.4802, Train Acc: 79.7178,
                        Val Loss: 3.0184, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:45,563:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 14:36:46,470:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4765, Train Acc: 84.5674,
                        Val Loss: 3.0388, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:46,470:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 14:36:47,399:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.4728, Train Acc: 85.9560,
                        Val Loss: 3.0672, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:47,400:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 14:36:48,303:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4692, Train Acc: 86.1482,
                        Val Loss: 3.0098, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:48,303:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 14:36:49,194:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.4655, Train Acc: 86.3476,
                        Val Loss: 2.8865, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:49,194:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 14:36:50,156:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.4618, Train Acc: 86.7251,
                        Val Loss: 2.7827, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:50,156:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 14:36:51,052:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4581, Train Acc: 86.8747,
                        Val Loss: 2.7049, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:51,052:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 14:36:51,954:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4542, Train Acc: 86.8960,
                        Val Loss: 2.6508, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:51,954:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 14:36:52,862:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4503, Train Acc: 87.1452,
                        Val Loss: 2.6340, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:52,862:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 14:36:53,755:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.4464, Train Acc: 87.2164,
                        Val Loss: 2.6437, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:53,755:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 14:36:54,663:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4422, Train Acc: 87.1594,
                        Val Loss: 2.6823, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:54,663:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 14:36:55,580:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.4379, Train Acc: 87.6080,
                        Val Loss: 2.7165, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:55,580:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 14:36:56,472:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.4335, Train Acc: 88.0068,
                        Val Loss: 2.7284, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:56,473:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 14:36:57,361:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.4290, Train Acc: 87.7290,
                        Val Loss: 2.7022, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:57,361:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 14:36:58,268:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4243, Train Acc: 87.6008,
                        Val Loss: 2.6259, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:58,268:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 14:36:59,173:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4195, Train Acc: 87.4014,
                        Val Loss: 2.4919, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:36:59,173:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 14:37:00,089:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.4147, Train Acc: 88.1849,
                        Val Loss: 2.4188, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:00,089:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 14:37:01,024:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.4099, Train Acc: 88.6407,
                        Val Loss: 2.3955, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:01,024:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 14:37:01,927:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4049, Train Acc: 88.6407,
                        Val Loss: 2.4234, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:01,927:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 14:37:02,813:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.3998, Train Acc: 88.5909,
                        Val Loss: 2.4201, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:02,813:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 14:37:03,700:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.3945, Train Acc: 88.3344,
                        Val Loss: 2.4341, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:03,701:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 14:37:04,613:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.3891, Train Acc: 88.2774,
                        Val Loss: 2.4858, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:04,614:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 14:37:05,522:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.3834, Train Acc: 88.4269,
                        Val Loss: 2.4908, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:05,522:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 14:37:06,462:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.3774, Train Acc: 88.2987,
                        Val Loss: 2.3802, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:06,462:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 14:37:07,382:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.3711, Train Acc: 88.4981,
                        Val Loss: 2.1364, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:07,382:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 14:37:08,310:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.3645, Train Acc: 88.8185,
                        Val Loss: 1.9484, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:08,310:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 14:37:09,211:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.3579, Train Acc: 89.0393,
                        Val Loss: 1.8051, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:09,211:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 14:37:10,113:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.3529, Train Acc: 90.3783,
                        Val Loss: 1.6779, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:10,113:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 14:37:11,022:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.3504, Train Acc: 89.5591,
                        Val Loss: 1.1771, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:37:11,022:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 14:37:11,260:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 14:37:11,260:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 14:37:20,159:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:37:25,646:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:37:25,646:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:37:25,646:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:37:25,647:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:37:25,647:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:37:25,647:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:37:25,652:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:37:25,653:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:37:25,653:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:37:25,653:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:37:25,653:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:37:25,653:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:37:26,129:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:37:28,637:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:2.9787421226501465
2022-09-05 14:37:28,640:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 10
2022-09-05 14:37:28,640:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 10
2022-09-05 14:37:28,640:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 10
2022-09-05 14:37:28,640:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:37:28,641:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:37:29,791:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 55.2508 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h37m25s_on_Sep_05_2022/MODELS_
2022-09-05 14:37:29,791:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.15s, LR: 0.00050, Train Loss: 0.7017, Train Acc: 49.7435,
                        Val Loss: 0.6890, Val Acc: 54.2313, Test Acc: 55.2508
2022-09-05 14:37:29,791:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:37:30,763:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 62.4682 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h37m25s_on_Sep_05_2022/MODELS_
2022-09-05 14:37:30,763:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.97s, LR: 0.00050, Train Loss: 0.6784, Train Acc: 58.6947,
                        Val Loss: 0.6779, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-05 14:37:30,763:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:37:31,763:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.00s, LR: 0.00050, Train Loss: 0.6660, Train Acc: 61.9420,
                        Val Loss: 0.6691, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-05 14:37:31,763:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:37:32,791:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.03s, LR: 0.00050, Train Loss: 0.6575, Train Acc: 62.0417,
                        Val Loss: 0.6632, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-05 14:37:32,791:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:37:33,715:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.6496, Train Acc: 62.7894,
                        Val Loss: 0.6588, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-05 14:37:33,716:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:37:34,636:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.6418, Train Acc: 63.2594,
                        Val Loss: 0.6554, Val Acc: 61.4503, Test Acc: 62.4682
2022-09-05 14:37:34,636:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:37:35,566:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 62.7427 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h37m25s_on_Sep_05_2022/MODELS_
2022-09-05 14:37:35,566:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.6343, Train Acc: 64.3561,
                        Val Loss: 0.6532, Val Acc: 61.6441, Test Acc: 62.7427
2022-09-05 14:37:35,567:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:37:36,490:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 63.3341 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h37m25s_on_Sep_05_2022/MODELS_
2022-09-05 14:37:36,490:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.6261, Train Acc: 64.8973,
                        Val Loss: 0.6520, Val Acc: 62.3837, Test Acc: 63.3341
2022-09-05 14:37:36,490:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:37:37,373:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 66.4349 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h37m25s_on_Sep_05_2022/MODELS_
2022-09-05 14:37:37,373:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 0.6177, Train Acc: 66.3144,
                        Val Loss: 0.6520, Val Acc: 64.8127, Test Acc: 66.4349
2022-09-05 14:37:37,373:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:37:38,333:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.6094, Train Acc: 66.9694,
                        Val Loss: 0.6522, Val Acc: 64.5543, Test Acc: 61.6334
2022-09-05 14:37:38,333:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:37:39,264:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.6010, Train Acc: 68.6072,
                        Val Loss: 0.6521, Val Acc: 62.1350, Test Acc: 62.0446
2022-09-05 14:37:39,264:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:37:40,189:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.5924, Train Acc: 69.7751,
                        Val Loss: 0.6505, Val Acc: 62.7939, Test Acc: 61.7338
2022-09-05 14:37:40,189:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:37:41,141:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.95s, LR: 0.00050, Train Loss: 0.5832, Train Acc: 70.6652,
                        Val Loss: 0.6477, Val Acc: 63.6305, Test Acc: 62.2271
2022-09-05 14:37:41,141:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:37:42,076:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.5729, Train Acc: 72.3601,
                        Val Loss: 0.6442, Val Acc: 65.9916, Test Acc: 62.9491
2022-09-05 14:37:42,076:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:38:01,260:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:38:06,716:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:38:06,716:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:38:06,716:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:38:06,718:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:38:06,718:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:38:06,718:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:38:06,723:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:38:06,723:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:38:06,723:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:38:06,724:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:38:06,724:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:38:06,724:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:38:07,253:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:38:16,213:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:38:21,677:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:38:21,677:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:38:21,677:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:38:21,678:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:38:21,678:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:38:21,678:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:38:21,687:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:38:21,687:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:38:21,688:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:38:21,688:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:38:21,688:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:38:21,688:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:38:22,114:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:38:26,279:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:4.585696220397949
2022-09-05 14:38:26,282:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 10
2022-09-05 14:38:26,282:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 10
2022-09-05 14:38:26,282:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 10
2022-09-05 14:38:26,282:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:38:26,283:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:38:27,429:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h38m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:38:27,429:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.15s, LR: 0.00050, Train Loss: 0.6522, Train Acc: 61.2377,
                        Val Loss: 21.3662, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:27,429:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:38:28,501:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.07s, LR: 0.00050, Train Loss: 0.5869, Train Acc: 65.9948,
                        Val Loss: 18.7391, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:28,501:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:38:29,564:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.06s, LR: 0.00050, Train Loss: 0.5508, Train Acc: 69.4843,
                        Val Loss: 15.4666, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:29,564:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:38:30,606:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 1.04s, LR: 0.00050, Train Loss: 0.5260, Train Acc: 77.5529,
                        Val Loss: 11.7033, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:30,606:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:38:31,554:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.95s, LR: 0.00050, Train Loss: 0.5081, Train Acc: 82.6019,
                        Val Loss: 8.6748, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:31,554:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:38:32,491:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.4943, Train Acc: 83.8836,
                        Val Loss: 7.1567, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:32,491:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:38:33,386:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.4833, Train Acc: 84.8734,
                        Val Loss: 6.5399, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:33,386:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:38:34,333:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.95s, LR: 0.00050, Train Loss: 0.4739, Train Acc: 85.4431,
                        Val Loss: 6.0638, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:34,333:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:38:35,261:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.4656, Train Acc: 86.2122,
                        Val Loss: 5.6024, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:35,261:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:38:36,241:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.98s, LR: 0.00050, Train Loss: 0.4581, Train Acc: 86.0056,
                        Val Loss: 4.8626, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:36,241:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:38:37,197:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.4512, Train Acc: 86.2050,
                        Val Loss: 4.0335, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:37,197:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:38:38,133:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.4446, Train Acc: 86.2548,
                        Val Loss: 3.4979, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:38,133:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:38:39,090:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.4383, Train Acc: 86.4542,
                        Val Loss: 3.1075, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:39,090:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:38:40,038:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.95s, LR: 0.00050, Train Loss: 0.4326, Train Acc: 86.1765,
                        Val Loss: 2.8891, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:40,038:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:38:40,989:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.95s, LR: 0.00050, Train Loss: 0.4271, Train Acc: 86.2263,
                        Val Loss: 2.7814, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:40,989:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 14:38:41,944:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.4217, Train Acc: 86.3759,
                        Val Loss: 2.6995, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:41,944:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 14:38:42,909:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 0.4163, Train Acc: 86.5254,
                        Val Loss: 2.6395, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:42,909:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 14:38:43,818:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.4111, Train Acc: 86.4756,
                        Val Loss: 2.6338, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:38:43,818:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 14:38:56,130:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:39:01,580:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:39:01,580:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:39:01,580:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:39:01,581:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:39:01,581:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:39:01,581:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:39:01,586:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:39:01,587:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:39:01,587:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:39:01,588:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:39:01,588:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:39:01,588:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:39:02,115:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:39:17,725:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:16.131492853164673
2022-09-05 14:39:17,727:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:39:17,727:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:39:17,727:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:39:17,727:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:39:17,729:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:39:21,571:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h39m01s_on_Sep_05_2022/MODELS_
2022-09-05 14:39:21,571:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.6980, Train Acc: 43.4146,
                        Val Loss: 3.7550, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:21,571:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:39:25,485:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.91s, LR: 0.00050, Train Loss: 0.6374, Train Acc: 65.7069,
                        Val Loss: 2.3348, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:25,485:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:39:29,162:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.68s, LR: 0.00050, Train Loss: 0.6032, Train Acc: 77.0659,
                        Val Loss: 0.9170, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:29,163:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:39:32,886:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 75.5209 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h39m01s_on_Sep_05_2022/MODELS_
2022-09-05 14:39:32,886:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.5768, Train Acc: 82.7707,
                        Val Loss: 0.5973, Val Acc: 75.0264, Test Acc: 75.5209
2022-09-05 14:39:32,886:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:39:36,714:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.5572, Train Acc: 84.0979,
                        Val Loss: 0.5822, Val Acc: 70.8687, Test Acc: 70.7881
2022-09-05 14:39:36,714:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:39:40,453:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.5391, Train Acc: 84.6104,
                        Val Loss: 0.7509, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:40,453:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:39:44,144:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.5225, Train Acc: 85.3596,
                        Val Loss: 0.9894, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:44,144:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:39:47,848:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.5070, Train Acc: 85.6962,
                        Val Loss: 1.1172, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:47,849:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:39:51,644:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.4913, Train Acc: 85.6884,
                        Val Loss: 1.1663, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:51,644:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:39:55,450:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.4765, Train Acc: 85.8983,
                        Val Loss: 1.2648, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:55,451:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:39:59,242:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.4625, Train Acc: 85.9590,
                        Val Loss: 1.2776, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:39:59,242:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:40:02,970:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.4477, Train Acc: 86.3300,
                        Val Loss: 1.2320, Val Acc: 50.0095, Test Acc: 50.0392
2022-09-05 14:40:02,971:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:40:15,639:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:40:21,048:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:40:21,048:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:40:21,049:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:40:21,049:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:40:21,049:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:40:21,049:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:40:21,054:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:40:21,055:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:40:21,055:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:40:21,056:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:40:21,056:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:40:21,056:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:40:21,606:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:40:46,484:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:25.42305612564087
2022-09-05 14:40:46,487:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:40:46,487:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:40:46,487:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:40:46,487:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:40:46,489:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:40:50,239:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h40m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:40:50,239:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.6888, Train Acc: 51.2041,
                        Val Loss: 0.7844, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:40:50,239:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:40:54,231:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 62.2515 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h40m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:40:54,231:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.99s, LR: 0.00050, Train Loss: 0.6158, Train Acc: 79.0522,
                        Val Loss: 0.6248, Val Acc: 61.4586, Test Acc: 62.2515
2022-09-05 14:40:54,231:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:40:57,956:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 80.9011 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h40m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:40:57,956:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.5769, Train Acc: 84.3127,
                        Val Loss: 0.5611, Val Acc: 81.1654, Test Acc: 80.9011
2022-09-05 14:40:57,956:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:41:01,660:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.5480, Train Acc: 85.2646,
                        Val Loss: 0.5290, Val Acc: 80.4598, Test Acc: 80.6205
2022-09-05 14:41:01,660:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:41:05,498:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.4794 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h40m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:41:05,498:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.5212, Train Acc: 85.9838,
                        Val Loss: 0.4807, Val Acc: 82.6889, Test Acc: 82.4794
2022-09-05 14:41:05,498:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:41:09,277:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.9599 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h40m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:41:09,277:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.4960, Train Acc: 86.4308,
                        Val Loss: 0.4405, Val Acc: 85.2456, Test Acc: 84.9599
2022-09-05 14:41:09,277:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:41:13,002:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.8156 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h40m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:41:13,002:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.4722, Train Acc: 86.6818,
                        Val Loss: 0.4318, Val Acc: 86.1833, Test Acc: 85.8156
2022-09-05 14:41:13,002:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:41:16,739:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.4513, Train Acc: 86.5399,
                        Val Loss: 0.4375, Val Acc: 85.2901, Test Acc: 84.8858
2022-09-05 14:41:16,739:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:41:20,438:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.4328, Train Acc: 86.9801,
                        Val Loss: 0.4482, Val Acc: 83.8607, Test Acc: 83.9389
2022-09-05 14:41:20,438:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:41:24,027:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.59s, LR: 0.00050, Train Loss: 0.4167, Train Acc: 86.9822,
                        Val Loss: 0.4555, Val Acc: 83.2288, Test Acc: 83.1085
2022-09-05 14:41:24,027:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:41:27,633:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00050, Train Loss: 0.4019, Train Acc: 86.9715,
                        Val Loss: 0.4535, Val Acc: 83.4411, Test Acc: 82.7898
2022-09-05 14:41:27,633:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:41:31,255:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00050, Train Loss: 0.3871, Train Acc: 87.2498,
                        Val Loss: 0.4426, Val Acc: 84.7452, Test Acc: 84.0579
2022-09-05 14:41:31,255:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:41:34,955:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.3744, Train Acc: 87.3441,
                        Val Loss: 0.4265, Val Acc: 85.5466, Test Acc: 85.1637
2022-09-05 14:41:34,955:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:41:38,565:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00050, Train Loss: 0.3623, Train Acc: 87.3563,
                        Val Loss: 0.4102, Val Acc: 86.0832, Test Acc: 85.7978
2022-09-05 14:41:38,565:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:41:42,184:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.2480 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h40m21s_on_Sep_05_2022/MODELS_
2022-09-05 14:41:42,184:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00050, Train Loss: 0.3512, Train Acc: 87.3280,
                        Val Loss: 0.3931, Val Acc: 86.7686, Test Acc: 86.2480
2022-09-05 14:41:42,184:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 14:41:45,791:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00050, Train Loss: 0.3420, Train Acc: 87.2151,
                        Val Loss: 0.3798, Val Acc: 86.7098, Test Acc: 86.1033
2022-09-05 14:41:45,791:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 14:41:49,424:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.63s, LR: 0.00050, Train Loss: 0.3329, Train Acc: 87.2389,
                        Val Loss: 0.3740, Val Acc: 86.0091, Test Acc: 85.6729
2022-09-05 14:41:49,424:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 14:41:53,069:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.65s, LR: 0.00050, Train Loss: 0.3254, Train Acc: 87.5380,
                        Val Loss: 0.3742, Val Acc: 85.3698, Test Acc: 84.6748
2022-09-05 14:41:53,069:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 14:41:56,760:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.3191, Train Acc: 87.6558,
                        Val Loss: 0.3782, Val Acc: 83.8610, Test Acc: 83.7413
2022-09-05 14:41:56,760:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 14:42:00,394:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.63s, LR: 0.00050, Train Loss: 0.3128, Train Acc: 87.7042,
                        Val Loss: 0.3857, Val Acc: 82.4134, Test Acc: 82.1090
2022-09-05 14:42:00,394:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 14:42:04,018:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00050, Train Loss: 0.3076, Train Acc: 87.4993,
                        Val Loss: 0.3941, Val Acc: 81.3085, Test Acc: 81.0382
2022-09-05 14:42:04,018:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 14:42:07,638:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00050, Train Loss: 0.3033, Train Acc: 87.6956,
                        Val Loss: 0.4026, Val Acc: 80.3204, Test Acc: 80.1595
2022-09-05 14:42:07,638:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 14:42:11,231:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.59s, LR: 0.00050, Train Loss: 0.2987, Train Acc: 87.6415,
                        Val Loss: 0.4142, Val Acc: 79.3610, Test Acc: 79.0806
2022-09-05 14:42:11,232:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 14:42:14,860:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.63s, LR: 0.00050, Train Loss: 0.2963, Train Acc: 87.7234,
                        Val Loss: 0.4266, Val Acc: 78.2113, Test Acc: 78.2213
2022-09-05 14:42:14,860:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 14:42:18,483:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00050, Train Loss: 0.2919, Train Acc: 87.8394,
                        Val Loss: 0.4409, Val Acc: 77.2264, Test Acc: 77.4931
2022-09-05 14:42:18,483:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 14:42:22,077:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.59s, LR: 0.00050, Train Loss: 0.2892, Train Acc: 88.3727,
                        Val Loss: 0.4502, Val Acc: 76.1673, Test Acc: 76.4013
2022-09-05 14:42:22,077:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 14:42:25,649:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.57s, LR: 0.00050, Train Loss: 0.2854, Train Acc: 88.2731,
                        Val Loss: 0.4708, Val Acc: 74.4335, Test Acc: 75.0286
2022-09-05 14:42:25,649:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 14:42:29,267:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00050, Train Loss: 0.2828, Train Acc: 88.1560,
                        Val Loss: 0.4533, Val Acc: 75.5037, Test Acc: 75.8864
2022-09-05 14:42:29,268:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 14:42:32,905:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.64s, LR: 0.00025, Train Loss: 0.2802, Train Acc: 88.1522,
                        Val Loss: 0.4506, Val Acc: 75.4666, Test Acc: 75.6676
2022-09-05 14:42:32,905:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 14:42:36,542:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.64s, LR: 0.00025, Train Loss: 0.2795, Train Acc: 88.0937,
                        Val Loss: 0.4625, Val Acc: 74.6573, Test Acc: 75.0785
2022-09-05 14:42:36,542:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 14:42:40,148:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00025, Train Loss: 0.2773, Train Acc: 88.4559,
                        Val Loss: 0.4829, Val Acc: 73.1770, Test Acc: 73.6329
2022-09-05 14:42:40,148:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 14:42:43,768:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00025, Train Loss: 0.2768, Train Acc: 88.1895,
                        Val Loss: 0.5042, Val Acc: 71.7627, Test Acc: 72.2038
2022-09-05 14:42:43,768:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 14:42:47,378:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00025, Train Loss: 0.2744, Train Acc: 88.3914,
                        Val Loss: 0.5373, Val Acc: 69.0148, Test Acc: 69.3883
2022-09-05 14:42:47,378:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 14:42:50,985:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00025, Train Loss: 0.2740, Train Acc: 88.4921,
                        Val Loss: 0.5627, Val Acc: 67.2266, Test Acc: 67.4536
2022-09-05 14:42:50,985:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 14:42:54,575:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.59s, LR: 0.00025, Train Loss: 0.2726, Train Acc: 88.3849,
                        Val Loss: 0.6016, Val Acc: 64.2306, Test Acc: 64.2824
2022-09-05 14:42:54,575:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 14:42:58,188:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00025, Train Loss: 0.2711, Train Acc: 88.3812,
                        Val Loss: 0.6541, Val Acc: 60.0458, Test Acc: 60.1403
2022-09-05 14:42:58,189:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 14:43:01,798:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00025, Train Loss: 0.2701, Train Acc: 88.6374,
                        Val Loss: 0.6931, Val Acc: 57.2875, Test Acc: 57.4590
2022-09-05 14:43:01,799:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 14:43:05,404:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00025, Train Loss: 0.2689, Train Acc: 88.5596,
                        Val Loss: 0.7230, Val Acc: 55.5609, Test Acc: 55.5628
2022-09-05 14:43:05,404:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 14:43:09,054:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.65s, LR: 0.00025, Train Loss: 0.2667, Train Acc: 88.8113,
                        Val Loss: 0.7322, Val Acc: 54.9377, Test Acc: 54.9139
2022-09-05 14:43:09,054:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 14:43:12,667:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00013, Train Loss: 0.2662, Train Acc: 88.8006,
                        Val Loss: 0.7111, Val Acc: 56.2579, Test Acc: 56.5166
2022-09-05 14:43:12,667:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 14:43:16,291:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00013, Train Loss: 0.2648, Train Acc: 88.7685,
                        Val Loss: 0.6921, Val Acc: 57.9098, Test Acc: 58.1706
2022-09-05 14:43:16,291:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 14:43:19,898:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00013, Train Loss: 0.2636, Train Acc: 88.9155,
                        Val Loss: 0.6765, Val Acc: 58.8647, Test Acc: 59.3324
2022-09-05 14:43:19,898:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 14:43:23,550:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.65s, LR: 0.00013, Train Loss: 0.2641, Train Acc: 88.7520,
                        Val Loss: 0.6640, Val Acc: 59.2445, Test Acc: 59.6470
2022-09-05 14:43:23,550:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 14:43:27,160:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00013, Train Loss: 0.2621, Train Acc: 89.3169,
                        Val Loss: 0.6573, Val Acc: 59.8763, Test Acc: 60.1140
2022-09-05 14:43:27,160:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 45/1000
2022-09-05 14:43:30,775:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.61s, LR: 0.00013, Train Loss: 0.2620, Train Acc: 89.0940,
                        Val Loss: 0.6503, Val Acc: 60.6976, Test Acc: 61.1162
2022-09-05 14:43:30,775:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 46/1000
2022-09-05 14:43:34,391:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.62s, LR: 0.00013, Train Loss: 0.2604, Train Acc: 89.0921,
                        Val Loss: 0.6391, Val Acc: 61.5042, Test Acc: 61.7616
2022-09-05 14:43:34,391:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 47/1000
2022-09-05 14:43:38,018:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.63s, LR: 0.00013, Train Loss: 0.2598, Train Acc: 89.0895,
                        Val Loss: 0.6285, Val Acc: 62.1057, Test Acc: 62.1471
2022-09-05 14:43:38,018:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 48/1000
2022-09-05 14:43:41,693:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00013, Train Loss: 0.2582, Train Acc: 89.3298,
                        Val Loss: 0.6056, Val Acc: 63.9600, Test Acc: 64.0828
2022-09-05 14:43:41,693:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 49/1000
2022-09-05 14:43:45,403:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00013, Train Loss: 0.2566, Train Acc: 89.4161,
                        Val Loss: 0.5690, Val Acc: 67.5358, Test Acc: 67.2776
2022-09-05 14:43:45,403:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 50/1000
2022-09-05 14:43:49,043:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.64s, LR: 0.00013, Train Loss: 0.2558, Train Acc: 89.2554,
                        Val Loss: 0.5346, Val Acc: 70.7806, Test Acc: 70.8637
2022-09-05 14:43:49,043:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 51/1000
2022-09-05 14:47:56,189:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 247.15s, LR: 0.00006, Train Loss: 0.2546, Train Acc: 89.2840,
                        Val Loss: 0.4924, Val Acc: 74.3263, Test Acc: 74.4778
2022-09-05 14:47:56,189:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 52/1000
2022-09-05 14:47:59,851:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.66s, LR: 0.00006, Train Loss: 0.2551, Train Acc: 89.3629,
                        Val Loss: 0.4461, Val Acc: 77.7302, Test Acc: 77.7724
2022-09-05 14:47:59,851:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 53/1000
2022-09-05 14:48:03,661:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00006, Train Loss: 0.2535, Train Acc: 89.5106,
                        Val Loss: 0.4032, Val Acc: 81.4338, Test Acc: 80.4253
2022-09-05 14:48:03,661:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 54/1000
2022-09-05 14:48:07,455:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00006, Train Loss: 0.2529, Train Acc: 89.5091,
                        Val Loss: 0.3710, Val Acc: 83.8555, Test Acc: 83.2669
2022-09-05 14:48:07,455:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 55/1000
2022-09-05 14:48:16,715:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:48:22,306:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:48:22,307:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:48:22,307:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:48:22,310:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:48:22,310:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:48:22,310:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:48:22,315:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:48:22,316:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:48:22,316:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:48:22,317:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:48:22,317:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 14:48:22,317:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:48:22,816:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:48:30,277:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:7.955242872238159
2022-09-05 14:48:30,280:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:48:30,280:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:48:30,280:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:48:30,280:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:48:30,281:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:48:34,185:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 53.9036 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:48:34,185:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.90s, LR: 0.00050, Train Loss: 0.6904, Train Acc: 53.9467,
                        Val Loss: 0.6912, Val Acc: 53.2518, Test Acc: 53.9036
2022-09-05 14:48:34,185:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:48:38,238:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 59.6625 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:48:38,238:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 4.05s, LR: 0.00050, Train Loss: 0.6756, Train Acc: 61.1817,
                        Val Loss: 0.6838, Val Acc: 58.5326, Test Acc: 59.6625
2022-09-05 14:48:38,238:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:48:42,080:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 60.4579 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:48:42,080:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.6663, Train Acc: 61.2213,
                        Val Loss: 0.6819, Val Acc: 59.3624, Test Acc: 60.4579
2022-09-05 14:48:42,080:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:48:45,840:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.6569, Train Acc: 61.8617,
                        Val Loss: 0.6836, Val Acc: 59.0278, Test Acc: 60.3649
2022-09-05 14:48:45,840:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:48:49,679:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.6454, Train Acc: 63.7236,
                        Val Loss: 0.6884, Val Acc: 56.6341, Test Acc: 57.8243
2022-09-05 14:48:49,679:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:48:53,461:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 61.7166 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:48:53,461:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.6296, Train Acc: 67.2542,
                        Val Loss: 0.6796, Val Acc: 61.0309, Test Acc: 61.7166
2022-09-05 14:48:53,461:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:48:57,236:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.6114, Train Acc: 69.6719,
                        Val Loss: 0.6820, Val Acc: 57.5849, Test Acc: 58.4278
2022-09-05 14:48:57,236:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:49:01,047:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 65.1977 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:49:01,047:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.5981, Train Acc: 70.7739,
                        Val Loss: 0.6740, Val Acc: 63.9001, Test Acc: 65.1977
2022-09-05 14:49:01,047:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:49:04,796:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.5896, Train Acc: 71.5676,
                        Val Loss: 0.6758, Val Acc: 61.5622, Test Acc: 62.5408
2022-09-05 14:49:04,796:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:49:08,606:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 67.7507 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:49:08,606:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.5808, Train Acc: 72.9312,
                        Val Loss: 0.6617, Val Acc: 66.5222, Test Acc: 67.7507
2022-09-05 14:49:08,606:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:49:12,367:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.5693, Train Acc: 73.7857,
                        Val Loss: 0.6721, Val Acc: 66.8979, Test Acc: 67.2985
2022-09-05 14:49:12,367:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:49:16,233:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 70.6132 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:49:16,233:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.87s, LR: 0.00050, Train Loss: 0.5605, Train Acc: 73.4578,
                        Val Loss: 0.6434, Val Acc: 69.7625, Test Acc: 70.6132
2022-09-05 14:49:16,233:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:49:20,031:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 72.5069 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:49:20,031:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.5453, Train Acc: 75.9872,
                        Val Loss: 0.6269, Val Acc: 71.9255, Test Acc: 72.5069
2022-09-05 14:49:20,031:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:49:23,838:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.5323, Train Acc: 76.1463,
                        Val Loss: 0.6236, Val Acc: 70.4592, Test Acc: 71.6238
2022-09-05 14:49:23,838:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:49:27,624:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 75.2441 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:49:27,624:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.5182, Train Acc: 76.9441,
                        Val Loss: 0.5900, Val Acc: 74.4290, Test Acc: 75.2441
2022-09-05 14:49:27,624:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 14:49:31,449:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.5033, Train Acc: 77.9199,
                        Val Loss: 0.5945, Val Acc: 72.5105, Test Acc: 73.7977
2022-09-05 14:49:31,449:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 14:49:35,281:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 76.0709 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:49:35,282:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.4844, Train Acc: 79.3850,
                        Val Loss: 0.5873, Val Acc: 74.6865, Test Acc: 76.0709
2022-09-05 14:49:35,282:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 14:49:39,043:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.4682, Train Acc: 80.9905,
                        Val Loss: 0.6007, Val Acc: 73.9346, Test Acc: 74.2679
2022-09-05 14:49:39,043:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 14:49:42,765:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.4452, Train Acc: 82.5228,
                        Val Loss: 0.5969, Val Acc: 73.6447, Test Acc: 75.2540
2022-09-05 14:49:42,765:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 14:49:46,510:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.4248, Train Acc: 83.6824,
                        Val Loss: 0.6404, Val Acc: 70.4296, Test Acc: 71.2975
2022-09-05 14:49:46,510:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 14:49:50,299:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.4187, Train Acc: 83.3849,
                        Val Loss: 0.7006, Val Acc: 68.0808, Test Acc: 68.8106
2022-09-05 14:49:50,299:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 14:49:54,114:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 79.5918 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:49:54,114:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.4146, Train Acc: 84.3600,
                        Val Loss: 0.6129, Val Acc: 76.8535, Test Acc: 79.5918
2022-09-05 14:49:54,114:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 14:49:57,923:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.3938, Train Acc: 84.7830,
                        Val Loss: 0.7885, Val Acc: 65.5278, Test Acc: 65.1181
2022-09-05 14:49:57,923:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 14:50:01,778:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 81.5371 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:50:01,778:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.3966, Train Acc: 84.3444,
                        Val Loss: 0.6024, Val Acc: 78.2317, Test Acc: 81.5371
2022-09-05 14:50:01,778:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 14:50:05,496:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3875, Train Acc: 85.2711,
                        Val Loss: 0.6647, Val Acc: 75.0682, Test Acc: 78.0674
2022-09-05 14:50:05,496:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 14:50:09,363:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.87s, LR: 0.00050, Train Loss: 0.3774, Train Acc: 85.5302,
                        Val Loss: 0.6793, Val Acc: 74.0732, Test Acc: 75.5570
2022-09-05 14:50:09,363:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 14:50:13,234:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.6949 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:50:13,234:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.87s, LR: 0.00050, Train Loss: 0.3715, Train Acc: 85.4968,
                        Val Loss: 0.5663, Val Acc: 80.9013, Test Acc: 82.6949
2022-09-05 14:50:13,234:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 14:50:16,955:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3524, Train Acc: 86.4668,
                        Val Loss: 0.6126, Val Acc: 77.7992, Test Acc: 80.7596
2022-09-05 14:50:16,955:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 14:50:20,747:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.3422, Train Acc: 86.8601,
                        Val Loss: 0.6052, Val Acc: 77.9245, Test Acc: 80.5242
2022-09-05 14:50:20,748:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 14:50:24,599:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.3313, Train Acc: 87.2957,
                        Val Loss: 0.5803, Val Acc: 78.8461, Test Acc: 81.7183
2022-09-05 14:50:24,599:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 14:50:28,366:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.2134 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:50:28,366:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.3217, Train Acc: 87.7034,
                        Val Loss: 0.5274, Val Acc: 81.0104, Test Acc: 84.2134
2022-09-05 14:50:28,366:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 14:50:32,133:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.3131, Train Acc: 87.4853,
                        Val Loss: 0.5358, Val Acc: 80.7650, Test Acc: 82.9145
2022-09-05 14:50:32,133:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 14:50:35,954:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.3006, Train Acc: 88.3805,
                        Val Loss: 0.5328, Val Acc: 80.7857, Test Acc: 83.0758
2022-09-05 14:50:35,954:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 14:50:39,816:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.2929, Train Acc: 89.2714,
                        Val Loss: 0.5138, Val Acc: 81.4204, Test Acc: 83.9607
2022-09-05 14:50:39,816:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 14:50:43,602:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.6484 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h48m22s_on_Sep_05_2022/MODELS_
2022-09-05 14:50:43,602:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.2831, Train Acc: 89.1680,
                        Val Loss: 0.5198, Val Acc: 80.6250, Test Acc: 84.6484
2022-09-05 14:50:43,602:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 14:50:47,388:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.2791, Train Acc: 88.6638,
                        Val Loss: 0.5310, Val Acc: 81.3324, Test Acc: 83.9749
2022-09-05 14:50:47,388:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 14:50:51,202:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.2729, Train Acc: 89.7071,
                        Val Loss: 0.5510, Val Acc: 80.7038, Test Acc: 83.2279
2022-09-05 14:50:51,203:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 14:50:54,952:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.2654, Train Acc: 90.2071,
                        Val Loss: 0.5200, Val Acc: 81.7089, Test Acc: 84.2050
2022-09-05 14:50:54,952:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 14:51:13,202:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:51:18,840:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:51:18,840:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:51:18,840:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:51:18,841:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:51:18,841:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:51:18,841:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:51:18,846:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:51:18,847:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:51:18,847:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:51:18,847:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:51:18,847:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:51:18,847:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:51:19,374:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:51:28,411:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:51:33,814:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:51:33,814:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:51:33,814:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:51:33,815:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:51:33,815:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:51:33,815:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:51:33,820:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:51:33,821:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:51:33,821:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:51:33,821:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:51:33,821:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:51:33,821:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:51:34,383:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:51:50,185:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:16.35823369026184
2022-09-05 14:51:50,189:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:51:50,189:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:51:50,189:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:51:50,189:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:51:50,190:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:51:53,976:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:51:53,976:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.6488, Train Acc: 66.4236,
                        Val Loss: 0.7288, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:51:53,976:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:51:57,897:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.92s, LR: 0.00050, Train Loss: 0.5758, Train Acc: 79.6933,
                        Val Loss: 0.7406, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:51:57,897:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:52:01,597:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.5162, Train Acc: 82.5251,
                        Val Loss: 0.7719, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:52:01,597:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:52:05,285:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.8548 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:05,285:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.4724, Train Acc: 84.3524,
                        Val Loss: 0.7711, Val Acc: 51.2453, Test Acc: 50.8548
2022-09-05 14:52:05,285:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:52:09,068:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 58.8109 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:09,068:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.4440, Train Acc: 85.4013,
                        Val Loss: 0.7179, Val Acc: 59.0117, Test Acc: 58.8109
2022-09-05 14:52:09,068:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:52:12,832:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 66.4783 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:12,832:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.4236, Train Acc: 85.9870,
                        Val Loss: 0.6215, Val Acc: 66.8501, Test Acc: 66.4783
2022-09-05 14:52:12,832:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:52:16,543:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 75.1764 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:16,543:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.4061, Train Acc: 86.5511,
                        Val Loss: 0.5172, Val Acc: 75.2330, Test Acc: 75.1764
2022-09-05 14:52:16,543:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:52:20,297:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 80.5253 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:20,297:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.3928, Train Acc: 87.1593,
                        Val Loss: 0.4515, Val Acc: 81.2689, Test Acc: 80.5253
2022-09-05 14:52:20,297:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:52:24,034:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.7463 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:24,034:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3812, Train Acc: 87.3533,
                        Val Loss: 0.4106, Val Acc: 84.2953, Test Acc: 83.7463
2022-09-05 14:52:24,034:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:52:27,776:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.2504 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:27,776:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3726, Train Acc: 87.1689,
                        Val Loss: 0.3906, Val Acc: 85.4005, Test Acc: 85.2504
2022-09-05 14:52:27,776:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:52:31,509:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.5344 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:31,509:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.3652, Train Acc: 87.3224,
                        Val Loss: 0.3806, Val Acc: 86.0848, Test Acc: 85.5344
2022-09-05 14:52:31,509:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:52:35,288:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.6709 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:35,288:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3573, Train Acc: 87.2274,
                        Val Loss: 0.3629, Val Acc: 87.0998, Test Acc: 86.6709
2022-09-05 14:52:35,288:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:52:39,100:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.3517, Train Acc: 87.2517,
                        Val Loss: 0.3579, Val Acc: 86.9625, Test Acc: 86.5349
2022-09-05 14:52:39,100:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:52:42,876:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.7248 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:42,876:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3442, Train Acc: 87.2943,
                        Val Loss: 0.3492, Val Acc: 87.1805, Test Acc: 86.7248
2022-09-05 14:52:42,876:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:52:46,597:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3387, Train Acc: 87.5505,
                        Val Loss: 0.3419, Val Acc: 87.4027, Test Acc: 86.6704
2022-09-05 14:52:46,597:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 14:52:50,318:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.9218 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:52:50,318:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3341, Train Acc: 87.3095,
                        Val Loss: 0.3345, Val Acc: 86.9459, Test Acc: 86.9218
2022-09-05 14:52:50,318:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 14:52:54,118:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3272, Train Acc: 87.6726,
                        Val Loss: 0.3322, Val Acc: 87.3212, Test Acc: 86.7976
2022-09-05 14:52:54,118:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 14:52:58,048:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.93s, LR: 0.00050, Train Loss: 0.3233, Train Acc: 87.6433,
                        Val Loss: 0.3291, Val Acc: 87.1205, Test Acc: 86.7133
2022-09-05 14:52:58,048:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 14:53:01,848:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 87.1751 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h51m33s_on_Sep_05_2022/MODELS_
2022-09-05 14:53:01,848:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3188, Train Acc: 87.8590,
                        Val Loss: 0.3210, Val Acc: 87.2713, Test Acc: 87.1751
2022-09-05 14:53:01,848:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 14:53:05,517:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.3147, Train Acc: 87.8107,
                        Val Loss: 0.3188, Val Acc: 87.3603, Test Acc: 86.8454
2022-09-05 14:53:05,517:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 14:53:09,234:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3111, Train Acc: 88.0420,
                        Val Loss: 0.3211, Val Acc: 87.1458, Test Acc: 86.6577
2022-09-05 14:53:09,235:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 14:53:13,012:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3065, Train Acc: 87.9272,
                        Val Loss: 0.3134, Val Acc: 87.2840, Test Acc: 86.7429
2022-09-05 14:53:13,012:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 14:53:16,792:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3033, Train Acc: 87.8620,
                        Val Loss: 0.3129, Val Acc: 87.1897, Test Acc: 86.8083
2022-09-05 14:53:16,793:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 14:53:20,534:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3011, Train Acc: 88.0163,
                        Val Loss: 0.3168, Val Acc: 86.9426, Test Acc: 86.6353
2022-09-05 14:53:20,534:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 14:53:24,331:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.2976, Train Acc: 87.9543,
                        Val Loss: 0.3088, Val Acc: 87.2831, Test Acc: 86.8484
2022-09-05 14:53:24,331:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 14:53:28,122:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.2953, Train Acc: 87.9068,
                        Val Loss: 0.3104, Val Acc: 86.9439, Test Acc: 86.8324
2022-09-05 14:53:28,122:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 14:53:31,863:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.2922, Train Acc: 88.1796,
                        Val Loss: 0.3155, Val Acc: 87.1412, Test Acc: 86.2404
2022-09-05 14:53:31,863:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 14:53:35,656:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.2896, Train Acc: 88.1284,
                        Val Loss: 0.3091, Val Acc: 87.2093, Test Acc: 86.6529
2022-09-05 14:53:35,656:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 14:53:39,398:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.2871, Train Acc: 88.4490,
                        Val Loss: 0.3173, Val Acc: 86.4136, Test Acc: 86.3675
2022-09-05 14:53:39,398:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 14:53:43,145:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.2859, Train Acc: 88.4962,
                        Val Loss: 0.3234, Val Acc: 86.7040, Test Acc: 85.8751
2022-09-05 14:53:43,145:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 14:53:46,867:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.2841, Train Acc: 88.1842,
                        Val Loss: 0.3209, Val Acc: 86.7276, Test Acc: 85.9803
2022-09-05 14:53:46,867:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 14:53:50,547:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.68s, LR: 0.00050, Train Loss: 0.2809, Train Acc: 88.7234,
                        Val Loss: 0.3359, Val Acc: 85.8617, Test Acc: 85.1698
2022-09-05 14:53:50,547:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 14:53:54,330:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.2800, Train Acc: 88.3634,
                        Val Loss: 0.3392, Val Acc: 85.7135, Test Acc: 85.4069
2022-09-05 14:53:54,331:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 14:53:58,123:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.2791, Train Acc: 88.3786,
                        Val Loss: 0.3476, Val Acc: 84.9954, Test Acc: 84.6442
2022-09-05 14:53:58,123:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 14:54:01,854:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.2770, Train Acc: 88.6653,
                        Val Loss: 0.3625, Val Acc: 84.3901, Test Acc: 83.9967
2022-09-05 14:54:01,854:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 14:54:05,565:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.2746, Train Acc: 88.6373,
                        Val Loss: 0.3774, Val Acc: 83.7617, Test Acc: 83.2210
2022-09-05 14:54:05,565:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 14:54:09,367:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00025, Train Loss: 0.2736, Train Acc: 88.7836,
                        Val Loss: 0.3820, Val Acc: 83.9056, Test Acc: 83.2294
2022-09-05 14:54:09,367:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 14:54:13,089:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00025, Train Loss: 0.2717, Train Acc: 88.6688,
                        Val Loss: 0.3788, Val Acc: 84.0629, Test Acc: 83.2516
2022-09-05 14:54:13,089:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 14:54:16,859:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00025, Train Loss: 0.2703, Train Acc: 88.7867,
                        Val Loss: 0.3652, Val Acc: 84.5832, Test Acc: 83.9205
2022-09-05 14:54:16,859:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 14:54:20,646:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00025, Train Loss: 0.2704, Train Acc: 88.7561,
                        Val Loss: 0.3734, Val Acc: 84.3326, Test Acc: 83.5317
2022-09-05 14:54:20,646:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 14:54:24,350:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00025, Train Loss: 0.2681, Train Acc: 88.8907,
                        Val Loss: 0.3897, Val Acc: 83.7014, Test Acc: 82.8979
2022-09-05 14:54:24,350:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 14:54:25,781:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 14:54:25,781:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 14:54:36,269:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:54:41,884:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:54:41,884:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:54:41,884:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:54:41,889:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:54:41,889:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:54:41,889:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:54:41,898:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:54:41,900:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:54:41,900:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:54:41,901:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:54:41,901:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:54:41,901:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:54:42,413:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:54:57,680:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:15.77303695678711
2022-09-05 14:54:57,683:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:54:57,683:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:54:57,683:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:54:57,684:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:54:57,685:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:55:01,581:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h54m41s_on_Sep_05_2022/MODELS_
2022-09-05 14:55:01,581:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.90s, LR: 0.00050, Train Loss: 0.6849, Train Acc: 58.8284,
                        Val Loss: 11.8325, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:01,581:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:55:05,527:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.95s, LR: 0.00050, Train Loss: 0.5844, Train Acc: 85.2481,
                        Val Loss: 8.8773, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:05,527:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:55:09,236:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.5386, Train Acc: 85.7767,
                        Val Loss: 6.1517, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:09,236:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:55:13,002:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.5070, Train Acc: 85.7750,
                        Val Loss: 4.0586, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:13,002:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:55:16,851:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.4814, Train Acc: 86.0017,
                        Val Loss: 3.3269, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:16,851:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:55:20,568:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.4593, Train Acc: 85.7820,
                        Val Loss: 3.0595, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:20,568:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:55:24,282:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.4398, Train Acc: 86.1622,
                        Val Loss: 2.8188, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:24,282:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:55:28,050:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.4245, Train Acc: 85.9543,
                        Val Loss: 2.5902, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:28,050:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:55:31,791:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.4103, Train Acc: 86.0962,
                        Val Loss: 2.2759, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:31,791:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:55:35,429:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.64s, LR: 0.00050, Train Loss: 0.3979, Train Acc: 86.2369,
                        Val Loss: 1.9773, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:35,429:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:55:39,175:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.3868, Train Acc: 86.3680,
                        Val Loss: 1.7708, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:39,175:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:55:42,892:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3757, Train Acc: 86.6687,
                        Val Loss: 1.6833, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:42,892:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:55:46,644:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.3662, Train Acc: 86.7866,
                        Val Loss: 1.6566, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:46,644:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:55:50,248:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.60s, LR: 0.00050, Train Loss: 0.3573, Train Acc: 86.7319,
                        Val Loss: 1.7646, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:50,249:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:55:53,953:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.3488, Train Acc: 86.7263,
                        Val Loss: 1.9907, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:55:53,953:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 14:55:54,613:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 14:55:54,613:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 14:56:19,340:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:56:25,121:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:56:25,121:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:56:25,121:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:56:25,122:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:56:25,122:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:56:25,122:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:56:25,127:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:56:25,128:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:56:25,128:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:56:25,129:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:56:25,129:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:56:25,129:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:56:25,639:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:56:41,229:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:16.094823837280273
2022-09-05 14:56:41,232:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:56:41,232:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:56:41,232:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:56:41,232:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:56:41,234:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:56:45,047:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h56m25s_on_Sep_05_2022/MODELS_
2022-09-05 14:56:45,048:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.6505, Train Acc: 70.5231,
                        Val Loss: 7.5254, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:56:45,048:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:56:48,949:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.90s, LR: 0.00050, Train Loss: 0.5720, Train Acc: 84.9652,
                        Val Loss: 6.8104, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:56:48,949:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:56:52,622:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.5298, Train Acc: 86.1491,
                        Val Loss: 6.6587, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:56:52,622:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:56:56,297:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.4921, Train Acc: 86.0938,
                        Val Loss: 5.9202, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:56:56,297:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:57:00,132:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.4638, Train Acc: 86.3484,
                        Val Loss: 4.8477, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:57:00,132:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:57:03,826:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.4433, Train Acc: 86.2790,
                        Val Loss: 4.3938, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:57:03,826:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:57:07,497:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.4259, Train Acc: 86.4007,
                        Val Loss: 4.0717, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:57:07,497:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:57:11,208:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.4129, Train Acc: 86.3822,
                        Val Loss: 4.0341, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:57:11,209:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:57:14,967:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.4006, Train Acc: 86.4567,
                        Val Loss: 4.0196, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:57:14,967:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:57:18,635:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.3895, Train Acc: 86.5210,
                        Val Loss: 4.2035, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:57:18,635:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:57:22,373:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3793, Train Acc: 86.7602,
                        Val Loss: 4.3905, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 14:57:22,373:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:57:34,925:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:57:40,575:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:57:40,575:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:57:40,576:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:57:40,584:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:57:40,585:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:57:40,585:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:57:40,590:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:57:40,591:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:57:40,591:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:57:40,591:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:57:40,591:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:57:40,591:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:57:41,106:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:57:56,632:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:16.03563904762268
2022-09-05 14:57:56,635:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:57:56,635:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:57:56,635:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:57:56,635:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:57:56,637:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:58:00,569:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 62.3293 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:00,569:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.93s, LR: 0.00050, Train Loss: 0.6770, Train Acc: 62.6516,
                        Val Loss: 0.6805, Val Acc: 61.5269, Test Acc: 62.3293
2022-09-05 14:58:00,569:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:58:04,531:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 63.1564 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:04,531:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.96s, LR: 0.00050, Train Loss: 0.6308, Train Acc: 67.5027,
                        Val Loss: 0.6687, Val Acc: 62.2141, Test Acc: 63.1564
2022-09-05 14:58:04,531:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:58:08,390:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.5895, Train Acc: 77.5919,
                        Val Loss: 0.6562, Val Acc: 59.2983, Test Acc: 60.0691
2022-09-05 14:58:08,391:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:58:12,200:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 63.4522 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:12,201:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.5535, Train Acc: 82.7682,
                        Val Loss: 0.6419, Val Acc: 62.7154, Test Acc: 63.4522
2022-09-05 14:58:12,201:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 14:58:16,102:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 67.3730 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:16,102:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.90s, LR: 0.00050, Train Loss: 0.5204, Train Acc: 84.3074,
                        Val Loss: 0.6246, Val Acc: 67.0991, Test Acc: 67.3730
2022-09-05 14:58:16,102:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 14:58:19,981:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 70.2941 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:19,982:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.88s, LR: 0.00050, Train Loss: 0.4955, Train Acc: 84.7544,
                        Val Loss: 0.6021, Val Acc: 70.1468, Test Acc: 70.2941
2022-09-05 14:58:19,982:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 14:58:23,823:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 74.0920 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:23,823:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.4747, Train Acc: 85.6229,
                        Val Loss: 0.5734, Val Acc: 73.1730, Test Acc: 74.0920
2022-09-05 14:58:23,823:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 14:58:27,657:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 75.8731 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:27,657:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.4576, Train Acc: 86.5464,
                        Val Loss: 0.5369, Val Acc: 76.1723, Test Acc: 75.8731
2022-09-05 14:58:27,657:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 14:58:31,529:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.8427 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:31,529:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.87s, LR: 0.00050, Train Loss: 0.4414, Train Acc: 86.8507,
                        Val Loss: 0.5051, Val Acc: 78.8182, Test Acc: 78.8427
2022-09-05 14:58:31,529:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 14:58:35,353:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.4993 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:35,353:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.4284, Train Acc: 86.8310,
                        Val Loss: 0.4698, Val Acc: 81.7737, Test Acc: 82.4993
2022-09-05 14:58:35,353:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 14:58:39,260:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.3897 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:39,260:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.91s, LR: 0.00050, Train Loss: 0.4169, Train Acc: 87.3092,
                        Val Loss: 0.4538, Val Acc: 82.7760, Test Acc: 83.3897
2022-09-05 14:58:39,260:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 14:58:43,145:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.88s, LR: 0.00050, Train Loss: 0.4050, Train Acc: 87.3985,
                        Val Loss: 0.4477, Val Acc: 82.4027, Test Acc: 82.8692
2022-09-05 14:58:43,145:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 14:58:47,064:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.5049 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:47,064:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.92s, LR: 0.00050, Train Loss: 0.3953, Train Acc: 87.2153,
                        Val Loss: 0.4197, Val Acc: 84.1754, Test Acc: 84.5049
2022-09-05 14:58:47,064:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 14:58:50,820:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.3849, Train Acc: 87.3839,
                        Val Loss: 0.4153, Val Acc: 83.7598, Test Acc: 84.0290
2022-09-05 14:58:50,820:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 14:58:54,677:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.9011 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:54,677:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.3760, Train Acc: 87.0517,
                        Val Loss: 0.3954, Val Acc: 85.0163, Test Acc: 84.9011
2022-09-05 14:58:54,677:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 14:58:58,506:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.5842 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:58:58,506:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.3683, Train Acc: 87.3546,
                        Val Loss: 0.3791, Val Acc: 85.9455, Test Acc: 85.5842
2022-09-05 14:58:58,506:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 14:59:02,376:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.87s, LR: 0.00050, Train Loss: 0.3595, Train Acc: 87.4351,
                        Val Loss: 0.3790, Val Acc: 85.6380, Test Acc: 85.2752
2022-09-05 14:59:02,376:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 14:59:06,172:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.2268 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:59:06,172:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3523, Train Acc: 87.3805,
                        Val Loss: 0.3599, Val Acc: 87.3331, Test Acc: 86.2268
2022-09-05 14:59:06,172:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 14:59:10,008:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.8301 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h57m40s_on_Sep_05_2022/MODELS_
2022-09-05 14:59:10,008:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.3456, Train Acc: 87.6485,
                        Val Loss: 0.3497, Val Acc: 87.1479, Test Acc: 86.8301
2022-09-05 14:59:10,008:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 14:59:13,791:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3377, Train Acc: 87.6308,
                        Val Loss: 0.3459, Val Acc: 87.3407, Test Acc: 86.5357
2022-09-05 14:59:13,791:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 14:59:14,717:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 14:59:14,717:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 14:59:24,048:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 14:59:29,375:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 14:59:29,375:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 14:59:29,376:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:59:29,376:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:59:29,377:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:59:29,377:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:59:29,382:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 14:59:29,382:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 14:59:29,383:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 14:59:29,383:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 14:59:29,383:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 14:59:29,383:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 14:59:29,890:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 14:59:41,654:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:12.265509128570557
2022-09-05 14:59:41,657:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 14:59:41,657:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 14:59:41,657:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 14:59:41,657:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 14:59:41,659:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 14:59:45,456:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 59.4481 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 14:59:45,456:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.6906, Train Acc: 49.8717,
                        Val Loss: 0.6822, Val Acc: 58.5060, Test Acc: 59.4481
2022-09-05 14:59:45,456:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 14:59:49,334:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.88s, LR: 0.00050, Train Loss: 0.6535, Train Acc: 76.3090,
                        Val Loss: 0.6803, Val Acc: 58.4034, Test Acc: 59.1076
2022-09-05 14:59:49,334:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 14:59:53,045:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 65.8227 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 14:59:53,045:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.6149, Train Acc: 81.1958,
                        Val Loss: 0.6745, Val Acc: 66.0363, Test Acc: 65.8227
2022-09-05 14:59:53,045:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 14:59:56,760:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 69.0412 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 14:59:56,760:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.5802, Train Acc: 83.5334,
                        Val Loss: 0.6667, Val Acc: 69.4208, Test Acc: 69.0412
2022-09-05 14:59:56,760:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:00:00,509:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.5507, Train Acc: 84.9425,
                        Val Loss: 0.6505, Val Acc: 68.8437, Test Acc: 67.8975
2022-09-05 15:00:00,509:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:00:04,222:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 73.0444 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:04,222:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.5273, Train Acc: 85.2461,
                        Val Loss: 0.6226, Val Acc: 72.9762, Test Acc: 73.0444
2022-09-05 15:00:04,222:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:00:07,883:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.9745 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:07,883:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.66s, LR: 0.00050, Train Loss: 0.5046, Train Acc: 85.9399,
                        Val Loss: 0.5876, Val Acc: 78.6552, Test Acc: 78.9745
2022-09-05 15:00:07,883:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:00:11,457:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.1939 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:11,458:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.57s, LR: 0.00050, Train Loss: 0.4830, Train Acc: 86.3787,
                        Val Loss: 0.5491, Val Acc: 83.5718, Test Acc: 83.1939
2022-09-05 15:00:11,458:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:00:15,090:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.4411 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:15,090:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.63s, LR: 0.00050, Train Loss: 0.4596, Train Acc: 86.7064,
                        Val Loss: 0.5156, Val Acc: 85.0744, Test Acc: 84.4411
2022-09-05 15:00:15,090:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:00:18,685:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.59s, LR: 0.00050, Train Loss: 0.4396, Train Acc: 86.8351,
                        Val Loss: 0.4923, Val Acc: 83.8730, Test Acc: 83.8417
2022-09-05 15:00:18,685:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:00:22,406:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.4219, Train Acc: 87.0888,
                        Val Loss: 0.4662, Val Acc: 83.8064, Test Acc: 83.7874
2022-09-05 15:00:22,406:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:00:26,127:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.9632 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:26,127:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.4042, Train Acc: 87.3705,
                        Val Loss: 0.4433, Val Acc: 84.2481, Test Acc: 84.9632
2022-09-05 15:00:26,127:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:00:29,972:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.3883, Train Acc: 87.1709,
                        Val Loss: 0.4239, Val Acc: 83.9700, Test Acc: 84.9292
2022-09-05 15:00:29,973:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:00:33,777:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4488 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:33,777:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3735, Train Acc: 87.1827,
                        Val Loss: 0.3976, Val Acc: 84.6423, Test Acc: 85.4488
2022-09-05 15:00:33,777:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:00:37,696:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.92s, LR: 0.00050, Train Loss: 0.3603, Train Acc: 87.3066,
                        Val Loss: 0.3833, Val Acc: 84.4220, Test Acc: 85.1902
2022-09-05 15:00:37,697:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:00:41,366:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4566 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:41,366:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.3498, Train Acc: 87.0800,
                        Val Loss: 0.3599, Val Acc: 85.1841, Test Acc: 85.4566
2022-09-05 15:00:41,366:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:00:45,141:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3374, Train Acc: 87.1902,
                        Val Loss: 0.3494, Val Acc: 85.5283, Test Acc: 85.4541
2022-09-05 15:00:45,141:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:00:48,884:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.1043 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:48,884:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3294, Train Acc: 87.5401,
                        Val Loss: 0.3357, Val Acc: 85.6256, Test Acc: 86.1043
2022-09-05 15:00:48,884:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:00:52,726:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.1543 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:52,726:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.3211, Train Acc: 87.4358,
                        Val Loss: 0.3346, Val Acc: 85.6580, Test Acc: 86.1543
2022-09-05 15:00:52,726:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:00:56,487:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.5271 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:00:56,487:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.3134, Train Acc: 87.6854,
                        Val Loss: 0.3223, Val Acc: 86.1611, Test Acc: 86.5271
2022-09-05 15:00:56,488:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:01:00,322:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.7582 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:01:00,322:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.3089, Train Acc: 87.6083,
                        Val Loss: 0.3146, Val Acc: 86.7082, Test Acc: 86.7582
2022-09-05 15:01:00,322:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:01:04,160:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.8105 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:01:04,160:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.3038, Train Acc: 87.6735,
                        Val Loss: 0.3162, Val Acc: 86.6385, Test Acc: 86.8105
2022-09-05 15:01:04,160:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:01:07,921:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.8127 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:01:07,921:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.2986, Train Acc: 87.8418,
                        Val Loss: 0.3159, Val Acc: 86.8571, Test Acc: 86.8127
2022-09-05 15:01:07,921:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 15:01:11,627:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 87.1142 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_14h59m29s_on_Sep_05_2022/MODELS_
2022-09-05 15:01:11,628:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.2954, Train Acc: 87.7519,
                        Val Loss: 0.3074, Val Acc: 87.3545, Test Acc: 87.1142
2022-09-05 15:01:11,628:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 15:01:15,370:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.2924, Train Acc: 87.6654,
                        Val Loss: 0.3152, Val Acc: 86.4475, Test Acc: 86.5511
2022-09-05 15:01:15,371:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 15:01:19,090:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.2926, Train Acc: 87.8216,
                        Val Loss: 0.3084, Val Acc: 87.1608, Test Acc: 87.0667
2022-09-05 15:01:19,091:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 15:01:22,790:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.2893, Train Acc: 87.8222,
                        Val Loss: 0.3184, Val Acc: 87.0390, Test Acc: 86.1497
2022-09-05 15:01:22,790:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 15:01:26,480:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.2856, Train Acc: 88.3370,
                        Val Loss: 0.3167, Val Acc: 86.9593, Test Acc: 86.5914
2022-09-05 15:01:26,480:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 15:01:30,179:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.2847, Train Acc: 88.3315,
                        Val Loss: 0.3225, Val Acc: 86.6230, Test Acc: 86.3307
2022-09-05 15:01:30,179:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 15:01:33,927:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.2829, Train Acc: 88.0576,
                        Val Loss: 0.3407, Val Acc: 85.8591, Test Acc: 85.3824
2022-09-05 15:01:33,927:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 15:01:37,601:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.2819, Train Acc: 88.1588,
                        Val Loss: 0.3376, Val Acc: 86.1654, Test Acc: 85.8626
2022-09-05 15:01:37,601:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 15:01:41,313:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.2788, Train Acc: 87.9893,
                        Val Loss: 0.3519, Val Acc: 85.4782, Test Acc: 85.1308
2022-09-05 15:01:41,313:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 15:01:45,047:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.2782, Train Acc: 88.0587,
                        Val Loss: 0.3522, Val Acc: 85.6223, Test Acc: 85.0253
2022-09-05 15:01:45,047:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 15:01:48,773:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.2768, Train Acc: 88.4516,
                        Val Loss: 0.3736, Val Acc: 84.0858, Test Acc: 83.9074
2022-09-05 15:01:48,774:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 15:01:52,448:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.2734, Train Acc: 88.1436,
                        Val Loss: 0.4053, Val Acc: 81.2662, Test Acc: 81.5883
2022-09-05 15:01:52,448:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 15:01:56,167:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00025, Train Loss: 0.2740, Train Acc: 88.0921,
                        Val Loss: 0.4026, Val Acc: 81.5937, Test Acc: 81.6446
2022-09-05 15:01:56,167:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 15:01:59,868:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00025, Train Loss: 0.2722, Train Acc: 88.3029,
                        Val Loss: 0.3995, Val Acc: 81.9925, Test Acc: 81.6882
2022-09-05 15:01:59,868:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 15:02:03,614:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00025, Train Loss: 0.2711, Train Acc: 88.5192,
                        Val Loss: 0.4052, Val Acc: 81.6731, Test Acc: 81.5491
2022-09-05 15:02:03,615:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 15:02:07,307:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00025, Train Loss: 0.2709, Train Acc: 88.4383,
                        Val Loss: 0.4181, Val Acc: 80.5204, Test Acc: 79.9078
2022-09-05 15:02:07,308:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 15:02:11,024:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00025, Train Loss: 0.2699, Train Acc: 88.5457,
                        Val Loss: 0.4181, Val Acc: 80.0847, Test Acc: 79.7008
2022-09-05 15:02:11,024:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 15:02:14,722:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00025, Train Loss: 0.2679, Train Acc: 88.5224,
                        Val Loss: 0.4203, Val Acc: 79.6628, Test Acc: 79.2247
2022-09-05 15:02:14,722:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 15:02:18,423:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00025, Train Loss: 0.2668, Train Acc: 88.2404,
                        Val Loss: 0.4338, Val Acc: 78.3986, Test Acc: 77.4544
2022-09-05 15:02:18,423:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 15:02:22,175:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00025, Train Loss: 0.2682, Train Acc: 88.4507,
                        Val Loss: 0.4239, Val Acc: 79.5496, Test Acc: 79.1793
2022-09-05 15:02:22,175:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 15:02:25,871:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00025, Train Loss: 0.2645, Train Acc: 88.7497,
                        Val Loss: 0.4378, Val Acc: 78.2598, Test Acc: 77.4537
2022-09-05 15:02:25,871:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 45/1000
2022-09-05 15:02:29,509:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.64s, LR: 0.00025, Train Loss: 0.2642, Train Acc: 88.8388,
                        Val Loss: 0.4407, Val Acc: 77.5459, Test Acc: 77.0295
2022-09-05 15:02:29,509:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 46/1000
2022-09-05 15:02:33,211:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00025, Train Loss: 0.2644, Train Acc: 88.3960,
                        Val Loss: 0.4587, Val Acc: 75.3005, Test Acc: 74.6442
2022-09-05 15:02:33,212:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 47/1000
2022-09-05 15:02:36,937:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00013, Train Loss: 0.2604, Train Acc: 88.4601,
                        Val Loss: 0.4410, Val Acc: 77.1746, Test Acc: 76.4829
2022-09-05 15:02:36,937:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 48/1000
2022-09-05 15:02:40,652:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00013, Train Loss: 0.2600, Train Acc: 88.8997,
                        Val Loss: 0.4199, Val Acc: 79.0989, Test Acc: 78.6503
2022-09-05 15:02:40,652:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 49/1000
2022-09-05 15:02:44,342:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00013, Train Loss: 0.2586, Train Acc: 88.8744,
                        Val Loss: 0.4089, Val Acc: 80.3616, Test Acc: 79.7101
2022-09-05 15:02:44,342:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 50/1000
2022-09-05 15:02:48,056:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00013, Train Loss: 0.2575, Train Acc: 88.7570,
                        Val Loss: 0.4003, Val Acc: 81.0883, Test Acc: 80.3099
2022-09-05 15:02:48,056:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 51/1000
2022-09-05 15:02:51,749:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00013, Train Loss: 0.2576, Train Acc: 88.5440,
                        Val Loss: 0.3836, Val Acc: 82.4901, Test Acc: 81.2473
2022-09-05 15:02:51,750:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 52/1000
2022-09-05 15:02:55,466:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00013, Train Loss: 0.2581, Train Acc: 88.6621,
                        Val Loss: 0.3726, Val Acc: 83.1762, Test Acc: 82.0156
2022-09-05 15:02:55,466:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 53/1000
2022-09-05 15:02:59,205:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00013, Train Loss: 0.2565, Train Acc: 88.8653,
                        Val Loss: 0.3634, Val Acc: 83.9972, Test Acc: 82.8894
2022-09-05 15:02:59,205:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 54/1000
2022-09-05 15:03:02,912:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00013, Train Loss: 0.2559, Train Acc: 88.8521,
                        Val Loss: 0.3677, Val Acc: 83.1375, Test Acc: 82.7267
2022-09-05 15:03:02,912:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 55/1000
2022-09-05 15:03:06,690:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00013, Train Loss: 0.2552, Train Acc: 88.9365,
                        Val Loss: 0.3690, Val Acc: 83.0712, Test Acc: 82.3653
2022-09-05 15:03:06,690:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 56/1000
2022-09-05 15:03:10,464:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00013, Train Loss: 0.2539, Train Acc: 88.7562,
                        Val Loss: 0.3629, Val Acc: 83.8492, Test Acc: 82.6821
2022-09-05 15:03:10,464:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 57/1000
2022-09-05 15:03:14,230:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00013, Train Loss: 0.2538, Train Acc: 88.9774,
                        Val Loss: 0.3681, Val Acc: 83.4989, Test Acc: 82.3234
2022-09-05 15:03:14,231:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 58/1000
2022-09-05 15:03:17,992:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00006, Train Loss: 0.2528, Train Acc: 88.9521,
                        Val Loss: 0.3593, Val Acc: 83.9542, Test Acc: 83.2739
2022-09-05 15:03:17,992:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 59/1000
2022-09-05 15:03:21,766:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00006, Train Loss: 0.2530, Train Acc: 88.8779,
                        Val Loss: 0.3491, Val Acc: 84.8144, Test Acc: 83.7802
2022-09-05 15:03:21,766:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 60/1000
2022-09-05 15:03:25,561:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00006, Train Loss: 0.2525, Train Acc: 88.9246,
                        Val Loss: 0.3423, Val Acc: 85.2940, Test Acc: 84.4009
2022-09-05 15:03:25,561:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 61/1000
2022-09-05 15:03:29,376:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00006, Train Loss: 0.2510, Train Acc: 88.9422,
                        Val Loss: 0.3374, Val Acc: 85.3720, Test Acc: 84.6434
2022-09-05 15:03:29,376:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 62/1000
2022-09-05 15:03:33,207:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00006, Train Loss: 0.2531, Train Acc: 88.9379,
                        Val Loss: 0.3344, Val Acc: 85.7235, Test Acc: 84.8825
2022-09-05 15:03:33,208:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 63/1000
2022-09-05 15:03:37,007:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00006, Train Loss: 0.2499, Train Acc: 89.0110,
                        Val Loss: 0.3339, Val Acc: 85.6134, Test Acc: 85.0434
2022-09-05 15:03:37,008:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 64/1000
2022-09-05 15:03:40,787:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00006, Train Loss: 0.2488, Train Acc: 89.0490,
                        Val Loss: 0.3331, Val Acc: 85.7596, Test Acc: 85.1942
2022-09-05 15:03:40,787:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 65/1000
2022-09-05 15:03:44,534:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00006, Train Loss: 0.2491, Train Acc: 88.9558,
                        Val Loss: 0.3311, Val Acc: 85.7790, Test Acc: 85.5388
2022-09-05 15:03:44,534:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 66/1000
2022-09-05 15:03:48,308:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00006, Train Loss: 0.2491, Train Acc: 89.0387,
                        Val Loss: 0.3290, Val Acc: 85.8623, Test Acc: 85.3238
2022-09-05 15:03:48,308:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 67/1000
2022-09-05 15:03:52,104:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00006, Train Loss: 0.2482, Train Acc: 89.2501,
                        Val Loss: 0.3274, Val Acc: 86.0205, Test Acc: 85.5322
2022-09-05 15:03:52,104:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 68/1000
2022-09-05 15:03:55,867:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00006, Train Loss: 0.2473, Train Acc: 88.9972,
                        Val Loss: 0.3269, Val Acc: 85.8780, Test Acc: 85.6252
2022-09-05 15:03:55,867:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 69/1000
2022-09-05 15:03:59,671:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00003, Train Loss: 0.2461, Train Acc: 89.3613,
                        Val Loss: 0.3267, Val Acc: 85.9434, Test Acc: 85.7987
2022-09-05 15:03:59,671:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 70/1000
2022-09-05 15:04:03,460:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00003, Train Loss: 0.2464, Train Acc: 88.9789,
                        Val Loss: 0.3267, Val Acc: 86.0359, Test Acc: 85.8490
2022-09-05 15:04:03,461:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 71/1000
2022-09-05 15:04:07,170:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00003, Train Loss: 0.2498, Train Acc: 89.1266,
                        Val Loss: 0.3265, Val Acc: 86.1874, Test Acc: 85.9404
2022-09-05 15:04:07,170:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 72/1000
2022-09-05 15:04:10,910:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00003, Train Loss: 0.2466, Train Acc: 89.4135,
                        Val Loss: 0.3260, Val Acc: 86.2575, Test Acc: 86.0328
2022-09-05 15:04:10,911:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 73/1000
2022-09-05 15:04:14,604:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00003, Train Loss: 0.2453, Train Acc: 89.3917,
                        Val Loss: 0.3261, Val Acc: 86.2712, Test Acc: 86.0168
2022-09-05 15:04:14,604:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 74/1000
2022-09-05 15:04:18,400:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00003, Train Loss: 0.2472, Train Acc: 89.2557,
                        Val Loss: 0.3262, Val Acc: 86.3885, Test Acc: 86.1533
2022-09-05 15:04:18,400:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 75/1000
2022-09-05 15:04:22,182:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00003, Train Loss: 0.2447, Train Acc: 89.2840,
                        Val Loss: 0.3253, Val Acc: 86.5333, Test Acc: 86.1513
2022-09-05 15:04:22,182:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 76/1000
2022-09-05 15:04:26,018:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00003, Train Loss: 0.2450, Train Acc: 89.3766,
                        Val Loss: 0.3256, Val Acc: 86.6119, Test Acc: 86.1447
2022-09-05 15:04:26,018:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 77/1000
2022-09-05 15:04:29,795:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00003, Train Loss: 0.2445, Train Acc: 89.3404,
                        Val Loss: 0.3266, Val Acc: 86.4358, Test Acc: 86.2812
2022-09-05 15:04:29,795:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 78/1000
2022-09-05 15:04:33,551:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00003, Train Loss: 0.2440, Train Acc: 89.4329,
                        Val Loss: 0.3276, Val Acc: 86.3046, Test Acc: 86.1576
2022-09-05 15:04:33,552:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 79/1000
2022-09-05 15:04:37,352:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00003, Train Loss: 0.2441, Train Acc: 89.2542,
                        Val Loss: 0.3275, Val Acc: 86.3314, Test Acc: 86.0800
2022-09-05 15:04:37,352:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 80/1000
2022-09-05 15:04:41,114:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00002, Train Loss: 0.2440, Train Acc: 89.3538,
                        Val Loss: 0.3277, Val Acc: 86.3962, Test Acc: 86.1687
2022-09-05 15:04:41,114:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 81/1000
2022-09-05 15:04:44,904:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00002, Train Loss: 0.2452, Train Acc: 89.4027,
                        Val Loss: 0.3279, Val Acc: 86.3051, Test Acc: 86.3237
2022-09-05 15:04:44,904:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 82/1000
2022-09-05 15:04:48,656:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00002, Train Loss: 0.2457, Train Acc: 89.2520,
                        Val Loss: 0.3282, Val Acc: 86.1997, Test Acc: 86.3947
2022-09-05 15:04:48,656:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 83/1000
2022-09-05 15:04:52,385:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00002, Train Loss: 0.2441, Train Acc: 89.1542,
                        Val Loss: 0.3287, Val Acc: 86.1739, Test Acc: 86.4741
2022-09-05 15:04:52,385:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 84/1000
2022-09-05 15:04:56,079:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00002, Train Loss: 0.2438, Train Acc: 89.3826,
                        Val Loss: 0.3290, Val Acc: 86.1405, Test Acc: 86.4879
2022-09-05 15:04:56,079:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 85/1000
2022-09-05 15:04:59,853:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00002, Train Loss: 0.2427, Train Acc: 89.3834,
                        Val Loss: 0.3293, Val Acc: 86.1717, Test Acc: 86.5346
2022-09-05 15:04:59,853:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 86/1000
2022-09-05 15:05:03,567:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00002, Train Loss: 0.2428, Train Acc: 89.3032,
                        Val Loss: 0.3298, Val Acc: 86.1909, Test Acc: 86.5757
2022-09-05 15:05:03,567:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 87/1000
2022-09-05 15:05:07,320:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00002, Train Loss: 0.2430, Train Acc: 89.4712,
                        Val Loss: 0.3297, Val Acc: 86.1047, Test Acc: 86.4878
2022-09-05 15:05:07,320:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 88/1000
2022-09-05 15:05:11,053:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00002, Train Loss: 0.2415, Train Acc: 89.6155,
                        Val Loss: 0.3299, Val Acc: 86.1047, Test Acc: 86.4204
2022-09-05 15:05:11,053:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 89/1000
2022-09-05 15:05:14,784:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00002, Train Loss: 0.2427, Train Acc: 89.4964,
                        Val Loss: 0.3306, Val Acc: 86.1909, Test Acc: 86.3614
2022-09-05 15:05:14,784:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 90/1000
2022-09-05 15:05:18,537:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00002, Train Loss: 0.2435, Train Acc: 89.3124,
                        Val Loss: 0.3308, Val Acc: 86.2013, Test Acc: 86.3138
2022-09-05 15:05:18,537:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 91/1000
2022-09-05 15:05:22,252:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00001, Train Loss: 0.2427, Train Acc: 89.4373,
                        Val Loss: 0.3311, Val Acc: 86.2212, Test Acc: 86.3708
2022-09-05 15:05:22,252:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 92/1000
2022-09-05 15:05:25,999:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00001, Train Loss: 0.2422, Train Acc: 89.3363,
                        Val Loss: 0.3311, Val Acc: 86.1634, Test Acc: 86.4212
2022-09-05 15:05:25,999:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 93/1000
2022-09-05 15:05:29,764:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00001, Train Loss: 0.2405, Train Acc: 89.5943,
                        Val Loss: 0.3310, Val Acc: 86.1963, Test Acc: 86.4409
2022-09-05 15:05:29,764:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 94/1000
2022-09-05 15:05:33,564:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00001, Train Loss: 0.2415, Train Acc: 89.3207,
                        Val Loss: 0.3312, Val Acc: 86.1409, Test Acc: 86.3650
2022-09-05 15:05:33,564:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 95/1000
2022-09-05 15:05:37,393:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00001, Train Loss: 0.2421, Train Acc: 89.5966,
                        Val Loss: 0.3315, Val Acc: 86.1340, Test Acc: 86.4155
2022-09-05 15:05:37,393:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 96/1000
2022-09-05 15:05:41,164:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00001, Train Loss: 0.2410, Train Acc: 89.7006,
                        Val Loss: 0.3316, Val Acc: 86.1236, Test Acc: 86.3865
2022-09-05 15:05:41,164:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 97/1000
2022-09-05 15:05:44,935:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00001, Train Loss: 0.2425, Train Acc: 89.4178,
                        Val Loss: 0.3320, Val Acc: 86.1729, Test Acc: 86.4258
2022-09-05 15:05:44,935:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 98/1000
2022-09-05 15:05:48,707:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00001, Train Loss: 0.2410, Train Acc: 89.3610,
                        Val Loss: 0.3324, Val Acc: 86.1833, Test Acc: 86.3677
2022-09-05 15:05:48,707:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 99/1000
2022-09-05 15:05:52,490:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00001, Train Loss: 0.2414, Train Acc: 89.3915,
                        Val Loss: 0.3328, Val Acc: 86.1842, Test Acc: 86.4351
2022-09-05 15:05:52,490:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 100/1000
2022-09-05 15:05:56,277:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00001, Train Loss: 0.2419, Train Acc: 89.6639,
                        Val Loss: 0.3331, Val Acc: 86.2438, Test Acc: 86.5145
2022-09-05 15:05:56,277:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 101/1000
2022-09-05 15:06:00,022:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00001, Train Loss: 0.2408, Train Acc: 89.5631,
                        Val Loss: 0.3331, Val Acc: 86.2533, Test Acc: 86.4668
2022-09-05 15:06:00,022:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 102/1000
2022-09-05 15:06:03,773:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00000, Train Loss: 0.2433, Train Acc: 89.3963,
                        Val Loss: 0.3333, Val Acc: 86.2931, Test Acc: 86.4957
2022-09-05 15:06:03,773:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 103/1000
2022-09-05 15:06:07,628:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00000, Train Loss: 0.2407, Train Acc: 89.5228,
                        Val Loss: 0.3332, Val Acc: 86.2741, Test Acc: 86.4854
2022-09-05 15:06:07,628:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 104/1000
2022-09-05 15:06:11,504:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.88s, LR: 0.00000, Train Loss: 0.2407, Train Acc: 89.5611,
                        Val Loss: 0.3332, Val Acc: 86.2922, Test Acc: 86.4078
2022-09-05 15:06:11,504:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 105/1000
2022-09-05 15:06:15,417:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.91s, LR: 0.00000, Train Loss: 0.2402, Train Acc: 89.3998,
                        Val Loss: 0.3333, Val Acc: 86.3026, Test Acc: 86.4078
2022-09-05 15:06:15,417:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 106/1000
2022-09-05 15:06:30,239:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:06:36,102:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:06:36,103:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:06:36,104:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:06:36,105:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:06:36,105:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:06:36,105:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:06:36,110:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:06:36,110:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:06:36,111:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:06:36,111:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:06:36,111:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:06:36,111:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:06:36,570:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:06:44,918:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:8.800556182861328
2022-09-05 15:06:44,922:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:06:44,922:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:06:44,922:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:06:44,922:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:06:44,923:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:06:48,840:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h06m36s_on_Sep_05_2022/MODELS_
2022-09-05 15:06:48,840:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.92s, LR: 0.00050, Train Loss: 0.7147, Train Acc: 35.5164,
                        Val Loss: 2.6894, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:06:48,840:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:06:52,810:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.2124 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h06m36s_on_Sep_05_2022/MODELS_
2022-09-05 15:06:52,810:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.97s, LR: 0.00050, Train Loss: 0.6376, Train Acc: 85.0454,
                        Val Loss: 0.7373, Val Acc: 50.0776, Test Acc: 50.2124
2022-09-05 15:06:52,810:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:06:56,609:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 64.6736 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h06m36s_on_Sep_05_2022/MODELS_
2022-09-05 15:06:56,609:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.5830, Train Acc: 86.1169,
                        Val Loss: 0.5551, Val Acc: 64.9110, Test Acc: 64.6736
2022-09-05 15:06:56,609:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:07:00,443:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.5414, Train Acc: 86.3488,
                        Val Loss: 1.0842, Val Acc: 50.0000, Test Acc: 50.0093
2022-09-05 15:07:00,443:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:07:04,330:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.5073, Train Acc: 86.8169,
                        Val Loss: 1.8260, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:07:04,330:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:07:08,156:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.4825, Train Acc: 86.6140,
                        Val Loss: 2.0135, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:07:08,157:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:07:20,491:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:07:26,160:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:07:26,160:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:07:26,160:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:07:26,161:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:07:26,161:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:07:26,161:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:07:26,166:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:07:26,167:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:07:26,167:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:07:26,168:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:07:26,168:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:07:26,168:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:07:26,662:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:07:36,912:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:10.738598823547363
2022-09-05 15:07:36,914:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:07:36,914:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:07:36,914:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:07:36,914:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:07:36,916:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:07:40,683:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:07:40,683:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.6681, Train Acc: 50.0000,
                        Val Loss: 0.8842, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:07:40,683:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:07:44,535:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.5798, Train Acc: 59.6919,
                        Val Loss: 0.9846, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:07:44,535:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:07:48,258:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.5333, Train Acc: 65.5661,
                        Val Loss: 1.0044, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:07:48,259:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:07:52,045:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.2466 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:07:52,045:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.5048, Train Acc: 71.2141,
                        Val Loss: 0.9141, Val Acc: 50.3314, Test Acc: 50.2466
2022-09-05 15:07:52,045:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:07:55,891:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 55.8406 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:07:55,891:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.4849, Train Acc: 76.1917,
                        Val Loss: 0.7262, Val Acc: 56.0869, Test Acc: 55.8406
2022-09-05 15:07:55,891:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:07:59,680:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 69.1217 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:07:59,680:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.4687, Train Acc: 79.7815,
                        Val Loss: 0.5621, Val Acc: 69.5219, Test Acc: 69.1217
2022-09-05 15:07:59,680:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:08:03,436:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 79.2063 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:08:03,436:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.4537, Train Acc: 83.6572,
                        Val Loss: 0.4749, Val Acc: 78.7459, Test Acc: 79.2063
2022-09-05 15:08:03,436:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:08:07,111:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.9611 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:08:07,111:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.68s, LR: 0.00050, Train Loss: 0.4413, Train Acc: 85.4430,
                        Val Loss: 0.4382, Val Acc: 82.0192, Test Acc: 82.9611
2022-09-05 15:08:07,111:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:08:10,879:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.7653 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:08:10,879:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.4293, Train Acc: 86.6110,
                        Val Loss: 0.4271, Val Acc: 83.1274, Test Acc: 83.7653
2022-09-05 15:08:10,879:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:08:14,618:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.4190, Train Acc: 87.2591,
                        Val Loss: 0.4241, Val Acc: 82.6299, Test Acc: 82.8571
2022-09-05 15:08:14,618:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:08:18,361:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.4095, Train Acc: 87.3018,
                        Val Loss: 0.4219, Val Acc: 81.8230, Test Acc: 81.9255
2022-09-05 15:08:18,361:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:08:22,061:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.3995, Train Acc: 87.3675,
                        Val Loss: 0.4166, Val Acc: 82.4215, Test Acc: 82.0581
2022-09-05 15:08:22,061:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:08:25,840:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3907, Train Acc: 87.1998,
                        Val Loss: 0.4098, Val Acc: 83.1205, Test Acc: 83.0347
2022-09-05 15:08:25,840:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:08:29,563:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.9496 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:08:29,563:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3817, Train Acc: 87.3485,
                        Val Loss: 0.4032, Val Acc: 83.9672, Test Acc: 83.9496
2022-09-05 15:08:29,563:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:08:33,312:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.9995 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h07m26s_on_Sep_05_2022/MODELS_
2022-09-05 15:08:33,312:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.3730, Train Acc: 87.5424,
                        Val Loss: 0.3960, Val Acc: 83.9845, Test Acc: 83.9995
2022-09-05 15:08:33,312:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:08:37,028:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.3655, Train Acc: 87.6694,
                        Val Loss: 0.3911, Val Acc: 84.1929, Test Acc: 83.8454
2022-09-05 15:08:37,028:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:08:40,786:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.3569, Train Acc: 87.9418,
                        Val Loss: 0.3974, Val Acc: 83.3365, Test Acc: 83.3163
2022-09-05 15:08:40,786:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:08:44,485:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.3498, Train Acc: 87.6897,
                        Val Loss: 0.3998, Val Acc: 82.8710, Test Acc: 82.7442
2022-09-05 15:08:44,485:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:08:48,221:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3430, Train Acc: 87.9450,
                        Val Loss: 0.4061, Val Acc: 82.1706, Test Acc: 82.0545
2022-09-05 15:08:48,221:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:08:51,998:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3361, Train Acc: 87.9421,
                        Val Loss: 0.4269, Val Acc: 80.5995, Test Acc: 80.5767
2022-09-05 15:08:51,998:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:08:55,779:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3304, Train Acc: 87.7369,
                        Val Loss: 0.4393, Val Acc: 79.3184, Test Acc: 79.4656
2022-09-05 15:08:55,780:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:09:02,180:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:09:07,868:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:09:07,868:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:09:07,868:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:09:07,869:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:09:07,869:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:09:07,869:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:09:07,874:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:09:07,875:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:09:07,875:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:09:07,876:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:09:07,876:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:09:07,876:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:09:08,330:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:09:19,943:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:12.062204122543335
2022-09-05 15:09:19,947:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:09:19,947:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:09:19,947:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:09:19,947:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:09:19,948:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:09:23,750:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h09m07s_on_Sep_05_2022/MODELS_
2022-09-05 15:09:23,750:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.6837, Train Acc: 50.0000,
                        Val Loss: 0.9742, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:09:23,750:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:09:27,666:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.92s, LR: 0.00050, Train Loss: 0.6185, Train Acc: 50.0000,
                        Val Loss: 0.8812, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:09:27,666:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:09:31,461:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.5874, Train Acc: 50.0000,
                        Val Loss: 1.5845, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:09:31,469:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:09:35,247:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.2900 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h09m07s_on_Sep_05_2022/MODELS_
2022-09-05 15:09:35,247:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.5592, Train Acc: 54.7234,
                        Val Loss: 1.1651, Val Acc: 50.3471, Test Acc: 50.2900
2022-09-05 15:09:35,247:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:09:39,156:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 79.2076 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h09m07s_on_Sep_05_2022/MODELS_
2022-09-05 15:09:39,156:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.91s, LR: 0.00050, Train Loss: 0.5368, Train Acc: 64.7570,
                        Val Loss: 0.4812, Val Acc: 79.4951, Test Acc: 79.2076
2022-09-05 15:09:39,156:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:09:42,982:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.5186, Train Acc: 70.4922,
                        Val Loss: 1.2645, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:09:42,982:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:09:46,766:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.5013, Train Acc: 75.7277,
                        Val Loss: 2.1296, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:09:46,766:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:09:50,651:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.4868, Train Acc: 80.7559,
                        Val Loss: 2.6112, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:09:50,651:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:09:54,557:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.91s, LR: 0.00050, Train Loss: 0.4731, Train Acc: 83.6521,
                        Val Loss: 3.0604, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:09:54,557:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:09:56,173:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 15:09:56,174:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 15:10:04,721:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:10:10,123:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:10:10,123:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:10:10,123:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:10:10,124:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:10:10,124:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:10:10,124:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:10:10,129:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:10:10,130:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:10:10,130:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:10:10,131:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:10:10,131:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:10:10,131:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:10:10,711:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:10:26,054:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:15.916047811508179
2022-09-05 15:10:26,057:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:10:26,057:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:10:26,057:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:10:26,057:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:10:26,058:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:10:29,972:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0402 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:10:29,972:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.91s, LR: 0.00050, Train Loss: 0.6939, Train Acc: 50.7363,
                        Val Loss: 0.6857, Val Acc: 50.0606, Test Acc: 50.0402
2022-09-05 15:10:29,972:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:10:33,971:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 58.4777 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:10:33,971:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 4.00s, LR: 0.00050, Train Loss: 0.6478, Train Acc: 59.2178,
                        Val Loss: 0.6772, Val Acc: 58.6140, Test Acc: 58.4777
2022-09-05 15:10:33,971:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:10:37,789:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 67.7708 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:10:37,789:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.6088, Train Acc: 74.5028,
                        Val Loss: 0.6687, Val Acc: 67.0443, Test Acc: 67.7708
2022-09-05 15:10:37,789:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:10:41,536:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.5712, Train Acc: 82.3263,
                        Val Loss: 0.6609, Val Acc: 58.2114, Test Acc: 59.7100
2022-09-05 15:10:41,538:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:10:45,375:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.5374, Train Acc: 84.0081,
                        Val Loss: 0.6462, Val Acc: 60.9151, Test Acc: 62.6858
2022-09-05 15:10:45,375:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:10:49,240:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 75.7256 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:10:49,240:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.5073, Train Acc: 85.0267,
                        Val Loss: 0.6196, Val Acc: 74.8450, Test Acc: 75.7256
2022-09-05 15:10:49,240:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:10:53,126:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.0168 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:10:53,126:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.4774, Train Acc: 86.1175,
                        Val Loss: 0.5931, Val Acc: 77.6375, Test Acc: 78.0168
2022-09-05 15:10:53,126:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:10:57,014:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.1953 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:10:57,014:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.4521, Train Acc: 86.6785,
                        Val Loss: 0.5556, Val Acc: 82.3219, Test Acc: 83.1953
2022-09-05 15:10:57,014:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:11:00,752:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.8260 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:00,752:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.4320, Train Acc: 86.7532,
                        Val Loss: 0.5214, Val Acc: 83.2117, Test Acc: 83.8260
2022-09-05 15:11:00,752:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:11:04,480:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.3770 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:04,480:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.4151, Train Acc: 87.1796,
                        Val Loss: 0.4927, Val Acc: 83.8755, Test Acc: 84.3770
2022-09-05 15:11:04,480:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:11:08,277:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3997, Train Acc: 87.0044,
                        Val Loss: 0.4726, Val Acc: 83.3991, Test Acc: 83.7995
2022-09-05 15:11:08,277:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:11:11,946:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.67s, LR: 0.00050, Train Loss: 0.3855, Train Acc: 86.9673,
                        Val Loss: 0.4453, Val Acc: 83.7911, Test Acc: 83.7353
2022-09-05 15:11:11,946:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:11:15,776:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.3731, Train Acc: 87.1593,
                        Val Loss: 0.4259, Val Acc: 83.5073, Test Acc: 83.4999
2022-09-05 15:11:15,777:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:11:19,549:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.3613, Train Acc: 87.2993,
                        Val Loss: 0.4072, Val Acc: 84.5740, Test Acc: 84.1902
2022-09-05 15:11:19,550:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:11:23,325:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.4101 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:23,325:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3503, Train Acc: 87.5996,
                        Val Loss: 0.3908, Val Acc: 84.0951, Test Acc: 84.4101
2022-09-05 15:11:23,325:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:11:27,068:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3428, Train Acc: 87.4334,
                        Val Loss: 0.3798, Val Acc: 84.6855, Test Acc: 84.1079
2022-09-05 15:11:27,068:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:11:30,864:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.5476 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:30,864:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3337, Train Acc: 87.2983,
                        Val Loss: 0.3680, Val Acc: 84.6087, Test Acc: 84.5476
2022-09-05 15:11:30,864:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:11:34,640:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.2589 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:34,640:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3264, Train Acc: 87.7158,
                        Val Loss: 0.3524, Val Acc: 85.5495, Test Acc: 85.2589
2022-09-05 15:11:34,640:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:11:38,460:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4598 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:38,460:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.3208, Train Acc: 87.7029,
                        Val Loss: 0.3433, Val Acc: 86.5149, Test Acc: 85.4598
2022-09-05 15:11:38,461:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:11:42,169:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.3145, Train Acc: 87.6977,
                        Val Loss: 0.3380, Val Acc: 86.1057, Test Acc: 85.4168
2022-09-05 15:11:42,169:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:11:45,955:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.4166 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:45,956:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.3116, Train Acc: 87.4012,
                        Val Loss: 0.3259, Val Acc: 86.7666, Test Acc: 86.4166
2022-09-05 15:11:45,956:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:11:49,723:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.3057, Train Acc: 87.7641,
                        Val Loss: 0.3345, Val Acc: 86.3460, Test Acc: 85.3952
2022-09-05 15:11:49,723:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:11:53,480:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.9865 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h10m10s_on_Sep_05_2022/MODELS_
2022-09-05 15:11:53,481:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.3024, Train Acc: 87.6988,
                        Val Loss: 0.3159, Val Acc: 87.1367, Test Acc: 86.9865
2022-09-05 15:11:53,481:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 15:11:57,225:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.3004, Train Acc: 87.8427,
                        Val Loss: 0.3191, Val Acc: 87.5312, Test Acc: 86.5457
2022-09-05 15:11:57,225:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 15:12:00,977:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.2985, Train Acc: 87.6655,
                        Val Loss: 0.3207, Val Acc: 87.1556, Test Acc: 86.1196
2022-09-05 15:12:00,977:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 15:12:04,758:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.2952, Train Acc: 87.9997,
                        Val Loss: 0.3176, Val Acc: 86.2736, Test Acc: 86.4874
2022-09-05 15:12:04,758:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 15:12:08,492:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.2920, Train Acc: 87.9560,
                        Val Loss: 0.3122, Val Acc: 87.3467, Test Acc: 86.9269
2022-09-05 15:12:08,492:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 15:12:12,229:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00050, Train Loss: 0.2908, Train Acc: 87.6372,
                        Val Loss: 0.3127, Val Acc: 87.4556, Test Acc: 86.7819
2022-09-05 15:12:12,229:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 15:12:15,978:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.2868, Train Acc: 88.1455,
                        Val Loss: 0.3134, Val Acc: 86.4220, Test Acc: 86.5895
2022-09-05 15:12:15,978:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 15:12:19,753:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.2890, Train Acc: 87.5341,
                        Val Loss: 0.3154, Val Acc: 86.5235, Test Acc: 86.6186
2022-09-05 15:12:19,753:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 15:12:23,531:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.2833, Train Acc: 88.3632,
                        Val Loss: 0.3142, Val Acc: 87.0280, Test Acc: 86.7360
2022-09-05 15:12:23,532:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 15:12:27,292:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.2828, Train Acc: 88.3327,
                        Val Loss: 0.3105, Val Acc: 87.2273, Test Acc: 86.9648
2022-09-05 15:12:27,292:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 15:12:31,044:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.2815, Train Acc: 88.4792,
                        Val Loss: 0.3091, Val Acc: 86.9563, Test Acc: 86.7983
2022-09-05 15:12:31,044:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 15:12:34,826:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.2804, Train Acc: 88.4057,
                        Val Loss: 0.3238, Val Acc: 86.1528, Test Acc: 85.5450
2022-09-05 15:12:34,826:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 15:12:38,542:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.2788, Train Acc: 88.2898,
                        Val Loss: 0.3146, Val Acc: 86.7510, Test Acc: 86.5657
2022-09-05 15:12:38,542:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 15:12:42,371:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.2758, Train Acc: 88.4322,
                        Val Loss: 0.3131, Val Acc: 87.0131, Test Acc: 86.4887
2022-09-05 15:12:42,371:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 15:12:46,138:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.2748, Train Acc: 88.4217,
                        Val Loss: 0.3221, Val Acc: 86.5011, Test Acc: 86.2264
2022-09-05 15:12:46,138:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 15:12:49,936:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.2727, Train Acc: 88.8642,
                        Val Loss: 0.3158, Val Acc: 87.2389, Test Acc: 86.6846
2022-09-05 15:12:49,936:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 15:12:53,792:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.2719, Train Acc: 88.4660,
                        Val Loss: 0.3317, Val Acc: 85.2692, Test Acc: 85.5065
2022-09-05 15:12:53,792:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 15:12:57,638:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.2719, Train Acc: 88.3921,
                        Val Loss: 0.3200, Val Acc: 86.5613, Test Acc: 86.3898
2022-09-05 15:12:57,639:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 15:13:01,405:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.2675, Train Acc: 88.7139,
                        Val Loss: 0.3330, Val Acc: 85.6487, Test Acc: 85.4270
2022-09-05 15:13:01,405:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 15:13:05,249:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.2677, Train Acc: 88.8358,
                        Val Loss: 0.3155, Val Acc: 86.9195, Test Acc: 86.8304
2022-09-05 15:13:05,249:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 15:13:09,071:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.2699, Train Acc: 88.3556,
                        Val Loss: 0.3420, Val Acc: 85.1131, Test Acc: 84.7555
2022-09-05 15:13:09,071:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 15:13:12,904:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.2646, Train Acc: 88.6766,
                        Val Loss: 0.3226, Val Acc: 86.4076, Test Acc: 86.3288
2022-09-05 15:13:12,904:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 45/1000
2022-09-05 15:13:16,649:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.74s, LR: 0.00025, Train Loss: 0.2638, Train Acc: 88.7138,
                        Val Loss: 0.3327, Val Acc: 85.8161, Test Acc: 85.8302
2022-09-05 15:13:16,649:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 46/1000
2022-09-05 15:13:20,479:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00025, Train Loss: 0.2619, Train Acc: 88.8990,
                        Val Loss: 0.3356, Val Acc: 85.7135, Test Acc: 85.8450
2022-09-05 15:13:20,479:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 47/1000
2022-09-05 15:13:24,343:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00025, Train Loss: 0.2606, Train Acc: 88.9457,
                        Val Loss: 0.3189, Val Acc: 87.0550, Test Acc: 86.5851
2022-09-05 15:13:24,343:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 48/1000
2022-09-05 15:13:28,115:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00025, Train Loss: 0.2592, Train Acc: 88.9581,
                        Val Loss: 0.3260, Val Acc: 85.9664, Test Acc: 86.0032
2022-09-05 15:13:28,115:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 49/1000
2022-09-05 15:13:31,921:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00025, Train Loss: 0.2576, Train Acc: 88.7704,
                        Val Loss: 0.3338, Val Acc: 85.5240, Test Acc: 85.7069
2022-09-05 15:13:31,921:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 50/1000
2022-09-05 15:13:35,704:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00025, Train Loss: 0.2569, Train Acc: 88.8859,
                        Val Loss: 0.3206, Val Acc: 86.4706, Test Acc: 86.4813
2022-09-05 15:13:35,704:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 51/1000
2022-09-05 15:13:39,533:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00025, Train Loss: 0.2552, Train Acc: 89.0960,
                        Val Loss: 0.3281, Val Acc: 86.0287, Test Acc: 86.0726
2022-09-05 15:13:39,533:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 52/1000
2022-09-05 15:14:35,147:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:14:39,297:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:14:39,297:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:14:39,300:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:14:39,301:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:14:39,301:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:14:39,301:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:14:39,306:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:14:39,307:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:14:39,307:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:14:39,307:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:14:39,307:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:14:39,307:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:14:39,534:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:14:54,673:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:15.360960006713867
2022-09-05 15:14:54,675:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:14:54,675:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:14:54,675:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:14:54,675:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:14:54,677:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:14:57,736:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h14m39s_on_Sep_05_2022/MODELS_
2022-09-05 15:14:57,736:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.06s, LR: 0.00050, Train Loss: 1.7906, Train Acc: 18.0553,
                        Val Loss: 6.4126, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:14:57,736:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:15:00,833:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.10s, LR: 0.00050, Train Loss: 1.7645, Train Acc: 21.2917,
                        Val Loss: 5.6387, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:15:00,833:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:15:03,790:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.7448, Train Acc: 22.5541,
                        Val Loss: 5.1224, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:15:03,790:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:15:06,722:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.7272, Train Acc: 24.2707,
                        Val Loss: 3.8776, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:15:06,722:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:15:09,710:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6795 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h14m39s_on_Sep_05_2022/MODELS_
2022-09-05 15:15:09,711:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.7110, Train Acc: 27.3984,
                        Val Loss: 2.5390, Val Acc: 16.6667, Test Acc: 16.6795
2022-09-05 15:15:09,711:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:15:12,741:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 18.4185 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h14m39s_on_Sep_05_2022/MODELS_
2022-09-05 15:15:12,741:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.03s, LR: 0.00050, Train Loss: 1.6969, Train Acc: 29.3192,
                        Val Loss: 2.2078, Val Acc: 18.3747, Test Acc: 18.4185
2022-09-05 15:15:12,741:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:15:15,675:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 18.8019 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h14m39s_on_Sep_05_2022/MODELS_
2022-09-05 15:15:15,676:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.6834, Train Acc: 30.7429,
                        Val Loss: 2.1173, Val Acc: 19.1955, Test Acc: 18.8019
2022-09-05 15:15:15,676:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:15:18,574:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 20.9952 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h14m39s_on_Sep_05_2022/MODELS_
2022-09-05 15:15:18,574:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.6742, Train Acc: 31.3868,
                        Val Loss: 1.9541, Val Acc: 19.8864, Test Acc: 20.9952
2022-09-05 15:15:18,574:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:15:21,606:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.03s, LR: 0.00050, Train Loss: 1.6550, Train Acc: 33.4088,
                        Val Loss: 4.4717, Val Acc: 16.6943, Test Acc: 16.7160
2022-09-05 15:15:21,606:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:15:24,589:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.6444, Train Acc: 33.4707,
                        Val Loss: 3.0757, Val Acc: 16.6815, Test Acc: 16.6667
2022-09-05 15:15:24,590:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:15:27,528:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.6299, Train Acc: 33.8605,
                        Val Loss: 3.0947, Val Acc: 16.6956, Test Acc: 17.0239
2022-09-05 15:15:27,529:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:15:30,457:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.6173, Train Acc: 35.2637,
                        Val Loss: 3.5307, Val Acc: 17.0645, Test Acc: 17.2760
2022-09-05 15:15:30,457:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:15:33,389:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.6027, Train Acc: 36.0358,
                        Val Loss: 5.0018, Val Acc: 17.5319, Test Acc: 17.5470
2022-09-05 15:15:33,390:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:15:45,692:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:15:49,778:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:15:49,778:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:15:49,779:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:15:49,779:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:15:49,779:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:15:49,779:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:15:49,784:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:15:49,785:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:15:49,785:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:15:49,786:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:15:49,786:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:15:49,786:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:15:50,025:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:16:12,697:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:22.905653953552246
2022-09-05 15:16:12,699:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:16:12,699:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:16:12,699:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:16:12,699:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:16:12,700:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:16:15,506:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h15m49s_on_Sep_05_2022/MODELS_
2022-09-05 15:16:15,506:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.81s, LR: 0.00050, Train Loss: 1.7946, Train Acc: 18.1331,
                        Val Loss: 20.4180, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:15,506:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:16:18,563:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.06s, LR: 0.00050, Train Loss: 1.7896, Train Acc: 19.0266,
                        Val Loss: 15.1038, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:18,563:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:16:21,393:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.83s, LR: 0.00050, Train Loss: 1.7862, Train Acc: 18.6370,
                        Val Loss: 11.6584, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:21,393:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:16:24,207:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.81s, LR: 0.00050, Train Loss: 1.7854, Train Acc: 19.1088,
                        Val Loss: 9.2786, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:24,207:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:16:27,140:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.7833, Train Acc: 18.8165,
                        Val Loss: 7.2957, Val Acc: 16.6810, Test Acc: 16.6667
2022-09-05 15:16:27,140:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:16:30,040:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.7808, Train Acc: 19.6304,
                        Val Loss: 6.3078, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:30,041:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:16:32,863:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.82s, LR: 0.00050, Train Loss: 1.7823, Train Acc: 19.4305,
                        Val Loss: 5.8597, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:32,863:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:16:35,705:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.84s, LR: 0.00050, Train Loss: 1.7764, Train Acc: 19.8571,
                        Val Loss: 5.0780, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:35,705:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:16:38,626:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.7777, Train Acc: 19.1522,
                        Val Loss: 4.4427, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:38,626:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:16:41,428:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.80s, LR: 0.00050, Train Loss: 1.7739, Train Acc: 20.6830,
                        Val Loss: 3.6238, Val Acc: 16.6971, Test Acc: 16.4225
2022-09-05 15:16:41,429:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:16:44,291:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.86s, LR: 0.00050, Train Loss: 1.7681, Train Acc: 21.0708,
                        Val Loss: 3.2747, Val Acc: 16.6799, Test Acc: 16.6667
2022-09-05 15:16:44,291:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:16:47,187:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6808 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h15m49s_on_Sep_05_2022/MODELS_
2022-09-05 15:16:47,187:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.7666, Train Acc: 21.2273,
                        Val Loss: 3.2140, Val Acc: 16.6826, Test Acc: 16.6808
2022-09-05 15:16:47,187:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:16:50,057:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.87s, LR: 0.00050, Train Loss: 1.7624, Train Acc: 21.7717,
                        Val Loss: 3.7390, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:50,057:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:16:52,904:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.85s, LR: 0.00050, Train Loss: 1.7604, Train Acc: 22.1090,
                        Val Loss: 4.1031, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:52,904:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:16:55,757:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.85s, LR: 0.00050, Train Loss: 1.7581, Train Acc: 22.2152,
                        Val Loss: 5.0512, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:55,757:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:16:58,584:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.83s, LR: 0.00050, Train Loss: 1.7526, Train Acc: 23.0163,
                        Val Loss: 4.9565, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:16:58,584:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:17:12,703:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:17:16,690:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:17:16,690:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:17:16,690:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:17:16,691:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:17:16,691:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:17:16,691:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:17:16,696:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:17:16,697:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:17:16,697:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:17:16,697:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:17:16,697:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:17:16,697:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:17:16,932:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:17:28,251:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:11.548443794250488
2022-09-05 15:17:28,252:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:17:28,252:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:17:28,252:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:17:28,252:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:17:28,254:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:17:31,282:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:17:31,282:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.03s, LR: 0.00050, Train Loss: 1.8019, Train Acc: 16.7887,
                        Val Loss: 9.9701, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:17:31,282:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:17:34,213:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.7954, Train Acc: 17.5159,
                        Val Loss: 4.8324, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:17:34,213:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:17:37,051:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.8180 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:17:37,051:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.84s, LR: 0.00050, Train Loss: 1.7916, Train Acc: 17.9966,
                        Val Loss: 3.2620, Val Acc: 17.1250, Test Acc: 16.8180
2022-09-05 15:17:37,051:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:17:39,956:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.7883, Train Acc: 18.8203,
                        Val Loss: 3.3748, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:17:39,957:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:17:43,004:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.05s, LR: 0.00050, Train Loss: 1.7859, Train Acc: 19.2665,
                        Val Loss: 3.9105, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:17:43,004:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:17:45,964:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.7827, Train Acc: 19.6404,
                        Val Loss: 4.2752, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:17:45,964:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:17:48,957:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.7821, Train Acc: 19.8648,
                        Val Loss: 4.3583, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:17:48,957:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:17:51,896:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.7780, Train Acc: 20.5495,
                        Val Loss: 4.5658, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:17:51,896:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:18:01,032:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:18:05,248:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:18:05,248:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:18:05,248:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:18:05,249:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:18:05,249:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:18:05,249:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:18:05,254:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:18:05,255:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:18:05,256:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:18:05,256:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:18:05,256:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:18:05,256:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:18:05,515:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:18:43,472:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:38.21010112762451
2022-09-05 15:18:43,474:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:18:43,474:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:18:43,474:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:18:43,474:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:18:43,476:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:18:46,466:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h18m05s_on_Sep_05_2022/MODELS_
2022-09-05 15:18:46,466:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.7955, Train Acc: 17.5073,
                        Val Loss: 7.0844, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:18:46,466:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:18:49,637:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.17s, LR: 0.00050, Train Loss: 1.7895, Train Acc: 17.9212,
                        Val Loss: 12.3048, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:18:49,650:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:18:52,670:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.02s, LR: 0.00050, Train Loss: 1.7855, Train Acc: 18.8455,
                        Val Loss: 14.4103, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:18:52,670:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:19:13,353:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:19:17,591:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:19:17,591:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:19:17,591:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:19:17,592:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:19:17,592:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:19:17,592:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:19:17,597:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:19:17,598:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:19:17,598:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:19:17,599:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:19:17,599:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:19:17,599:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:19:17,868:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:19:32,980:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:15.37627100944519
2022-09-05 15:19:32,983:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:19:32,983:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:19:32,983:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:19:32,983:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:19:32,984:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:19:35,953:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 20.4213 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h19m17s_on_Sep_05_2022/MODELS_
2022-09-05 15:19:35,953:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.7985, Train Acc: 17.5843,
                        Val Loss: 1.9263, Val Acc: 20.7878, Test Acc: 20.4213
2022-09-05 15:19:35,953:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:19:39,054:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.10s, LR: 0.00050, Train Loss: 1.7584, Train Acc: 23.0879,
                        Val Loss: 1.9210, Val Acc: 17.5364, Test Acc: 17.3887
2022-09-05 15:19:39,054:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:19:41,825:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.77s, LR: 0.00050, Train Loss: 1.7343, Train Acc: 25.8687,
                        Val Loss: 1.9134, Val Acc: 18.0393, Test Acc: 17.9042
2022-09-05 15:19:41,825:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:19:44,627:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 21.9965 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h19m17s_on_Sep_05_2022/MODELS_
2022-09-05 15:19:44,627:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.80s, LR: 0.00050, Train Loss: 1.7103, Train Acc: 29.6363,
                        Val Loss: 1.9059, Val Acc: 21.3782, Test Acc: 21.9965
2022-09-05 15:19:44,627:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:19:47,551:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 22.8591 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h19m17s_on_Sep_05_2022/MODELS_
2022-09-05 15:19:47,551:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.6915, Train Acc: 32.7426,
                        Val Loss: 1.9049, Val Acc: 21.9644, Test Acc: 22.8591
2022-09-05 15:19:47,551:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:19:50,437:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.89s, LR: 0.00050, Train Loss: 1.6708, Train Acc: 35.1822,
                        Val Loss: 1.9237, Val Acc: 21.5220, Test Acc: 21.8197
2022-09-05 15:19:50,438:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:19:53,352:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 23.6573 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h19m17s_on_Sep_05_2022/MODELS_
2022-09-05 15:19:53,352:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.6514, Train Acc: 37.1171,
                        Val Loss: 1.9565, Val Acc: 22.6730, Test Acc: 23.6573
2022-09-05 15:19:53,352:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:19:56,258:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 25.1327 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h19m17s_on_Sep_05_2022/MODELS_
2022-09-05 15:19:56,258:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.6322, Train Acc: 38.1365,
                        Val Loss: 1.9961, Val Acc: 24.2780, Test Acc: 25.1327
2022-09-05 15:19:56,258:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:19:59,185:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.6159, Train Acc: 38.6305,
                        Val Loss: 2.1191, Val Acc: 21.9848, Test Acc: 21.9392
2022-09-05 15:19:59,185:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:20:02,060:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.88s, LR: 0.00050, Train Loss: 1.5964, Train Acc: 40.4583,
                        Val Loss: 2.3516, Val Acc: 20.3953, Test Acc: 19.9298
2022-09-05 15:20:02,060:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:20:04,856:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.80s, LR: 0.00050, Train Loss: 1.5786, Train Acc: 41.0873,
                        Val Loss: 2.6958, Val Acc: 19.5667, Test Acc: 19.4012
2022-09-05 15:20:04,856:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:20:07,756:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.5633, Train Acc: 41.7410,
                        Val Loss: 3.0826, Val Acc: 19.0569, Test Acc: 18.8284
2022-09-05 15:20:07,756:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:20:10,665:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.5467, Train Acc: 42.6308,
                        Val Loss: 2.9784, Val Acc: 19.4078, Test Acc: 19.1934
2022-09-05 15:20:10,665:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:20:13,545:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.88s, LR: 0.00050, Train Loss: 1.5233, Train Acc: 43.9119,
                        Val Loss: 2.8720, Val Acc: 21.0225, Test Acc: 20.6227
2022-09-05 15:20:13,545:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:20:16,474:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.5066, Train Acc: 45.0037,
                        Val Loss: 3.1719, Val Acc: 24.4045, Test Acc: 23.8932
2022-09-05 15:20:16,474:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:20:19,392:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.4854, Train Acc: 46.3621,
                        Val Loss: 4.5788, Val Acc: 18.1494, Test Acc: 18.1002
2022-09-05 15:20:19,393:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:20:22,429:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.04s, LR: 0.00025, Train Loss: 1.4683, Train Acc: 47.0384,
                        Val Loss: 5.1993, Val Acc: 17.2958, Test Acc: 17.0973
2022-09-05 15:20:22,429:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:20:30,880:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:20:34,916:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:20:34,916:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:20:34,916:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:20:34,921:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:20:34,921:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 15:20:34,921:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:20:34,927:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:20:34,928:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:20:34,928:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:20:34,929:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:20:34,929:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 15:20:34,929:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:20:35,161:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:20:43,442:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:8.507768154144287
2022-09-05 15:20:43,445:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:20:43,445:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:20:43,445:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:20:43,445:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:20:43,447:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:20:46,428:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.8086 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:20:46,428:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.7916, Train Acc: 18.0600,
                        Val Loss: 1.8601, Val Acc: 16.7618, Test Acc: 16.8086
2022-09-05 15:20:46,428:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:20:49,618:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 19.1193 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:20:49,618:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.19s, LR: 0.00050, Train Loss: 1.7657, Train Acc: 19.8828,
                        Val Loss: 1.8363, Val Acc: 18.8780, Test Acc: 19.1193
2022-09-05 15:20:49,618:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:20:52,429:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 19.6061 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:20:52,429:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.81s, LR: 0.00050, Train Loss: 1.7460, Train Acc: 21.7847,
                        Val Loss: 1.8174, Val Acc: 19.0905, Test Acc: 19.6061
2022-09-05 15:20:52,429:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:20:55,334:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 20.9101 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:20:55,334:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.7293, Train Acc: 24.4396,
                        Val Loss: 1.8061, Val Acc: 20.6643, Test Acc: 20.9101
2022-09-05 15:20:55,334:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:20:58,209:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 21.0841 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:20:58,209:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.88s, LR: 0.00050, Train Loss: 1.7163, Train Acc: 26.1889,
                        Val Loss: 1.8054, Val Acc: 20.5621, Test Acc: 21.0841
2022-09-05 15:20:58,209:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:21:01,124:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 21.2256 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:01,124:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.7002, Train Acc: 27.0217,
                        Val Loss: 1.8062, Val Acc: 20.8256, Test Acc: 21.2256
2022-09-05 15:21:01,124:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:21:04,040:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 22.0646 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:04,040:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.6843, Train Acc: 29.2791,
                        Val Loss: 1.8031, Val Acc: 21.3656, Test Acc: 22.0646
2022-09-05 15:21:04,040:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:21:06,973:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 26.2926 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:06,973:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.6674, Train Acc: 30.1015,
                        Val Loss: 1.8332, Val Acc: 25.6506, Test Acc: 26.2926
2022-09-05 15:21:06,973:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:21:09,861:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 26.3429 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:09,861:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.89s, LR: 0.00050, Train Loss: 1.6491, Train Acc: 31.1665,
                        Val Loss: 1.9177, Val Acc: 26.3737, Test Acc: 26.3429
2022-09-05 15:21:09,861:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:21:12,845:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.6334, Train Acc: 33.4311,
                        Val Loss: 1.9283, Val Acc: 23.9759, Test Acc: 23.0328
2022-09-05 15:21:12,845:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:21:15,898:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.05s, LR: 0.00050, Train Loss: 1.6170, Train Acc: 35.3623,
                        Val Loss: 1.7905, Val Acc: 24.1018, Test Acc: 24.6550
2022-09-05 15:21:15,898:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:21:18,801:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.6013, Train Acc: 38.0403,
                        Val Loss: 1.8758, Val Acc: 24.0386, Test Acc: 24.3621
2022-09-05 15:21:18,801:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:21:21,683:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.88s, LR: 0.00050, Train Loss: 1.5908, Train Acc: 40.0896,
                        Val Loss: 2.0603, Val Acc: 22.9235, Test Acc: 23.1355
2022-09-05 15:21:21,683:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:21:24,614:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.5763, Train Acc: 40.6200,
                        Val Loss: 2.0653, Val Acc: 23.9646, Test Acc: 24.2038
2022-09-05 15:21:24,614:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:21:27,498:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 27.6170 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:27,498:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.88s, LR: 0.00050, Train Loss: 1.5620, Train Acc: 41.4999,
                        Val Loss: 1.9187, Val Acc: 26.6723, Test Acc: 27.6170
2022-09-05 15:21:27,498:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:21:30,440:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 28.6435 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:30,441:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.5467, Train Acc: 41.9961,
                        Val Loss: 1.9044, Val Acc: 27.7731, Test Acc: 28.6435
2022-09-05 15:21:30,441:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:21:33,419:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 31.4757 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:33,419:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.5352, Train Acc: 42.6572,
                        Val Loss: 1.7770, Val Acc: 30.6224, Test Acc: 31.4757
2022-09-05 15:21:33,419:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:21:36,384:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 35.8091 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:36,384:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.5133, Train Acc: 43.7083,
                        Val Loss: 1.6865, Val Acc: 34.5114, Test Acc: 35.8091
2022-09-05 15:21:36,384:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:21:39,260:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 37.8999 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:39,260:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.88s, LR: 0.00050, Train Loss: 1.5096, Train Acc: 44.0416,
                        Val Loss: 1.6688, Val Acc: 36.6258, Test Acc: 37.8999
2022-09-05 15:21:39,260:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:21:42,176:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 39.0551 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:42,176:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.4830, Train Acc: 44.8767,
                        Val Loss: 1.6400, Val Acc: 38.7814, Test Acc: 39.0551
2022-09-05 15:21:42,176:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:21:45,150:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.4739, Train Acc: 45.5991,
                        Val Loss: 1.6416, Val Acc: 38.2438, Test Acc: 38.7233
2022-09-05 15:21:45,150:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:21:48,054:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.4614, Train Acc: 45.9948,
                        Val Loss: 1.6913, Val Acc: 37.3760, Test Acc: 36.6969
2022-09-05 15:21:48,054:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:21:51,076:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.02s, LR: 0.00050, Train Loss: 1.4546, Train Acc: 45.7734,
                        Val Loss: 1.7807, Val Acc: 38.6779, Test Acc: 37.6007
2022-09-05 15:21:51,076:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 15:21:54,026:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 39.2588 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:54,026:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.95s, LR: 0.00050, Train Loss: 1.4441, Train Acc: 46.8542,
                        Val Loss: 1.6473, Val Acc: 38.9956, Test Acc: 39.2588
2022-09-05 15:21:54,026:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 15:21:57,019:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 39.3864 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:21:57,019:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.4230, Train Acc: 47.5416,
                        Val Loss: 1.6660, Val Acc: 38.2435, Test Acc: 39.3864
2022-09-05 15:21:57,019:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 15:22:00,004:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 41.1940 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:22:00,004:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.4080, Train Acc: 48.1617,
                        Val Loss: 1.6470, Val Acc: 39.3935, Test Acc: 41.1940
2022-09-05 15:22:00,004:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 15:22:02,924:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 42.5298 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:22:02,924:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.3860, Train Acc: 48.9544,
                        Val Loss: 1.5992, Val Acc: 40.4828, Test Acc: 42.5298
2022-09-05 15:22:02,924:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 15:22:05,830:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 43.2747 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:22:05,830:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.3737, Train Acc: 49.2793,
                        Val Loss: 1.5852, Val Acc: 41.4534, Test Acc: 43.2747
2022-09-05 15:22:05,830:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 15:22:08,811:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.3576, Train Acc: 50.1737,
                        Val Loss: 1.6255, Val Acc: 41.4744, Test Acc: 42.8317
2022-09-05 15:22:08,811:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 15:22:11,727:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.3381, Train Acc: 51.0163,
                        Val Loss: 1.6465, Val Acc: 41.4679, Test Acc: 42.6362
2022-09-05 15:22:11,727:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 15:22:14,584:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.86s, LR: 0.00050, Train Loss: 1.3190, Train Acc: 52.1280,
                        Val Loss: 1.6507, Val Acc: 41.6087, Test Acc: 42.7343
2022-09-05 15:22:14,584:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 15:22:17,551:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.3059, Train Acc: 51.9245,
                        Val Loss: 1.6444, Val Acc: 40.2690, Test Acc: 42.0308
2022-09-05 15:22:17,551:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 15:22:20,417:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.87s, LR: 0.00050, Train Loss: 1.2813, Train Acc: 53.4591,
                        Val Loss: 1.6760, Val Acc: 40.1527, Test Acc: 41.2761
2022-09-05 15:22:20,417:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 15:22:23,322:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.2501, Train Acc: 54.9249,
                        Val Loss: 1.7469, Val Acc: 40.0714, Test Acc: 41.3204
2022-09-05 15:22:23,323:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 15:22:26,310:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.2336, Train Acc: 55.4695,
                        Val Loss: 1.7424, Val Acc: 40.9356, Test Acc: 42.9852
2022-09-05 15:22:26,310:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 15:22:29,206:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.2301, Train Acc: 55.4272,
                        Val Loss: 1.7808, Val Acc: 41.5525, Test Acc: 42.6787
2022-09-05 15:22:29,206:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 15:22:32,171:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 43.6592 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h20m34s_on_Sep_05_2022/MODELS_
2022-09-05 15:22:32,171:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.2056, Train Acc: 56.5063,
                        Val Loss: 1.7563, Val Acc: 42.2393, Test Acc: 43.6592
2022-09-05 15:22:32,171:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 15:22:35,116:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.2091, Train Acc: 56.2054,
                        Val Loss: 1.9038, Val Acc: 40.2588, Test Acc: 41.1990
2022-09-05 15:22:35,116:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 15:22:38,082:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.1806, Train Acc: 57.5625,
                        Val Loss: 1.8888, Val Acc: 41.8608, Test Acc: 42.7230
2022-09-05 15:22:38,082:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 15:22:41,019:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00025, Train Loss: 1.1732, Train Acc: 57.9228,
                        Val Loss: 1.9367, Val Acc: 42.5093, Test Acc: 43.3273
2022-09-05 15:22:41,019:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 15:22:49,577:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:22:53,806:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:22:53,806:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:22:53,807:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:22:53,808:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:22:53,808:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:22:53,808:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:22:53,812:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:22:53,813:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:22:53,813:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:22:53,814:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:22:53,814:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:22:53,814:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:22:54,078:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:23:09,151:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:15.33216905593872
2022-09-05 15:23:09,154:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:23:09,154:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:23:09,154:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:23:09,154:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:23:09,155:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:23:12,344:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.7654 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:12,344:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.19s, LR: 0.00050, Train Loss: 1.7944, Train Acc: 17.2280,
                        Val Loss: 1.9640, Val Acc: 16.7953, Test Acc: 16.7654
2022-09-05 15:23:12,344:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:23:15,499:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.8856 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:15,499:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.16s, LR: 0.00050, Train Loss: 1.7669, Train Acc: 19.1448,
                        Val Loss: 1.9476, Val Acc: 16.7985, Test Acc: 16.8856
2022-09-05 15:23:15,499:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:23:18,522:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 17.4994 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:18,523:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.02s, LR: 0.00050, Train Loss: 1.7487, Train Acc: 19.1896,
                        Val Loss: 1.9364, Val Acc: 17.5488, Test Acc: 17.4994
2022-09-05 15:23:18,523:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:23:21,603:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 18.4108 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:21,603:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.08s, LR: 0.00050, Train Loss: 1.7342, Train Acc: 19.5555,
                        Val Loss: 1.9459, Val Acc: 18.5691, Test Acc: 18.4108
2022-09-05 15:23:21,604:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:23:24,843:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 19.2600 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:24,843:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.24s, LR: 0.00050, Train Loss: 1.7227, Train Acc: 20.9864,
                        Val Loss: 1.9569, Val Acc: 19.4439, Test Acc: 19.2600
2022-09-05 15:23:24,843:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:23:27,954:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 24.2522 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:27,954:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.11s, LR: 0.00050, Train Loss: 1.7097, Train Acc: 22.1203,
                        Val Loss: 1.9949, Val Acc: 24.7277, Test Acc: 24.2522
2022-09-05 15:23:27,954:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:23:31,031:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.08s, LR: 0.00050, Train Loss: 1.6943, Train Acc: 22.9543,
                        Val Loss: 2.0983, Val Acc: 19.8568, Test Acc: 19.4299
2022-09-05 15:23:31,031:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:23:34,001:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.6771, Train Acc: 25.3717,
                        Val Loss: 2.2153, Val Acc: 19.4453, Test Acc: 19.2835
2022-09-05 15:23:34,001:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:23:37,088:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.09s, LR: 0.00050, Train Loss: 1.6634, Train Acc: 28.8480,
                        Val Loss: 2.2961, Val Acc: 19.5767, Test Acc: 19.4024
2022-09-05 15:23:37,088:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:23:40,135:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.05s, LR: 0.00050, Train Loss: 1.6428, Train Acc: 32.6663,
                        Val Loss: 2.3238, Val Acc: 19.8410, Test Acc: 19.7015
2022-09-05 15:23:40,135:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:23:43,138:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.00s, LR: 0.00050, Train Loss: 1.6218, Train Acc: 34.6773,
                        Val Loss: 2.1673, Val Acc: 21.5495, Test Acc: 21.1278
2022-09-05 15:23:43,138:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:23:46,137:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 24.5563 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:46,137:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.00s, LR: 0.00050, Train Loss: 1.6032, Train Acc: 36.1183,
                        Val Loss: 1.9528, Val Acc: 24.9257, Test Acc: 24.5563
2022-09-05 15:23:46,137:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:23:49,126:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.5878, Train Acc: 37.0533,
                        Val Loss: 2.0755, Val Acc: 24.3034, Test Acc: 22.9110
2022-09-05 15:23:49,126:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:23:52,100:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 26.8528 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:52,100:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.5704, Train Acc: 38.7777,
                        Val Loss: 2.3031, Val Acc: 27.8870, Test Acc: 26.8528
2022-09-05 15:23:52,100:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:23:55,061:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 27.2249 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h22m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:23:55,061:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00025, Train Loss: 1.5504, Train Acc: 40.4181,
                        Val Loss: 2.5721, Val Acc: 27.5759, Test Acc: 27.2249
2022-09-05 15:23:55,061:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:23:57,997:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00025, Train Loss: 1.5411, Train Acc: 40.6495,
                        Val Loss: 2.8095, Val Acc: 26.2249, Test Acc: 25.7477
2022-09-05 15:23:57,997:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:24:01,085:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.09s, LR: 0.00025, Train Loss: 1.5305, Train Acc: 41.3358,
                        Val Loss: 3.0727, Val Acc: 25.4511, Test Acc: 25.3783
2022-09-05 15:24:01,086:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:24:04,093:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.01s, LR: 0.00025, Train Loss: 1.5159, Train Acc: 41.5970,
                        Val Loss: 3.6848, Val Acc: 24.8560, Test Acc: 25.1241
2022-09-05 15:24:04,093:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:24:07,209:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.12s, LR: 0.00025, Train Loss: 1.5116, Train Acc: 42.5024,
                        Val Loss: 4.2377, Val Acc: 24.1582, Test Acc: 24.6784
2022-09-05 15:24:07,209:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:24:10,399:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.19s, LR: 0.00025, Train Loss: 1.4941, Train Acc: 43.7249,
                        Val Loss: 4.1386, Val Acc: 24.1782, Test Acc: 24.7616
2022-09-05 15:24:10,399:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:24:13,510:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.11s, LR: 0.00025, Train Loss: 1.4848, Train Acc: 44.1542,
                        Val Loss: 3.6690, Val Acc: 25.2383, Test Acc: 25.2608
2022-09-05 15:24:13,510:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:24:16,602:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.09s, LR: 0.00025, Train Loss: 1.4694, Train Acc: 44.8642,
                        Val Loss: 3.7733, Val Acc: 24.2658, Test Acc: 24.2049
2022-09-05 15:24:16,602:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:24:28,999:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:24:33,518:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:24:33,518:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:24:33,519:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:24:33,532:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:24:33,532:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:24:33,532:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:24:33,537:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:24:33,538:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:24:33,539:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:24:33,540:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:24:33,540:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:24:33,540:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:24:33,859:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:24:48,893:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:15.347712993621826
2022-09-05 15:24:48,896:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:24:48,896:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:24:48,896:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:24:48,896:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:24:48,897:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:24:52,000:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.4711 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h24m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:24:52,000:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.10s, LR: 0.00050, Train Loss: 1.7976, Train Acc: 16.5122,
                        Val Loss: 3.1148, Val Acc: 17.5305, Test Acc: 16.4711
2022-09-05 15:24:52,000:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:24:55,140:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.5838 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h24m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:24:55,140:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.14s, LR: 0.00050, Train Loss: 1.7938, Train Acc: 16.9651,
                        Val Loss: 4.2611, Val Acc: 16.6946, Test Acc: 16.5838
2022-09-05 15:24:55,140:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:24:58,033:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h24m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:24:58,033:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.89s, LR: 0.00050, Train Loss: 1.7897, Train Acc: 17.3599,
                        Val Loss: 3.6390, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:24:58,033:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:25:00,969:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.7884, Train Acc: 17.5548,
                        Val Loss: 3.3707, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:00,969:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:25:04,016:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.05s, LR: 0.00050, Train Loss: 1.7852, Train Acc: 18.0269,
                        Val Loss: 2.5389, Val Acc: 16.4463, Test Acc: 16.6061
2022-09-05 15:25:04,016:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:25:07,000:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.7260 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h24m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:25:07,000:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.7828, Train Acc: 18.7503,
                        Val Loss: 2.6351, Val Acc: 16.7528, Test Acc: 16.7260
2022-09-05 15:25:07,000:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:25:09,890:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 17.3744 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h24m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:25:09,891:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.89s, LR: 0.00050, Train Loss: 1.7822, Train Acc: 19.1667,
                        Val Loss: 3.2041, Val Acc: 16.3970, Test Acc: 17.3744
2022-09-05 15:25:09,891:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:25:12,726:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.84s, LR: 0.00050, Train Loss: 1.7759, Train Acc: 20.0528,
                        Val Loss: 3.6301, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:12,726:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:25:15,775:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.05s, LR: 0.00050, Train Loss: 1.7747, Train Acc: 20.6814,
                        Val Loss: 3.5180, Val Acc: 16.2393, Test Acc: 16.1853
2022-09-05 15:25:15,775:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:25:18,694:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.7710, Train Acc: 21.0880,
                        Val Loss: 3.3172, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:18,694:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:25:21,594:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.7628, Train Acc: 21.6585,
                        Val Loss: 4.1102, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:21,594:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:25:24,594:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.00s, LR: 0.00050, Train Loss: 1.7598, Train Acc: 22.1834,
                        Val Loss: 4.1993, Val Acc: 16.6694, Test Acc: 17.2052
2022-09-05 15:25:24,594:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:25:27,544:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.95s, LR: 0.00050, Train Loss: 1.7578, Train Acc: 22.1791,
                        Val Loss: 3.9263, Val Acc: 16.6475, Test Acc: 17.0330
2022-09-05 15:25:27,544:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:25:30,412:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.87s, LR: 0.00050, Train Loss: 1.7577, Train Acc: 22.8897,
                        Val Loss: 8.1975, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:30,412:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:25:33,356:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.7543, Train Acc: 23.0472,
                        Val Loss: 10.0621, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:33,356:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:25:36,213:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.86s, LR: 0.00050, Train Loss: 1.7524, Train Acc: 23.2816,
                        Val Loss: 9.7818, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:36,213:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:25:39,053:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.84s, LR: 0.00025, Train Loss: 1.7437, Train Acc: 24.6581,
                        Val Loss: 10.2799, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:39,053:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:25:41,872:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.82s, LR: 0.00025, Train Loss: 1.7395, Train Acc: 24.7067,
                        Val Loss: 10.3280, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:41,872:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:25:44,674:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.80s, LR: 0.00025, Train Loss: 1.7408, Train Acc: 24.9369,
                        Val Loss: 9.1711, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:44,674:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:25:47,604:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00025, Train Loss: 1.7311, Train Acc: 26.9582,
                        Val Loss: 5.9029, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:47,604:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:25:50,664:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.06s, LR: 0.00025, Train Loss: 1.7329, Train Acc: 25.6502,
                        Val Loss: 7.7445, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:50,664:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:25:53,613:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.95s, LR: 0.00025, Train Loss: 1.7338, Train Acc: 25.5562,
                        Val Loss: 10.9065, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:53,613:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:25:56,537:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00025, Train Loss: 1.7306, Train Acc: 24.9899,
                        Val Loss: 8.9867, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:56,537:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 15:25:59,723:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.19s, LR: 0.00025, Train Loss: 1.7252, Train Acc: 25.7170,
                        Val Loss: 7.9266, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:25:59,723:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 15:26:02,939:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.22s, LR: 0.00025, Train Loss: 1.7267, Train Acc: 26.1388,
                        Val Loss: 10.7319, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:26:02,940:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 15:26:05,961:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.02s, LR: 0.00025, Train Loss: 1.7190, Train Acc: 26.5574,
                        Val Loss: 7.8827, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:26:05,961:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 15:26:08,895:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00025, Train Loss: 1.7133, Train Acc: 27.3939,
                        Val Loss: 1.9568, Val Acc: 14.7193, Test Acc: 15.9630
2022-09-05 15:26:08,895:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 15:26:11,762:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.87s, LR: 0.00025, Train Loss: 1.7159, Train Acc: 26.0447,
                        Val Loss: 3.2855, Val Acc: 16.5606, Test Acc: 16.6493
2022-09-05 15:26:11,762:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 15:26:14,741:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00025, Train Loss: 1.7122, Train Acc: 26.6660,
                        Val Loss: 8.9630, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:26:14,741:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 15:26:17,632:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.89s, LR: 0.00025, Train Loss: 1.7118, Train Acc: 26.5672,
                        Val Loss: 7.6124, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:26:17,632:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 15:26:20,510:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.88s, LR: 0.00025, Train Loss: 1.7052, Train Acc: 26.6830,
                        Val Loss: 2.4237, Val Acc: 15.3317, Test Acc: 14.8204
2022-09-05 15:26:20,510:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 15:26:39,691:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:26:43,999:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:26:43,999:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:26:43,999:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:26:44,000:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:26:44,000:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:26:44,000:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:26:44,005:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:26:44,006:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:26:44,006:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:26:44,006:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:26:44,007:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:26:44,007:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:26:44,237:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:27:02,266:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:18.2533438205719
2022-09-05 15:27:02,269:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:27:02,269:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:27:02,269:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:27:02,269:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:27:02,271:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:27:05,276:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:05,276:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.01s, LR: 0.00050, Train Loss: 1.7930, Train Acc: 16.7964,
                        Val Loss: 1.8570, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:27:05,276:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:27:08,379:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.10s, LR: 0.00050, Train Loss: 1.7664, Train Acc: 18.6078,
                        Val Loss: 1.8285, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:27:08,379:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:27:11,316:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 17.0665 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:11,316:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.7506, Train Acc: 20.7707,
                        Val Loss: 1.8049, Val Acc: 17.0437, Test Acc: 17.0665
2022-09-05 15:27:11,316:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:27:14,259:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 22.9903 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:14,259:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.7363, Train Acc: 24.7559,
                        Val Loss: 1.7852, Val Acc: 23.4480, Test Acc: 22.9903
2022-09-05 15:27:14,259:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:27:17,333:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.07s, LR: 0.00050, Train Loss: 1.7217, Train Acc: 27.5400,
                        Val Loss: 1.7698, Val Acc: 23.4311, Test Acc: 22.6494
2022-09-05 15:27:17,333:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:27:20,294:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 24.6854 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:20,294:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.7077, Train Acc: 28.9514,
                        Val Loss: 1.7561, Val Acc: 24.8938, Test Acc: 24.6854
2022-09-05 15:27:20,294:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:27:23,266:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 25.4253 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:23,266:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.6900, Train Acc: 30.5583,
                        Val Loss: 1.7416, Val Acc: 25.5393, Test Acc: 25.4253
2022-09-05 15:27:23,266:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:27:26,167:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 25.4448 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:26,167:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.6782, Train Acc: 32.3992,
                        Val Loss: 1.7350, Val Acc: 24.7600, Test Acc: 25.4448
2022-09-05 15:27:26,167:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:27:29,195:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.03s, LR: 0.00050, Train Loss: 1.6603, Train Acc: 34.5587,
                        Val Loss: 1.7655, Val Acc: 21.7114, Test Acc: 21.9712
2022-09-05 15:27:29,195:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:27:32,142:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.95s, LR: 0.00050, Train Loss: 1.6449, Train Acc: 35.3009,
                        Val Loss: 1.8567, Val Acc: 20.4329, Test Acc: 20.3826
2022-09-05 15:27:32,142:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:27:35,123:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.6276, Train Acc: 35.8968,
                        Val Loss: 1.9520, Val Acc: 20.5266, Test Acc: 20.3749
2022-09-05 15:27:35,124:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:27:38,102:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.6085, Train Acc: 36.4977,
                        Val Loss: 2.0296, Val Acc: 20.7827, Test Acc: 20.7066
2022-09-05 15:27:38,102:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:27:41,068:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.5969, Train Acc: 37.0418,
                        Val Loss: 2.0752, Val Acc: 21.6475, Test Acc: 21.5747
2022-09-05 15:27:41,068:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:27:44,029:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.5806, Train Acc: 38.6889,
                        Val Loss: 2.0141, Val Acc: 23.2787, Test Acc: 23.5315
2022-09-05 15:27:44,029:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:27:47,003:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 28.4493 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:47,003:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.5630, Train Acc: 40.3224,
                        Val Loss: 1.8238, Val Acc: 28.3957, Test Acc: 28.4493
2022-09-05 15:27:47,003:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:27:49,993:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 33.0111 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:49,993:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.5467, Train Acc: 40.6166,
                        Val Loss: 1.7011, Val Acc: 32.3880, Test Acc: 33.0111
2022-09-05 15:27:49,993:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:27:52,994:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 35.1754 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:52,994:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.00s, LR: 0.00050, Train Loss: 1.5299, Train Acc: 41.3964,
                        Val Loss: 1.6375, Val Acc: 34.4261, Test Acc: 35.1754
2022-09-05 15:27:52,994:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:27:55,949:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 36.1459 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:55,949:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.95s, LR: 0.00050, Train Loss: 1.5115, Train Acc: 42.3887,
                        Val Loss: 1.6338, Val Acc: 35.0104, Test Acc: 36.1459
2022-09-05 15:27:55,949:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:27:58,875:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 38.4770 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:27:58,875:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00050, Train Loss: 1.4966, Train Acc: 42.8025,
                        Val Loss: 1.5849, Val Acc: 37.3462, Test Acc: 38.4770
2022-09-05 15:27:58,875:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:28:01,871:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 38.5024 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:28:01,871:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.00s, LR: 0.00050, Train Loss: 1.4696, Train Acc: 44.0743,
                        Val Loss: 1.5983, Val Acc: 38.5386, Test Acc: 38.5024
2022-09-05 15:28:01,871:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:28:04,789:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 38.5497 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h26m43s_on_Sep_05_2022/MODELS_
2022-09-05 15:28:04,789:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.92s, LR: 0.00050, Train Loss: 1.4609, Train Acc: 43.8822,
                        Val Loss: 1.6457, Val Acc: 37.5828, Test Acc: 38.5497
2022-09-05 15:28:04,789:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:28:07,687:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.4356, Train Acc: 45.7033,
                        Val Loss: 1.6636, Val Acc: 35.6497, Test Acc: 36.7274
2022-09-05 15:28:07,687:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:28:10,671:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.4172, Train Acc: 46.4417,
                        Val Loss: 1.6528, Val Acc: 35.8033, Test Acc: 35.6949
2022-09-05 15:28:10,671:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 15:28:13,539:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.87s, LR: 0.00050, Train Loss: 1.3996, Train Acc: 47.1757,
                        Val Loss: 1.6973, Val Acc: 34.6774, Test Acc: 35.0466
2022-09-05 15:28:13,539:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 15:28:16,451:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.3702, Train Acc: 48.4039,
                        Val Loss: 1.9562, Val Acc: 30.4738, Test Acc: 31.9737
2022-09-05 15:28:16,451:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 15:28:19,356:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.91s, LR: 0.00050, Train Loss: 1.3475, Train Acc: 49.9123,
                        Val Loss: 2.4598, Val Acc: 27.5154, Test Acc: 28.7555
2022-09-05 15:28:19,356:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 15:28:22,343:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.99s, LR: 0.00050, Train Loss: 1.3350, Train Acc: 51.1582,
                        Val Loss: 2.2801, Val Acc: 29.0900, Test Acc: 30.2366
2022-09-05 15:28:22,343:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 15:28:25,308:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.3108, Train Acc: 52.4977,
                        Val Loss: 2.5613, Val Acc: 27.6693, Test Acc: 29.2096
2022-09-05 15:28:25,308:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 15:28:28,263:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.2886, Train Acc: 53.5953,
                        Val Loss: 2.1930, Val Acc: 30.1471, Test Acc: 31.8529
2022-09-05 15:28:28,264:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 15:28:31,232:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.2559, Train Acc: 55.5169,
                        Val Loss: 2.1958, Val Acc: 32.3908, Test Acc: 33.5060
2022-09-05 15:28:31,232:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 15:28:34,164:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00025, Train Loss: 1.2405, Train Acc: 55.4417,
                        Val Loss: 2.3059, Val Acc: 31.9566, Test Acc: 33.3801
2022-09-05 15:28:34,164:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 15:28:37,174:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.01s, LR: 0.00025, Train Loss: 1.2368, Train Acc: 55.0370,
                        Val Loss: 2.4430, Val Acc: 30.5239, Test Acc: 31.7655
2022-09-05 15:28:37,174:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 15:28:40,106:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.93s, LR: 0.00025, Train Loss: 1.2123, Train Acc: 56.8507,
                        Val Loss: 2.2873, Val Acc: 31.3451, Test Acc: 32.2262
2022-09-05 15:28:40,106:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 15:28:43,127:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.02s, LR: 0.00025, Train Loss: 1.2029, Train Acc: 57.4580,
                        Val Loss: 2.2777, Val Acc: 30.4796, Test Acc: 32.0348
2022-09-05 15:28:43,127:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 15:28:56,569:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:29:00,783:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:29:00,783:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:29:00,783:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:29:00,784:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:29:00,784:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:29:00,784:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:29:00,789:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:29:00,791:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:29:00,791:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:29:00,792:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:29:00,792:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:29:00,792:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:29:01,055:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:29:19,534:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:18.73651695251465
2022-09-05 15:29:19,536:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:29:19,536:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:29:19,536:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:29:19,536:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:29:19,538:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:29:22,796:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 17.5391 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h29m00s_on_Sep_05_2022/MODELS_
2022-09-05 15:29:22,796:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.26s, LR: 0.00050, Train Loss: 1.7893, Train Acc: 17.7923,
                        Val Loss: 1.8364, Val Acc: 17.2018, Test Acc: 17.5391
2022-09-05 15:29:22,796:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:29:26,264:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.47s, LR: 0.00050, Train Loss: 1.7586, Train Acc: 21.2782,
                        Val Loss: 1.8351, Val Acc: 17.5488, Test Acc: 17.4994
2022-09-05 15:29:26,265:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:29:29,427:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.16s, LR: 0.00050, Train Loss: 1.7393, Train Acc: 23.6026,
                        Val Loss: 1.8526, Val Acc: 17.4202, Test Acc: 17.2513
2022-09-05 15:29:29,427:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:29:32,484:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.06s, LR: 0.00050, Train Loss: 1.7236, Train Acc: 25.8385,
                        Val Loss: 1.8965, Val Acc: 16.9342, Test Acc: 16.8935
2022-09-05 15:29:32,484:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:29:35,656:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.17s, LR: 0.00050, Train Loss: 1.7068, Train Acc: 27.9197,
                        Val Loss: 2.0234, Val Acc: 16.9704, Test Acc: 16.8694
2022-09-05 15:29:35,656:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:29:38,670:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.01s, LR: 0.00050, Train Loss: 1.6902, Train Acc: 28.1511,
                        Val Loss: 2.3505, Val Acc: 16.8033, Test Acc: 16.7907
2022-09-05 15:29:38,671:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:29:41,738:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.07s, LR: 0.00050, Train Loss: 1.6750, Train Acc: 29.5768,
                        Val Loss: 3.1862, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:29:41,739:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:29:44,719:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.6584, Train Acc: 29.5632,
                        Val Loss: 4.4270, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:29:44,719:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:29:47,781:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.06s, LR: 0.00050, Train Loss: 1.6481, Train Acc: 30.7700,
                        Val Loss: 5.5390, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:29:47,781:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:29:48,556:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 15:29:48,556:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 15:30:02,513:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:30:06,865:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:30:06,865:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:30:06,865:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:30:06,866:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:30:06,866:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:30:06,866:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:30:06,871:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:30:06,872:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:30:06,872:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:30:06,873:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:30:06,873:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:30:06,873:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:30:07,106:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:30:24,987:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:18.109383821487427
2022-09-05 15:30:24,990:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:30:24,990:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:30:24,990:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:30:24,990:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:30:24,991:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:30:28,026:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h30m06s_on_Sep_05_2022/MODELS_
2022-09-05 15:30:28,026:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.03s, LR: 0.00050, Train Loss: 1.8025, Train Acc: 15.8780,
                        Val Loss: 6.0416, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:30:28,026:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:30:31,066:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.04s, LR: 0.00050, Train Loss: 1.7964, Train Acc: 15.9073,
                        Val Loss: 9.1225, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:30:31,066:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:30:34,030:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.96s, LR: 0.00050, Train Loss: 1.7931, Train Acc: 17.8621,
                        Val Loss: 11.9692, Val Acc: 16.8575, Test Acc: 16.5934
2022-09-05 15:30:34,030:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:30:45,080:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:30:49,331:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:30:49,331:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:30:49,332:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:30:49,332:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:30:49,332:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:30:49,332:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:30:49,337:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:30:49,338:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:30:49,338:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:30:49,339:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:30:49,339:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:30:49,339:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:30:49,559:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:31:08,184:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:18.840569257736206
2022-09-05 15:31:08,187:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:31:08,187:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:31:08,187:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:31:08,187:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:31:08,189:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:31:11,243:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h30m49s_on_Sep_05_2022/MODELS_
2022-09-05 15:31:11,243:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.05s, LR: 0.00050, Train Loss: 1.7981, Train Acc: 16.2245,
                        Val Loss: 10.0611, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:31:11,243:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:31:14,320:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.08s, LR: 0.00050, Train Loss: 1.7933, Train Acc: 17.4568,
                        Val Loss: 6.9252, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:31:14,320:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:31:17,301:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.7893, Train Acc: 18.6373,
                        Val Loss: 5.5854, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:31:17,301:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:31:20,311:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.01s, LR: 0.00050, Train Loss: 1.7871, Train Acc: 18.8817,
                        Val Loss: 5.3624, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:31:20,311:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:31:23,377:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.07s, LR: 0.00050, Train Loss: 1.7843, Train Acc: 19.4441,
                        Val Loss: 6.6941, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:31:23,377:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:31:26,328:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.95s, LR: 0.00050, Train Loss: 1.7814, Train Acc: 20.3414,
                        Val Loss: 7.4615, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:31:26,329:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:31:36,292:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:31:40,396:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 7, 'n_classes': 6}
2022-09-05 15:31:40,396:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 15:31:40,397:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:31:40,401:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:31:40,401:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:31:40,401:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:31:40,407:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:31:40,408:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524779
2022-09-05 15:31:40,409:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:31:40,409:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:31:40,409:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:31:40,409:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:31:40,643:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:31:58,558:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:18.1422061920166
2022-09-05 15:31:58,560:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:31:58,560:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:31:58,560:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:31:58,560:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 15:31:58,562:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:32:01,566:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_16_15h31m40s_on_Sep_05_2022/MODELS_
2022-09-05 15:32:01,566:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.00s, LR: 0.00050, Train Loss: 1.8017, Train Acc: 16.7544,
                        Val Loss: 12.6737, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:32:01,566:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:32:04,504:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.94s, LR: 0.00050, Train Loss: 1.7945, Train Acc: 17.6886,
                        Val Loss: 12.5898, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:32:04,505:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:32:07,409:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.90s, LR: 0.00050, Train Loss: 1.7895, Train Acc: 17.7140,
                        Val Loss: 10.5812, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:32:07,409:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:32:10,375:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.97s, LR: 0.00050, Train Loss: 1.7882, Train Acc: 17.7123,
                        Val Loss: 9.7375, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:32:10,375:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:32:13,485:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.11s, LR: 0.00050, Train Loss: 1.7875, Train Acc: 17.1641,
                        Val Loss: 10.0173, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:32:13,485:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:32:16,462:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 2.98s, LR: 0.00050, Train Loss: 1.7841, Train Acc: 18.3585,
                        Val Loss: 8.6661, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 15:32:16,462:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:32:17,779:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 15:32:17,779:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 15:32:34,516:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:32:40,257:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:32:40,257:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:32:40,257:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:32:40,258:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:32:40,258:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:32:40,258:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:32:40,263:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:32:40,264:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:32:40,264:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:32:40,265:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:32:40,265:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:32:40,265:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:32:40,735:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:32:56,557:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:16.286665201187134
2022-09-05 15:32:56,559:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:32:56,559:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:32:56,559:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:32:56,560:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:32:56,561:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:33:00,425:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h32m40s_on_Sep_05_2022/MODELS_
2022-09-05 15:33:00,426:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.6632, Train Acc: 50.0000,
                        Val Loss: 12.9446, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:00,426:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:33:04,370:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.94s, LR: 0.00050, Train Loss: 0.5821, Train Acc: 50.0000,
                        Val Loss: 10.8681, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:04,370:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:33:08,144:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.5450, Train Acc: 51.0770,
                        Val Loss: 11.0544, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:08,145:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:33:11,835:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.5228, Train Acc: 60.0912,
                        Val Loss: 10.2970, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:11,835:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:33:15,641:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.5072, Train Acc: 68.4511,
                        Val Loss: 9.1211, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:15,642:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:33:19,403:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.4947, Train Acc: 74.0402,
                        Val Loss: 7.8126, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:19,403:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:33:23,119:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.4831, Train Acc: 78.3200,
                        Val Loss: 6.4427, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:23,120:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:33:26,852:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.4734, Train Acc: 82.0940,
                        Val Loss: 5.3195, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:26,852:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:33:30,534:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.68s, LR: 0.00050, Train Loss: 0.4635, Train Acc: 84.9725,
                        Val Loss: 4.5232, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:30,534:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:33:34,330:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.4538, Train Acc: 85.8421,
                        Val Loss: 4.0761, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:34,330:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:33:38,061:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.4445, Train Acc: 86.0848,
                        Val Loss: 3.9136, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:38,061:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:33:41,793:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.4341, Train Acc: 86.2155,
                        Val Loss: 3.8239, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:41,793:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:33:45,645:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.4244, Train Acc: 86.3008,
                        Val Loss: 3.6837, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:45,658:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:33:49,347:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.4140, Train Acc: 85.9443,
                        Val Loss: 3.6209, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:49,347:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:33:53,158:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.4032, Train Acc: 85.7229,
                        Val Loss: 3.7226, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:53,158:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:33:56,959:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3937, Train Acc: 86.3866,
                        Val Loss: 3.8145, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:33:56,959:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:34:02,476:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:34:08,107:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:34:08,107:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:34:08,107:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:34:08,119:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:34:08,119:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:34:08,119:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:34:08,124:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:34:08,125:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:34:08,126:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:34:08,126:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:34:08,126:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:34:08,126:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:34:08,573:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:34:24,043:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:15.911370992660522
2022-09-05 15:34:24,046:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:34:24,046:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:34:24,046:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:34:24,046:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:34:24,047:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:34:27,862:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:34:27,863:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.7026, Train Acc: 50.0000,
                        Val Loss: 1.1262, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:27,863:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:34:31,868:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 4.01s, LR: 0.00050, Train Loss: 0.6203, Train Acc: 50.0220,
                        Val Loss: 3.0592, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:31,868:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:34:35,616:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.5753, Train Acc: 53.0967,
                        Val Loss: 4.2043, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:35,616:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:34:39,363:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.5424, Train Acc: 67.3407,
                        Val Loss: 3.8831, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:39,363:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:34:43,227:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.5194, Train Acc: 80.4509,
                        Val Loss: 2.7968, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:43,227:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:34:46,983:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.5011, Train Acc: 83.2321,
                        Val Loss: 2.0290, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:46,983:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:34:50,806:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.4842, Train Acc: 83.7673,
                        Val Loss: 1.6369, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:50,806:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:34:54,519:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.4696, Train Acc: 84.5227,
                        Val Loss: 1.2702, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:34:54,519:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:34:58,210:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0093 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:34:58,210:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.69s, LR: 0.00050, Train Loss: 0.4553, Train Acc: 85.0741,
                        Val Loss: 1.0195, Val Acc: 50.0000, Test Acc: 50.0093
2022-09-05 15:34:58,211:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:35:01,966:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0187 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:01,966:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.4419, Train Acc: 85.1431,
                        Val Loss: 0.9363, Val Acc: 50.0000, Test Acc: 50.0187
2022-09-05 15:35:01,966:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:35:05,693:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0392 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:05,693:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.4290, Train Acc: 85.2591,
                        Val Loss: 1.0218, Val Acc: 50.0095, Test Acc: 50.0392
2022-09-05 15:35:05,693:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:35:09,416:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.72s, LR: 0.00050, Train Loss: 0.4159, Train Acc: 85.4843,
                        Val Loss: 1.0154, Val Acc: 50.0199, Test Acc: 50.0392
2022-09-05 15:35:09,416:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:35:13,198:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.4042, Train Acc: 85.6390,
                        Val Loss: 1.0260, Val Acc: 50.0597, Test Acc: 50.0392
2022-09-05 15:35:13,198:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:35:16,981:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3927, Train Acc: 85.8521,
                        Val Loss: 1.1127, Val Acc: 50.0389, Test Acc: 50.0392
2022-09-05 15:35:16,981:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:35:20,774:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0785 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:20,774:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.3817, Train Acc: 85.8873,
                        Val Loss: 1.0942, Val Acc: 50.0985, Test Acc: 50.0785
2022-09-05 15:35:20,774:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:35:24,585:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.1765 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:24,585:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.3717, Train Acc: 85.9294,
                        Val Loss: 1.0481, Val Acc: 50.1922, Test Acc: 50.1765
2022-09-05 15:35:24,585:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:35:28,427:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.3878 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:28,427:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.3617, Train Acc: 86.3820,
                        Val Loss: 0.9807, Val Acc: 50.4620, Test Acc: 50.3878
2022-09-05 15:35:28,427:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:35:32,208:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 51.6188 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:32,208:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3527, Train Acc: 86.5606,
                        Val Loss: 0.8509, Val Acc: 52.0154, Test Acc: 51.6188
2022-09-05 15:35:32,208:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:35:36,045:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 59.2902 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:36,045:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.3449, Train Acc: 86.5784,
                        Val Loss: 0.6804, Val Acc: 58.9455, Test Acc: 59.2902
2022-09-05 15:35:36,045:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:35:39,824:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 69.7676 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:39,824:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3364, Train Acc: 86.8282,
                        Val Loss: 0.5470, Val Acc: 69.6834, Test Acc: 69.7676
2022-09-05 15:35:39,824:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:35:43,673:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 73.7013 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:43,673:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.3297, Train Acc: 87.0782,
                        Val Loss: 0.4965, Val Acc: 73.3179, Test Acc: 73.7013
2022-09-05 15:35:43,673:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:35:47,423:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.3249, Train Acc: 87.0001,
                        Val Loss: 0.4977, Val Acc: 73.0698, Test Acc: 73.5005
2022-09-05 15:35:47,423:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:35:51,156:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.3178, Train Acc: 87.1044,
                        Val Loss: 0.5611, Val Acc: 70.3672, Test Acc: 70.7356
2022-09-05 15:35:51,156:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 15:35:54,936:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3136, Train Acc: 87.3876,
                        Val Loss: 0.5670, Val Acc: 71.7528, Test Acc: 72.0869
2022-09-05 15:35:54,936:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 15:35:58,665:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 77.8926 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:35:58,665:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.3077, Train Acc: 87.4369,
                        Val Loss: 0.4811, Val Acc: 77.4732, Test Acc: 77.8926
2022-09-05 15:35:58,665:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 15:36:02,380:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.3050, Train Acc: 87.4130,
                        Val Loss: 0.5049, Val Acc: 75.2715, Test Acc: 75.7329
2022-09-05 15:36:02,380:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 15:36:06,152:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.3012, Train Acc: 87.5618,
                        Val Loss: 0.4649, Val Acc: 75.2515, Test Acc: 75.8197
2022-09-05 15:36:06,152:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 15:36:10,001:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.4201 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h34m08s_on_Sep_05_2022/MODELS_
2022-09-05 15:36:10,001:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.2972, Train Acc: 87.5597,
                        Val Loss: 0.4223, Val Acc: 77.8396, Test Acc: 78.4201
2022-09-05 15:36:10,001:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 15:36:13,788:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.2938, Train Acc: 87.5131,
                        Val Loss: 0.4825, Val Acc: 74.6268, Test Acc: 74.9548
2022-09-05 15:36:13,788:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 15:36:17,549:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.76s, LR: 0.00050, Train Loss: 0.2910, Train Acc: 87.7567,
                        Val Loss: 0.7181, Val Acc: 61.8605, Test Acc: 62.2917
2022-09-05 15:36:17,549:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 15:36:21,246:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.2894, Train Acc: 87.4794,
                        Val Loss: 0.6133, Val Acc: 67.9701, Test Acc: 68.3519
2022-09-05 15:36:21,247:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 15:36:25,062:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.81s, LR: 0.00050, Train Loss: 0.2868, Train Acc: 87.7840,
                        Val Loss: 0.4369, Val Acc: 77.7615, Test Acc: 78.0062
2022-09-05 15:36:25,062:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 15:36:28,902:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.2914, Train Acc: 87.1182,
                        Val Loss: 0.6689, Val Acc: 62.4212, Test Acc: 62.8872
2022-09-05 15:36:28,902:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 15:36:32,717:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.2874, Train Acc: 87.8648,
                        Val Loss: 0.8141, Val Acc: 63.2501, Test Acc: 63.5650
2022-09-05 15:36:32,717:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 15:36:36,595:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.88s, LR: 0.00050, Train Loss: 0.2862, Train Acc: 87.7671,
                        Val Loss: 1.0263, Val Acc: 52.5582, Test Acc: 52.2131
2022-09-05 15:36:36,595:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 15:36:40,442:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.2812, Train Acc: 88.0837,
                        Val Loss: 1.1451, Val Acc: 50.1193, Test Acc: 50.1383
2022-09-05 15:36:40,442:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 15:36:45,899:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:36:51,616:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:36:51,616:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:36:51,617:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:36:51,618:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:36:51,618:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:36:51,618:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:36:51,623:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:36:51,624:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:36:51,624:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:36:51,624:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:36:51,624:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:36:51,624:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:36:52,133:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:37:07,670:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:16.039339065551758
2022-09-05 15:37:07,674:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:37:07,674:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:37:07,674:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:37:07,674:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:37:07,675:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:37:11,571:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h36m51s_on_Sep_05_2022/MODELS_
2022-09-05 15:37:11,571:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.90s, LR: 0.00050, Train Loss: 0.6414, Train Acc: 51.8372,
                        Val Loss: 6.5821, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:37:11,571:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:37:28,146:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:37:33,766:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:37:33,767:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:37:33,767:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:37:33,768:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:37:33,768:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:37:33,768:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:37:33,773:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:37:33,774:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:37:33,774:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:37:33,775:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:37:33,775:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:37:33,775:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:37:34,290:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:37:45,871:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:12.091155052185059
2022-09-05 15:37:45,874:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:37:45,874:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:37:45,875:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:37:45,875:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:37:45,876:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:37:49,761:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.3676 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h37m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:37:49,761:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.6779, Train Acc: 55.7031,
                        Val Loss: 0.6367, Val Acc: 50.0776, Test Acc: 50.3676
2022-09-05 15:37:49,761:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:37:53,665:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 73.2839 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h37m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:37:53,665:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.90s, LR: 0.00050, Train Loss: 0.6047, Train Acc: 81.3067,
                        Val Loss: 0.5710, Val Acc: 72.6815, Test Acc: 73.2839
2022-09-05 15:37:53,665:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:37:57,515:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.2869 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h37m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:37:57,516:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.5617, Train Acc: 84.9684,
                        Val Loss: 0.5084, Val Acc: 84.7450, Test Acc: 84.2869
2022-09-05 15:37:57,516:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:38:01,308:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.79s, LR: 0.00050, Train Loss: 0.5304, Train Acc: 85.8552,
                        Val Loss: 0.4767, Val Acc: 84.3905, Test Acc: 83.9581
2022-09-05 15:38:01,308:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:38:05,201:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.5054, Train Acc: 86.3796,
                        Val Loss: 0.4426, Val Acc: 84.7767, Test Acc: 84.2526
2022-09-05 15:38:05,201:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:38:08,953:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.7626 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h37m33s_on_Sep_05_2022/MODELS_
2022-09-05 15:38:08,953:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.75s, LR: 0.00050, Train Loss: 0.4821, Train Acc: 86.8027,
                        Val Loss: 0.4230, Val Acc: 84.7100, Test Acc: 84.7626
2022-09-05 15:38:08,953:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:38:12,654:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.70s, LR: 0.00050, Train Loss: 0.4604, Train Acc: 86.9996,
                        Val Loss: 0.4369, Val Acc: 82.2951, Test Acc: 83.6375
2022-09-05 15:38:12,654:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:38:16,459:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.4429, Train Acc: 87.3384,
                        Val Loss: 0.4652, Val Acc: 79.5834, Test Acc: 80.5103
2022-09-05 15:38:16,459:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:38:20,282:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.4268, Train Acc: 87.5336,
                        Val Loss: 0.4829, Val Acc: 79.2832, Test Acc: 79.1885
2022-09-05 15:38:20,283:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:38:24,086:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.4126, Train Acc: 87.5256,
                        Val Loss: 0.4827, Val Acc: 79.4634, Test Acc: 79.6169
2022-09-05 15:38:24,086:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:38:27,888:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3996, Train Acc: 87.2953,
                        Val Loss: 0.4729, Val Acc: 79.7422, Test Acc: 80.4045
2022-09-05 15:38:27,889:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:38:31,597:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.71s, LR: 0.00050, Train Loss: 0.3864, Train Acc: 87.3927,
                        Val Loss: 0.4563, Val Acc: 80.2749, Test Acc: 81.8476
2022-09-05 15:38:31,597:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:38:35,456:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.3745, Train Acc: 87.3246,
                        Val Loss: 0.4350, Val Acc: 82.1505, Test Acc: 83.3202
2022-09-05 15:38:35,456:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:38:39,260:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.80s, LR: 0.00050, Train Loss: 0.3634, Train Acc: 87.2489,
                        Val Loss: 0.4136, Val Acc: 83.8954, Test Acc: 83.7124
2022-09-05 15:38:39,260:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:38:43,078:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.3532, Train Acc: 87.3018,
                        Val Loss: 0.3955, Val Acc: 84.6685, Test Acc: 84.4535
2022-09-05 15:38:43,079:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:38:46,901:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.3444, Train Acc: 87.2611,
                        Val Loss: 0.3927, Val Acc: 84.4813, Test Acc: 83.8334
2022-09-05 15:38:46,901:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:38:50,670:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.77s, LR: 0.00050, Train Loss: 0.3355, Train Acc: 87.5744,
                        Val Loss: 0.4013, Val Acc: 82.2521, Test Acc: 82.3629
2022-09-05 15:38:50,670:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:38:54,557:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.3283, Train Acc: 87.5472,
                        Val Loss: 0.4132, Val Acc: 80.7004, Test Acc: 80.9668
2022-09-05 15:38:54,557:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:38:58,459:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.90s, LR: 0.00050, Train Loss: 0.3222, Train Acc: 87.6728,
                        Val Loss: 0.4267, Val Acc: 78.7514, Test Acc: 78.9616
2022-09-05 15:38:58,459:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:39:11,327:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:39:16,673:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:39:16,673:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:39:16,673:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:39:16,674:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:39:16,674:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:39:16,674:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:39:16,679:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:39:16,679:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:39:16,680:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:39:16,680:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:39:16,680:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:39:16,680:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:39:17,228:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:39:33,206:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:16.520550966262817
2022-09-05 15:39:33,210:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:39:33,210:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:39:33,210:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:39:33,210:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:39:33,212:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:39:37,144:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h39m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:39:37,144:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.93s, LR: 0.00050, Train Loss: 0.7311, Train Acc: 48.9775,
                        Val Loss: 1.6540, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:39:37,144:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:39:41,179:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 53.2116 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h39m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:39:41,179:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 4.04s, LR: 0.00050, Train Loss: 0.6079, Train Acc: 85.0338,
                        Val Loss: 0.6605, Val Acc: 52.5333, Test Acc: 53.2116
2022-09-05 15:39:41,179:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:39:45,038:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 75.9739 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h39m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:39:45,038:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.5558, Train Acc: 86.3621,
                        Val Loss: 0.4920, Val Acc: 75.4670, Test Acc: 75.9739
2022-09-05 15:39:45,038:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:39:48,893:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.5268, Train Acc: 86.2939,
                        Val Loss: 0.4888, Val Acc: 73.8633, Test Acc: 73.3071
2022-09-05 15:39:48,893:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:39:52,799:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.91s, LR: 0.00050, Train Loss: 0.5030, Train Acc: 86.7293,
                        Val Loss: 0.7058, Val Acc: 57.9758, Test Acc: 57.9821
2022-09-05 15:39:52,800:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:39:56,676:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.88s, LR: 0.00050, Train Loss: 0.4820, Train Acc: 87.0170,
                        Val Loss: 0.8587, Val Acc: 52.6213, Test Acc: 52.2686
2022-09-05 15:39:56,676:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:40:00,508:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.83s, LR: 0.00050, Train Loss: 0.4618, Train Acc: 87.1561,
                        Val Loss: 0.8934, Val Acc: 52.1395, Test Acc: 51.9523
2022-09-05 15:40:00,508:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:40:04,440:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.93s, LR: 0.00050, Train Loss: 0.4445, Train Acc: 87.3071,
                        Val Loss: 0.8491, Val Acc: 53.1967, Test Acc: 52.7869
2022-09-05 15:40:04,440:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:40:08,380:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.94s, LR: 0.00050, Train Loss: 0.4286, Train Acc: 87.2148,
                        Val Loss: 0.7575, Val Acc: 55.9749, Test Acc: 55.8509
2022-09-05 15:40:08,380:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:40:12,225:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.85s, LR: 0.00050, Train Loss: 0.4142, Train Acc: 87.4312,
                        Val Loss: 0.5977, Val Acc: 64.6963, Test Acc: 65.2592
2022-09-05 15:40:12,225:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:40:16,063:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.3493 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h39m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:40:16,063:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.4006, Train Acc: 87.0729,
                        Val Loss: 0.4741, Val Acc: 77.9564, Test Acc: 78.3493
2022-09-05 15:40:16,063:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:40:19,956:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.3530 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h39m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:40:19,956:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.3871, Train Acc: 87.2226,
                        Val Loss: 0.4605, Val Acc: 83.0288, Test Acc: 82.3530
2022-09-05 15:40:19,956:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:40:23,814:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.86s, LR: 0.00050, Train Loss: 0.3752, Train Acc: 87.1982,
                        Val Loss: 0.5019, Val Acc: 73.6850, Test Acc: 73.6040
2022-09-05 15:40:23,814:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:40:27,656:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.84s, LR: 0.00050, Train Loss: 0.3640, Train Acc: 87.3042,
                        Val Loss: 0.5381, Val Acc: 67.8926, Test Acc: 67.9927
2022-09-05 15:40:27,656:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:40:31,472:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.82s, LR: 0.00050, Train Loss: 0.3537, Train Acc: 87.2937,
                        Val Loss: 0.5685, Val Acc: 64.0174, Test Acc: 64.3787
2022-09-05 15:40:31,472:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:40:35,248:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.78s, LR: 0.00050, Train Loss: 0.3448, Train Acc: 87.4092,
                        Val Loss: 0.6185, Val Acc: 59.2721, Test Acc: 59.5333
2022-09-05 15:40:35,248:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:40:39,140:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.89s, LR: 0.00050, Train Loss: 0.3360, Train Acc: 87.5416,
                        Val Loss: 0.7022, Val Acc: 54.7862, Test Acc: 54.6550
2022-09-05 15:40:39,140:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:40:42,873:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.73s, LR: 0.00050, Train Loss: 0.3284, Train Acc: 87.5716,
                        Val Loss: 0.8285, Val Acc: 51.3551, Test Acc: 51.1923
2022-09-05 15:40:42,873:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:40:44,571:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 15:40:44,571:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 15:40:59,672:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:41:05,114:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:41:05,114:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:41:05,114:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:41:05,115:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:41:05,115:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:41:05,115:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:41:05,120:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:41:05,121:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:41:05,121:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:41:05,121:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:41:05,121:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:41:05,121:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:41:05,657:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:41:30,535:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:25.409523010253906
2022-09-05 15:41:30,538:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 50
2022-09-05 15:41:30,538:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 50
2022-09-05 15:41:30,538:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 50
2022-09-05 15:41:30,538:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:41:30,540:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:41:34,478:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h41m05s_on_Sep_05_2022/MODELS_
2022-09-05 15:41:34,478:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 3.94s, LR: 0.00050, Train Loss: 0.6636, Train Acc: 50.0000,
                        Val Loss: 6.4628, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:41:34,478:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:41:38,567:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 4.09s, LR: 0.00050, Train Loss: 0.5957, Train Acc: 59.7697,
                        Val Loss: 5.6849, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:41:38,567:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:41:48,771:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:41:54,555:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:41:54,556:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:41:54,556:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:41:54,557:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:41:54,557:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:41:54,557:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:41:54,563:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:41:54,564:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:41:54,564:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:41:54,565:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:41:54,565:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:41:54,565:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:41:55,116:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:42:45,501:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:50.92761492729187
2022-09-05 15:42:45,504:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 15:42:45,504:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 15:42:45,504:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 15:42:45,504:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:42:45,506:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:42:53,299:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h41m54s_on_Sep_05_2022/MODELS_
2022-09-05 15:42:53,299:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.6183, Train Acc: 74.5917,
                        Val Loss: 9.5616, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:42:53,299:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:43:00,925:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.63s, LR: 0.00050, Train Loss: 0.5159, Train Acc: 86.4269,
                        Val Loss: 7.0611, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:43:00,925:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:43:10,244:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:43:16,185:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:43:16,185:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:43:16,185:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:43:16,193:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:43:16,193:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:43:16,193:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:43:16,198:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:43:16,199:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:43:16,199:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:43:16,200:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:43:16,202:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:43:16,202:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:43:16,735:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:43:48,157:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:31.94908905029297
2022-09-05 15:43:48,160:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 15:43:48,160:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 15:43:48,160:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 15:43:48,160:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:43:48,161:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:43:56,085:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h43m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:43:56,085:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.92s, LR: 0.00050, Train Loss: 0.6088, Train Acc: 50.0000,
                        Val Loss: 10.5567, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:43:56,085:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:44:03,872:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.5359, Train Acc: 55.4755,
                        Val Loss: 8.5888, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:03,873:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:44:11,493:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.5022, Train Acc: 66.5369,
                        Val Loss: 5.7984, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:11,493:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:44:19,083:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.4801, Train Acc: 79.7148,
                        Val Loss: 4.1154, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:19,083:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:44:26,768:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.4588, Train Acc: 85.3301,
                        Val Loss: 3.0387, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:26,768:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:44:34,385:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.4389, Train Acc: 86.1958,
                        Val Loss: 2.4251, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:34,385:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:44:42,085:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.4195, Train Acc: 86.3460,
                        Val Loss: 2.1632, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:42,086:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:44:49,784:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.4006, Train Acc: 86.6131,
                        Val Loss: 1.4726, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:49,784:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:44:57,380:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.3817, Train Acc: 86.8093,
                        Val Loss: 1.2706, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:44:57,381:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:45:04,926:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.3646, Train Acc: 87.2061,
                        Val Loss: 1.7525, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:45:04,926:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:45:12,579:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0325 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h43m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:45:12,579:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.3492, Train Acc: 87.2232,
                        Val Loss: 1.1620, Val Acc: 50.0109, Test Acc: 50.0325
2022-09-05 15:45:12,579:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:45:20,183:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.1931 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h43m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:45:20,183:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.3352, Train Acc: 87.4084,
                        Val Loss: 1.4189, Val Acc: 50.1587, Test Acc: 50.1931
2022-09-05 15:45:20,183:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:45:27,822:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 51.9065 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h43m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:45:27,822:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.3245, Train Acc: 87.3788,
                        Val Loss: 0.8977, Val Acc: 52.1359, Test Acc: 51.9065
2022-09-05 15:45:27,822:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:45:35,549:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.3137, Train Acc: 87.2500,
                        Val Loss: 2.1905, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:45:35,549:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:45:42,895:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.35s, LR: 0.00050, Train Loss: 0.3072, Train Acc: 87.4960,
                        Val Loss: 3.5735, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:45:42,895:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:45:50,529:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.63s, LR: 0.00050, Train Loss: 0.3007, Train Acc: 87.5415,
                        Val Loss: 5.8635, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:45:50,529:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:45:57,908:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.38s, LR: 0.00050, Train Loss: 0.2971, Train Acc: 87.5330,
                        Val Loss: 2.1057, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:45:57,908:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:46:05,565:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 60.3071 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h43m16s_on_Sep_05_2022/MODELS_
2022-09-05 15:46:05,565:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.2936, Train Acc: 87.6596,
                        Val Loss: 0.7227, Val Acc: 60.3011, Test Acc: 60.3071
2022-09-05 15:46:05,565:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:46:13,086:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.52s, LR: 0.00050, Train Loss: 0.2903, Train Acc: 87.6760,
                        Val Loss: 2.0031, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:46:13,086:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:46:20,778:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.2857, Train Acc: 87.8996,
                        Val Loss: 1.0383, Val Acc: 50.7767, Test Acc: 50.7921
2022-09-05 15:46:20,778:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:46:28,425:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.2850, Train Acc: 88.0656,
                        Val Loss: 3.2178, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:46:28,425:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:46:47,484:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:46:53,270:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:46:53,271:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:46:53,272:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:46:53,273:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:46:53,273:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:46:53,273:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:46:53,278:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:46:53,278:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:46:53,279:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:46:53,279:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:46:53,279:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:46:53,279:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:46:53,792:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:47:17,630:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:24.345113039016724
2022-09-05 15:47:17,634:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 15:47:17,634:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 15:47:17,634:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 15:47:17,634:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:47:17,636:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:47:25,675:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 56.6270 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:47:25,675:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 8.04s, LR: 0.00050, Train Loss: 0.6166, Train Acc: 73.2242,
                        Val Loss: 0.6789, Val Acc: 55.8224, Test Acc: 56.6270
2022-09-05 15:47:25,675:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:47:33,822:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 59.7973 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:47:33,823:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 8.15s, LR: 0.00050, Train Loss: 0.5197, Train Acc: 84.9515,
                        Val Loss: 0.6480, Val Acc: 59.2580, Test Acc: 59.7973
2022-09-05 15:47:33,823:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:47:41,778:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 73.6567 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:47:41,778:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.96s, LR: 0.00050, Train Loss: 0.4567, Train Acc: 86.7759,
                        Val Loss: 0.5620, Val Acc: 72.9174, Test Acc: 73.6567
2022-09-05 15:47:41,778:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:47:49,522:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.9712 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:47:49,522:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.4119, Train Acc: 87.1434,
                        Val Loss: 0.4663, Val Acc: 82.7353, Test Acc: 82.9712
2022-09-05 15:47:49,522:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:47:57,167:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.7937 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:47:57,167:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.3774, Train Acc: 87.1317,
                        Val Loss: 0.4076, Val Acc: 85.6953, Test Acc: 84.7937
2022-09-05 15:47:57,167:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:48:04,801:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.5330 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:48:04,801:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.63s, LR: 0.00050, Train Loss: 0.3516, Train Acc: 87.4104,
                        Val Loss: 0.3727, Val Acc: 86.3512, Test Acc: 85.5330
2022-09-05 15:48:04,801:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:48:12,889:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 8.09s, LR: 0.00050, Train Loss: 0.3314, Train Acc: 87.6298,
                        Val Loss: 0.3600, Val Acc: 85.7362, Test Acc: 85.1014
2022-09-05 15:48:12,890:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:48:20,703:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.8532 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:48:20,703:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.81s, LR: 0.00050, Train Loss: 0.3170, Train Acc: 87.7275,
                        Val Loss: 0.3370, Val Acc: 86.3875, Test Acc: 85.8532
2022-09-05 15:48:20,703:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:48:28,437:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.9336 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:48:28,437:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.3061, Train Acc: 87.8544,
                        Val Loss: 0.3348, Val Acc: 86.2949, Test Acc: 85.9336
2022-09-05 15:48:28,437:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:48:36,336:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.0781 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:48:36,336:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.90s, LR: 0.00050, Train Loss: 0.2998, Train Acc: 87.8142,
                        Val Loss: 0.3254, Val Acc: 86.6173, Test Acc: 86.0781
2022-09-05 15:48:36,336:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:48:43,866:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.1552 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h46m53s_on_Sep_05_2022/MODELS_
2022-09-05 15:48:43,866:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.2937, Train Acc: 87.9874,
                        Val Loss: 0.3252, Val Acc: 86.4977, Test Acc: 86.1552
2022-09-05 15:48:43,866:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:48:51,687:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.82s, LR: 0.00050, Train Loss: 0.2897, Train Acc: 87.7890,
                        Val Loss: 0.3264, Val Acc: 86.2188, Test Acc: 86.0409
2022-09-05 15:48:51,687:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:48:59,346:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.2870, Train Acc: 87.8632,
                        Val Loss: 0.3283, Val Acc: 86.2320, Test Acc: 85.9921
2022-09-05 15:48:59,347:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:49:07,055:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.71s, LR: 0.00050, Train Loss: 0.2828, Train Acc: 88.0589,
                        Val Loss: 0.3454, Val Acc: 85.1444, Test Acc: 84.6723
2022-09-05 15:49:07,055:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:49:14,847:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.2790, Train Acc: 88.0502,
                        Val Loss: 0.3534, Val Acc: 84.7647, Test Acc: 84.1581
2022-09-05 15:49:14,847:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:49:22,580:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.2792, Train Acc: 87.9677,
                        Val Loss: 0.4111, Val Acc: 81.3182, Test Acc: 81.4078
2022-09-05 15:49:22,580:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:49:30,240:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.2786, Train Acc: 88.2958,
                        Val Loss: 0.3819, Val Acc: 82.7053, Test Acc: 82.4792
2022-09-05 15:49:30,240:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:49:37,992:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.75s, LR: 0.00050, Train Loss: 0.2748, Train Acc: 88.4135,
                        Val Loss: 0.4057, Val Acc: 81.2386, Test Acc: 81.1998
2022-09-05 15:49:37,992:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:49:45,717:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.2725, Train Acc: 88.1560,
                        Val Loss: 0.4559, Val Acc: 78.0367, Test Acc: 78.4817
2022-09-05 15:49:45,718:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:49:53,533:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.82s, LR: 0.00050, Train Loss: 0.2698, Train Acc: 88.3154,
                        Val Loss: 0.4450, Val Acc: 79.3045, Test Acc: 79.1777
2022-09-05 15:49:53,533:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:50:01,169:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.2704, Train Acc: 88.2493,
                        Val Loss: 0.4426, Val Acc: 80.9028, Test Acc: 80.5745
2022-09-05 15:50:01,169:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:50:08,864:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.2697, Train Acc: 88.4714,
                        Val Loss: 0.4163, Val Acc: 80.5157, Test Acc: 80.6905
2022-09-05 15:50:08,864:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:50:22,015:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:50:27,931:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:50:27,931:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:50:27,931:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:50:27,932:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:50:27,933:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:50:27,933:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:50:27,938:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:50:27,939:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:50:27,939:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:50:27,940:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:50:27,940:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:50:27,940:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:50:28,422:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:50:50,321:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:22.375756978988647
2022-09-05 15:50:50,324:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 15:50:50,324:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 15:50:50,324:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 15:50:50,324:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:50:50,326:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:50:57,816:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h50m27s_on_Sep_05_2022/MODELS_
2022-09-05 15:50:57,817:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.49s, LR: 0.00050, Train Loss: 0.6697, Train Acc: 60.0420,
                        Val Loss: 12.5752, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:50:57,817:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:51:05,204:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.39s, LR: 0.00050, Train Loss: 0.5726, Train Acc: 85.6172,
                        Val Loss: 5.0817, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:51:05,204:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:51:12,610:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.41s, LR: 0.00050, Train Loss: 0.5291, Train Acc: 86.1952,
                        Val Loss: 2.4539, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:51:12,611:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:51:20,056:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.4946, Train Acc: 86.2394,
                        Val Loss: 1.6417, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:51:20,056:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:51:27,355:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.30s, LR: 0.00050, Train Loss: 0.4626, Train Acc: 86.4930,
                        Val Loss: 1.1338, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:51:27,355:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:51:34,590:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 60.8571 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h50m27s_on_Sep_05_2022/MODELS_
2022-09-05 15:51:34,591:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.24s, LR: 0.00050, Train Loss: 0.4335, Train Acc: 86.7847,
                        Val Loss: 0.5821, Val Acc: 60.9027, Test Acc: 60.8571
2022-09-05 15:51:34,591:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:51:42,015:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.1103 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h50m27s_on_Sep_05_2022/MODELS_
2022-09-05 15:51:42,015:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.42s, LR: 0.00050, Train Loss: 0.4078, Train Acc: 86.7830,
                        Val Loss: 0.4684, Val Acc: 82.3581, Test Acc: 82.1103
2022-09-05 15:51:42,015:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:51:49,347:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.33s, LR: 0.00050, Train Loss: 0.3839, Train Acc: 86.8348,
                        Val Loss: 0.5472, Val Acc: 67.7523, Test Acc: 68.0628
2022-09-05 15:51:49,348:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:51:56,627:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.28s, LR: 0.00050, Train Loss: 0.3614, Train Acc: 87.1980,
                        Val Loss: 0.5134, Val Acc: 70.6724, Test Acc: 70.6528
2022-09-05 15:51:56,628:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:52:03,915:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.29s, LR: 0.00050, Train Loss: 0.3432, Train Acc: 87.4271,
                        Val Loss: 0.4232, Val Acc: 79.8572, Test Acc: 79.8564
2022-09-05 15:52:03,915:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:52:11,287:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.3288, Train Acc: 87.3043,
                        Val Loss: 0.4024, Val Acc: 81.5910, Test Acc: 81.8073
2022-09-05 15:52:11,287:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:52:18,741:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.3159, Train Acc: 87.2824,
                        Val Loss: 0.4084, Val Acc: 81.6338, Test Acc: 81.3423
2022-09-05 15:52:18,741:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:52:26,309:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.3087, Train Acc: 87.3964,
                        Val Loss: 0.8796, Val Acc: 55.9480, Test Acc: 55.6621
2022-09-05 15:52:26,309:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:52:34,116:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.81s, LR: 0.00050, Train Loss: 0.3008, Train Acc: 87.4110,
                        Val Loss: 1.1240, Val Acc: 52.2956, Test Acc: 52.1539
2022-09-05 15:52:34,116:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:52:41,945:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.83s, LR: 0.00050, Train Loss: 0.2948, Train Acc: 87.4784,
                        Val Loss: 1.1838, Val Acc: 51.0611, Test Acc: 51.0201
2022-09-05 15:52:41,945:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:52:49,586:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.2918, Train Acc: 87.5155,
                        Val Loss: 1.9964, Val Acc: 50.0061, Test Acc: 50.0000
2022-09-05 15:52:49,586:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:52:51,636:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 15:52:51,636:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 15:52:53,805:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:52:59,370:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:52:59,370:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:52:59,371:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:52:59,372:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:52:59,372:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:52:59,372:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:52:59,377:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:52:59,378:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-05 15:52:59,378:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:52:59,379:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:52:59,379:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:52:59,379:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:52:59,854:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 15:53:28,056:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:28.672186136245728
2022-09-05 15:53:28,058:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 15:53:28,058:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 15:53:28,058:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 15:53:28,058:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:53:28,060:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:53:35,753:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:53:35,753:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.6775, Train Acc: 53.3816,
                        Val Loss: 0.7342, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:53:35,753:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:53:43,742:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.99s, LR: 0.00050, Train Loss: 0.6120, Train Acc: 74.2355,
                        Val Loss: 0.6897, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:53:43,742:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:53:51,655:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 51.7157 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:53:51,655:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.91s, LR: 0.00050, Train Loss: 0.5604, Train Acc: 81.8078,
                        Val Loss: 0.6624, Val Acc: 51.5291, Test Acc: 51.7157
2022-09-05 15:53:51,655:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:53:59,348:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 71.6872 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:53:59,348:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.5178, Train Acc: 84.1799,
                        Val Loss: 0.6090, Val Acc: 68.8840, Test Acc: 71.6872
2022-09-05 15:53:59,348:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 15:54:06,925:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 79.2246 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:54:06,925:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.58s, LR: 0.00050, Train Loss: 0.4757, Train Acc: 85.7181,
                        Val Loss: 0.5611, Val Acc: 77.4602, Test Acc: 79.2246
2022-09-05 15:54:06,925:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 15:54:14,528:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.1303 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:54:14,528:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.4481, Train Acc: 85.6866,
                        Val Loss: 0.5034, Val Acc: 83.4574, Test Acc: 83.1303
2022-09-05 15:54:14,528:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 15:54:22,470:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.1885 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:54:22,471:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.94s, LR: 0.00050, Train Loss: 0.4198, Train Acc: 86.2134,
                        Val Loss: 0.4700, Val Acc: 85.0624, Test Acc: 85.1885
2022-09-05 15:54:22,471:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 15:54:30,253:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.78s, LR: 0.00050, Train Loss: 0.3965, Train Acc: 86.3134,
                        Val Loss: 0.4348, Val Acc: 84.7784, Test Acc: 84.4731
2022-09-05 15:54:30,253:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 15:54:37,970:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.0718 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:54:37,970:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.3780, Train Acc: 86.7187,
                        Val Loss: 0.3965, Val Acc: 86.0160, Test Acc: 86.0718
2022-09-05 15:54:37,970:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 15:54:45,665:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.1763 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:54:45,665:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.3580, Train Acc: 86.9030,
                        Val Loss: 0.3831, Val Acc: 86.2228, Test Acc: 86.1763
2022-09-05 15:54:45,665:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 15:54:53,492:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.83s, LR: 0.00050, Train Loss: 0.3437, Train Acc: 87.0797,
                        Val Loss: 0.3641, Val Acc: 86.0498, Test Acc: 85.9633
2022-09-05 15:54:53,492:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 15:55:01,179:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.3364 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:55:01,180:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.3655, Train Acc: 83.9626,
                        Val Loss: 0.3516, Val Acc: 86.0977, Test Acc: 86.3364
2022-09-05 15:55:01,180:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 15:55:09,153:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.97s, LR: 0.00050, Train Loss: 0.3277, Train Acc: 86.7505,
                        Val Loss: 0.3483, Val Acc: 85.5644, Test Acc: 85.7702
2022-09-05 15:55:09,153:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 15:55:17,054:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.4986 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:55:17,054:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.90s, LR: 0.00050, Train Loss: 0.3193, Train Acc: 86.9300,
                        Val Loss: 0.3329, Val Acc: 86.5037, Test Acc: 86.4986
2022-09-05 15:55:17,054:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 15:55:24,885:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.5778 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:55:24,885:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.83s, LR: 0.00050, Train Loss: 0.3168, Train Acc: 86.8795,
                        Val Loss: 0.3296, Val Acc: 86.8252, Test Acc: 86.5778
2022-09-05 15:55:24,885:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 15:55:32,720:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.83s, LR: 0.00050, Train Loss: 0.3806, Train Acc: 83.6981,
                        Val Loss: 0.3346, Val Acc: 86.2920, Test Acc: 86.1152
2022-09-05 15:55:32,720:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 15:55:40,463:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.3265, Train Acc: 85.7570,
                        Val Loss: 0.3457, Val Acc: 85.6201, Test Acc: 85.7478
2022-09-05 15:55:40,463:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 15:55:48,215:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.7025 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_15h52m59s_on_Sep_05_2022/MODELS_
2022-09-05 15:55:48,215:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.75s, LR: 0.00050, Train Loss: 0.3153, Train Acc: 86.5478,
                        Val Loss: 0.3288, Val Acc: 86.8396, Test Acc: 86.7025
2022-09-05 15:55:48,215:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 15:55:55,989:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.77s, LR: 0.00050, Train Loss: 0.3133, Train Acc: 86.6863,
                        Val Loss: 0.3315, Val Acc: 86.4420, Test Acc: 86.5374
2022-09-05 15:55:55,989:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 15:56:03,873:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.88s, LR: 0.00050, Train Loss: 0.3095, Train Acc: 86.8791,
                        Val Loss: 0.3309, Val Acc: 86.1317, Test Acc: 86.4881
2022-09-05 15:56:03,874:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 15:56:11,754:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.88s, LR: 0.00050, Train Loss: 0.3071, Train Acc: 86.9507,
                        Val Loss: 0.3279, Val Acc: 86.4911, Test Acc: 86.3353
2022-09-05 15:56:11,754:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 15:56:19,545:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.3338, Train Acc: 85.0029,
                        Val Loss: 0.3394, Val Acc: 86.2356, Test Acc: 86.5161
2022-09-05 15:56:19,545:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 15:56:27,413:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.87s, LR: 0.00050, Train Loss: 0.3288, Train Acc: 85.7794,
                        Val Loss: 0.3585, Val Acc: 84.6013, Test Acc: 84.9691
2022-09-05 15:56:27,413:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 15:56:35,236:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.82s, LR: 0.00050, Train Loss: 0.3473, Train Acc: 84.9310,
                        Val Loss: 0.3396, Val Acc: 85.6874, Test Acc: 85.7561
2022-09-05 15:56:35,236:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 15:56:43,206:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.97s, LR: 0.00050, Train Loss: 0.3104, Train Acc: 86.8082,
                        Val Loss: 0.3445, Val Acc: 85.7255, Test Acc: 85.4627
2022-09-05 15:56:43,206:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 15:56:50,982:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.78s, LR: 0.00050, Train Loss: 0.3256, Train Acc: 85.6112,
                        Val Loss: 0.3249, Val Acc: 86.5481, Test Acc: 86.3990
2022-09-05 15:56:50,982:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 15:56:58,688:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.71s, LR: 0.00050, Train Loss: 0.3042, Train Acc: 87.1867,
                        Val Loss: 0.3268, Val Acc: 86.1723, Test Acc: 86.3540
2022-09-05 15:56:58,688:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 15:57:06,548:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.86s, LR: 0.00050, Train Loss: 0.3151, Train Acc: 86.3250,
                        Val Loss: 0.3194, Val Acc: 86.7326, Test Acc: 86.4684
2022-09-05 15:57:06,548:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 15:57:17,021:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:57:22,832:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 32, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:57:22,833:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:57:22,833:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:57:22,834:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:57:22,834:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:57:22,834:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:57:22,839:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:57:22,840:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526439
2022-09-05 15:57:22,840:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:57:22,840:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:57:22,840:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:57:22,840:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:57:23,318:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 15:58:02,332:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:39.486324071884155
2022-09-05 15:58:02,335:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 15:58:02,335:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 15:58:02,335:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 15:58:02,335:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:58:02,336:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:58:10,383:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_15h57m22s_on_Sep_05_2022/MODELS_
2022-09-05 15:58:10,383:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 8.05s, LR: 0.00050, Train Loss: 0.5798, Train Acc: 73.4268,
                        Val Loss: 13.1207, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:58:10,383:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:58:18,294:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.91s, LR: 0.00050, Train Loss: 0.4781, Train Acc: 86.1530,
                        Val Loss: 8.8609, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:58:18,294:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:58:25,954:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.4389, Train Acc: 86.4989,
                        Val Loss: 9.8497, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 15:58:25,955:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:58:38,343:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 15:58:44,006:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 32, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 15:58:44,006:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 15:58:44,007:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:58:44,007:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:58:44,007:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:58:44,007:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:58:44,012:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 15:58:44,013:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526439
2022-09-05 15:58:44,014:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 15:58:44,014:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 15:58:44,014:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 15:58:44,014:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 15:58:44,516:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 15:59:26,513:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:42.493160009384155
2022-09-05 15:59:26,516:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 15:59:26,516:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 15:59:26,516:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 15:59:26,516:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 15:59:26,517:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 15:59:34,384:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.8743 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_15h58m44s_on_Sep_05_2022/MODELS_
2022-09-05 15:59:34,385:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.87s, LR: 0.00050, Train Loss: 0.6264, Train Acc: 76.9613,
                        Val Loss: 0.7263, Val Acc: 50.8136, Test Acc: 50.8743
2022-09-05 15:59:34,385:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 15:59:42,128:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.1021 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_15h58m44s_on_Sep_05_2022/MODELS_
2022-09-05 15:59:42,128:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.5341, Train Acc: 86.4254,
                        Val Loss: 0.4207, Val Acc: 82.7312, Test Acc: 83.1021
2022-09-05 15:59:42,128:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 15:59:49,633:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.9911 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_15h58m44s_on_Sep_05_2022/MODELS_
2022-09-05 15:59:49,633:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.51s, LR: 0.00050, Train Loss: 0.4776, Train Acc: 86.9638,
                        Val Loss: 0.4072, Val Acc: 84.2909, Test Acc: 83.9911
2022-09-05 15:59:49,633:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 15:59:57,051:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.42s, LR: 0.00050, Train Loss: 0.4356, Train Acc: 87.4135,
                        Val Loss: 0.4399, Val Acc: 80.8987, Test Acc: 80.8585
2022-09-05 15:59:57,051:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:00:04,488:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.44s, LR: 0.00050, Train Loss: 0.4001, Train Acc: 87.5294,
                        Val Loss: 0.4452, Val Acc: 82.1536, Test Acc: 81.9120
2022-09-05 16:00:04,489:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:00:12,104:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.3690, Train Acc: 87.6654,
                        Val Loss: 0.4586, Val Acc: 78.8849, Test Acc: 78.5779
2022-09-05 16:00:12,104:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:00:19,737:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.63s, LR: 0.00050, Train Loss: 0.3455, Train Acc: 87.3128,
                        Val Loss: 0.5661, Val Acc: 66.7247, Test Acc: 67.5065
2022-09-05 16:00:19,738:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:00:36,282:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:00:41,641:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 32, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:00:41,641:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:00:41,641:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:00:41,642:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:00:41,642:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:00:41,642:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:00:41,647:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:00:41,648:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526439
2022-09-05 16:00:41,648:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:00:41,649:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:00:41,649:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:00:41,649:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:00:42,170:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 16:01:45,449:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:63.795177936553955
2022-09-05 16:01:45,452:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:01:45,452:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:01:45,452:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:01:45,452:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:01:45,453:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:01:53,339:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:01:53,339:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.89s, LR: 0.00050, Train Loss: 0.6638, Train Acc: 50.5414,
                        Val Loss: 0.7039, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:01:53,339:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:02:00,971:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 60.4795 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:02:00,972:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.63s, LR: 0.00050, Train Loss: 0.5725, Train Acc: 61.9088,
                        Val Loss: 0.6916, Val Acc: 60.0671, Test Acc: 60.4795
2022-09-05 16:02:00,972:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:02:08,651:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 62.8676 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:02:08,651:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.68s, LR: 0.00050, Train Loss: 0.5123, Train Acc: 69.2683,
                        Val Loss: 0.6106, Val Acc: 62.5660, Test Acc: 62.8676
2022-09-05 16:02:08,651:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:02:16,385:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 68.4163 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:02:16,385:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.4760, Train Acc: 75.0776,
                        Val Loss: 0.5230, Val Acc: 67.8817, Test Acc: 68.4163
2022-09-05 16:02:16,385:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:02:23,953:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 80.5357 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:02:23,953:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.4476, Train Acc: 84.7706,
                        Val Loss: 0.4711, Val Acc: 80.8356, Test Acc: 80.5357
2022-09-05 16:02:23,953:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:02:31,563:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.2880 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:02:31,563:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.61s, LR: 0.00050, Train Loss: 0.4244, Train Acc: 87.1787,
                        Val Loss: 0.4446, Val Acc: 84.9973, Test Acc: 84.2880
2022-09-05 16:02:31,563:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:02:39,097:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.4732 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:02:39,097:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.4036, Train Acc: 87.6020,
                        Val Loss: 0.4247, Val Acc: 84.7312, Test Acc: 84.4732
2022-09-05 16:02:39,097:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:02:46,847:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.4450 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h00m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:02:46,848:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.75s, LR: 0.00050, Train Loss: 0.3830, Train Acc: 87.7311,
                        Val Loss: 0.3881, Val Acc: 86.3146, Test Acc: 86.4450
2022-09-05 16:02:46,848:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:02:54,273:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.43s, LR: 0.00050, Train Loss: 0.3640, Train Acc: 87.7318,
                        Val Loss: 0.3720, Val Acc: 86.1222, Test Acc: 85.9082
2022-09-05 16:02:54,274:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:03:01,859:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.3481, Train Acc: 87.6872,
                        Val Loss: 0.3621, Val Acc: 86.2454, Test Acc: 85.6088
2022-09-05 16:03:01,859:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 16:03:09,340:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.48s, LR: 0.00050, Train Loss: 0.3330, Train Acc: 87.7981,
                        Val Loss: 0.3450, Val Acc: 86.4171, Test Acc: 86.1709
2022-09-05 16:03:09,340:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 16:03:16,823:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.48s, LR: 0.00050, Train Loss: 0.3200, Train Acc: 87.9711,
                        Val Loss: 0.3623, Val Acc: 85.4004, Test Acc: 85.0139
2022-09-05 16:03:16,823:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 16:03:24,558:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.3112, Train Acc: 87.8317,
                        Val Loss: 0.3391, Val Acc: 86.3615, Test Acc: 85.9314
2022-09-05 16:03:24,558:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 16:03:32,214:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.3014, Train Acc: 88.0636,
                        Val Loss: 0.3538, Val Acc: 84.9819, Test Acc: 84.6468
2022-09-05 16:03:32,214:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 16:03:39,735:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.52s, LR: 0.00050, Train Loss: 0.2936, Train Acc: 87.9787,
                        Val Loss: 0.3558, Val Acc: 84.8276, Test Acc: 84.9141
2022-09-05 16:03:39,736:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 16:03:47,454:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.2891, Train Acc: 88.1674,
                        Val Loss: 0.3669, Val Acc: 84.6283, Test Acc: 84.1088
2022-09-05 16:03:47,454:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 16:03:55,010:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 0.2863, Train Acc: 88.1201,
                        Val Loss: 0.3472, Val Acc: 85.1255, Test Acc: 84.8741
2022-09-05 16:03:55,010:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 16:04:02,539:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.2818, Train Acc: 88.2273,
                        Val Loss: 0.3620, Val Acc: 84.3781, Test Acc: 83.7061
2022-09-05 16:04:02,539:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 16:04:10,215:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.68s, LR: 0.00050, Train Loss: 0.2770, Train Acc: 87.9741,
                        Val Loss: 0.3732, Val Acc: 83.8748, Test Acc: 83.3558
2022-09-05 16:04:10,215:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 16:04:18,077:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.86s, LR: 0.00050, Train Loss: 0.2744, Train Acc: 88.3676,
                        Val Loss: 0.3690, Val Acc: 84.2375, Test Acc: 83.5105
2022-09-05 16:04:18,077:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 16:04:25,732:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.2742, Train Acc: 88.1935,
                        Val Loss: 0.4058, Val Acc: 82.3217, Test Acc: 81.7745
2022-09-05 16:04:25,732:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 16:04:29,449:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 16:04:29,449:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 16:04:41,096:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:04:46,452:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 32, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:04:46,453:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:04:46,454:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:04:46,454:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:04:46,455:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:04:46,455:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:04:46,460:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:04:46,460:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526439
2022-09-05 16:04:46,461:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:04:46,461:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:04:46,461:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:04:46,461:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:04:46,949:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 16:05:49,730:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:63.26241111755371
2022-09-05 16:05:49,732:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:05:49,732:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:05:49,732:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:05:49,732:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:05:49,734:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:05:57,636:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h04m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:05:57,636:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.90s, LR: 0.00050, Train Loss: 0.6237, Train Acc: 76.2271,
                        Val Loss: 1.8947, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:05:57,636:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:06:05,187:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0061 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h04m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:06:05,187:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.5291, Train Acc: 85.5701,
                        Val Loss: 1.7545, Val Acc: 50.0000, Test Acc: 50.0061
2022-09-05 16:06:05,187:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:06:12,878:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 52.2489 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h04m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:06:12,878:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.4818, Train Acc: 86.5691,
                        Val Loss: 0.8509, Val Acc: 52.4931, Test Acc: 52.2489
2022-09-05 16:06:12,878:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:06:20,607:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 65.2362 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h04m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:06:20,607:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.4503, Train Acc: 87.2731,
                        Val Loss: 0.5397, Val Acc: 64.7781, Test Acc: 65.2362
2022-09-05 16:06:20,607:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:06:28,262:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 67.6685 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_32_16h04m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:06:28,262:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.4256, Train Acc: 87.3013,
                        Val Loss: 0.5264, Val Acc: 67.4456, Test Acc: 67.6685
2022-09-05 16:06:28,262:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:06:35,832:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.4066, Train Acc: 87.6418,
                        Val Loss: 0.5510, Val Acc: 60.4705, Test Acc: 60.4266
2022-09-05 16:06:35,832:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:06:43,618:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.3925, Train Acc: 87.5756,
                        Val Loss: 0.5780, Val Acc: 55.4492, Test Acc: 55.1152
2022-09-05 16:06:43,619:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:06:51,208:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.3795, Train Acc: 87.5768,
                        Val Loss: 0.6449, Val Acc: 51.3964, Test Acc: 51.2188
2022-09-05 16:06:51,208:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:06:58,698:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.49s, LR: 0.00050, Train Loss: 0.3673, Train Acc: 87.6975,
                        Val Loss: 0.7285, Val Acc: 50.4520, Test Acc: 50.3508
2022-09-05 16:06:58,698:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:07:06,271:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.3559, Train Acc: 87.7050,
                        Val Loss: 0.8361, Val Acc: 50.0315, Test Acc: 50.0278
2022-09-05 16:07:06,271:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 16:07:09,320:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 16:07:09,320:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 16:07:17,934:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:07:23,581:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 8, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:07:23,581:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:07:23,581:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:07:23,582:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:07:23,582:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:07:23,582:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:07:23,587:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:07:23,588:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-05 16:07:23,588:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:07:23,589:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:07:23,589:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:07:23,589:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:07:24,074:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 16:08:05,574:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:41.980555057525635
2022-09-05 16:08:05,577:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:08:05,577:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:08:05,577:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:08:05,577:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:08:05,579:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:08:13,331:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 52.3769 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h07m23s_on_Sep_05_2022/MODELS_
2022-09-05 16:08:13,331:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.75s, LR: 0.00050, Train Loss: 0.6443, Train Acc: 74.0787,
                        Val Loss: 0.6393, Val Acc: 52.6763, Test Acc: 52.3769
2022-09-05 16:08:13,331:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:08:21,062:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 53.7553 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h07m23s_on_Sep_05_2022/MODELS_
2022-09-05 16:08:21,062:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.5266, Train Acc: 85.9223,
                        Val Loss: 0.7259, Val Acc: 54.0382, Test Acc: 53.7553
2022-09-05 16:08:21,062:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:08:28,755:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 68.1682 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h07m23s_on_Sep_05_2022/MODELS_
2022-09-05 16:08:28,755:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.4648, Train Acc: 86.6227,
                        Val Loss: 0.5573, Val Acc: 67.8822, Test Acc: 68.1682
2022-09-05 16:08:28,756:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:08:36,362:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.1614 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h07m23s_on_Sep_05_2022/MODELS_
2022-09-05 16:08:36,362:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.61s, LR: 0.00050, Train Loss: 0.4240, Train Acc: 87.0826,
                        Val Loss: 0.4172, Val Acc: 83.1492, Test Acc: 83.1614
2022-09-05 16:08:36,362:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:08:43,904:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.1869 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h07m23s_on_Sep_05_2022/MODELS_
2022-09-05 16:08:43,904:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.54s, LR: 0.00050, Train Loss: 0.3924, Train Acc: 87.4957,
                        Val Loss: 0.4012, Val Acc: 86.5026, Test Acc: 86.1869
2022-09-05 16:08:43,904:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:08:51,345:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.44s, LR: 0.00050, Train Loss: 0.3659, Train Acc: 87.4051,
                        Val Loss: 0.4070, Val Acc: 86.0623, Test Acc: 85.5331
2022-09-05 16:08:51,346:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:08:58,849:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.50s, LR: 0.00050, Train Loss: 0.3447, Train Acc: 87.3838,
                        Val Loss: 0.4299, Val Acc: 83.0017, Test Acc: 82.8480
2022-09-05 16:08:58,849:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:09:06,450:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.3275, Train Acc: 87.5399,
                        Val Loss: 0.4682, Val Acc: 77.0267, Test Acc: 77.6850
2022-09-05 16:09:06,450:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:09:14,146:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.3143, Train Acc: 87.5470,
                        Val Loss: 0.5142, Val Acc: 70.0174, Test Acc: 70.7651
2022-09-05 16:09:14,146:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:09:21,867:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.3036, Train Acc: 87.7135,
                        Val Loss: 0.5695, Val Acc: 63.8850, Test Acc: 63.9611
2022-09-05 16:09:21,867:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 16:09:29,590:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.2970, Train Acc: 87.8336,
                        Val Loss: 0.7312, Val Acc: 55.6731, Test Acc: 56.4147
2022-09-05 16:09:29,590:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 16:09:37,287:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.2906, Train Acc: 87.8049,
                        Val Loss: 1.1309, Val Acc: 50.7307, Test Acc: 50.7226
2022-09-05 16:09:37,287:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 16:09:39,066:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 16:09:39,066:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 16:09:46,160:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:09:52,075:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 8, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:09:52,075:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:09:52,076:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:09:52,077:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:09:52,077:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:09:52,077:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:09:52,082:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:09:52,083:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-05 16:09:52,083:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:09:52,083:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:09:52,083:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:09:52,083:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:09:52,589:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 16:10:15,967:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:23.878803968429565
2022-09-05 16:10:15,971:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:10:15,971:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:10:15,971:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:10:15,971:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:10:15,972:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:10:23,761:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h09m52s_on_Sep_05_2022/MODELS_
2022-09-05 16:10:23,761:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.6081, Train Acc: 75.2678,
                        Val Loss: 9.0216, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:10:23,761:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:10:31,536:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.77s, LR: 0.00050, Train Loss: 0.5068, Train Acc: 85.8920,
                        Val Loss: 7.2711, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:10:31,536:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:10:33,592:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 16:10:33,592:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 16:10:36,308:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:10:42,164:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 8, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:10:42,166:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:10:42,166:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:10:42,167:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:10:42,167:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:10:42,167:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:10:42,172:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:10:42,173:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-05 16:10:42,173:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:10:42,174:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:10:42,174:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:10:42,174:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:10:42,660:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 16:11:05,474:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:23.29058289527893
2022-09-05 16:11:05,477:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:11:05,477:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:11:05,477:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:11:05,477:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:11:05,479:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:11:14,147:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0061 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h10m42s_on_Sep_05_2022/MODELS_
2022-09-05 16:11:14,147:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 8.67s, LR: 0.00050, Train Loss: 0.6317, Train Acc: 78.1547,
                        Val Loss: 0.9019, Val Acc: 50.0000, Test Acc: 50.0061
2022-09-05 16:11:14,147:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:11:22,166:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 54.0642 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h10m42s_on_Sep_05_2022/MODELS_
2022-09-05 16:11:22,166:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 8.02s, LR: 0.00050, Train Loss: 0.5199, Train Acc: 86.8100,
                        Val Loss: 0.7606, Val Acc: 54.5511, Test Acc: 54.0642
2022-09-05 16:11:22,166:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:11:30,043:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.5302 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h10m42s_on_Sep_05_2022/MODELS_
2022-09-05 16:11:30,043:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.88s, LR: 0.00050, Train Loss: 0.4520, Train Acc: 87.0748,
                        Val Loss: 0.4702, Val Acc: 77.8632, Test Acc: 78.5302
2022-09-05 16:11:30,044:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:11:37,949:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.1400 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h10m42s_on_Sep_05_2022/MODELS_
2022-09-05 16:11:37,949:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.91s, LR: 0.00050, Train Loss: 0.4084, Train Acc: 87.0488,
                        Val Loss: 0.4150, Val Acc: 85.2443, Test Acc: 85.1400
2022-09-05 16:11:37,949:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:11:45,691:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.3763, Train Acc: 87.3727,
                        Val Loss: 0.4070, Val Acc: 84.4545, Test Acc: 84.1159
2022-09-05 16:11:45,691:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:12:27,158:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:12:31,543:main_SBMs_node_classification.py:340 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'n_classes': 1}
2022-09-05 16:12:31,543:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:12:31,543:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:12:31,543:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:12:31,543:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:12:31,543:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:12:31,548:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:12:31,549:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523281
2022-09-05 16:12:31,549:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:12:31,549:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:12:31,549:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:12:31,549:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:12:51,385:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:12:55,953:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:12:55,953:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:12:55,953:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:12:55,953:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:12:55,953:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:12:55,953:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:12:55,958:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:12:55,959:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523382
2022-09-05 16:12:55,959:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:12:55,959:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:12:55,959:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:12:55,959:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:12:55,964:main_CYCLES_graph_classification.py:54 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-05 16:13:12,241:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 16:13:12,242:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 16:13:12,242:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 16:13:12,242:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:13:12,245:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:13:35,537:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_8_16h12m55s_on_Sep_05_2022/MODELS_
2022-09-05 16:13:35,538:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 23.29s, LR: 0.00050, Train Loss: 0.9566, Train Acc: 0.4750,
                        Val Loss: 2.8467, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 16:13:35,538:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:13:58,778:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 23.24s, LR: 0.00050, Train Loss: 0.8429, Train Acc: 0.5650,
                        Val Loss: 1.7904, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 16:13:58,779:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:14:20,177:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5002 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_8_16h12m55s_on_Sep_05_2022/MODELS_
2022-09-05 16:14:20,178:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.40s, LR: 0.00050, Train Loss: 0.8064, Train Acc: 0.5300,
                        Val Loss: 1.4760, Val Acc: 0.5000, Test Acc: 0.5002
2022-09-05 16:14:20,178:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:14:41,716:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5036 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_8_16h12m55s_on_Sep_05_2022/MODELS_
2022-09-05 16:14:41,717:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.54s, LR: 0.00050, Train Loss: 0.7346, Train Acc: 0.5650,
                        Val Loss: 0.8923, Val Acc: 0.5060, Test Acc: 0.5036
2022-09-05 16:14:41,717:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:15:04,848:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5159 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_8_16h12m55s_on_Sep_05_2022/MODELS_
2022-09-05 16:15:04,849:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 23.13s, LR: 0.00050, Train Loss: 0.7189, Train Acc: 0.5750,
                        Val Loss: 0.7197, Val Acc: 0.5460, Test Acc: 0.5159
2022-09-05 16:15:04,849:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:15:27,898:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 23.05s, LR: 0.00050, Train Loss: 0.7399, Train Acc: 0.5550,
                        Val Loss: 0.7569, Val Acc: 0.5160, Test Acc: 0.5092
2022-09-05 16:15:27,898:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:15:51,178:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5332 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_8_16h12m55s_on_Sep_05_2022/MODELS_
2022-09-05 16:15:51,178:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 23.28s, LR: 0.00050, Train Loss: 0.7247, Train Acc: 0.5900,
                        Val Loss: 0.7232, Val Acc: 0.5150, Test Acc: 0.5332
2022-09-05 16:15:51,178:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:16:13,220:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.04s, LR: 0.00050, Train Loss: 0.6882, Train Acc: 0.5800,
                        Val Loss: 0.7073, Val Acc: 0.5690, Test Acc: 0.5226
2022-09-05 16:16:13,221:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:16:34,900:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.68s, LR: 0.00050, Train Loss: 0.7117, Train Acc: 0.5800,
                        Val Loss: 0.7361, Val Acc: 0.5460, Test Acc: 0.5198
2022-09-05 16:16:34,900:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:16:58,269:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:17:02,728:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:17:02,728:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:17:02,728:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:17:02,728:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:17:02,728:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:17:02,728:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:17:02,733:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:17:02,734:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523382
2022-09-05 16:17:02,734:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:17:02,734:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:17:02,734:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:17:02,734:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:17:02,739:main_CYCLES_graph_classification.py:54 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-05 16:17:22,664:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:17:27,268:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:17:27,269:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:17:27,269:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:17:27,269:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:17:27,269:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:17:27,269:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:17:27,274:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:17:27,275:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524022
2022-09-05 16:17:27,275:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:17:27,275:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:17:27,275:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:17:27,276:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:17:27,281:main_CYCLES_graph_classification.py:54 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-05 16:17:44,069:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 16:17:44,070:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 16:17:44,070:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 16:17:44,070:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:17:44,071:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:18:06,787:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:18:06,788:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.72s, LR: 0.00050, Train Loss: 0.8242, Train Acc: 0.4950,
                        Val Loss: 1.4054, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 16:18:06,789:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:18:29,857:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 23.07s, LR: 0.00050, Train Loss: 0.7824, Train Acc: 0.4800,
                        Val Loss: 1.0122, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 16:18:29,858:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:18:52,058:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5002 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:18:52,058:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.20s, LR: 0.00050, Train Loss: 0.7500, Train Acc: 0.5300,
                        Val Loss: 0.8344, Val Acc: 0.5000, Test Acc: 0.5002
2022-09-05 16:18:52,059:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:19:14,015:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5013 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:19:14,016:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.96s, LR: 0.00050, Train Loss: 0.7332, Train Acc: 0.5400,
                        Val Loss: 0.7671, Val Acc: 0.5020, Test Acc: 0.5013
2022-09-05 16:19:14,016:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:19:35,259:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5061 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:19:35,259:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.24s, LR: 0.00050, Train Loss: 0.6747, Train Acc: 0.5950,
                        Val Loss: 0.7704, Val Acc: 0.5160, Test Acc: 0.5061
2022-09-05 16:19:35,259:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:19:56,659:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5404 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:19:56,659:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.40s, LR: 0.00050, Train Loss: 0.6620, Train Acc: 0.6400,
                        Val Loss: 0.6925, Val Acc: 0.5420, Test Acc: 0.5404
2022-09-05 16:19:56,659:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:20:18,659:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5598 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:20:18,659:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 22.00s, LR: 0.00050, Train Loss: 0.7136, Train Acc: 0.5900,
                        Val Loss: 0.6915, Val Acc: 0.5590, Test Acc: 0.5598
2022-09-05 16:20:18,659:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:21:18,621:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5658 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:21:18,622:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 59.96s, LR: 0.00050, Train Loss: 0.7075, Train Acc: 0.5950,
                        Val Loss: 0.6906, Val Acc: 0.5620, Test Acc: 0.5658
2022-09-05 16:21:18,622:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:24:33,852:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 195.23s, LR: 0.00050, Train Loss: 0.6977, Train Acc: 0.5550,
                        Val Loss: 0.7150, Val Acc: 0.5670, Test Acc: 0.5642
2022-09-05 16:24:33,852:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:34:31,346:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 597.49s, LR: 0.00050, Train Loss: 0.6555, Train Acc: 0.6250,
                        Val Loss: 0.8469, Val Acc: 0.5170, Test Acc: 0.5081
2022-09-05 16:34:31,346:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 16:34:53,147:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.80s, LR: 0.00050, Train Loss: 0.6381, Train Acc: 0.6300,
                        Val Loss: 0.7065, Val Acc: 0.5770, Test Acc: 0.5603
2022-09-05 16:34:53,148:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 16:35:14,082:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5739 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_16h17m27s_on_Sep_05_2022/MODELS_
2022-09-05 16:35:14,083:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 20.94s, LR: 0.00050, Train Loss: 0.6595, Train Acc: 0.5850,
                        Val Loss: 0.6739, Val Acc: 0.6000, Test Acc: 0.5739
2022-09-05 16:35:14,083:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 16:35:35,229:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.15s, LR: 0.00050, Train Loss: 0.6594, Train Acc: 0.6100,
                        Val Loss: 0.6942, Val Acc: 0.5560, Test Acc: 0.5658
2022-09-05 16:35:35,230:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 16:35:56,534:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.30s, LR: 0.00050, Train Loss: 0.6115, Train Acc: 0.6600,
                        Val Loss: 0.7281, Val Acc: 0.5650, Test Acc: 0.5490
2022-09-05 16:35:56,535:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 16:36:23,200:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:36:27,506:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:36:27,506:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:36:27,506:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:36:27,506:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:36:27,506:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:36:27,506:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:36:27,511:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:36:27,512:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527862
2022-09-05 16:36:27,512:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:36:27,512:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:36:27,512:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:36:27,512:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:36:27,517:main_CYCLES_graph_classification.py:54 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-05 16:36:44,049:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 16:36:44,050:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 16:36:44,050:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 16:36:44,050:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:36:44,052:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:40:49,018:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:40:53,485:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:40:53,485:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:40:53,486:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:40:53,486:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:40:53,486:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:40:53,486:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:40:53,491:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:40:53,492:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527862
2022-09-05 16:40:53,492:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:40:53,492:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:40:53,492:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:40:53,492:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:40:53,497:main_CYCLES_graph_classification.py:54 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-05 16:41:10,063:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 16:41:10,063:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 16:41:10,063:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 16:41:10,063:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:41:10,065:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:41:26,330:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:41:30,631:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:41:30,632:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:41:30,632:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:41:30,632:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:41:30,632:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:41:30,632:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:41:30,637:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:41:30,638:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525302
2022-09-05 16:41:30,638:pe_layer.py:65 -             __init__(): pos_enc
2022-09-05 16:41:30,638:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:41:30,638:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:41:30,638:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:41:30,643:main_CYCLES_graph_classification.py:54 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-05 16:41:46,778:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 16:41:46,778:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 16:41:46,778:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 16:41:46,778:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:41:46,780:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:42:08,746:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_16h41m30s_on_Sep_05_2022/MODELS_
2022-09-05 16:42:08,747:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.97s, LR: 0.00050, Train Loss: 0.7828, Train Acc: 0.5350,
                        Val Loss: 0.9731, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 16:42:08,747:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:42:29,575:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5083 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_16h41m30s_on_Sep_05_2022/MODELS_
2022-09-05 16:42:29,576:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 20.83s, LR: 0.00050, Train Loss: 0.7676, Train Acc: 0.4650,
                        Val Loss: 0.7278, Val Acc: 0.5060, Test Acc: 0.5083
2022-09-05 16:42:29,576:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:42:50,486:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 20.91s, LR: 0.00050, Train Loss: 0.6729, Train Acc: 0.6150,
                        Val Loss: 1.2759, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 16:42:50,487:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:43:09,976:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:43:14,268:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:43:14,268:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:43:14,268:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:43:14,269:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:43:14,269:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:43:14,269:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:43:14,274:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:43:14,275:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526359
2022-09-05 16:43:14,275:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:43:14,276:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:43:14,276:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:43:14,276:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:43:14,282:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 16:43:55,512:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:41.23674511909485
2022-09-05 16:43:55,527:main_CYCLES_graph_classification.py:114 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 16:43:55,527:main_CYCLES_graph_classification.py:115 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 16:43:55,527:main_CYCLES_graph_classification.py:116 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 16:43:55,527:main_CYCLES_graph_classification.py:117 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:43:55,529:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:44:17,344:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_16h43m14s_on_Sep_05_2022/MODELS_
2022-09-05 16:44:17,345:main_CYCLES_graph_classification.py:180 -   train_val_pipeline(): 	Time: 21.82s, LR: 0.00050, Train Loss: 0.7685, Train Acc: 0.5750,
                        Val Loss: 32.3651, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 16:44:17,345:main_CYCLES_graph_classification.py:142 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:44:51,259:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:44:55,565:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 128, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 16:44:55,565:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 16:44:55,565:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:44:55,567:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:44:55,567:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:44:55,567:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:44:55,572:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:44:55,572:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 549495
2022-09-05 16:44:55,573:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:44:55,574:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:44:55,574:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:44:55,574:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:44:55,579:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-05 16:50:40,271:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:50:46,198:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 8, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:50:46,198:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:50:46,198:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:50:46,199:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:50:46,199:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:50:46,199:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:50:46,208:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:50:46,208:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-05 16:50:46,209:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:50:46,209:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:50:46,209:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:50:46,209:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:50:46,781:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 16:51:04,984:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:18.76889395713806
2022-09-05 16:51:04,986:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:51:04,986:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:51:04,986:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:51:04,986:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:51:04,988:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:51:12,443:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h50m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:51:12,443:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.6717, Train Acc: 54.9972,
                        Val Loss: 8.5367, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:51:12,443:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:51:19,918:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.47s, LR: 0.00050, Train Loss: 0.5474, Train Acc: 82.1167,
                        Val Loss: 3.7751, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:51:19,918:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:51:27,271:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.2316 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h50m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:51:27,271:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.35s, LR: 0.00050, Train Loss: 0.4876, Train Acc: 86.3661,
                        Val Loss: 1.6354, Val Acc: 50.3977, Test Acc: 50.2316
2022-09-05 16:51:27,271:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:51:34,691:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 57.6426 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h50m46s_on_Sep_05_2022/MODELS_
2022-09-05 16:51:34,691:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.42s, LR: 0.00050, Train Loss: 0.4490, Train Acc: 86.2546,
                        Val Loss: 0.6805, Val Acc: 57.8187, Test Acc: 57.6426
2022-09-05 16:51:34,691:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:51:41,999:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.31s, LR: 0.00050, Train Loss: 0.4186, Train Acc: 86.3480,
                        Val Loss: 1.5348, Val Acc: 50.0000, Test Acc: 50.0061
2022-09-05 16:51:41,999:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:51:49,312:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.31s, LR: 0.00050, Train Loss: 0.3935, Train Acc: 86.5512,
                        Val Loss: 2.2296, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:51:49,312:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:51:56,698:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.39s, LR: 0.00050, Train Loss: 0.3720, Train Acc: 86.4951,
                        Val Loss: 2.5983, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:51:56,698:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:52:04,071:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.3531, Train Acc: 86.6966,
                        Val Loss: 2.4855, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:52:04,071:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:52:11,444:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.3362, Train Acc: 86.9065,
                        Val Loss: 1.8274, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:52:11,444:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:52:18,965:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.52s, LR: 0.00050, Train Loss: 0.3234, Train Acc: 87.1071,
                        Val Loss: 1.3982, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:52:18,965:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 16:52:21,429:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 16:52:21,429:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 16:52:35,562:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:52:41,062:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 8, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:52:41,062:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:52:41,062:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:52:41,063:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:52:41,063:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:52:41,063:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:52:41,068:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:52:41,069:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-05 16:52:41,069:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:52:41,070:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:52:41,070:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:52:41,070:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:52:41,551:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 16:53:04,301:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:23.223350048065186
2022-09-05 16:53:04,304:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:53:04,304:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:53:04,304:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:53:04,304:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:53:04,305:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:53:11,915:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h52m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:53:11,915:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.61s, LR: 0.00050, Train Loss: 0.6652, Train Acc: 73.4799,
                        Val Loss: 0.8942, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:53:11,915:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:53:19,446:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.6100, Train Acc: 86.4808,
                        Val Loss: 2.2217, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:53:19,447:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:53:26,959:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.51s, LR: 0.00050, Train Loss: 0.5770, Train Acc: 86.3497,
                        Val Loss: 1.4881, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:53:26,959:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:53:34,720:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.76s, LR: 0.00050, Train Loss: 0.5454, Train Acc: 86.2964,
                        Val Loss: 0.7501, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-05 16:53:34,720:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:53:42,411:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 58.7019 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h52m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:53:42,411:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.5154, Train Acc: 86.5875,
                        Val Loss: 0.5930, Val Acc: 58.8621, Test Acc: 58.7019
2022-09-05 16:53:42,412:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:53:49,914:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 77.2666 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h52m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:53:49,914:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.50s, LR: 0.00050, Train Loss: 0.4870, Train Acc: 86.3829,
                        Val Loss: 0.5392, Val Acc: 76.3501, Test Acc: 77.2666
2022-09-05 16:53:49,914:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:53:57,554:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.3998 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h52m41s_on_Sep_05_2022/MODELS_
2022-09-05 16:53:57,554:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.4602, Train Acc: 86.4094,
                        Val Loss: 0.5303, Val Acc: 83.7157, Test Acc: 83.3998
2022-09-05 16:53:57,554:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:54:19,787:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 16:54:25,313:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'rw_pos_enc': False, 'pos_enc_dim': 8, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'in_dim': 3, 'n_classes': 2}
2022-09-05 16:54:25,313:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-05 16:54:25,313:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:54:25,314:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:54:25,314:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:54:25,314:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:54:25,319:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 16:54:25,320:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-05 16:54:25,320:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 16:54:25,321:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 16:54:25,321:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 16:54:25,321:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 16:54:25,890:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 16:54:48,226:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:22.899991035461426
2022-09-05 16:54:48,226:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-05 16:54:59,467:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 16:54:59,468:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 16:54:59,468:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 16:54:59,468:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 16:54:59,469:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 16:55:18,174:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 60.2932 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:55:18,174:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 18.71s, LR: 0.00050, Train Loss: 0.6665, Train Acc: 56.7170,
                        Val Loss: 0.6854, Val Acc: 56.0178, Test Acc: 60.2932
2022-09-05 16:55:18,174:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 16:55:36,031:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 61.6053 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:55:36,031:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.86s, LR: 0.00050, Train Loss: 0.5988, Train Acc: 70.7220,
                        Val Loss: 0.6550, Val Acc: 60.1035, Test Acc: 61.6053
2022-09-05 16:55:36,031:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 16:55:53,967:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.94s, LR: 0.00050, Train Loss: 0.5464, Train Acc: 80.0705,
                        Val Loss: 0.6630, Val Acc: 55.2271, Test Acc: 57.3207
2022-09-05 16:55:53,968:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 16:56:11,458:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 64.8405 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:56:11,458:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.49s, LR: 0.00050, Train Loss: 0.5113, Train Acc: 82.3020,
                        Val Loss: 0.6297, Val Acc: 63.2619, Test Acc: 64.8405
2022-09-05 16:56:11,458:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 16:56:28,879:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 73.9700 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:56:28,879:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.42s, LR: 0.00050, Train Loss: 0.4689, Train Acc: 83.8655,
                        Val Loss: 0.5791, Val Acc: 72.9098, Test Acc: 73.9700
2022-09-05 16:56:28,879:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 16:56:46,170:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 81.7691 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:56:46,171:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.29s, LR: 0.00050, Train Loss: 0.4349, Train Acc: 84.6034,
                        Val Loss: 0.5066, Val Acc: 81.6119, Test Acc: 81.7691
2022-09-05 16:56:46,171:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 16:57:03,501:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.33s, LR: 0.00050, Train Loss: 0.4063, Train Acc: 85.2589,
                        Val Loss: 0.4747, Val Acc: 81.4072, Test Acc: 81.6086
2022-09-05 16:57:03,502:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 16:57:20,975:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.5089 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:57:20,975:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.47s, LR: 0.00050, Train Loss: 0.3938, Train Acc: 84.8335,
                        Val Loss: 0.4086, Val Acc: 84.9418, Test Acc: 84.5089
2022-09-05 16:57:20,975:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 16:57:38,367:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.39s, LR: 0.00050, Train Loss: 0.3744, Train Acc: 84.7703,
                        Val Loss: 0.4402, Val Acc: 80.0909, Test Acc: 79.8423
2022-09-05 16:57:38,367:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 16:57:55,698:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.0889 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:57:55,698:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.33s, LR: 0.00050, Train Loss: 0.3663, Train Acc: 84.4800,
                        Val Loss: 0.3635, Val Acc: 85.0546, Test Acc: 85.0889
2022-09-05 16:57:55,698:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 16:58:12,936:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.2466 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 16:58:12,936:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.24s, LR: 0.00050, Train Loss: 0.3481, Train Acc: 85.4365,
                        Val Loss: 0.3467, Val Acc: 86.3393, Test Acc: 85.2466
2022-09-05 16:58:12,936:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 16:58:30,504:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.57s, LR: 0.00050, Train Loss: 0.3394, Train Acc: 85.1024,
                        Val Loss: 0.3973, Val Acc: 81.7315, Test Acc: 81.8589
2022-09-05 16:58:30,504:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 16:58:47,960:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.46s, LR: 0.00050, Train Loss: 0.3429, Train Acc: 85.0838,
                        Val Loss: 0.4318, Val Acc: 80.2785, Test Acc: 80.3187
2022-09-05 16:58:47,960:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 16:59:05,610:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.65s, LR: 0.00050, Train Loss: 0.3363, Train Acc: 85.4381,
                        Val Loss: 0.4021, Val Acc: 80.9608, Test Acc: 80.7353
2022-09-05 16:59:05,611:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 16:59:23,420:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.81s, LR: 0.00050, Train Loss: 0.3365, Train Acc: 85.0089,
                        Val Loss: 0.3612, Val Acc: 83.8401, Test Acc: 83.5605
2022-09-05 16:59:23,420:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 16:59:40,916:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.50s, LR: 0.00050, Train Loss: 0.3374, Train Acc: 84.9216,
                        Val Loss: 0.3822, Val Acc: 82.8503, Test Acc: 82.8254
2022-09-05 16:59:40,916:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 16:59:58,369:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.45s, LR: 0.00050, Train Loss: 0.3363, Train Acc: 84.9583,
                        Val Loss: 0.3531, Val Acc: 84.2361, Test Acc: 84.5495
2022-09-05 16:59:58,369:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 17:00:16,036:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.67s, LR: 0.00050, Train Loss: 0.3464, Train Acc: 84.2037,
                        Val Loss: 0.3497, Val Acc: 85.5303, Test Acc: 85.1324
2022-09-05 17:00:16,037:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 17:00:33,291:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.25s, LR: 0.00050, Train Loss: 0.3306, Train Acc: 85.5453,
                        Val Loss: 0.3580, Val Acc: 84.4734, Test Acc: 84.0811
2022-09-05 17:00:33,291:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 17:00:50,475:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4951 to out/SBMs_node_classification_b26-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_8_16h54m25s_on_Sep_05_2022/MODELS_
2022-09-05 17:00:50,475:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.18s, LR: 0.00050, Train Loss: 0.3243, Train Acc: 85.3271,
                        Val Loss: 0.3424, Val Acc: 84.9822, Test Acc: 85.4951
2022-09-05 17:00:50,475:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 17:01:08,130:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.65s, LR: 0.00050, Train Loss: 0.3480, Train Acc: 84.1215,
                        Val Loss: 0.3385, Val Acc: 85.8887, Test Acc: 85.3514
2022-09-05 17:01:08,130:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 17:01:25,784:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.65s, LR: 0.00050, Train Loss: 0.3843, Train Acc: 83.5273,
                        Val Loss: 0.3390, Val Acc: 86.0421, Test Acc: 85.1789
2022-09-05 17:01:25,784:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 17:01:43,215:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.43s, LR: 0.00050, Train Loss: 0.3561, Train Acc: 83.4590,
                        Val Loss: 0.3699, Val Acc: 84.3562, Test Acc: 84.2795
2022-09-05 17:01:43,215:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 17:02:00,941:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.73s, LR: 0.00050, Train Loss: 0.3324, Train Acc: 85.2306,
                        Val Loss: 0.3540, Val Acc: 85.4200, Test Acc: 84.9975
2022-09-05 17:02:00,941:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 17:02:18,743:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.80s, LR: 0.00050, Train Loss: 0.3249, Train Acc: 85.3505,
                        Val Loss: 0.3571, Val Acc: 84.5643, Test Acc: 84.7915
2022-09-05 17:02:18,743:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 17:02:36,345:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.60s, LR: 0.00050, Train Loss: 0.3296, Train Acc: 85.3417,
                        Val Loss: 0.3440, Val Acc: 85.3244, Test Acc: 85.2192
2022-09-05 17:02:36,345:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 17:02:54,053:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.71s, LR: 0.00050, Train Loss: 0.3234, Train Acc: 85.3793,
                        Val Loss: 0.3460, Val Acc: 84.5810, Test Acc: 84.8548
2022-09-05 17:02:54,053:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 17:03:11,758:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.71s, LR: 0.00050, Train Loss: 0.3284, Train Acc: 85.1325,
                        Val Loss: 0.3407, Val Acc: 84.9721, Test Acc: 84.9672
2022-09-05 17:03:11,759:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 17:03:29,378:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 17.62s, LR: 0.00050, Train Loss: 0.3233, Train Acc: 85.4403,
                        Val Loss: 0.3391, Val Acc: 84.9929, Test Acc: 84.9702
2022-09-05 17:03:29,379:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 17:04:02,882:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:04:07,039:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 7, 'n_classes': 6}
2022-09-05 17:04:07,040:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:04:07,040:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:04:07,041:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:04:07,041:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:04:07,041:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:04:07,046:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:04:07,046:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523939
2022-09-05 17:04:07,047:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:04:07,047:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:04:07,047:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:04:07,047:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:04:07,285:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 17:04:26,241:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:19.188243865966797
2022-09-05 17:04:26,241:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-05 17:04:37,914:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 17:04:37,915:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 17:04:37,915:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 17:04:37,915:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 17:04:37,916:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:04:57,689:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_8_17h04m07s_on_Sep_05_2022/MODELS_
2022-09-05 17:04:57,690:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.77s, LR: 0.00050, Train Loss: 1.8030, Train Acc: 16.6796,
                        Val Loss: 9.7253, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:04:57,690:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:05:17,794:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.10s, LR: 0.00050, Train Loss: 1.7994, Train Acc: 16.9374,
                        Val Loss: 4.7057, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:05:17,795:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:05:37,381:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 17.2332 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_8_17h04m07s_on_Sep_05_2022/MODELS_
2022-09-05 17:05:37,382:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.59s, LR: 0.00050, Train Loss: 1.7910, Train Acc: 17.3763,
                        Val Loss: 2.6673, Val Acc: 16.7522, Test Acc: 17.2332
2022-09-05 17:05:37,382:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:05:56,856:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.47s, LR: 0.00050, Train Loss: 1.7932, Train Acc: 17.7891,
                        Val Loss: 2.7912, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:05:56,856:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:06:16,461:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.60s, LR: 0.00050, Train Loss: 1.7894, Train Acc: 17.8316,
                        Val Loss: 2.6519, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:06:16,461:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:06:36,857:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.40s, LR: 0.00050, Train Loss: 1.7912, Train Acc: 18.1182,
                        Val Loss: 2.8355, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:06:36,857:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 17:06:56,903:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.05s, LR: 0.00050, Train Loss: 1.7870, Train Acc: 19.0073,
                        Val Loss: 2.1300, Val Acc: 16.4201, Test Acc: 16.6369
2022-09-05 17:06:56,903:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 17:07:16,444:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.54s, LR: 0.00050, Train Loss: 1.7857, Train Acc: 18.4024,
                        Val Loss: 2.1174, Val Acc: 16.3467, Test Acc: 16.4354
2022-09-05 17:07:16,444:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 17:07:36,024:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.58s, LR: 0.00050, Train Loss: 1.7810, Train Acc: 20.1386,
                        Val Loss: 2.2967, Val Acc: 16.2988, Test Acc: 17.0298
2022-09-05 17:07:36,024:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 17:07:55,338:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.31s, LR: 0.00050, Train Loss: 1.7844, Train Acc: 19.4263,
                        Val Loss: 1.9364, Val Acc: 15.4495, Test Acc: 16.5298
2022-09-05 17:07:55,338:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 17:08:15,633:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.30s, LR: 0.00050, Train Loss: 1.7859, Train Acc: 19.1340,
                        Val Loss: 1.8061, Val Acc: 16.9051, Test Acc: 16.7992
2022-09-05 17:08:15,633:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 17:08:35,228:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.60s, LR: 0.00050, Train Loss: 1.7836, Train Acc: 19.7440,
                        Val Loss: 1.8048, Val Acc: 17.1004, Test Acc: 16.3554
2022-09-05 17:08:35,229:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 17:08:55,136:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 17.3520 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_8_17h04m07s_on_Sep_05_2022/MODELS_
2022-09-05 17:08:55,136:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.91s, LR: 0.00050, Train Loss: 1.7880, Train Acc: 18.6671,
                        Val Loss: 1.9320, Val Acc: 16.6270, Test Acc: 17.3520
2022-09-05 17:08:55,136:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 17:09:15,247:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.11s, LR: 0.00050, Train Loss: 1.7845, Train Acc: 19.3723,
                        Val Loss: 2.2551, Val Acc: 16.3928, Test Acc: 16.9736
2022-09-05 17:09:15,248:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 17:09:35,406:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.16s, LR: 0.00050, Train Loss: 1.7775, Train Acc: 21.0514,
                        Val Loss: 5.3489, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:09:35,406:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 17:09:55,418:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.01s, LR: 0.00050, Train Loss: 1.7853, Train Acc: 19.3246,
                        Val Loss: 11.6561, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:09:55,419:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 17:10:15,285:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.87s, LR: 0.00050, Train Loss: 1.7876, Train Acc: 18.8758,
                        Val Loss: 12.2216, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:10:15,285:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 17:10:35,139:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 19.85s, LR: 0.00050, Train Loss: 1.7795, Train Acc: 19.1120,
                        Val Loss: 9.1784, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:10:35,139:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 17:10:59,205:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 24.07s, LR: 0.00050, Train Loss: 1.7815, Train Acc: 18.7400,
                        Val Loss: 5.5489, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:10:59,205:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 17:11:01,127:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 17:11:01,127:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 17:11:10,067:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:11:14,240:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 7, 'n_classes': 6}
2022-09-05 17:11:14,240:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:11:14,240:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:11:14,241:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:11:14,241:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:11:14,241:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:11:14,246:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:11:14,247:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523939
2022-09-05 17:11:14,247:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:11:14,247:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:11:14,247:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:11:14,247:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:11:14,507:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 17:11:40,177:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:25.925192832946777
2022-09-05 17:11:40,177:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-05 17:11:52,459:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-05 17:11:52,459:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-05 17:11:52,459:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-05 17:11:52,459:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 6
2022-09-05 17:11:52,460:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:12:13,841:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6458 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_8_17h11m14s_on_Sep_05_2022/MODELS_
2022-09-05 17:12:13,841:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 21.38s, LR: 0.00050, Train Loss: 1.7874, Train Acc: 17.7740,
                        Val Loss: 2.5292, Val Acc: 16.5506, Test Acc: 16.6458
2022-09-05 17:12:13,841:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:12:34,237:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_1_8_17h11m14s_on_Sep_05_2022/MODELS_
2022-09-05 17:12:34,237:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 20.40s, LR: 0.00050, Train Loss: 1.7552, Train Acc: 21.5312,
                        Val Loss: 3.0317, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-05 17:12:34,237:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:13:07,986:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:13:12,498:main_CYCLES_graph_classification.py:330 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:13:12,498:main_CYCLES_graph_classification.py:331 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:13:12,499:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:13:12,500:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:13:12,500:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:13:12,500:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:13:12,505:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:13:12,506:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:13:12,506:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:13:12,506:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:13:12,506:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:13:12,506:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:15:32,697:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:18:05,086:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:18:09,690:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:18:09,690:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:18:09,690:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:18:09,691:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:18:09,691:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:18:09,691:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:18:09,699:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:18:09,700:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:18:09,701:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:18:09,702:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:18:09,702:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:18:09,702:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:18:09,709:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:18:57,468:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:47.76737904548645
2022-09-05 17:18:57,468:main_CYCLES_graph_classification.py:95 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-05 17:21:23,763:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:21:23,763:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:21:23,764:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:21:23,764:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:21:23,767:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:22:54,689:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h18m09s_on_Sep_05_2022/MODELS_
2022-09-05 17:22:54,691:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 90.92s, LR: 0.00050, Train Loss: 0.8475, Train Acc: 0.5350,
                        Val Loss: 31.9007, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:22:54,691:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:24:31,976:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:24:36,479:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:24:36,480:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:24:36,480:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:24:36,481:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:24:36,481:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:24:36,481:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:24:36,485:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:24:36,486:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:24:36,486:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:24:36,487:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:24:36,487:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:24:36,487:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:24:36,492:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:25:24,039:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:47.55301380157471
2022-09-05 17:25:24,055:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:25:24,055:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:25:24,055:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:25:24,055:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:25:24,058:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:25:46,622:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h24m36s_on_Sep_05_2022/MODELS_
2022-09-05 17:25:46,623:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.57s, LR: 0.00050, Train Loss: 0.8426, Train Acc: 0.5050,
                        Val Loss: 22.0395, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:25:46,623:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:26:09,189:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.57s, LR: 0.00050, Train Loss: 0.6442, Train Acc: 0.6150,
                        Val Loss: 14.6033, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:26:09,190:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:26:32,779:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.59s, LR: 0.00050, Train Loss: 0.6109, Train Acc: 0.6950,
                        Val Loss: 10.5546, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:26:32,779:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:26:49,793:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:26:54,291:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:26:54,291:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:26:54,291:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:26:54,292:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:26:54,292:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:26:54,292:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:26:54,297:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:26:54,298:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:26:54,298:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:26:54,299:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:26:54,299:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:26:54,299:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:26:54,304:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:27:58,913:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:64.61483097076416
2022-09-05 17:27:58,928:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:27:58,928:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:27:58,928:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:27:58,928:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:27:58,930:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:28:22,891:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h26m54s_on_Sep_05_2022/MODELS_
2022-09-05 17:28:22,892:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.96s, LR: 0.00050, Train Loss: 0.8039, Train Acc: 0.5100,
                        Val Loss: 9.9065, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:28:22,892:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:28:45,371:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.48s, LR: 0.00050, Train Loss: 0.7484, Train Acc: 0.5900,
                        Val Loss: 3.1627, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:28:45,372:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:29:08,749:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.38s, LR: 0.00050, Train Loss: 0.6221, Train Acc: 0.6900,
                        Val Loss: 1.0738, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:29:08,750:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:29:30,477:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.73s, LR: 0.00050, Train Loss: 0.5667, Train Acc: 0.7000,
                        Val Loss: 1.3219, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:29:30,478:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:29:52,249:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5001 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h26m54s_on_Sep_05_2022/MODELS_
2022-09-05 17:29:52,249:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.77s, LR: 0.00050, Train Loss: 0.5879, Train Acc: 0.7500,
                        Val Loss: 1.6169, Val Acc: 0.5000, Test Acc: 0.5001
2022-09-05 17:29:52,249:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:30:13,958:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5492 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h26m54s_on_Sep_05_2022/MODELS_
2022-09-05 17:30:13,958:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.71s, LR: 0.00050, Train Loss: 0.5453, Train Acc: 0.7300,
                        Val Loss: 0.8809, Val Acc: 0.5620, Test Acc: 0.5492
2022-09-05 17:30:13,958:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 17:30:36,138:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.18s, LR: 0.00050, Train Loss: 0.5511, Train Acc: 0.6850,
                        Val Loss: 1.0835, Val Acc: 0.5220, Test Acc: 0.5203
2022-09-05 17:30:36,138:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 17:30:59,233:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.09s, LR: 0.00050, Train Loss: 0.5192, Train Acc: 0.7550,
                        Val Loss: 1.3865, Val Acc: 0.5100, Test Acc: 0.5092
2022-09-05 17:30:59,233:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 17:31:28,640:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:31:33,452:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:31:33,452:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:31:33,452:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:31:33,453:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:31:33,453:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:31:33,453:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:31:33,458:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:31:33,458:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:31:33,459:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:31:33,459:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:31:33,459:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:31:33,459:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:31:33,464:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:32:49,586:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:76.12712502479553
2022-09-05 17:32:49,604:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:32:49,604:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:32:49,604:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:32:49,604:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:32:49,606:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:33:12,576:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.4980 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h31m33s_on_Sep_05_2022/MODELS_
2022-09-05 17:33:12,578:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.97s, LR: 0.00050, Train Loss: 0.7922, Train Acc: 0.5750,
                        Val Loss: 0.7037, Val Acc: 0.4990, Test Acc: 0.4980
2022-09-05 17:33:12,578:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:33:35,429:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h31m33s_on_Sep_05_2022/MODELS_
2022-09-05 17:33:35,430:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.85s, LR: 0.00050, Train Loss: 0.6246, Train Acc: 0.6700,
                        Val Loss: 6.5094, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:33:35,430:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:33:57,009:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5060 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h31m33s_on_Sep_05_2022/MODELS_
2022-09-05 17:33:57,010:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.58s, LR: 0.00050, Train Loss: 0.6246, Train Acc: 0.7150,
                        Val Loss: 1.1230, Val Acc: 0.5090, Test Acc: 0.5060
2022-09-05 17:33:57,010:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:34:19,056:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5693 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h31m33s_on_Sep_05_2022/MODELS_
2022-09-05 17:34:19,057:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.05s, LR: 0.00050, Train Loss: 0.5420, Train Acc: 0.7600,
                        Val Loss: 0.7272, Val Acc: 0.5710, Test Acc: 0.5693
2022-09-05 17:34:19,057:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:34:42,521:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6312 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h31m33s_on_Sep_05_2022/MODELS_
2022-09-05 17:34:42,521:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.46s, LR: 0.00050, Train Loss: 0.5667, Train Acc: 0.7400,
                        Val Loss: 0.6477, Val Acc: 0.6200, Test Acc: 0.6312
2022-09-05 17:34:42,521:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:35:05,338:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.82s, LR: 0.00050, Train Loss: 0.5324, Train Acc: 0.7300,
                        Val Loss: 0.7653, Val Acc: 0.5760, Test Acc: 0.5855
2022-09-05 17:35:05,339:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 17:35:27,873:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00050, Train Loss: 0.5062, Train Acc: 0.7600,
                        Val Loss: 4.5399, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:35:27,874:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 17:35:50,529:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.66s, LR: 0.00050, Train Loss: 0.5105, Train Acc: 0.7450,
                        Val Loss: 0.8661, Val Acc: 0.5720, Test Acc: 0.5607
2022-09-05 17:35:50,530:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 17:36:16,726:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.20s, LR: 0.00050, Train Loss: 0.4943, Train Acc: 0.7650,
                        Val Loss: 4.0076, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:36:16,726:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 17:36:40,609:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.88s, LR: 0.00050, Train Loss: 0.4752, Train Acc: 0.7700,
                        Val Loss: 5.7594, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:36:40,609:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 17:36:54,592:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:36:59,325:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:36:59,325:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:36:59,325:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:36:59,326:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:36:59,326:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:36:59,326:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:36:59,331:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:36:59,332:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:36:59,333:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:36:59,333:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:36:59,333:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:36:59,333:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:36:59,338:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:38:13,796:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:74.46389698982239
2022-09-05 17:38:13,814:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:38:13,814:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:38:13,814:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:38:13,814:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:38:13,817:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:38:36,407:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h36m59s_on_Sep_05_2022/MODELS_
2022-09-05 17:38:36,408:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.59s, LR: 0.00050, Train Loss: 0.7987, Train Acc: 0.5500,
                        Val Loss: 55.5652, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:38:36,408:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:38:53,442:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:38:58,016:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:38:58,016:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:38:58,016:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:38:58,017:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:38:58,017:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:38:58,017:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:38:58,022:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:38:58,023:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:38:58,023:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:38:58,024:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:38:58,024:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:38:58,024:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:38:58,030:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:39:36,766:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:38.74237298965454
2022-09-05 17:39:36,783:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:39:36,783:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:39:36,783:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:39:36,783:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:39:36,785:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:40:00,540:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.4972 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h38m58s_on_Sep_05_2022/MODELS_
2022-09-05 17:40:00,541:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.76s, LR: 0.00050, Train Loss: 0.7077, Train Acc: 0.5950,
                        Val Loss: 1.7871, Val Acc: 0.5000, Test Acc: 0.4972
2022-09-05 17:40:00,541:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:40:22,127:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h38m58s_on_Sep_05_2022/MODELS_
2022-09-05 17:40:22,127:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.59s, LR: 0.00050, Train Loss: 0.7021, Train Acc: 0.6250,
                        Val Loss: 7.2613, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:40:22,127:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:40:44,480:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5257 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h38m58s_on_Sep_05_2022/MODELS_
2022-09-05 17:40:44,480:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.35s, LR: 0.00050, Train Loss: 0.6349, Train Acc: 0.6750,
                        Val Loss: 1.1084, Val Acc: 0.5210, Test Acc: 0.5257
2022-09-05 17:40:44,480:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:41:09,058:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.58s, LR: 0.00050, Train Loss: 0.5562, Train Acc: 0.7250,
                        Val Loss: 1.5857, Val Acc: 0.5010, Test Acc: 0.5008
2022-09-05 17:41:09,059:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:41:32,701:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.64s, LR: 0.00050, Train Loss: 0.5347, Train Acc: 0.7550,
                        Val Loss: 1.3790, Val Acc: 0.5020, Test Acc: 0.5001
2022-09-05 17:41:32,701:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:41:53,977:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:41:58,839:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:41:58,839:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:41:58,839:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:41:58,840:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:41:58,840:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:41:58,840:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:41:58,846:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:41:58,846:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:41:58,847:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:41:58,847:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:41:58,847:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:41:58,847:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:41:58,853:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:42:36,291:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:37.444077253341675
2022-09-05 17:42:36,310:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:42:36,310:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:42:36,310:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:42:36,310:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:42:36,313:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:43:01,991:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h41m58s_on_Sep_05_2022/MODELS_
2022-09-05 17:43:01,993:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.68s, LR: 0.00050, Train Loss: 0.7374, Train Acc: 0.6050,
                        Val Loss: 11.9584, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:43:01,993:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:43:27,479:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.49s, LR: 0.00050, Train Loss: 0.6166, Train Acc: 0.6500,
                        Val Loss: 1.8684, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:43:27,480:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:43:50,486:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.01s, LR: 0.00050, Train Loss: 0.6019, Train Acc: 0.7200,
                        Val Loss: 2.4600, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:43:50,486:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:44:13,111:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6403 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h41m58s_on_Sep_05_2022/MODELS_
2022-09-05 17:44:13,112:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.63s, LR: 0.00050, Train Loss: 0.5368, Train Acc: 0.7350,
                        Val Loss: 0.6511, Val Acc: 0.6480, Test Acc: 0.6403
2022-09-05 17:44:13,112:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:44:35,046:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.93s, LR: 0.00050, Train Loss: 0.5811, Train Acc: 0.7150,
                        Val Loss: 0.7698, Val Acc: 0.5250, Test Acc: 0.5283
2022-09-05 17:44:35,046:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:44:57,010:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.96s, LR: 0.00050, Train Loss: 0.5295, Train Acc: 0.7300,
                        Val Loss: 1.8170, Val Acc: 0.5050, Test Acc: 0.5050
2022-09-05 17:44:57,010:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 17:45:19,594:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.58s, LR: 0.00050, Train Loss: 0.5177, Train Acc: 0.7150,
                        Val Loss: 1.2854, Val Acc: 0.5610, Test Acc: 0.5550
2022-09-05 17:45:19,595:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 17:45:34,402:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:45:39,165:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:45:39,165:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:45:39,165:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:45:39,166:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:45:39,166:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:45:39,166:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:45:39,175:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:45:39,176:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:45:39,176:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:45:39,177:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:45:39,177:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:45:39,177:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:45:39,184:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:46:13,786:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:34.60968017578125
2022-09-05 17:46:13,802:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:46:13,803:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:46:13,803:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:46:13,803:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:46:13,805:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:46:35,406:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h45m39s_on_Sep_05_2022/MODELS_
2022-09-05 17:46:35,408:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.60s, LR: 0.00050, Train Loss: 0.7313, Train Acc: 0.6100,
                        Val Loss: 64.6013, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:46:35,408:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:46:56,773:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.36s, LR: 0.00050, Train Loss: 0.6156, Train Acc: 0.6850,
                        Val Loss: 15.7450, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:46:56,773:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:47:17,705:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.93s, LR: 0.00050, Train Loss: 0.6022, Train Acc: 0.7050,
                        Val Loss: 10.3628, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:47:17,706:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:47:39,100:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5231 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h45m39s_on_Sep_05_2022/MODELS_
2022-09-05 17:47:39,100:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.39s, LR: 0.00050, Train Loss: 0.5248, Train Acc: 0.7700,
                        Val Loss: 2.2889, Val Acc: 0.5290, Test Acc: 0.5231
2022-09-05 17:47:39,100:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:48:00,195:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.09s, LR: 0.00050, Train Loss: 0.5453, Train Acc: 0.7350,
                        Val Loss: 4.1522, Val Acc: 0.5000, Test Acc: 0.5001
2022-09-05 17:48:00,196:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:48:21,042:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.85s, LR: 0.00050, Train Loss: 0.5255, Train Acc: 0.7400,
                        Val Loss: 4.9245, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:48:21,042:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 17:48:42,192:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5720 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h45m39s_on_Sep_05_2022/MODELS_
2022-09-05 17:48:42,192:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.15s, LR: 0.00050, Train Loss: 0.5021, Train Acc: 0.7600,
                        Val Loss: 0.7882, Val Acc: 0.5680, Test Acc: 0.5720
2022-09-05 17:48:42,192:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 17:49:04,807:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.61s, LR: 0.00050, Train Loss: 0.5046, Train Acc: 0.7650,
                        Val Loss: 4.4341, Val Acc: 0.5010, Test Acc: 0.5005
2022-09-05 17:49:04,808:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 17:49:25,442:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6097 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h45m39s_on_Sep_05_2022/MODELS_
2022-09-05 17:49:25,442:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.63s, LR: 0.00050, Train Loss: 0.4934, Train Acc: 0.7700,
                        Val Loss: 0.8225, Val Acc: 0.6330, Test Acc: 0.6097
2022-09-05 17:49:25,442:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 17:49:46,425:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00050, Train Loss: 0.4799, Train Acc: 0.7500,
                        Val Loss: 0.7572, Val Acc: 0.6050, Test Acc: 0.5869
2022-09-05 17:49:46,425:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 17:50:07,124:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6385 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h45m39s_on_Sep_05_2022/MODELS_
2022-09-05 17:50:07,124:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.70s, LR: 0.00050, Train Loss: 0.4587, Train Acc: 0.7750,
                        Val Loss: 0.6770, Val Acc: 0.6380, Test Acc: 0.6385
2022-09-05 17:50:07,124:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 17:50:27,713:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.59s, LR: 0.00050, Train Loss: 0.4274, Train Acc: 0.7650,
                        Val Loss: 1.8687, Val Acc: 0.5000, Test Acc: 0.5001
2022-09-05 17:50:27,713:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 17:50:48,343:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.63s, LR: 0.00050, Train Loss: 0.4076, Train Acc: 0.7850,
                        Val Loss: 2.2013, Val Acc: 0.5130, Test Acc: 0.5112
2022-09-05 17:50:48,344:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 17:51:08,876:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.53s, LR: 0.00050, Train Loss: 0.3920, Train Acc: 0.8300,
                        Val Loss: 1.2250, Val Acc: 0.5680, Test Acc: 0.5755
2022-09-05 17:51:08,876:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 17:51:29,478:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.60s, LR: 0.00050, Train Loss: 0.3827, Train Acc: 0.8150,
                        Val Loss: 1.0839, Val Acc: 0.6390, Test Acc: 0.6290
2022-09-05 17:51:29,479:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 17:51:50,405:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6939 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h45m39s_on_Sep_05_2022/MODELS_
2022-09-05 17:51:50,406:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.93s, LR: 0.00050, Train Loss: 0.3674, Train Acc: 0.8300,
                        Val Loss: 0.7287, Val Acc: 0.6890, Test Acc: 0.6939
2022-09-05 17:51:50,406:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 17:52:12,068:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7035 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h45m39s_on_Sep_05_2022/MODELS_
2022-09-05 17:52:12,069:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.66s, LR: 0.00050, Train Loss: 0.3835, Train Acc: 0.8450,
                        Val Loss: 0.8358, Val Acc: 0.7150, Test Acc: 0.7035
2022-09-05 17:52:12,069:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 17:52:34,712:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.64s, LR: 0.00050, Train Loss: 0.3755, Train Acc: 0.8550,
                        Val Loss: 6.0833, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:52:34,712:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 17:52:56,847:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00050, Train Loss: 0.3666, Train Acc: 0.8600,
                        Val Loss: 1.5866, Val Acc: 0.5160, Test Acc: 0.5126
2022-09-05 17:52:56,847:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 17:53:19,272:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.42s, LR: 0.00050, Train Loss: 0.3360, Train Acc: 0.8650,
                        Val Loss: 1.2665, Val Acc: 0.6010, Test Acc: 0.6155
2022-09-05 17:53:19,272:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 17:53:41,696:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.42s, LR: 0.00050, Train Loss: 0.3442, Train Acc: 0.8650,
                        Val Loss: 0.9152, Val Acc: 0.5950, Test Acc: 0.5913
2022-09-05 17:53:41,697:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 17:54:04,330:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.63s, LR: 0.00050, Train Loss: 0.3400, Train Acc: 0.8200,
                        Val Loss: 1.3292, Val Acc: 0.5430, Test Acc: 0.5491
2022-09-05 17:54:04,331:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 17:54:09,177:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:54:13,602:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:54:13,602:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:54:13,603:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:54:13,603:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:54:13,604:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:54:13,604:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:54:13,608:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:54:13,609:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 17:54:13,610:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:54:13,610:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:54:13,610:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:54:13,610:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:54:13,615:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 17:54:48,251:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:34.64148569107056
2022-09-05 17:54:48,269:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:54:48,269:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:54:48,269:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:54:48,269:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:54:48,271:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:55:11,278:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5015 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h54m13s_on_Sep_05_2022/MODELS_
2022-09-05 17:55:11,279:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.01s, LR: 0.00050, Train Loss: 1.0068, Train Acc: 0.5000,
                        Val Loss: 0.7436, Val Acc: 0.5010, Test Acc: 0.5015
2022-09-05 17:55:11,279:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:55:32,714:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5078 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h54m13s_on_Sep_05_2022/MODELS_
2022-09-05 17:55:32,714:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.43s, LR: 0.00050, Train Loss: 0.8610, Train Acc: 0.4700,
                        Val Loss: 1.0362, Val Acc: 0.5020, Test Acc: 0.5078
2022-09-05 17:55:32,714:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 17:55:54,432:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.72s, LR: 0.00050, Train Loss: 0.7657, Train Acc: 0.4850,
                        Val Loss: 0.7946, Val Acc: 0.4860, Test Acc: 0.5049
2022-09-05 17:55:54,433:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 17:56:16,667:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5146 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_17h54m13s_on_Sep_05_2022/MODELS_
2022-09-05 17:56:16,668:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.23s, LR: 0.00050, Train Loss: 0.7070, Train Acc: 0.5650,
                        Val Loss: 0.7302, Val Acc: 0.5320, Test Acc: 0.5146
2022-09-05 17:56:16,668:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 17:56:37,992:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.32s, LR: 0.00050, Train Loss: 0.7123, Train Acc: 0.5650,
                        Val Loss: 0.8055, Val Acc: 0.5070, Test Acc: 0.4965
2022-09-05 17:56:37,992:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 17:56:59,544:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.55s, LR: 0.00050, Train Loss: 0.7733, Train Acc: 0.5000,
                        Val Loss: 0.8051, Val Acc: 0.5030, Test Acc: 0.5094
2022-09-05 17:56:59,544:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 17:57:20,872:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:57:25,212:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:57:25,212:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:57:25,212:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:57:25,213:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:57:25,213:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:57:25,213:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:57:25,219:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:57:25,219:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523455
2022-09-05 17:57:25,220:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:57:25,220:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:57:25,221:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:57:25,221:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:57:25,226:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 17:57:57,033:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:31.8131582736969
2022-09-05 17:57:57,048:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:57:57,048:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:57:57,048:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:57:57,048:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:57:57,050:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:58:18,063:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_8_17h57m25s_on_Sep_05_2022/MODELS_
2022-09-05 17:58:18,064:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.01s, LR: 0.00050, Train Loss: 0.7386, Train Acc: 0.6000,
                        Val Loss: 41.8175, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:58:18,064:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 17:58:38,896:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 17:58:43,228:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 17:58:43,228:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 17:58:43,229:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:58:43,230:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:58:43,230:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:58:43,230:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:58:43,235:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 17:58:43,235:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-05 17:58:43,236:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 17:58:43,236:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 17:58:43,236:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 17:58:43,236:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 17:58:43,241:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 17:59:22,109:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:38.87357997894287
2022-09-05 17:59:22,127:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 17:59:22,127:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 17:59:22,127:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 17:59:22,127:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 17:59:22,130:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 17:59:44,116:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_17h58m43s_on_Sep_05_2022/MODELS_
2022-09-05 17:59:44,117:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.99s, LR: 0.00050, Train Loss: 0.9078, Train Acc: 0.5300,
                        Val Loss: 0.7670, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 17:59:44,117:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 18:00:05,678:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.56s, LR: 0.00050, Train Loss: 0.7532, Train Acc: 0.5250,
                        Val Loss: 0.9814, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:00:05,678:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 18:00:26,480:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5043 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_17h58m43s_on_Sep_05_2022/MODELS_
2022-09-05 18:00:26,480:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.80s, LR: 0.00050, Train Loss: 0.6814, Train Acc: 0.5900,
                        Val Loss: 0.8977, Val Acc: 0.5170, Test Acc: 0.5043
2022-09-05 18:00:26,480:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 18:00:46,671:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.19s, LR: 0.00050, Train Loss: 0.5969, Train Acc: 0.6700,
                        Val Loss: 1.1711, Val Acc: 0.5000, Test Acc: 0.5002
2022-09-05 18:00:46,671:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 18:01:07,653:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00050, Train Loss: 0.6191, Train Acc: 0.6200,
                        Val Loss: 1.3170, Val Acc: 0.5040, Test Acc: 0.5031
2022-09-05 18:01:07,654:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 18:01:28,990:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5475 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_17h58m43s_on_Sep_05_2022/MODELS_
2022-09-05 18:01:28,991:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.34s, LR: 0.00050, Train Loss: 0.5493, Train Acc: 0.7000,
                        Val Loss: 0.7446, Val Acc: 0.5440, Test Acc: 0.5475
2022-09-05 18:01:28,991:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 18:01:49,157:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5731 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_17h58m43s_on_Sep_05_2022/MODELS_
2022-09-05 18:01:49,158:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.17s, LR: 0.00050, Train Loss: 0.5029, Train Acc: 0.7800,
                        Val Loss: 0.8104, Val Acc: 0.5910, Test Acc: 0.5731
2022-09-05 18:01:49,158:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 18:02:09,408:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6018 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_17h58m43s_on_Sep_05_2022/MODELS_
2022-09-05 18:02:09,409:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.25s, LR: 0.00050, Train Loss: 0.5193, Train Acc: 0.7850,
                        Val Loss: 0.8345, Val Acc: 0.5950, Test Acc: 0.6018
2022-09-05 18:02:09,409:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 18:02:30,321:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.91s, LR: 0.00050, Train Loss: 0.5538, Train Acc: 0.7100,
                        Val Loss: 1.3284, Val Acc: 0.5010, Test Acc: 0.5003
2022-09-05 18:02:30,321:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 18:02:51,134:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.81s, LR: 0.00050, Train Loss: 0.4836, Train Acc: 0.7650,
                        Val Loss: 1.1373, Val Acc: 0.5410, Test Acc: 0.5361
2022-09-05 18:02:51,134:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 18:03:11,670:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.54s, LR: 0.00050, Train Loss: 0.4740, Train Acc: 0.7750,
                        Val Loss: 1.7620, Val Acc: 0.5250, Test Acc: 0.5235
2022-09-05 18:03:11,671:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 18:03:32,080:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.41s, LR: 0.00050, Train Loss: 0.4124, Train Acc: 0.8350,
                        Val Loss: 1.2258, Val Acc: 0.5290, Test Acc: 0.5364
2022-09-05 18:03:32,080:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 18:03:52,598:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.52s, LR: 0.00050, Train Loss: 0.3880, Train Acc: 0.8350,
                        Val Loss: 1.5089, Val Acc: 0.5620, Test Acc: 0.5478
2022-09-05 18:03:52,599:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 18:04:13,110:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6568 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_17h58m43s_on_Sep_05_2022/MODELS_
2022-09-05 18:04:13,111:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.51s, LR: 0.00050, Train Loss: 0.3784, Train Acc: 0.8400,
                        Val Loss: 0.7746, Val Acc: 0.6470, Test Acc: 0.6568
2022-09-05 18:04:13,111:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 18:04:33,763:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.65s, LR: 0.00050, Train Loss: 0.3704, Train Acc: 0.8500,
                        Val Loss: 2.0995, Val Acc: 0.5490, Test Acc: 0.5380
2022-09-05 18:04:33,763:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 18:04:54,555:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.79s, LR: 0.00050, Train Loss: 0.3416, Train Acc: 0.8500,
                        Val Loss: 0.9786, Val Acc: 0.6190, Test Acc: 0.6162
2022-09-05 18:04:54,556:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 18:05:14,919:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.36s, LR: 0.00050, Train Loss: 0.3221, Train Acc: 0.8550,
                        Val Loss: 1.2356, Val Acc: 0.5760, Test Acc: 0.5813
2022-09-05 18:05:14,919:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 18:05:35,272:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6961 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_17h58m43s_on_Sep_05_2022/MODELS_
2022-09-05 18:05:35,273:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.35s, LR: 0.00025, Train Loss: 0.3039, Train Acc: 0.8800,
                        Val Loss: 0.6607, Val Acc: 0.6960, Test Acc: 0.6961
2022-09-05 18:05:35,273:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 18:05:56,259:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.99s, LR: 0.00025, Train Loss: 0.3073, Train Acc: 0.8550,
                        Val Loss: 1.0357, Val Acc: 0.6070, Test Acc: 0.5919
2022-09-05 18:05:56,259:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 18:06:16,998:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.74s, LR: 0.00025, Train Loss: 0.2940, Train Acc: 0.8550,
                        Val Loss: 1.3551, Val Acc: 0.5500, Test Acc: 0.5493
2022-09-05 18:06:16,999:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 18:06:37,524:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.52s, LR: 0.00025, Train Loss: 0.2450, Train Acc: 0.9200,
                        Val Loss: 1.0076, Val Acc: 0.5930, Test Acc: 0.6129
2022-09-05 18:06:37,524:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 18:06:57,926:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.40s, LR: 0.00025, Train Loss: 0.2873, Train Acc: 0.8650,
                        Val Loss: 0.7131, Val Acc: 0.6920, Test Acc: 0.6862
2022-09-05 18:06:57,927:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 18:07:18,390:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.46s, LR: 0.00025, Train Loss: 0.2278, Train Acc: 0.9100,
                        Val Loss: 0.7910, Val Acc: 0.6730, Test Acc: 0.6603
2022-09-05 18:07:18,391:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 18:07:32,630:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 18:07:37,056:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 18:07:37,056:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 18:07:37,056:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:07:37,057:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:07:37,057:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:07:37,058:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:07:37,063:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 18:07:37,064:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-05 18:07:37,064:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:07:37,064:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:07:37,064:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:07:37,064:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:07:37,070:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 18:08:26,651:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:49.58675289154053
2022-09-05 18:08:26,669:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 18:08:26,669:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 18:08:26,669:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 18:08:26,669:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 18:08:26,672:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 18:08:48,784:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h07m37s_on_Sep_05_2022/MODELS_
2022-09-05 18:08:48,785:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.11s, LR: 0.00050, Train Loss: 0.8094, Train Acc: 0.5000,
                        Val Loss: 9.5811, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:08:48,786:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 18:09:10,039:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.25s, LR: 0.00050, Train Loss: 0.7088, Train Acc: 0.5650,
                        Val Loss: 2.1655, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:09:10,040:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 18:09:30,938:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.90s, LR: 0.00050, Train Loss: 0.6272, Train Acc: 0.6800,
                        Val Loss: 1.9289, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:09:30,939:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 18:09:52,077:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.14s, LR: 0.00050, Train Loss: 0.5774, Train Acc: 0.7250,
                        Val Loss: 1.7767, Val Acc: 0.4990, Test Acc: 0.5000
2022-09-05 18:09:52,077:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 18:10:13,009:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5244 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h07m37s_on_Sep_05_2022/MODELS_
2022-09-05 18:10:13,009:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.93s, LR: 0.00050, Train Loss: 0.5537, Train Acc: 0.7400,
                        Val Loss: 0.8505, Val Acc: 0.5300, Test Acc: 0.5244
2022-09-05 18:10:13,009:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 18:10:34,111:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6768 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h07m37s_on_Sep_05_2022/MODELS_
2022-09-05 18:10:34,112:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.10s, LR: 0.00050, Train Loss: 0.5424, Train Acc: 0.7150,
                        Val Loss: 0.6013, Val Acc: 0.6920, Test Acc: 0.6768
2022-09-05 18:10:34,112:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 18:10:55,021:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.91s, LR: 0.00050, Train Loss: 0.5313, Train Acc: 0.7350,
                        Val Loss: 0.7363, Val Acc: 0.6120, Test Acc: 0.6041
2022-09-05 18:10:55,021:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 18:11:15,929:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.91s, LR: 0.00050, Train Loss: 0.5419, Train Acc: 0.7750,
                        Val Loss: 1.1112, Val Acc: 0.5160, Test Acc: 0.5124
2022-09-05 18:11:15,930:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 18:11:37,876:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.95s, LR: 0.00050, Train Loss: 0.5214, Train Acc: 0.7300,
                        Val Loss: 1.0090, Val Acc: 0.5550, Test Acc: 0.5519
2022-09-05 18:11:37,876:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 18:11:51,318:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 18:11:55,665:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 18:11:55,665:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 18:11:55,665:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:11:55,666:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:11:55,666:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:11:55,666:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:11:55,671:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 18:11:55,671:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-05 18:11:55,672:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:11:55,672:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:11:55,672:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:11:55,672:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:11:55,677:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 18:12:57,705:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:62.033775806427
2022-09-05 18:12:57,721:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 18:12:57,721:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 18:12:57,721:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 18:12:57,721:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 18:12:57,723:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 18:13:19,642:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:13:19,643:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.92s, LR: 0.00050, Train Loss: 0.9042, Train Acc: 0.4750,
                        Val Loss: 3.2082, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:13:19,643:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 18:13:41,029:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5206 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:13:41,029:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.39s, LR: 0.00050, Train Loss: 0.7365, Train Acc: 0.5250,
                        Val Loss: 1.2265, Val Acc: 0.5070, Test Acc: 0.5206
2022-09-05 18:13:41,029:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 18:14:01,814:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00050, Train Loss: 0.6595, Train Acc: 0.6200,
                        Val Loss: 1.0906, Val Acc: 0.5260, Test Acc: 0.5101
2022-09-05 18:14:01,814:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 18:14:22,746:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5356 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:14:22,746:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.93s, LR: 0.00050, Train Loss: 0.6171, Train Acc: 0.6650,
                        Val Loss: 0.7195, Val Acc: 0.5540, Test Acc: 0.5356
2022-09-05 18:14:22,746:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 18:14:44,000:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5578 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:14:44,001:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.25s, LR: 0.00050, Train Loss: 0.6879, Train Acc: 0.6500,
                        Val Loss: 0.6745, Val Acc: 0.5740, Test Acc: 0.5578
2022-09-05 18:14:44,001:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 18:15:05,207:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.21s, LR: 0.00050, Train Loss: 0.6726, Train Acc: 0.6500,
                        Val Loss: 0.8367, Val Acc: 0.5630, Test Acc: 0.5510
2022-09-05 18:15:05,207:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 18:15:26,084:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.88s, LR: 0.00050, Train Loss: 0.6664, Train Acc: 0.6700,
                        Val Loss: 0.8025, Val Acc: 0.5320, Test Acc: 0.5390
2022-09-05 18:15:26,085:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 18:15:46,918:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6370 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:15:46,919:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.83s, LR: 0.00050, Train Loss: 0.6161, Train Acc: 0.6400,
                        Val Loss: 0.6296, Val Acc: 0.6540, Test Acc: 0.6370
2022-09-05 18:15:46,919:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 18:16:07,850:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6512 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:16:07,850:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.93s, LR: 0.00050, Train Loss: 0.5716, Train Acc: 0.7100,
                        Val Loss: 0.6260, Val Acc: 0.6700, Test Acc: 0.6512
2022-09-05 18:16:07,850:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 18:16:29,659:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.81s, LR: 0.00050, Train Loss: 0.5542, Train Acc: 0.7550,
                        Val Loss: 0.7845, Val Acc: 0.5650, Test Acc: 0.5580
2022-09-05 18:16:29,659:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 18:16:50,808:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.15s, LR: 0.00050, Train Loss: 0.6033, Train Acc: 0.6850,
                        Val Loss: 0.6679, Val Acc: 0.6300, Test Acc: 0.6227
2022-09-05 18:16:50,808:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 18:17:11,900:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.09s, LR: 0.00050, Train Loss: 0.5539, Train Acc: 0.7050,
                        Val Loss: 0.7219, Val Acc: 0.6400, Test Acc: 0.6305
2022-09-05 18:17:11,901:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 18:17:33,071:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.17s, LR: 0.00050, Train Loss: 0.5194, Train Acc: 0.7550,
                        Val Loss: 0.7888, Val Acc: 0.6030, Test Acc: 0.5912
2022-09-05 18:17:33,071:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 18:17:54,230:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6535 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:17:54,231:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.16s, LR: 0.00050, Train Loss: 0.4976, Train Acc: 0.7150,
                        Val Loss: 0.6434, Val Acc: 0.6720, Test Acc: 0.6535
2022-09-05 18:17:54,231:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 18:18:15,706:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.48s, LR: 0.00050, Train Loss: 0.4848, Train Acc: 0.7700,
                        Val Loss: 0.8321, Val Acc: 0.6140, Test Acc: 0.6027
2022-09-05 18:18:15,707:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 18:18:39,543:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.84s, LR: 0.00050, Train Loss: 0.4445, Train Acc: 0.8300,
                        Val Loss: 0.9433, Val Acc: 0.6000, Test Acc: 0.5932
2022-09-05 18:18:39,544:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 18:19:01,092:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.55s, LR: 0.00050, Train Loss: 0.4364, Train Acc: 0.8150,
                        Val Loss: 1.0949, Val Acc: 0.5860, Test Acc: 0.5767
2022-09-05 18:19:01,092:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 18:19:22,060:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.97s, LR: 0.00050, Train Loss: 0.4215, Train Acc: 0.8200,
                        Val Loss: 0.7793, Val Acc: 0.6300, Test Acc: 0.6266
2022-09-05 18:19:22,060:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 18:19:43,040:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6582 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:19:43,040:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00050, Train Loss: 0.4093, Train Acc: 0.8150,
                        Val Loss: 0.6817, Val Acc: 0.6780, Test Acc: 0.6582
2022-09-05 18:19:43,040:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 18:20:04,116:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.08s, LR: 0.00050, Train Loss: 0.4386, Train Acc: 0.8050,
                        Val Loss: 1.4621, Val Acc: 0.5420, Test Acc: 0.5363
2022-09-05 18:20:04,116:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 18:20:25,084:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.97s, LR: 0.00025, Train Loss: 0.4087, Train Acc: 0.8100,
                        Val Loss: 0.7397, Val Acc: 0.6460, Test Acc: 0.6379
2022-09-05 18:20:25,084:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 18:20:46,030:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7050 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:20:46,030:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.95s, LR: 0.00025, Train Loss: 0.3659, Train Acc: 0.8650,
                        Val Loss: 0.5763, Val Acc: 0.7180, Test Acc: 0.7050
2022-09-05 18:20:46,031:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 18:21:07,006:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00025, Train Loss: 0.3268, Train Acc: 0.8900,
                        Val Loss: 0.6300, Val Acc: 0.6930, Test Acc: 0.6981
2022-09-05 18:21:07,007:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 18:21:27,985:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00025, Train Loss: 0.3104, Train Acc: 0.9050,
                        Val Loss: 0.6654, Val Acc: 0.6810, Test Acc: 0.6837
2022-09-05 18:21:27,985:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 18:21:49,124:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.14s, LR: 0.00025, Train Loss: 0.3172, Train Acc: 0.8850,
                        Val Loss: 0.6838, Val Acc: 0.6880, Test Acc: 0.6776
2022-09-05 18:21:49,124:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 18:22:10,316:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.19s, LR: 0.00025, Train Loss: 0.2977, Train Acc: 0.9000,
                        Val Loss: 0.6846, Val Acc: 0.7090, Test Acc: 0.6848
2022-09-05 18:22:10,316:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 18:22:31,454:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.14s, LR: 0.00025, Train Loss: 0.2876, Train Acc: 0.8850,
                        Val Loss: 0.6755, Val Acc: 0.7030, Test Acc: 0.7029
2022-09-05 18:22:31,454:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 18:22:52,590:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7137 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:22:52,590:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.14s, LR: 0.00025, Train Loss: 0.2687, Train Acc: 0.9000,
                        Val Loss: 0.6799, Val Acc: 0.7120, Test Acc: 0.7137
2022-09-05 18:22:52,590:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 18:23:13,747:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7176 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:23:13,748:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.16s, LR: 0.00025, Train Loss: 0.2675, Train Acc: 0.8850,
                        Val Loss: 0.6826, Val Acc: 0.7280, Test Acc: 0.7176
2022-09-05 18:23:13,748:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 18:23:34,902:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.15s, LR: 0.00025, Train Loss: 0.2383, Train Acc: 0.9100,
                        Val Loss: 0.6932, Val Acc: 0.6910, Test Acc: 0.6973
2022-09-05 18:23:34,903:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 18:23:55,884:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00025, Train Loss: 0.2421, Train Acc: 0.9250,
                        Val Loss: 0.7249, Val Acc: 0.7150, Test Acc: 0.6980
2022-09-05 18:23:55,884:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 18:24:16,878:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.99s, LR: 0.00025, Train Loss: 0.2299, Train Acc: 0.9150,
                        Val Loss: 0.7148, Val Acc: 0.6810, Test Acc: 0.6840
2022-09-05 18:24:16,878:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 18:24:37,851:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.97s, LR: 0.00025, Train Loss: 0.1890, Train Acc: 0.9600,
                        Val Loss: 1.0730, Val Acc: 0.6700, Test Acc: 0.6683
2022-09-05 18:24:37,851:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 18:24:58,848:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.00s, LR: 0.00013, Train Loss: 0.2031, Train Acc: 0.9250,
                        Val Loss: 1.0046, Val Acc: 0.6830, Test Acc: 0.6731
2022-09-05 18:24:58,849:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 18:25:19,815:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.97s, LR: 0.00013, Train Loss: 0.1904, Train Acc: 0.9400,
                        Val Loss: 0.7344, Val Acc: 0.6970, Test Acc: 0.6944
2022-09-05 18:25:19,815:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 18:25:40,775:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.96s, LR: 0.00013, Train Loss: 0.2388, Train Acc: 0.9100,
                        Val Loss: 0.9185, Val Acc: 0.6520, Test Acc: 0.6405
2022-09-05 18:25:40,775:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 18:26:01,827:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.05s, LR: 0.00013, Train Loss: 0.2187, Train Acc: 0.9200,
                        Val Loss: 0.9046, Val Acc: 0.6600, Test Acc: 0.6562
2022-09-05 18:26:01,827:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 18:26:22,571:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.74s, LR: 0.00013, Train Loss: 0.1861, Train Acc: 0.9400,
                        Val Loss: 0.7735, Val Acc: 0.7180, Test Acc: 0.7054
2022-09-05 18:26:22,571:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 18:26:43,343:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7239 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_18h11m55s_on_Sep_05_2022/MODELS_
2022-09-05 18:26:43,343:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.77s, LR: 0.00013, Train Loss: 0.1685, Train Acc: 0.9450,
                        Val Loss: 0.7505, Val Acc: 0.7200, Test Acc: 0.7239
2022-09-05 18:26:43,343:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 18:27:04,000:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.66s, LR: 0.00013, Train Loss: 0.1582, Train Acc: 0.9500,
                        Val Loss: 0.7781, Val Acc: 0.6810, Test Acc: 0.6867
2022-09-05 18:27:04,001:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 18:27:24,615:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.61s, LR: 0.00013, Train Loss: 0.1737, Train Acc: 0.9450,
                        Val Loss: 0.7478, Val Acc: 0.7040, Test Acc: 0.7014
2022-09-05 18:27:24,615:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 18:27:45,274:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.66s, LR: 0.00013, Train Loss: 0.1774, Train Acc: 0.9550,
                        Val Loss: 0.7517, Val Acc: 0.7160, Test Acc: 0.7181
2022-09-05 18:27:45,275:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 18:28:05,995:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.72s, LR: 0.00013, Train Loss: 0.1511, Train Acc: 0.9450,
                        Val Loss: 0.7776, Val Acc: 0.7080, Test Acc: 0.7150
2022-09-05 18:28:05,995:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 18:28:26,665:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.67s, LR: 0.00013, Train Loss: 0.1540, Train Acc: 0.9350,
                        Val Loss: 0.7429, Val Acc: 0.7220, Test Acc: 0.7165
2022-09-05 18:28:26,666:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 45/1000
2022-09-05 18:28:47,268:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.60s, LR: 0.00006, Train Loss: 0.1644, Train Acc: 0.9400,
                        Val Loss: 0.8095, Val Acc: 0.6930, Test Acc: 0.6830
2022-09-05 18:28:47,268:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 46/1000
2022-09-05 18:29:07,955:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.69s, LR: 0.00006, Train Loss: 0.1429, Train Acc: 0.9550,
                        Val Loss: 0.7484, Val Acc: 0.7210, Test Acc: 0.7131
2022-09-05 18:29:07,955:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 47/1000
2022-09-05 18:29:30,090:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00006, Train Loss: 0.1372, Train Acc: 0.9650,
                        Val Loss: 0.7813, Val Acc: 0.7200, Test Acc: 0.7038
2022-09-05 18:29:30,090:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 48/1000
2022-09-05 18:30:05,862:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 18:30:10,184:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 18:30:10,184:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 18:30:10,185:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:30:10,186:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:30:10,186:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:30:10,186:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:30:10,191:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 18:30:10,191:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526359
2022-09-05 18:30:10,192:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:30:10,192:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:30:10,192:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:30:10,192:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:30:10,197:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-05 18:31:12,028:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:61.836846113204956
2022-09-05 18:31:12,045:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 18:31:12,045:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 18:31:12,045:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 18:31:12,045:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 18:31:12,047:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 18:31:33,600:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:31:33,602:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.55s, LR: 0.00050, Train Loss: 0.7697, Train Acc: 0.5300,
                        Val Loss: 1.3581, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:31:33,602:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 18:31:54,797:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.19s, LR: 0.00050, Train Loss: 0.7148, Train Acc: 0.5550,
                        Val Loss: 0.8496, Val Acc: 0.4740, Test Acc: 0.4904
2022-09-05 18:31:54,798:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 18:32:15,596:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.80s, LR: 0.00050, Train Loss: 0.6578, Train Acc: 0.6650,
                        Val Loss: 1.0928, Val Acc: 0.4950, Test Acc: 0.4886
2022-09-05 18:32:15,596:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 18:32:36,392:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.80s, LR: 0.00050, Train Loss: 0.6381, Train Acc: 0.6450,
                        Val Loss: 1.5281, Val Acc: 0.4860, Test Acc: 0.4931
2022-09-05 18:32:36,393:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 18:32:57,183:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5238 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:32:57,183:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.79s, LR: 0.00050, Train Loss: 0.6500, Train Acc: 0.6350,
                        Val Loss: 0.8179, Val Acc: 0.5250, Test Acc: 0.5238
2022-09-05 18:32:57,183:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 18:33:17,988:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5874 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:33:17,988:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.81s, LR: 0.00050, Train Loss: 0.6122, Train Acc: 0.6800,
                        Val Loss: 0.6762, Val Acc: 0.6060, Test Acc: 0.5874
2022-09-05 18:33:17,988:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 18:33:38,790:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6139 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:33:38,790:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.80s, LR: 0.00050, Train Loss: 0.6071, Train Acc: 0.6900,
                        Val Loss: 0.6484, Val Acc: 0.6240, Test Acc: 0.6139
2022-09-05 18:33:38,790:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 18:33:59,607:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.82s, LR: 0.00050, Train Loss: 0.5724, Train Acc: 0.7450,
                        Val Loss: 1.7538, Val Acc: 0.5000, Test Acc: 0.5005
2022-09-05 18:33:59,608:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 18:34:20,509:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6556 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:34:20,510:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.90s, LR: 0.00050, Train Loss: 0.5818, Train Acc: 0.7150,
                        Val Loss: 0.6001, Val Acc: 0.6640, Test Acc: 0.6556
2022-09-05 18:34:20,510:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 18:34:41,227:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.72s, LR: 0.00050, Train Loss: 0.5622, Train Acc: 0.7300,
                        Val Loss: 0.7346, Val Acc: 0.5990, Test Acc: 0.5855
2022-09-05 18:34:41,228:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 18:35:02,095:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.87s, LR: 0.00050, Train Loss: 0.5579, Train Acc: 0.7150,
                        Val Loss: 0.6685, Val Acc: 0.6400, Test Acc: 0.6375
2022-09-05 18:35:02,096:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 18:35:22,831:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.73s, LR: 0.00050, Train Loss: 0.5492, Train Acc: 0.7100,
                        Val Loss: 0.6250, Val Acc: 0.6420, Test Acc: 0.6379
2022-09-05 18:35:22,831:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 18:35:43,565:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.73s, LR: 0.00050, Train Loss: 0.5410, Train Acc: 0.7400,
                        Val Loss: 0.7138, Val Acc: 0.6090, Test Acc: 0.6089
2022-09-05 18:35:43,565:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 18:36:05,601:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6902 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:36:05,601:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.04s, LR: 0.00050, Train Loss: 0.4818, Train Acc: 0.7750,
                        Val Loss: 0.6102, Val Acc: 0.6920, Test Acc: 0.6902
2022-09-05 18:36:05,601:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 18:36:28,738:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.14s, LR: 0.00050, Train Loss: 0.4489, Train Acc: 0.8150,
                        Val Loss: 0.6838, Val Acc: 0.6470, Test Acc: 0.6378
2022-09-05 18:36:28,739:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 18:36:51,067:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.33s, LR: 0.00050, Train Loss: 0.4221, Train Acc: 0.8500,
                        Val Loss: 0.7214, Val Acc: 0.6330, Test Acc: 0.6220
2022-09-05 18:36:51,067:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 18:37:13,776:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.71s, LR: 0.00050, Train Loss: 0.3867, Train Acc: 0.8250,
                        Val Loss: 0.7993, Val Acc: 0.6430, Test Acc: 0.6351
2022-09-05 18:37:13,777:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 18:37:35,801:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.02s, LR: 0.00050, Train Loss: 0.4091, Train Acc: 0.8250,
                        Val Loss: 0.7873, Val Acc: 0.6370, Test Acc: 0.6370
2022-09-05 18:37:35,802:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 18:37:57,747:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.95s, LR: 0.00050, Train Loss: 0.3984, Train Acc: 0.8000,
                        Val Loss: 1.0232, Val Acc: 0.5690, Test Acc: 0.5595
2022-09-05 18:37:57,748:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 18:38:19,528:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.78s, LR: 0.00050, Train Loss: 0.4410, Train Acc: 0.8050,
                        Val Loss: 0.7394, Val Acc: 0.6210, Test Acc: 0.6247
2022-09-05 18:38:19,528:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 18:38:41,315:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.79s, LR: 0.00025, Train Loss: 0.4102, Train Acc: 0.8000,
                        Val Loss: 1.5504, Val Acc: 0.5180, Test Acc: 0.5182
2022-09-05 18:38:41,316:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 18:39:03,021:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.70s, LR: 0.00025, Train Loss: 0.3697, Train Acc: 0.8500,
                        Val Loss: 0.6192, Val Acc: 0.6720, Test Acc: 0.6646
2022-09-05 18:39:03,021:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 18:39:24,803:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.78s, LR: 0.00025, Train Loss: 0.2855, Train Acc: 0.9100,
                        Val Loss: 0.7079, Val Acc: 0.6590, Test Acc: 0.6654
2022-09-05 18:39:24,803:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 18:39:46,568:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.77s, LR: 0.00025, Train Loss: 0.2735, Train Acc: 0.8900,
                        Val Loss: 0.8923, Val Acc: 0.6190, Test Acc: 0.6113
2022-09-05 18:39:46,569:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 18:40:08,322:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.75s, LR: 0.00025, Train Loss: 0.2706, Train Acc: 0.8650,
                        Val Loss: 0.8768, Val Acc: 0.6460, Test Acc: 0.6416
2022-09-05 18:40:08,323:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 18:40:30,049:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.73s, LR: 0.00025, Train Loss: 0.2574, Train Acc: 0.9050,
                        Val Loss: 0.9144, Val Acc: 0.6290, Test Acc: 0.6261
2022-09-05 18:40:30,049:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 18:40:51,920:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.87s, LR: 0.00025, Train Loss: 0.2424, Train Acc: 0.9000,
                        Val Loss: 0.7077, Val Acc: 0.6880, Test Acc: 0.6878
2022-09-05 18:40:51,921:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 18:41:13,814:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.89s, LR: 0.00025, Train Loss: 0.2193, Train Acc: 0.9250,
                        Val Loss: 0.7330, Val Acc: 0.6870, Test Acc: 0.6795
2022-09-05 18:41:13,815:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 18:41:35,605:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.79s, LR: 0.00025, Train Loss: 0.2292, Train Acc: 0.9050,
                        Val Loss: 0.7034, Val Acc: 0.6820, Test Acc: 0.6783
2022-09-05 18:41:35,605:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 18:41:57,316:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7171 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:41:57,317:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.71s, LR: 0.00025, Train Loss: 0.2067, Train Acc: 0.9300,
                        Val Loss: 0.6939, Val Acc: 0.7290, Test Acc: 0.7171
2022-09-05 18:41:57,317:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 18:42:19,047:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.73s, LR: 0.00025, Train Loss: 0.1930, Train Acc: 0.9250,
                        Val Loss: 0.7004, Val Acc: 0.7260, Test Acc: 0.7138
2022-09-05 18:42:19,048:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 18:42:41,395:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7240 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_32_18h30m10s_on_Sep_05_2022/MODELS_
2022-09-05 18:42:41,396:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.35s, LR: 0.00013, Train Loss: 0.1898, Train Acc: 0.9000,
                        Val Loss: 0.6983, Val Acc: 0.7330, Test Acc: 0.7240
2022-09-05 18:42:41,396:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 18:43:03,531:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00013, Train Loss: 0.1470, Train Acc: 0.9500,
                        Val Loss: 0.8251, Val Acc: 0.6890, Test Acc: 0.6829
2022-09-05 18:43:03,531:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 18:43:20,716:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 18:43:25,534:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 40, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 18:43:25,534:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 18:43:25,534:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:43:25,535:pe_layer.py:129 -             __init__(): Using 40 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:43:25,535:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:43:25,535:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:43:25,540:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 18:43:25,541:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527583
2022-09-05 18:43:25,541:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 18:43:25,542:pe_layer.py:129 -             __init__(): Using 40 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 18:43:25,542:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 18:43:25,542:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 18:43:25,547:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (40).
2022-09-05 18:44:38,508:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:72.9669098854065
2022-09-05 18:44:38,532:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 18:44:38,532:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 18:44:38,532:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 18:44:38,532:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 18:44:38,535:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 18:45:06,858:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_40_18h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 18:45:06,860:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 28.32s, LR: 0.00050, Train Loss: 0.7805, Train Acc: 0.5350,
                        Val Loss: 1.2678, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:45:06,861:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 18:45:52,009:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 45.15s, LR: 0.00050, Train Loss: 0.6871, Train Acc: 0.5950,
                        Val Loss: 9.1968, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:45:52,011:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 18:46:17,807:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.80s, LR: 0.00050, Train Loss: 0.6196, Train Acc: 0.6700,
                        Val Loss: 1.5646, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 18:46:17,807:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 18:46:41,524:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5004 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_40_18h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 18:46:41,524:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.72s, LR: 0.00050, Train Loss: 0.5731, Train Acc: 0.7400,
                        Val Loss: 1.3082, Val Acc: 0.5000, Test Acc: 0.5004
2022-09-05 18:46:41,524:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 18:47:04,865:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5858 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_40_18h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 18:47:04,866:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.34s, LR: 0.00050, Train Loss: 0.5607, Train Acc: 0.6950,
                        Val Loss: 0.7763, Val Acc: 0.5940, Test Acc: 0.5858
2022-09-05 18:47:04,866:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 18:47:27,798:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5939 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_40_18h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 18:47:27,798:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.93s, LR: 0.00050, Train Loss: 0.5657, Train Acc: 0.6900,
                        Val Loss: 0.8647, Val Acc: 0.5950, Test Acc: 0.5939
2022-09-05 18:47:27,799:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 18:47:50,812:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6405 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_40_18h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 18:47:50,812:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.01s, LR: 0.00050, Train Loss: 0.5146, Train Acc: 0.7800,
                        Val Loss: 0.6694, Val Acc: 0.6290, Test Acc: 0.6405
2022-09-05 18:47:50,813:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 18:48:14,724:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.91s, LR: 0.00050, Train Loss: 0.5065, Train Acc: 0.7550,
                        Val Loss: 0.8271, Val Acc: 0.5860, Test Acc: 0.5860
2022-09-05 18:48:14,725:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 18:48:37,310:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.58s, LR: 0.00050, Train Loss: 0.4963, Train Acc: 0.7550,
                        Val Loss: 0.7493, Val Acc: 0.6160, Test Acc: 0.6138
2022-09-05 18:48:37,310:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 18:49:00,711:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7099 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_40_18h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 18:49:00,712:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.40s, LR: 0.00050, Train Loss: 0.4704, Train Acc: 0.7950,
                        Val Loss: 0.5801, Val Acc: 0.7120, Test Acc: 0.7099
2022-09-05 18:49:00,712:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 18:49:24,319:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.61s, LR: 0.00050, Train Loss: 0.4732, Train Acc: 0.7600,
                        Val Loss: 1.3001, Val Acc: 0.5020, Test Acc: 0.5014
2022-09-05 18:49:24,320:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 18:49:48,208:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.89s, LR: 0.00050, Train Loss: 0.4579, Train Acc: 0.8000,
                        Val Loss: 0.8957, Val Acc: 0.6290, Test Acc: 0.6327
2022-09-05 18:49:48,209:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 18:50:11,619:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.41s, LR: 0.00050, Train Loss: 0.4145, Train Acc: 0.8100,
                        Val Loss: 0.8174, Val Acc: 0.6220, Test Acc: 0.6244
2022-09-05 18:50:11,620:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 18:50:33,142:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.52s, LR: 0.00050, Train Loss: 0.3876, Train Acc: 0.8150,
                        Val Loss: 0.7226, Val Acc: 0.6560, Test Acc: 0.6744
2022-09-05 18:50:33,142:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 18:50:55,270:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00050, Train Loss: 0.3732, Train Acc: 0.8600,
                        Val Loss: 0.7532, Val Acc: 0.6650, Test Acc: 0.6550
2022-09-05 18:50:55,271:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 18:51:16,678:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.41s, LR: 0.00050, Train Loss: 0.3661, Train Acc: 0.8750,
                        Val Loss: 2.2249, Val Acc: 0.5430, Test Acc: 0.5409
2022-09-05 18:51:16,679:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 18:51:38,793:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.11s, LR: 0.00050, Train Loss: 0.3345, Train Acc: 0.8500,
                        Val Loss: 2.6720, Val Acc: 0.5070, Test Acc: 0.5050
2022-09-05 18:51:38,793:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 18:52:00,256:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.46s, LR: 0.00050, Train Loss: 0.3485, Train Acc: 0.8450,
                        Val Loss: 0.6329, Val Acc: 0.6980, Test Acc: 0.6956
2022-09-05 18:52:00,257:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 18:52:22,021:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.76s, LR: 0.00050, Train Loss: 0.3003, Train Acc: 0.8950,
                        Val Loss: 0.9075, Val Acc: 0.6490, Test Acc: 0.6424
2022-09-05 18:52:22,022:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 18:52:44,142:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.12s, LR: 0.00050, Train Loss: 0.3132, Train Acc: 0.8900,
                        Val Loss: 2.9471, Val Acc: 0.5000, Test Acc: 0.5004
2022-09-05 18:52:44,143:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 18:53:06,773:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.63s, LR: 0.00050, Train Loss: 0.3451, Train Acc: 0.8500,
                        Val Loss: 2.1336, Val Acc: 0.5010, Test Acc: 0.5020
2022-09-05 18:53:06,773:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 18:53:29,855:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.08s, LR: 0.00025, Train Loss: 0.2691, Train Acc: 0.8900,
                        Val Loss: 1.0019, Val Acc: 0.6460, Test Acc: 0.6523
2022-09-05 18:53:29,855:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 18:53:52,897:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.04s, LR: 0.00025, Train Loss: 0.2266, Train Acc: 0.9150,
                        Val Loss: 2.8498, Val Acc: 0.5360, Test Acc: 0.5352
2022-09-05 18:53:52,897:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 18:54:15,812:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.91s, LR: 0.00025, Train Loss: 0.2209, Train Acc: 0.9150,
                        Val Loss: 0.7158, Val Acc: 0.6760, Test Acc: 0.6710
2022-09-05 18:54:15,812:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 18:54:37,435:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.62s, LR: 0.00025, Train Loss: 0.2128, Train Acc: 0.9100,
                        Val Loss: 1.0757, Val Acc: 0.5980, Test Acc: 0.6116
2022-09-05 18:54:37,435:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 18:54:59,124:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.69s, LR: 0.00025, Train Loss: 0.1585, Train Acc: 0.9600,
                        Val Loss: 0.7274, Val Acc: 0.6770, Test Acc: 0.6863
2022-09-05 18:54:59,125:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 18:55:22,389:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.26s, LR: 0.00025, Train Loss: 0.1707, Train Acc: 0.9400,
                        Val Loss: 0.7350, Val Acc: 0.6880, Test Acc: 0.6873
2022-09-05 18:55:22,390:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 18:55:45,814:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.42s, LR: 0.00025, Train Loss: 0.1596, Train Acc: 0.9600,
                        Val Loss: 0.9592, Val Acc: 0.6410, Test Acc: 0.6334
2022-09-05 18:55:45,814:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 18:56:09,787:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.97s, LR: 0.00025, Train Loss: 0.1713, Train Acc: 0.9400,
                        Val Loss: 1.4650, Val Acc: 0.6480, Test Acc: 0.6444
2022-09-05 18:56:09,788:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 18:56:32,086:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.30s, LR: 0.00025, Train Loss: 0.1687, Train Acc: 0.9400,
                        Val Loss: 1.5107, Val Acc: 0.6190, Test Acc: 0.6132
2022-09-05 18:56:32,086:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 18:56:55,711:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.62s, LR: 0.00025, Train Loss: 0.1535, Train Acc: 0.9650,
                        Val Loss: 1.2219, Val Acc: 0.5940, Test Acc: 0.5900
2022-09-05 18:56:55,711:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 18:57:19,478:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.77s, LR: 0.00025, Train Loss: 0.1534, Train Acc: 0.9450,
                        Val Loss: 1.2146, Val Acc: 0.5790, Test Acc: 0.5793
2022-09-05 18:57:19,479:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 18:57:42,749:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7296 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_40_18h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 18:57:42,749:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.27s, LR: 0.00013, Train Loss: 0.1082, Train Acc: 0.9750,
                        Val Loss: 0.6811, Val Acc: 0.7200, Test Acc: 0.7296
2022-09-05 18:57:42,750:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 18:58:06,540:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.79s, LR: 0.00013, Train Loss: 0.1128, Train Acc: 0.9700,
                        Val Loss: 0.8114, Val Acc: 0.7100, Test Acc: 0.7012
2022-09-05 18:58:06,540:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 18:58:29,441:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.90s, LR: 0.00013, Train Loss: 0.0945, Train Acc: 0.9750,
                        Val Loss: 0.7230, Val Acc: 0.7240, Test Acc: 0.7148
2022-09-05 18:58:29,442:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 18:58:53,202:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.76s, LR: 0.00013, Train Loss: 0.1259, Train Acc: 0.9650,
                        Val Loss: 1.3066, Val Acc: 0.5960, Test Acc: 0.5983
2022-09-05 18:58:53,202:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 18:59:16,151:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.95s, LR: 0.00013, Train Loss: 0.1178, Train Acc: 0.9550,
                        Val Loss: 1.1800, Val Acc: 0.6330, Test Acc: 0.6207
2022-09-05 18:59:16,151:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 18:59:37,906:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.76s, LR: 0.00013, Train Loss: 0.1040, Train Acc: 0.9650,
                        Val Loss: 0.7185, Val Acc: 0.6990, Test Acc: 0.7032
2022-09-05 18:59:37,907:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 18:59:59,272:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.37s, LR: 0.00013, Train Loss: 0.0868, Train Acc: 0.9850,
                        Val Loss: 1.0102, Val Acc: 0.6450, Test Acc: 0.6445
2022-09-05 18:59:59,273:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 19:00:21,093:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.82s, LR: 0.00013, Train Loss: 0.1148, Train Acc: 0.9650,
                        Val Loss: 0.8165, Val Acc: 0.7090, Test Acc: 0.7034
2022-09-05 19:00:21,094:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 19:00:42,344:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 19:00:46,636:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 19:00:46,636:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 19:00:46,637:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 19:00:46,638:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 19:00:46,638:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 19:00:46,638:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 19:00:46,643:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 19:00:46,644:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-05 19:00:46,644:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 19:00:46,644:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 19:00:46,644:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 19:00:46,644:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 19:00:46,650:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 19:02:01,078:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:74.43430018424988
2022-09-05 19:02:01,096:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 19:02:01,097:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 19:02:01,097:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 19:02:01,097:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 19:02:01,099:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 19:02:25,251:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:02:25,253:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.15s, LR: 0.00050, Train Loss: 0.9575, Train Acc: 0.5300,
                        Val Loss: 2.4546, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 19:02:25,254:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 19:02:47,424:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5266 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:02:47,424:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.17s, LR: 0.00050, Train Loss: 0.7787, Train Acc: 0.5000,
                        Val Loss: 0.9663, Val Acc: 0.5460, Test Acc: 0.5266
2022-09-05 19:02:47,424:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 19:03:08,733:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.31s, LR: 0.00050, Train Loss: 0.7480, Train Acc: 0.5450,
                        Val Loss: 0.9458, Val Acc: 0.5340, Test Acc: 0.5181
2022-09-05 19:03:08,734:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 19:03:30,829:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.09s, LR: 0.00050, Train Loss: 0.6884, Train Acc: 0.5600,
                        Val Loss: 0.8329, Val Acc: 0.5120, Test Acc: 0.5052
2022-09-05 19:03:30,829:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 19:03:53,192:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.36s, LR: 0.00050, Train Loss: 0.7144, Train Acc: 0.5550,
                        Val Loss: 0.8064, Val Acc: 0.5170, Test Acc: 0.5064
2022-09-05 19:03:53,193:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 19:04:15,950:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5539 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:04:15,951:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.76s, LR: 0.00050, Train Loss: 0.7143, Train Acc: 0.5500,
                        Val Loss: 0.6923, Val Acc: 0.5580, Test Acc: 0.5539
2022-09-05 19:04:15,951:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 19:04:38,882:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.93s, LR: 0.00050, Train Loss: 0.7088, Train Acc: 0.5400,
                        Val Loss: 0.7263, Val Acc: 0.5650, Test Acc: 0.5460
2022-09-05 19:04:38,883:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 19:05:01,410:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00050, Train Loss: 0.7084, Train Acc: 0.5850,
                        Val Loss: 0.8524, Val Acc: 0.5450, Test Acc: 0.5208
2022-09-05 19:05:01,411:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 19:05:23,605:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.19s, LR: 0.00050, Train Loss: 0.6795, Train Acc: 0.6400,
                        Val Loss: 0.7069, Val Acc: 0.5520, Test Acc: 0.5388
2022-09-05 19:05:23,606:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 19:05:45,470:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6006 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:05:45,470:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.86s, LR: 0.00050, Train Loss: 0.6422, Train Acc: 0.6850,
                        Val Loss: 0.6536, Val Acc: 0.6150, Test Acc: 0.6006
2022-09-05 19:05:45,470:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 19:06:07,615:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6030 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:06:07,615:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.15s, LR: 0.00050, Train Loss: 0.6751, Train Acc: 0.5900,
                        Val Loss: 0.6607, Val Acc: 0.6010, Test Acc: 0.6030
2022-09-05 19:06:07,615:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 19:06:29,600:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6049 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:06:29,600:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.98s, LR: 0.00050, Train Loss: 0.6190, Train Acc: 0.6800,
                        Val Loss: 0.6472, Val Acc: 0.6260, Test Acc: 0.6049
2022-09-05 19:06:29,600:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 19:06:51,038:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.44s, LR: 0.00050, Train Loss: 0.6153, Train Acc: 0.6800,
                        Val Loss: 0.8593, Val Acc: 0.5870, Test Acc: 0.5725
2022-09-05 19:06:51,039:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 19:07:13,605:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.57s, LR: 0.00050, Train Loss: 0.6238, Train Acc: 0.6400,
                        Val Loss: 0.8062, Val Acc: 0.5530, Test Acc: 0.5487
2022-09-05 19:07:13,606:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 19:07:37,411:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.80s, LR: 0.00050, Train Loss: 0.6148, Train Acc: 0.6700,
                        Val Loss: 0.6566, Val Acc: 0.6020, Test Acc: 0.5977
2022-09-05 19:07:37,411:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 19:08:00,304:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6146 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:08:00,304:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.89s, LR: 0.00050, Train Loss: 0.5793, Train Acc: 0.7250,
                        Val Loss: 0.6498, Val Acc: 0.6360, Test Acc: 0.6146
2022-09-05 19:08:00,304:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 19:08:23,986:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.68s, LR: 0.00050, Train Loss: 0.5736, Train Acc: 0.6850,
                        Val Loss: 0.8173, Val Acc: 0.5740, Test Acc: 0.5665
2022-09-05 19:08:23,987:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 19:08:47,069:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.08s, LR: 0.00050, Train Loss: 0.5745, Train Acc: 0.6700,
                        Val Loss: 0.7350, Val Acc: 0.5890, Test Acc: 0.5810
2022-09-05 19:08:47,069:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 19:09:09,851:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.78s, LR: 0.00050, Train Loss: 0.5796, Train Acc: 0.6900,
                        Val Loss: 0.8667, Val Acc: 0.5600, Test Acc: 0.5606
2022-09-05 19:09:09,851:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 19:09:35,838:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6189 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:09:35,839:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.99s, LR: 0.00050, Train Loss: 0.5679, Train Acc: 0.7050,
                        Val Loss: 0.6999, Val Acc: 0.6300, Test Acc: 0.6189
2022-09-05 19:09:35,839:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 19:10:01,462:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.62s, LR: 0.00050, Train Loss: 0.5497, Train Acc: 0.7000,
                        Val Loss: 0.8024, Val Acc: 0.6050, Test Acc: 0.5975
2022-09-05 19:10:01,463:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 19:10:26,903:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.44s, LR: 0.00050, Train Loss: 0.5854, Train Acc: 0.7000,
                        Val Loss: 0.9826, Val Acc: 0.6260, Test Acc: 0.6153
2022-09-05 19:10:26,904:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 19:10:53,184:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6277 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:10:53,185:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.28s, LR: 0.00050, Train Loss: 0.5595, Train Acc: 0.7200,
                        Val Loss: 0.7601, Val Acc: 0.6420, Test Acc: 0.6277
2022-09-05 19:10:53,185:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 19:11:18,569:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.38s, LR: 0.00025, Train Loss: 0.5024, Train Acc: 0.7450,
                        Val Loss: 0.8377, Val Acc: 0.6370, Test Acc: 0.6190
2022-09-05 19:11:18,569:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 19:11:43,405:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6767 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:11:43,405:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.84s, LR: 0.00025, Train Loss: 0.5334, Train Acc: 0.7600,
                        Val Loss: 0.6140, Val Acc: 0.6930, Test Acc: 0.6767
2022-09-05 19:11:43,405:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 19:12:08,395:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.99s, LR: 0.00025, Train Loss: 0.4852, Train Acc: 0.7850,
                        Val Loss: 0.7462, Val Acc: 0.6360, Test Acc: 0.6347
2022-09-05 19:12:08,396:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 19:12:34,338:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.94s, LR: 0.00025, Train Loss: 0.4658, Train Acc: 0.8000,
                        Val Loss: 0.6202, Val Acc: 0.6920, Test Acc: 0.6707
2022-09-05 19:12:34,339:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 19:13:00,321:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.98s, LR: 0.00025, Train Loss: 0.4770, Train Acc: 0.7750,
                        Val Loss: 0.7133, Val Acc: 0.6350, Test Acc: 0.6294
2022-09-05 19:13:00,321:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 19:13:26,041:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.72s, LR: 0.00025, Train Loss: 0.4542, Train Acc: 0.8100,
                        Val Loss: 0.7455, Val Acc: 0.6620, Test Acc: 0.6534
2022-09-05 19:13:26,042:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 19:13:52,794:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.75s, LR: 0.00025, Train Loss: 0.4136, Train Acc: 0.8250,
                        Val Loss: 0.6264, Val Acc: 0.6850, Test Acc: 0.6756
2022-09-05 19:13:52,795:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 19:14:18,790:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.00s, LR: 0.00025, Train Loss: 0.4489, Train Acc: 0.8000,
                        Val Loss: 0.6908, Val Acc: 0.6660, Test Acc: 0.6549
2022-09-05 19:14:18,791:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 19:14:45,151:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.36s, LR: 0.00025, Train Loss: 0.4388, Train Acc: 0.8300,
                        Val Loss: 0.6662, Val Acc: 0.6620, Test Acc: 0.6519
2022-09-05 19:14:45,152:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 19:15:11,769:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.62s, LR: 0.00025, Train Loss: 0.4285, Train Acc: 0.8050,
                        Val Loss: 0.7627, Val Acc: 0.6190, Test Acc: 0.6091
2022-09-05 19:15:11,770:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 19:15:38,634:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.86s, LR: 0.00025, Train Loss: 0.4633, Train Acc: 0.7800,
                        Val Loss: 0.7684, Val Acc: 0.6780, Test Acc: 0.6587
2022-09-05 19:15:38,635:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 19:16:04,815:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6798 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_19h00m46s_on_Sep_05_2022/MODELS_
2022-09-05 19:16:04,815:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.18s, LR: 0.00025, Train Loss: 0.4565, Train Acc: 0.7850,
                        Val Loss: 0.6712, Val Acc: 0.6850, Test Acc: 0.6798
2022-09-05 19:16:04,815:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 19:16:31,481:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.67s, LR: 0.00025, Train Loss: 0.4689, Train Acc: 0.8250,
                        Val Loss: 1.1790, Val Acc: 0.5890, Test Acc: 0.5828
2022-09-05 19:16:31,481:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 19:16:57,683:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.20s, LR: 0.00013, Train Loss: 0.4133, Train Acc: 0.8200,
                        Val Loss: 0.7617, Val Acc: 0.6510, Test Acc: 0.6579
2022-09-05 19:16:57,683:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 19:17:11,609:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 19:17:16,603:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 80, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 19:17:16,603:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 19:17:16,603:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 19:17:16,608:pe_layer.py:129 -             __init__(): Using 80 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 19:17:16,608:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 19:17:16,608:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 19:17:16,614:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 19:17:16,615:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 535623
2022-09-05 19:17:16,615:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 19:17:16,616:pe_layer.py:129 -             __init__(): Using 80 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 19:17:16,616:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 19:17:16,616:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 19:17:16,621:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (80).
2022-09-05 19:30:22,779:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:786.163412809372
2022-09-05 19:30:22,804:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 19:30:22,804:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 19:30:22,804:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 19:30:22,805:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 19:30:22,807:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 19:30:48,239:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.4987 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:30:48,240:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.43s, LR: 0.00050, Train Loss: 0.9232, Train Acc: 0.5050,
                        Val Loss: 1.6512, Val Acc: 0.4940, Test Acc: 0.4987
2022-09-05 19:30:48,241:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 19:31:12,821:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:31:12,822:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.58s, LR: 0.00050, Train Loss: 0.7771, Train Acc: 0.5550,
                        Val Loss: 1.1697, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 19:31:12,822:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 19:31:36,965:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00050, Train Loss: 0.7079, Train Acc: 0.5050,
                        Val Loss: 0.7540, Val Acc: 0.4760, Test Acc: 0.4815
2022-09-05 19:31:36,965:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 19:32:01,012:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5080 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:32:01,012:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.05s, LR: 0.00050, Train Loss: 0.6825, Train Acc: 0.5350,
                        Val Loss: 1.0565, Val Acc: 0.5270, Test Acc: 0.5080
2022-09-05 19:32:01,012:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 19:32:25,103:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5233 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:32:25,103:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.09s, LR: 0.00050, Train Loss: 0.7729, Train Acc: 0.5300,
                        Val Loss: 0.7011, Val Acc: 0.5400, Test Acc: 0.5233
2022-09-05 19:32:25,103:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 19:32:49,157:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.05s, LR: 0.00050, Train Loss: 0.7429, Train Acc: 0.5300,
                        Val Loss: 0.8780, Val Acc: 0.5350, Test Acc: 0.5233
2022-09-05 19:32:49,158:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 19:33:13,324:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00050, Train Loss: 0.7514, Train Acc: 0.5750,
                        Val Loss: 0.7133, Val Acc: 0.5170, Test Acc: 0.5037
2022-09-05 19:33:13,325:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 19:33:37,422:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00050, Train Loss: 0.6603, Train Acc: 0.6300,
                        Val Loss: 0.7679, Val Acc: 0.5080, Test Acc: 0.5044
2022-09-05 19:33:37,423:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 19:34:01,499:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5244 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:34:01,500:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.08s, LR: 0.00050, Train Loss: 0.6555, Train Acc: 0.6250,
                        Val Loss: 0.7395, Val Acc: 0.5280, Test Acc: 0.5244
2022-09-05 19:34:01,500:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 19:34:25,657:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5294 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:34:25,658:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.16s, LR: 0.00050, Train Loss: 0.6528, Train Acc: 0.6550,
                        Val Loss: 0.7585, Val Acc: 0.5330, Test Acc: 0.5294
2022-09-05 19:34:25,658:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 19:34:49,802:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00050, Train Loss: 0.6491, Train Acc: 0.6050,
                        Val Loss: 0.7314, Val Acc: 0.5320, Test Acc: 0.5243
2022-09-05 19:34:49,803:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 19:35:13,942:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5942 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:35:13,943:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00050, Train Loss: 0.6269, Train Acc: 0.6550,
                        Val Loss: 0.6596, Val Acc: 0.6140, Test Acc: 0.5942
2022-09-05 19:35:13,943:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 19:35:38,082:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6150 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:35:38,084:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00050, Train Loss: 0.6362, Train Acc: 0.6150,
                        Val Loss: 0.6445, Val Acc: 0.6200, Test Acc: 0.6150
2022-09-05 19:35:38,084:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 19:36:02,187:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00050, Train Loss: 0.6342, Train Acc: 0.6400,
                        Val Loss: 0.7224, Val Acc: 0.5570, Test Acc: 0.5783
2022-09-05 19:36:02,188:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 19:36:26,364:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6208 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:36:26,365:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00050, Train Loss: 0.6364, Train Acc: 0.6700,
                        Val Loss: 0.6411, Val Acc: 0.6400, Test Acc: 0.6208
2022-09-05 19:36:26,365:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 19:36:50,921:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.56s, LR: 0.00050, Train Loss: 0.5904, Train Acc: 0.6950,
                        Val Loss: 0.8858, Val Acc: 0.5050, Test Acc: 0.5081
2022-09-05 19:36:50,922:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 19:37:15,137:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.22s, LR: 0.00050, Train Loss: 0.5538, Train Acc: 0.7300,
                        Val Loss: 0.7444, Val Acc: 0.5540, Test Acc: 0.5583
2022-09-05 19:37:15,137:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 19:37:39,476:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6410 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:37:39,477:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.34s, LR: 0.00050, Train Loss: 0.5373, Train Acc: 0.7650,
                        Val Loss: 0.6581, Val Acc: 0.6470, Test Acc: 0.6410
2022-09-05 19:37:39,477:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 19:38:03,641:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6613 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:38:03,642:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00050, Train Loss: 0.5784, Train Acc: 0.7250,
                        Val Loss: 0.6608, Val Acc: 0.6730, Test Acc: 0.6613
2022-09-05 19:38:03,642:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 19:38:27,903:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.26s, LR: 0.00050, Train Loss: 0.5843, Train Acc: 0.7250,
                        Val Loss: 0.7265, Val Acc: 0.6370, Test Acc: 0.6256
2022-09-05 19:38:27,904:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 19:38:52,087:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00050, Train Loss: 0.5793, Train Acc: 0.7050,
                        Val Loss: 0.7722, Val Acc: 0.5850, Test Acc: 0.5823
2022-09-05 19:38:52,087:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 19:39:16,336:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.25s, LR: 0.00050, Train Loss: 0.5795, Train Acc: 0.6950,
                        Val Loss: 0.6353, Val Acc: 0.6660, Test Acc: 0.6383
2022-09-05 19:39:16,337:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 19:39:40,528:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.19s, LR: 0.00050, Train Loss: 0.5656, Train Acc: 0.7050,
                        Val Loss: 1.0813, Val Acc: 0.5180, Test Acc: 0.5154
2022-09-05 19:39:40,528:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 19:40:04,658:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.13s, LR: 0.00050, Train Loss: 0.5209, Train Acc: 0.7400,
                        Val Loss: 0.9124, Val Acc: 0.5190, Test Acc: 0.5250
2022-09-05 19:40:04,660:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 19:40:28,861:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.20s, LR: 0.00050, Train Loss: 0.5243, Train Acc: 0.7600,
                        Val Loss: 0.7525, Val Acc: 0.6490, Test Acc: 0.6327
2022-09-05 19:40:28,862:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 19:40:53,081:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.22s, LR: 0.00050, Train Loss: 0.5583, Train Acc: 0.7100,
                        Val Loss: 0.7915, Val Acc: 0.5920, Test Acc: 0.5907
2022-09-05 19:40:53,083:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 19:41:17,245:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6975 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:41:17,246:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.16s, LR: 0.00050, Train Loss: 0.4926, Train Acc: 0.7850,
                        Val Loss: 0.5990, Val Acc: 0.6960, Test Acc: 0.6975
2022-09-05 19:41:17,246:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 19:41:41,394:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.15s, LR: 0.00050, Train Loss: 0.4616, Train Acc: 0.8150,
                        Val Loss: 0.7520, Val Acc: 0.6140, Test Acc: 0.6030
2022-09-05 19:41:41,395:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 19:42:05,524:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.13s, LR: 0.00050, Train Loss: 0.4260, Train Acc: 0.8250,
                        Val Loss: 0.7516, Val Acc: 0.6330, Test Acc: 0.6245
2022-09-05 19:42:05,524:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 19:42:29,841:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.32s, LR: 0.00050, Train Loss: 0.3970, Train Acc: 0.8200,
                        Val Loss: 0.6905, Val Acc: 0.6610, Test Acc: 0.6489
2022-09-05 19:42:29,842:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 19:42:54,016:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00050, Train Loss: 0.4398, Train Acc: 0.8150,
                        Val Loss: 0.9551, Val Acc: 0.6280, Test Acc: 0.6275
2022-09-05 19:42:54,017:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 19:43:18,171:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.15s, LR: 0.00050, Train Loss: 0.4370, Train Acc: 0.8150,
                        Val Loss: 1.3532, Val Acc: 0.5610, Test Acc: 0.5534
2022-09-05 19:43:18,173:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 19:43:42,339:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00050, Train Loss: 0.3924, Train Acc: 0.8550,
                        Val Loss: 1.1233, Val Acc: 0.5550, Test Acc: 0.5463
2022-09-05 19:43:42,340:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 19:44:06,520:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00050, Train Loss: 0.4894, Train Acc: 0.7500,
                        Val Loss: 0.9430, Val Acc: 0.5580, Test Acc: 0.5633
2022-09-05 19:44:06,521:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 19:44:30,698:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00050, Train Loss: 0.5062, Train Acc: 0.7750,
                        Val Loss: 1.0515, Val Acc: 0.5660, Test Acc: 0.5585
2022-09-05 19:44:30,699:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 19:44:54,869:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00050, Train Loss: 0.4855, Train Acc: 0.7850,
                        Val Loss: 1.0203, Val Acc: 0.6320, Test Acc: 0.6474
2022-09-05 19:44:54,869:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 19:45:19,017:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.15s, LR: 0.00050, Train Loss: 0.4227, Train Acc: 0.8300,
                        Val Loss: 0.7952, Val Acc: 0.6260, Test Acc: 0.6173
2022-09-05 19:45:19,018:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 19:45:43,114:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00050, Train Loss: 0.3853, Train Acc: 0.8250,
                        Val Loss: 0.8003, Val Acc: 0.6270, Test Acc: 0.6312
2022-09-05 19:45:43,115:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 19:46:07,229:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.11s, LR: 0.00025, Train Loss: 0.3844, Train Acc: 0.8450,
                        Val Loss: 0.7714, Val Acc: 0.6630, Test Acc: 0.6521
2022-09-05 19:46:07,229:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 19:46:31,383:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.15s, LR: 0.00025, Train Loss: 0.3296, Train Acc: 0.8800,
                        Val Loss: 0.8215, Val Acc: 0.6730, Test Acc: 0.6751
2022-09-05 19:46:31,385:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 19:46:55,552:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00025, Train Loss: 0.3218, Train Acc: 0.8900,
                        Val Loss: 0.7085, Val Acc: 0.6750, Test Acc: 0.6700
2022-09-05 19:46:55,552:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 19:47:19,815:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.26s, LR: 0.00025, Train Loss: 0.3446, Train Acc: 0.8550,
                        Val Loss: 0.7866, Val Acc: 0.6560, Test Acc: 0.6559
2022-09-05 19:47:19,815:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 19:47:43,920:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00025, Train Loss: 0.2963, Train Acc: 0.8850,
                        Val Loss: 0.7003, Val Acc: 0.6870, Test Acc: 0.6791
2022-09-05 19:47:43,921:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 19:48:08,135:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7107 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:48:08,135:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.21s, LR: 0.00025, Train Loss: 0.2816, Train Acc: 0.8700,
                        Val Loss: 0.6513, Val Acc: 0.7200, Test Acc: 0.7107
2022-09-05 19:48:08,136:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 45/1000
2022-09-05 19:48:32,392:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.26s, LR: 0.00025, Train Loss: 0.2872, Train Acc: 0.8800,
                        Val Loss: 0.7069, Val Acc: 0.7030, Test Acc: 0.6996
2022-09-05 19:48:32,393:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 46/1000
2022-09-05 19:48:56,557:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.16s, LR: 0.00025, Train Loss: 0.3034, Train Acc: 0.8850,
                        Val Loss: 0.7150, Val Acc: 0.6950, Test Acc: 0.6854
2022-09-05 19:48:56,557:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 47/1000
2022-09-05 19:49:20,797:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7108 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:49:20,798:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.24s, LR: 0.00025, Train Loss: 0.3071, Train Acc: 0.8750,
                        Val Loss: 0.6806, Val Acc: 0.7100, Test Acc: 0.7108
2022-09-05 19:49:20,798:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 48/1000
2022-09-05 19:49:44,937:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00025, Train Loss: 0.2450, Train Acc: 0.9000,
                        Val Loss: 0.7890, Val Acc: 0.6800, Test Acc: 0.6773
2022-09-05 19:49:44,938:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 49/1000
2022-09-05 19:50:09,549:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.61s, LR: 0.00025, Train Loss: 0.2758, Train Acc: 0.8850,
                        Val Loss: 0.7206, Val Acc: 0.7080, Test Acc: 0.7032
2022-09-05 19:50:09,550:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 50/1000
2022-09-05 19:50:33,769:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.22s, LR: 0.00013, Train Loss: 0.2438, Train Acc: 0.9200,
                        Val Loss: 0.6909, Val Acc: 0.7150, Test Acc: 0.7104
2022-09-05 19:50:33,770:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 51/1000
2022-09-05 19:50:57,776:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.01s, LR: 0.00013, Train Loss: 0.2347, Train Acc: 0.9100,
                        Val Loss: 0.7112, Val Acc: 0.6910, Test Acc: 0.6967
2022-09-05 19:50:57,777:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 52/1000
2022-09-05 19:51:22,216:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.44s, LR: 0.00013, Train Loss: 0.2402, Train Acc: 0.9250,
                        Val Loss: 0.6759, Val Acc: 0.7200, Test Acc: 0.7098
2022-09-05 19:51:22,217:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 53/1000
2022-09-05 19:51:46,411:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.19s, LR: 0.00013, Train Loss: 0.1986, Train Acc: 0.9250,
                        Val Loss: 0.6722, Val Acc: 0.7170, Test Acc: 0.7076
2022-09-05 19:51:46,411:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 54/1000
2022-09-05 19:52:10,615:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.20s, LR: 0.00013, Train Loss: 0.2420, Train Acc: 0.8900,
                        Val Loss: 0.6983, Val Acc: 0.7070, Test Acc: 0.6989
2022-09-05 19:52:10,616:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 55/1000
2022-09-05 19:52:34,786:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00013, Train Loss: 0.1899, Train Acc: 0.9300,
                        Val Loss: 0.7702, Val Acc: 0.6830, Test Acc: 0.6836
2022-09-05 19:52:34,787:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 56/1000
2022-09-05 19:52:59,104:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.32s, LR: 0.00013, Train Loss: 0.2033, Train Acc: 0.9250,
                        Val Loss: 0.7432, Val Acc: 0.7110, Test Acc: 0.7043
2022-09-05 19:52:59,104:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 57/1000
2022-09-05 19:53:23,443:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.34s, LR: 0.00013, Train Loss: 0.1672, Train Acc: 0.9400,
                        Val Loss: 0.7307, Val Acc: 0.7120, Test Acc: 0.7094
2022-09-05 19:53:23,443:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 58/1000
2022-09-05 19:53:47,883:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.44s, LR: 0.00013, Train Loss: 0.1680, Train Acc: 0.9400,
                        Val Loss: 0.7448, Val Acc: 0.7110, Test Acc: 0.7090
2022-09-05 19:53:47,883:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 59/1000
2022-09-05 19:54:12,461:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.58s, LR: 0.00013, Train Loss: 0.1656, Train Acc: 0.9350,
                        Val Loss: 0.7405, Val Acc: 0.7210, Test Acc: 0.7101
2022-09-05 19:54:12,461:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 60/1000
2022-09-05 19:54:36,872:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7130 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:54:36,872:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.41s, LR: 0.00013, Train Loss: 0.1769, Train Acc: 0.9150,
                        Val Loss: 0.7453, Val Acc: 0.7200, Test Acc: 0.7130
2022-09-05 19:54:36,872:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 61/1000
2022-09-05 19:55:01,283:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.41s, LR: 0.00006, Train Loss: 0.1750, Train Acc: 0.9300,
                        Val Loss: 0.7472, Val Acc: 0.7130, Test Acc: 0.7100
2022-09-05 19:55:01,283:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 62/1000
2022-09-05 19:55:25,682:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.40s, LR: 0.00006, Train Loss: 0.1379, Train Acc: 0.9650,
                        Val Loss: 0.7504, Val Acc: 0.7160, Test Acc: 0.7122
2022-09-05 19:55:25,682:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 63/1000
2022-09-05 19:55:50,026:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7136 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:55:50,026:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.34s, LR: 0.00006, Train Loss: 0.1458, Train Acc: 0.9350,
                        Val Loss: 0.7448, Val Acc: 0.7250, Test Acc: 0.7136
2022-09-05 19:55:50,026:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 64/1000
2022-09-05 19:56:14,433:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7157 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_80_19h17m16s_on_Sep_05_2022/MODELS_
2022-09-05 19:56:14,433:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.41s, LR: 0.00006, Train Loss: 0.1756, Train Acc: 0.9400,
                        Val Loss: 0.7827, Val Acc: 0.7160, Test Acc: 0.7157
2022-09-05 19:56:14,433:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 65/1000
2022-09-05 19:56:38,889:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.46s, LR: 0.00006, Train Loss: 0.1961, Train Acc: 0.9200,
                        Val Loss: 0.7731, Val Acc: 0.7250, Test Acc: 0.7138
2022-09-05 19:56:38,890:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 66/1000
2022-09-05 19:57:03,251:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.36s, LR: 0.00006, Train Loss: 0.1614, Train Acc: 0.9300,
                        Val Loss: 0.7610, Val Acc: 0.7270, Test Acc: 0.7124
2022-09-05 19:57:03,251:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 67/1000
2022-09-05 19:57:29,215:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.96s, LR: 0.00006, Train Loss: 0.1480, Train Acc: 0.9500,
                        Val Loss: 0.7523, Val Acc: 0.7160, Test Acc: 0.7104
2022-09-05 19:57:29,216:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 68/1000
2022-09-05 19:58:16,158:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 19:58:21,064:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 19:58:21,064:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 19:58:21,064:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 19:58:21,065:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 19:58:21,065:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 19:58:21,065:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 19:58:21,070:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 19:58:21,071:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524763
2022-09-05 19:58:21,071:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 19:58:21,072:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 19:58:21,072:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 19:58:21,072:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 19:58:21,077:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-05 19:59:39,625:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:78.55410099029541
2022-09-05 19:59:39,644:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 19:59:39,645:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 19:59:39,645:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 19:59:39,645:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 19:59:39,647:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 20:00:05,153:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_19h58m21s_on_Sep_05_2022/MODELS_
2022-09-05 20:00:05,154:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.51s, LR: 0.00050, Train Loss: 0.7216, Train Acc: 0.6500,
                        Val Loss: 32.7560, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 20:00:05,154:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 20:00:32,245:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 27.09s, LR: 0.00050, Train Loss: 0.6707, Train Acc: 0.6550,
                        Val Loss: 3.7274, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 20:00:32,246:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 20:00:59,061:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.81s, LR: 0.00050, Train Loss: 0.5944, Train Acc: 0.6650,
                        Val Loss: 1.9483, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 20:00:59,061:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 20:01:24,801:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5002 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_19h58m21s_on_Sep_05_2022/MODELS_
2022-09-05 20:01:24,801:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.74s, LR: 0.00050, Train Loss: 0.5457, Train Acc: 0.7400,
                        Val Loss: 1.6732, Val Acc: 0.5000, Test Acc: 0.5002
2022-09-05 20:01:24,801:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 20:01:49,150:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6158 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_19h58m21s_on_Sep_05_2022/MODELS_
2022-09-05 20:01:49,150:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.35s, LR: 0.00050, Train Loss: 0.5546, Train Acc: 0.7000,
                        Val Loss: 0.6685, Val Acc: 0.6080, Test Acc: 0.6158
2022-09-05 20:01:49,150:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 20:02:13,500:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.35s, LR: 0.00050, Train Loss: 0.5076, Train Acc: 0.7400,
                        Val Loss: 3.6628, Val Acc: 0.5010, Test Acc: 0.5000
2022-09-05 20:02:13,501:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 20:02:37,942:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.44s, LR: 0.00050, Train Loss: 0.4858, Train Acc: 0.7750,
                        Val Loss: 0.8361, Val Acc: 0.5900, Test Acc: 0.5850
2022-09-05 20:02:37,943:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 20:03:02,401:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.46s, LR: 0.00050, Train Loss: 0.4853, Train Acc: 0.7550,
                        Val Loss: 0.8592, Val Acc: 0.5670, Test Acc: 0.5702
2022-09-05 20:03:02,402:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 20:03:26,933:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6828 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_19h58m21s_on_Sep_05_2022/MODELS_
2022-09-05 20:03:26,933:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.53s, LR: 0.00050, Train Loss: 0.4718, Train Acc: 0.7650,
                        Val Loss: 0.7163, Val Acc: 0.6770, Test Acc: 0.6828
2022-09-05 20:03:26,933:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 20:03:51,374:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.44s, LR: 0.00050, Train Loss: 0.4629, Train Acc: 0.7600,
                        Val Loss: 2.4899, Val Acc: 0.5010, Test Acc: 0.5021
2022-09-05 20:03:51,374:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 20:04:15,898:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.52s, LR: 0.00050, Train Loss: 0.4569, Train Acc: 0.7900,
                        Val Loss: 1.2088, Val Acc: 0.5020, Test Acc: 0.5008
2022-09-05 20:04:15,899:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 20:04:40,422:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6984 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_20_19h58m21s_on_Sep_05_2022/MODELS_
2022-09-05 20:04:40,423:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.52s, LR: 0.00050, Train Loss: 0.4293, Train Acc: 0.8000,
                        Val Loss: 0.6336, Val Acc: 0.6920, Test Acc: 0.6984
2022-09-05 20:04:40,423:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 20:05:04,809:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.39s, LR: 0.00050, Train Loss: 0.4447, Train Acc: 0.7800,
                        Val Loss: 0.8642, Val Acc: 0.5350, Test Acc: 0.5310
2022-09-05 20:05:04,810:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 20:05:29,392:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.58s, LR: 0.00050, Train Loss: 0.4205, Train Acc: 0.8200,
                        Val Loss: 0.9957, Val Acc: 0.5650, Test Acc: 0.5812
2022-09-05 20:05:29,393:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 20:05:53,818:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.42s, LR: 0.00050, Train Loss: 0.3921, Train Acc: 0.8000,
                        Val Loss: 4.7280, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 20:05:53,819:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 20:06:18,723:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.90s, LR: 0.00050, Train Loss: 0.3768, Train Acc: 0.8350,
                        Val Loss: 1.3749, Val Acc: 0.5680, Test Acc: 0.5648
2022-09-05 20:06:18,724:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 20:06:43,364:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.64s, LR: 0.00050, Train Loss: 0.3966, Train Acc: 0.8350,
                        Val Loss: 2.7657, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 20:06:43,365:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 20:07:08,284:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.92s, LR: 0.00050, Train Loss: 0.3675, Train Acc: 0.8400,
                        Val Loss: 2.8828, Val Acc: 0.5210, Test Acc: 0.5165
2022-09-05 20:07:08,284:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 20:08:09,459:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 20:08:13,084:main_molecules_graph_regression.py:340 -                 main(): {'num_train_data': 7000, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'edge_feat': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': 'DEBUG.log', 'device': device(type='cpu'), 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-05 20:08:13,084:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'saev'}
2022-09-05 20:08:13,084:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 20:08:13,085:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 20:08:13,085:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 20:08:13,085:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 20:08:13,090:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 20:08:13,091:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526354
2022-09-05 20:08:13,091:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 20:08:13,092:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 20:08:13,092:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 20:08:13,092:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 20:08:13,097:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 20:08:37,012:main_molecules_graph_regression.py:68 -   train_val_pipeline(): Time PE:23.92122507095337
2022-09-05 20:08:37,028:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 20:08:37,029:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 20:08:37,029:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-05 20:08:37,031:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 20:08:53,568:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.8672961592674255
2022-09-05 20:08:53,569:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.54s, LR: 0.00070, Train Loss: 1.1737, Train MAE: 1.1737,
                            Val Loss: 0.8220, Val Acc: 0.8220, Test MAE: 0.8673
2022-09-05 20:08:53,575:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 20:09:09,836:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.7512173280119896
2022-09-05 20:09:09,836:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.26s, LR: 0.00070, Train Loss: 0.7065, Train MAE: 0.7065,
                            Val Loss: 0.6951, Val Acc: 0.6951, Test MAE: 0.7512
2022-09-05 20:09:09,842:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 20:09:25,630:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.657515324652195
2022-09-05 20:09:25,630:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.79s, LR: 0.00070, Train Loss: 0.6460, Train MAE: 0.6460,
                            Val Loss: 0.6316, Val Acc: 0.6316, Test MAE: 0.6575
2022-09-05 20:09:25,636:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 20:09:41,062:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6273230612277985
2022-09-05 20:09:41,063:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.43s, LR: 0.00070, Train Loss: 0.6232, Train MAE: 0.6232,
                            Val Loss: 0.6005, Val Acc: 0.6005, Test MAE: 0.6273
2022-09-05 20:09:41,068:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 20:09:56,092:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.02s, LR: 0.00070, Train Loss: 0.5875, Train MAE: 0.5875,
                            Val Loss: 0.6573, Val Acc: 0.6573, Test MAE: 0.6846
2022-09-05 20:09:56,098:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 20:10:11,166:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5771476440131664
2022-09-05 20:10:11,166:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.07s, LR: 0.00070, Train Loss: 0.5658, Train MAE: 0.5658,
                            Val Loss: 0.5533, Val Acc: 0.5533, Test MAE: 0.5771
2022-09-05 20:10:11,172:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 20:10:26,169:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5600474402308464
2022-09-05 20:10:26,169:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.00s, LR: 0.00070, Train Loss: 0.5735, Train MAE: 0.5735,
                            Val Loss: 0.5381, Val Acc: 0.5381, Test MAE: 0.5600
2022-09-05 20:10:26,175:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 20:10:41,128:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5351083613932133
2022-09-05 20:10:41,128:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.95s, LR: 0.00070, Train Loss: 0.5151, Train MAE: 0.5151,
                            Val Loss: 0.5229, Val Acc: 0.5229, Test MAE: 0.5351
2022-09-05 20:10:41,135:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 20:10:56,099:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5172295495867729
2022-09-05 20:10:56,100:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.97s, LR: 0.00070, Train Loss: 0.4960, Train MAE: 0.4960,
                            Val Loss: 0.5015, Val Acc: 0.5015, Test MAE: 0.5172
2022-09-05 20:10:56,105:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 20:11:11,198:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5061141103506088
2022-09-05 20:11:11,198:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.09s, LR: 0.00070, Train Loss: 0.4742, Train MAE: 0.4742,
                            Val Loss: 0.4882, Val Acc: 0.4882, Test MAE: 0.5061
2022-09-05 20:11:11,204:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 20:11:26,229:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.48666178435087204
2022-09-05 20:11:26,230:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.03s, LR: 0.00070, Train Loss: 0.4630, Train MAE: 0.4630,
                            Val Loss: 0.4729, Val Acc: 0.4729, Test MAE: 0.4867
2022-09-05 20:11:26,235:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 20:11:41,365:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.13s, LR: 0.00070, Train Loss: 0.4604, Train MAE: 0.4604,
                            Val Loss: 0.4749, Val Acc: 0.4749, Test MAE: 0.4932
2022-09-05 20:11:41,371:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 20:11:56,392:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4761875979602337
2022-09-05 20:11:56,393:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.02s, LR: 0.00070, Train Loss: 0.4314, Train MAE: 0.4314,
                            Val Loss: 0.4596, Val Acc: 0.4596, Test MAE: 0.4762
2022-09-05 20:11:56,398:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 20:12:11,496:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.10s, LR: 0.00070, Train Loss: 0.4332, Train MAE: 0.4332,
                            Val Loss: 0.4980, Val Acc: 0.4980, Test MAE: 0.5289
2022-09-05 20:12:11,502:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 20:12:27,066:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.460066732019186
2022-09-05 20:12:27,066:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.56s, LR: 0.00070, Train Loss: 0.4256, Train MAE: 0.4256,
                            Val Loss: 0.4470, Val Acc: 0.4470, Test MAE: 0.4601
2022-09-05 20:12:27,072:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 20:12:43,145:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00070, Train Loss: 0.4116, Train MAE: 0.4116,
                            Val Loss: 0.4508, Val Acc: 0.4508, Test MAE: 0.4641
2022-09-05 20:12:43,150:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 20:12:59,029:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.88s, LR: 0.00070, Train Loss: 0.4067, Train MAE: 0.4067,
                            Val Loss: 0.4752, Val Acc: 0.4752, Test MAE: 0.4925
2022-09-05 20:12:59,034:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 20:13:15,038:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4463953413069248
2022-09-05 20:13:15,039:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.00s, LR: 0.00070, Train Loss: 0.4078, Train MAE: 0.4078,
                            Val Loss: 0.4217, Val Acc: 0.4217, Test MAE: 0.4464
2022-09-05 20:13:15,045:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 20:13:30,752:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.71s, LR: 0.00070, Train Loss: 0.3977, Train MAE: 0.3977,
                            Val Loss: 0.4431, Val Acc: 0.4431, Test MAE: 0.4569
2022-09-05 20:13:30,757:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 20:13:46,022:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.44025396928191185
2022-09-05 20:13:46,022:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.26s, LR: 0.00070, Train Loss: 0.3801, Train MAE: 0.3801,
                            Val Loss: 0.4255, Val Acc: 0.4255, Test MAE: 0.4403
2022-09-05 20:13:46,027:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 20:14:01,277:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.25s, LR: 0.00070, Train Loss: 0.3768, Train MAE: 0.3768,
                            Val Loss: 0.4475, Val Acc: 0.4475, Test MAE: 0.4542
2022-09-05 20:14:01,283:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 20:14:16,473:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4310154877603054
2022-09-05 20:14:16,473:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.19s, LR: 0.00070, Train Loss: 0.3734, Train MAE: 0.3734,
                            Val Loss: 0.4114, Val Acc: 0.4114, Test MAE: 0.4310
2022-09-05 20:14:16,479:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 20:14:31,763:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.28s, LR: 0.00070, Train Loss: 0.3662, Train MAE: 0.3662,
                            Val Loss: 0.4127, Val Acc: 0.4127, Test MAE: 0.4341
2022-09-05 20:14:31,768:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 20:14:46,996:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.42351236194372177
2022-09-05 20:14:46,997:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.23s, LR: 0.00070, Train Loss: 0.3715, Train MAE: 0.3715,
                            Val Loss: 0.4041, Val Acc: 0.4041, Test MAE: 0.4235
2022-09-05 20:14:47,002:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 20:15:02,199:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.40643489733338356
2022-09-05 20:15:02,199:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.20s, LR: 0.00070, Train Loss: 0.3493, Train MAE: 0.3493,
                            Val Loss: 0.3893, Val Acc: 0.3893, Test MAE: 0.4064
2022-09-05 20:15:02,204:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 20:15:17,443:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.24s, LR: 0.00070, Train Loss: 0.3456, Train MAE: 0.3456,
                            Val Loss: 0.3884, Val Acc: 0.3884, Test MAE: 0.4090
2022-09-05 20:15:17,449:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 20:15:32,749:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.30s, LR: 0.00070, Train Loss: 0.3487, Train MAE: 0.3487,
                            Val Loss: 0.4480, Val Acc: 0.4480, Test MAE: 0.4729
2022-09-05 20:15:32,754:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 20:15:48,024:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.27s, LR: 0.00070, Train Loss: 0.3512, Train MAE: 0.3512,
                            Val Loss: 0.4393, Val Acc: 0.4393, Test MAE: 0.4492
2022-09-05 20:15:48,030:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 20:16:03,340:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.31s, LR: 0.00070, Train Loss: 0.3462, Train MAE: 0.3462,
                            Val Loss: 0.4227, Val Acc: 0.4227, Test MAE: 0.4354
2022-09-05 20:16:03,346:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 20:16:18,565:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4036381244659424
2022-09-05 20:16:18,565:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.22s, LR: 0.00070, Train Loss: 0.3293, Train MAE: 0.3293,
                            Val Loss: 0.3957, Val Acc: 0.3957, Test MAE: 0.4036
2022-09-05 20:16:18,571:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 20:16:33,876:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.31s, LR: 0.00070, Train Loss: 0.3267, Train MAE: 0.3267,
                            Val Loss: 0.4016, Val Acc: 0.4016, Test MAE: 0.4144
2022-09-05 20:16:33,882:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 20:16:49,089:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.3842857889831066
2022-09-05 20:16:49,090:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.21s, LR: 0.00070, Train Loss: 0.3129, Train MAE: 0.3129,
                            Val Loss: 0.3838, Val Acc: 0.3838, Test MAE: 0.3843
2022-09-05 20:16:49,096:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 20:17:04,637:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.3767237178981304
2022-09-05 20:17:04,637:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.54s, LR: 0.00070, Train Loss: 0.3156, Train MAE: 0.3156,
                            Val Loss: 0.3859, Val Acc: 0.3859, Test MAE: 0.3767
2022-09-05 20:17:04,643:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 20:17:19,856:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.3715897873044014
2022-09-05 20:17:19,856:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.21s, LR: 0.00070, Train Loss: 0.3110, Train MAE: 0.3110,
                            Val Loss: 0.3784, Val Acc: 0.3784, Test MAE: 0.3716
2022-09-05 20:17:19,862:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 20:17:35,165:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.36132263392210007
2022-09-05 20:17:35,167:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.30s, LR: 0.00070, Train Loss: 0.3089, Train MAE: 0.3089,
                            Val Loss: 0.3689, Val Acc: 0.3689, Test MAE: 0.3613
2022-09-05 20:17:35,173:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 20:17:50,363:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.353364959359169
2022-09-05 20:17:50,364:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.19s, LR: 0.00070, Train Loss: 0.2913, Train MAE: 0.2913,
                            Val Loss: 0.3648, Val Acc: 0.3648, Test MAE: 0.3534
2022-09-05 20:17:50,369:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 20:18:05,564:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.19s, LR: 0.00070, Train Loss: 0.2880, Train MAE: 0.2880,
                            Val Loss: 0.4265, Val Acc: 0.4265, Test MAE: 0.4199
2022-09-05 20:18:05,569:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 20:18:20,734:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.32925983518362045
2022-09-05 20:18:20,734:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.16s, LR: 0.00070, Train Loss: 0.2974, Train MAE: 0.2974,
                            Val Loss: 0.3410, Val Acc: 0.3410, Test MAE: 0.3293
2022-09-05 20:18:20,740:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 20:18:35,944:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.20s, LR: 0.00070, Train Loss: 0.2786, Train MAE: 0.2786,
                            Val Loss: 0.3675, Val Acc: 0.3675, Test MAE: 0.3468
2022-09-05 20:18:35,950:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 20:18:51,211:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.26s, LR: 0.00070, Train Loss: 0.2804, Train MAE: 0.2804,
                            Val Loss: 0.3547, Val Acc: 0.3547, Test MAE: 0.3492
2022-09-05 20:18:51,216:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 20:19:06,506:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.29s, LR: 0.00070, Train Loss: 0.2712, Train MAE: 0.2712,
                            Val Loss: 0.3829, Val Acc: 0.3829, Test MAE: 0.3564
2022-09-05 20:19:06,512:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 20:19:24,234:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.3257550075650215
2022-09-05 20:19:24,236:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.72s, LR: 0.00070, Train Loss: 0.2935, Train MAE: 0.2935,
                            Val Loss: 0.3538, Val Acc: 0.3538, Test MAE: 0.3258
2022-09-05 20:19:24,242:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 20:19:40,272:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.30833008885383606
2022-09-05 20:19:40,273:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.03s, LR: 0.00070, Train Loss: 0.2585, Train MAE: 0.2585,
                            Val Loss: 0.3420, Val Acc: 0.3420, Test MAE: 0.3083
2022-09-05 20:19:40,278:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 20:19:55,759:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.48s, LR: 0.00070, Train Loss: 0.2502, Train MAE: 0.2502,
                            Val Loss: 0.3434, Val Acc: 0.3434, Test MAE: 0.3160
2022-09-05 20:19:55,764:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 45/1000
2022-09-05 20:20:11,040:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.28s, LR: 0.00070, Train Loss: 0.2572, Train MAE: 0.2572,
                            Val Loss: 0.3827, Val Acc: 0.3827, Test MAE: 0.3516
2022-09-05 20:20:11,046:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 46/1000
2022-09-05 20:20:26,417:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.37s, LR: 0.00070, Train Loss: 0.2463, Train MAE: 0.2463,
                            Val Loss: 0.4482, Val Acc: 0.4482, Test MAE: 0.4248
2022-09-05 20:20:26,422:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 47/1000
2022-09-05 20:20:42,008:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2950861304998398
2022-09-05 20:20:42,008:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.59s, LR: 0.00070, Train Loss: 0.2690, Train MAE: 0.2690,
                            Val Loss: 0.3428, Val Acc: 0.3428, Test MAE: 0.2951
2022-09-05 20:20:42,014:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 48/1000
2022-09-05 20:20:57,306:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.29s, LR: 0.00070, Train Loss: 0.2488, Train MAE: 0.2488,
                            Val Loss: 0.3443, Val Acc: 0.3443, Test MAE: 0.2976
2022-09-05 20:20:57,312:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 49/1000
2022-09-05 20:21:13,959:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.65s, LR: 0.00070, Train Loss: 0.2367, Train MAE: 0.2367,
                            Val Loss: 0.3522, Val Acc: 0.3522, Test MAE: 0.3149
2022-09-05 20:21:13,964:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 50/1000
2022-09-05 20:21:30,432:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.27497557923197746
2022-09-05 20:21:30,432:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.47s, LR: 0.00035, Train Loss: 0.2056, Train MAE: 0.2056,
                            Val Loss: 0.3088, Val Acc: 0.3088, Test MAE: 0.2750
2022-09-05 20:21:30,438:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 51/1000
2022-09-05 20:21:46,071:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.63s, LR: 0.00035, Train Loss: 0.1901, Train MAE: 0.1901,
                            Val Loss: 0.3078, Val Acc: 0.3078, Test MAE: 0.2797
2022-09-05 20:21:46,077:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 52/1000
2022-09-05 20:22:01,488:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.41s, LR: 0.00035, Train Loss: 0.1835, Train MAE: 0.1835,
                            Val Loss: 0.3064, Val Acc: 0.3064, Test MAE: 0.2793
2022-09-05 20:22:01,494:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 53/1000
2022-09-05 20:22:16,821:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.27184219658374786
2022-09-05 20:22:16,821:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.33s, LR: 0.00035, Train Loss: 0.1840, Train MAE: 0.1840,
                            Val Loss: 0.3039, Val Acc: 0.3039, Test MAE: 0.2718
2022-09-05 20:22:16,827:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 54/1000
2022-09-05 20:22:32,087:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.26s, LR: 0.00035, Train Loss: 0.1741, Train MAE: 0.1741,
                            Val Loss: 0.3140, Val Acc: 0.3140, Test MAE: 0.2818
2022-09-05 20:22:32,092:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 55/1000
2022-09-05 20:22:47,492:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2700135111808777
2022-09-05 20:22:47,493:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.40s, LR: 0.00035, Train Loss: 0.1729, Train MAE: 0.1729,
                            Val Loss: 0.3000, Val Acc: 0.3000, Test MAE: 0.2700
2022-09-05 20:22:47,498:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 56/1000
2022-09-05 20:23:02,874:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.38s, LR: 0.00035, Train Loss: 0.1664, Train MAE: 0.1664,
                            Val Loss: 0.2943, Val Acc: 0.2943, Test MAE: 0.2701
2022-09-05 20:23:02,879:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 57/1000
2022-09-05 20:23:18,269:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.39s, LR: 0.00035, Train Loss: 0.1670, Train MAE: 0.1670,
                            Val Loss: 0.3209, Val Acc: 0.3209, Test MAE: 0.2829
2022-09-05 20:23:18,274:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 58/1000
2022-09-05 20:23:33,645:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.37s, LR: 0.00035, Train Loss: 0.1645, Train MAE: 0.1645,
                            Val Loss: 0.3059, Val Acc: 0.3059, Test MAE: 0.2730
2022-09-05 20:23:33,651:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 59/1000
2022-09-05 20:23:49,036:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.39s, LR: 0.00035, Train Loss: 0.1607, Train MAE: 0.1607,
                            Val Loss: 0.3045, Val Acc: 0.3045, Test MAE: 0.2729
2022-09-05 20:23:49,041:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 60/1000
2022-09-05 20:24:04,441:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.40s, LR: 0.00035, Train Loss: 0.1553, Train MAE: 0.1553,
                            Val Loss: 0.3096, Val Acc: 0.3096, Test MAE: 0.2726
2022-09-05 20:24:04,446:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 61/1000
2022-09-05 20:24:19,767:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.32s, LR: 0.00035, Train Loss: 0.1525, Train MAE: 0.1525,
                            Val Loss: 0.3046, Val Acc: 0.3046, Test MAE: 0.2704
2022-09-05 20:24:19,773:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 62/1000
2022-09-05 20:24:35,164:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.26284370571374893
2022-09-05 20:24:35,164:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.39s, LR: 0.00035, Train Loss: 0.1535, Train MAE: 0.1535,
                            Val Loss: 0.2997, Val Acc: 0.2997, Test MAE: 0.2628
2022-09-05 20:24:35,170:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 63/1000
2022-09-05 20:24:50,603:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.43s, LR: 0.00035, Train Loss: 0.1477, Train MAE: 0.1477,
                            Val Loss: 0.2943, Val Acc: 0.2943, Test MAE: 0.2646
2022-09-05 20:24:50,609:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 64/1000
2022-09-05 20:25:05,320:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.71s, LR: 0.00035, Train Loss: 0.1467, Train MAE: 0.1467,
                            Val Loss: 0.2976, Val Acc: 0.2976, Test MAE: 0.2667
2022-09-05 20:25:05,325:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 65/1000
2022-09-05 20:25:18,549:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 13.22s, LR: 0.00035, Train Loss: 0.1460, Train MAE: 0.1460,
                            Val Loss: 0.2992, Val Acc: 0.2992, Test MAE: 0.2694
2022-09-05 20:25:18,555:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 66/1000
2022-09-05 20:25:31,500:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 12.95s, LR: 0.00035, Train Loss: 0.1419, Train MAE: 0.1419,
                            Val Loss: 0.3286, Val Acc: 0.3286, Test MAE: 0.2928
2022-09-05 20:25:31,506:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 67/1000
2022-09-05 20:25:45,701:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.20s, LR: 0.00035, Train Loss: 0.1524, Train MAE: 0.1524,
                            Val Loss: 0.3043, Val Acc: 0.3043, Test MAE: 0.2656
2022-09-05 20:25:45,707:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 68/1000
2022-09-05 20:25:59,700:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 13.99s, LR: 0.00017, Train Loss: 0.1241, Train MAE: 0.1241,
                            Val Loss: 0.2912, Val Acc: 0.2912, Test MAE: 0.2641
2022-09-05 20:25:59,705:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 69/1000
2022-09-05 20:26:14,646:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2566402517259121
2022-09-05 20:26:14,647:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.94s, LR: 0.00017, Train Loss: 0.1168, Train MAE: 0.1168,
                            Val Loss: 0.2920, Val Acc: 0.2920, Test MAE: 0.2566
2022-09-05 20:26:14,653:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 70/1000
2022-09-05 20:26:29,982:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.33s, LR: 0.00017, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.2903, Val Acc: 0.2903, Test MAE: 0.2584
2022-09-05 20:26:29,987:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 71/1000
2022-09-05 20:26:45,779:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.79s, LR: 0.00017, Train Loss: 0.1110, Train MAE: 0.1110,
                            Val Loss: 0.2931, Val Acc: 0.2931, Test MAE: 0.2604
2022-09-05 20:26:45,785:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 72/1000
2022-09-05 20:27:01,415:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.63s, LR: 0.00017, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.2959, Val Acc: 0.2959, Test MAE: 0.2577
2022-09-05 20:27:01,420:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 73/1000
2022-09-05 20:27:17,107:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.69s, LR: 0.00017, Train Loss: 0.1062, Train MAE: 0.1062,
                            Val Loss: 0.2927, Val Acc: 0.2927, Test MAE: 0.2618
2022-09-05 20:27:17,112:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 74/1000
2022-09-05 20:27:32,896:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.78s, LR: 0.00017, Train Loss: 0.1059, Train MAE: 0.1059,
                            Val Loss: 0.2932, Val Acc: 0.2932, Test MAE: 0.2624
2022-09-05 20:27:32,901:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 75/1000
2022-09-05 20:27:48,665:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.76s, LR: 0.00017, Train Loss: 0.1030, Train MAE: 0.1030,
                            Val Loss: 0.2949, Val Acc: 0.2949, Test MAE: 0.2606
2022-09-05 20:27:48,670:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 76/1000
2022-09-05 20:28:04,705:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.03s, LR: 0.00017, Train Loss: 0.1023, Train MAE: 0.1023,
                            Val Loss: 0.2957, Val Acc: 0.2957, Test MAE: 0.2616
2022-09-05 20:28:04,711:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 77/1000
2022-09-05 20:28:20,397:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.69s, LR: 0.00017, Train Loss: 0.1021, Train MAE: 0.1021,
                            Val Loss: 0.2932, Val Acc: 0.2932, Test MAE: 0.2598
2022-09-05 20:28:20,403:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 78/1000
2022-09-05 20:28:36,130:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.73s, LR: 0.00017, Train Loss: 0.0990, Train MAE: 0.0990,
                            Val Loss: 0.2932, Val Acc: 0.2932, Test MAE: 0.2633
2022-09-05 20:28:36,136:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 79/1000
2022-09-05 20:28:51,863:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.73s, LR: 0.00017, Train Loss: 0.1009, Train MAE: 0.1009,
                            Val Loss: 0.2898, Val Acc: 0.2898, Test MAE: 0.2626
2022-09-05 20:28:51,868:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 80/1000
2022-09-05 20:29:07,597:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.73s, LR: 0.00017, Train Loss: 0.0986, Train MAE: 0.0986,
                            Val Loss: 0.2928, Val Acc: 0.2928, Test MAE: 0.2626
2022-09-05 20:29:07,603:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 81/1000
2022-09-05 20:29:23,347:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.74s, LR: 0.00017, Train Loss: 0.1012, Train MAE: 0.1012,
                            Val Loss: 0.2911, Val Acc: 0.2911, Test MAE: 0.2605
2022-09-05 20:29:23,352:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 82/1000
2022-09-05 20:29:39,000:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.65s, LR: 0.00017, Train Loss: 0.1024, Train MAE: 0.1024,
                            Val Loss: 0.2953, Val Acc: 0.2953, Test MAE: 0.2607
2022-09-05 20:29:39,005:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 83/1000
2022-09-05 20:29:54,772:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.77s, LR: 0.00017, Train Loss: 0.0965, Train MAE: 0.0965,
                            Val Loss: 0.2951, Val Acc: 0.2951, Test MAE: 0.2646
2022-09-05 20:29:54,777:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 84/1000
2022-09-05 20:30:10,545:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.77s, LR: 0.00017, Train Loss: 0.0952, Train MAE: 0.0952,
                            Val Loss: 0.2940, Val Acc: 0.2940, Test MAE: 0.2603
2022-09-05 20:30:10,551:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 85/1000
2022-09-05 20:30:26,304:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.75s, LR: 0.00017, Train Loss: 0.0925, Train MAE: 0.0925,
                            Val Loss: 0.2901, Val Acc: 0.2901, Test MAE: 0.2623
2022-09-05 20:30:26,310:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 86/1000
2022-09-05 20:30:42,089:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.78s, LR: 0.00017, Train Loss: 0.0906, Train MAE: 0.0906,
                            Val Loss: 0.2951, Val Acc: 0.2951, Test MAE: 0.2588
2022-09-05 20:30:42,095:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 87/1000
2022-09-05 20:30:57,783:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.69s, LR: 0.00017, Train Loss: 0.0899, Train MAE: 0.0899,
                            Val Loss: 0.2950, Val Acc: 0.2950, Test MAE: 0.2661
2022-09-05 20:30:57,789:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 88/1000
2022-09-05 20:31:13,665:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.88s, LR: 0.00017, Train Loss: 0.0885, Train MAE: 0.0885,
                            Val Loss: 0.2934, Val Acc: 0.2934, Test MAE: 0.2623
2022-09-05 20:31:13,671:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 89/1000
2022-09-05 20:31:29,426:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.75s, LR: 0.00017, Train Loss: 0.0896, Train MAE: 0.0896,
                            Val Loss: 0.2936, Val Acc: 0.2936, Test MAE: 0.2594
2022-09-05 20:31:29,431:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 90/1000
2022-09-05 20:31:45,178:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.75s, LR: 0.00017, Train Loss: 0.0887, Train MAE: 0.0887,
                            Val Loss: 0.2915, Val Acc: 0.2915, Test MAE: 0.2652
2022-09-05 20:31:45,183:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 91/1000
2022-09-05 20:32:01,135:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.95s, LR: 0.00009, Train Loss: 0.0786, Train MAE: 0.0786,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2601
2022-09-05 20:32:01,140:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 92/1000
2022-09-05 20:32:17,738:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.60s, LR: 0.00009, Train Loss: 0.0717, Train MAE: 0.0717,
                            Val Loss: 0.2908, Val Acc: 0.2908, Test MAE: 0.2600
2022-09-05 20:32:17,743:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 93/1000
2022-09-05 20:32:32,893:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.15s, LR: 0.00009, Train Loss: 0.0697, Train MAE: 0.0697,
                            Val Loss: 0.2921, Val Acc: 0.2921, Test MAE: 0.2600
2022-09-05 20:32:32,898:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 94/1000
2022-09-05 20:32:47,488:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.59s, LR: 0.00009, Train Loss: 0.0693, Train MAE: 0.0693,
                            Val Loss: 0.2924, Val Acc: 0.2924, Test MAE: 0.2590
2022-09-05 20:32:47,493:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 95/1000
2022-09-05 20:33:01,738:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.24s, LR: 0.00009, Train Loss: 0.0669, Train MAE: 0.0669,
                            Val Loss: 0.2940, Val Acc: 0.2940, Test MAE: 0.2579
2022-09-05 20:33:01,744:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 96/1000
2022-09-05 20:33:19,247:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2566370163112879
2022-09-05 20:33:19,247:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.50s, LR: 0.00009, Train Loss: 0.0666, Train MAE: 0.0666,
                            Val Loss: 0.2904, Val Acc: 0.2904, Test MAE: 0.2566
2022-09-05 20:33:19,253:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 97/1000
2022-09-05 20:33:36,540:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2563746366649866
2022-09-05 20:33:36,541:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.29s, LR: 0.00009, Train Loss: 0.0671, Train MAE: 0.0671,
                            Val Loss: 0.2904, Val Acc: 0.2904, Test MAE: 0.2564
2022-09-05 20:33:36,547:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 98/1000
2022-09-05 20:33:52,684:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00009, Train Loss: 0.0655, Train MAE: 0.0655,
                            Val Loss: 0.2935, Val Acc: 0.2935, Test MAE: 0.2564
2022-09-05 20:33:52,690:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 99/1000
2022-09-05 20:34:10,581:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.89s, LR: 0.00009, Train Loss: 0.0639, Train MAE: 0.0639,
                            Val Loss: 0.2935, Val Acc: 0.2935, Test MAE: 0.2576
2022-09-05 20:34:10,588:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 100/1000
2022-09-05 20:34:27,852:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.26s, LR: 0.00009, Train Loss: 0.0642, Train MAE: 0.0642,
                            Val Loss: 0.2931, Val Acc: 0.2931, Test MAE: 0.2588
2022-09-05 20:34:27,858:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 101/1000
2022-09-05 20:34:45,643:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.78s, LR: 0.00009, Train Loss: 0.0636, Train MAE: 0.0636,
                            Val Loss: 0.2939, Val Acc: 0.2939, Test MAE: 0.2570
2022-09-05 20:34:45,650:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 102/1000
2022-09-05 20:35:02,750:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.10s, LR: 0.00004, Train Loss: 0.0564, Train MAE: 0.0564,
                            Val Loss: 0.2928, Val Acc: 0.2928, Test MAE: 0.2571
2022-09-05 20:35:02,758:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 103/1000
2022-09-05 20:35:20,240:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.48s, LR: 0.00004, Train Loss: 0.0538, Train MAE: 0.0538,
                            Val Loss: 0.2917, Val Acc: 0.2917, Test MAE: 0.2576
2022-09-05 20:35:20,246:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 104/1000
2022-09-05 20:35:37,455:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2558805514127016
2022-09-05 20:35:37,455:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.21s, LR: 0.00004, Train Loss: 0.0519, Train MAE: 0.0519,
                            Val Loss: 0.2929, Val Acc: 0.2929, Test MAE: 0.2559
2022-09-05 20:35:37,462:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 105/1000
2022-09-05 20:35:54,698:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.24s, LR: 0.00004, Train Loss: 0.0511, Train MAE: 0.0511,
                            Val Loss: 0.2912, Val Acc: 0.2912, Test MAE: 0.2560
2022-09-05 20:35:54,704:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 106/1000
2022-09-05 20:36:10,471:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.77s, LR: 0.00004, Train Loss: 0.0500, Train MAE: 0.0500,
                            Val Loss: 0.2923, Val Acc: 0.2923, Test MAE: 0.2565
2022-09-05 20:36:10,476:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 107/1000
2022-09-05 20:36:25,881:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.40s, LR: 0.00004, Train Loss: 0.0501, Train MAE: 0.0501,
                            Val Loss: 0.2921, Val Acc: 0.2921, Test MAE: 0.2571
2022-09-05 20:36:25,886:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 108/1000
2022-09-05 20:36:39,789:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 13.90s, LR: 0.00004, Train Loss: 0.0496, Train MAE: 0.0496,
                            Val Loss: 0.2918, Val Acc: 0.2918, Test MAE: 0.2565
2022-09-05 20:36:39,794:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 109/1000
2022-09-05 20:36:55,334:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.54s, LR: 0.00004, Train Loss: 0.0489, Train MAE: 0.0489,
                            Val Loss: 0.2923, Val Acc: 0.2923, Test MAE: 0.2567
2022-09-05 20:36:55,339:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 110/1000
2022-09-05 20:37:11,338:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.00s, LR: 0.00004, Train Loss: 0.0479, Train MAE: 0.0479,
                            Val Loss: 0.2936, Val Acc: 0.2936, Test MAE: 0.2567
2022-09-05 20:37:11,344:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 111/1000
2022-09-05 20:37:26,862:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.52s, LR: 0.00004, Train Loss: 0.0480, Train MAE: 0.0480,
                            Val Loss: 0.2937, Val Acc: 0.2937, Test MAE: 0.2574
2022-09-05 20:37:26,867:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 112/1000
2022-09-05 20:37:42,638:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.77s, LR: 0.00004, Train Loss: 0.0476, Train MAE: 0.0476,
                            Val Loss: 0.2923, Val Acc: 0.2923, Test MAE: 0.2574
2022-09-05 20:37:42,643:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 113/1000
2022-09-05 20:37:58,349:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.71s, LR: 0.00002, Train Loss: 0.0464, Train MAE: 0.0464,
                            Val Loss: 0.2931, Val Acc: 0.2931, Test MAE: 0.2561
2022-09-05 20:37:58,355:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 114/1000
2022-09-05 20:38:13,996:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.64s, LR: 0.00002, Train Loss: 0.0435, Train MAE: 0.0435,
                            Val Loss: 0.2935, Val Acc: 0.2935, Test MAE: 0.2564
2022-09-05 20:38:14,001:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 115/1000
2022-09-05 20:38:29,616:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.61s, LR: 0.00002, Train Loss: 0.0428, Train MAE: 0.0428,
                            Val Loss: 0.2933, Val Acc: 0.2933, Test MAE: 0.2562
2022-09-05 20:38:29,621:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 116/1000
2022-09-05 20:38:45,290:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.67s, LR: 0.00002, Train Loss: 0.0417, Train MAE: 0.0417,
                            Val Loss: 0.2928, Val Acc: 0.2928, Test MAE: 0.2570
2022-09-05 20:38:45,296:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 117/1000
2022-09-05 20:39:00,891:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.59s, LR: 0.00002, Train Loss: 0.0415, Train MAE: 0.0415,
                            Val Loss: 0.2940, Val Acc: 0.2940, Test MAE: 0.2567
2022-09-05 20:39:00,896:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 118/1000
2022-09-05 20:39:16,603:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.71s, LR: 0.00002, Train Loss: 0.0417, Train MAE: 0.0417,
                            Val Loss: 0.2936, Val Acc: 0.2936, Test MAE: 0.2572
2022-09-05 20:39:16,608:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 119/1000
2022-09-05 20:39:32,316:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.71s, LR: 0.00002, Train Loss: 0.0410, Train MAE: 0.0410,
                            Val Loss: 0.2932, Val Acc: 0.2932, Test MAE: 0.2567
2022-09-05 20:39:32,322:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 120/1000
2022-09-05 20:39:47,867:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.55s, LR: 0.00002, Train Loss: 0.0403, Train MAE: 0.0403,
                            Val Loss: 0.2938, Val Acc: 0.2938, Test MAE: 0.2572
2022-09-05 20:39:47,873:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 121/1000
2022-09-05 20:40:03,490:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.62s, LR: 0.00002, Train Loss: 0.0402, Train MAE: 0.0402,
                            Val Loss: 0.2935, Val Acc: 0.2935, Test MAE: 0.2568
2022-09-05 20:40:03,496:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 122/1000
2022-09-05 20:40:19,128:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.63s, LR: 0.00002, Train Loss: 0.0397, Train MAE: 0.0397,
                            Val Loss: 0.2940, Val Acc: 0.2940, Test MAE: 0.2570
2022-09-05 20:40:19,134:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 123/1000
2022-09-05 20:40:34,788:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.65s, LR: 0.00002, Train Loss: 0.0398, Train MAE: 0.0398,
                            Val Loss: 0.2941, Val Acc: 0.2941, Test MAE: 0.2568
2022-09-05 20:40:34,795:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 124/1000
2022-09-05 20:40:50,343:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.55s, LR: 0.00001, Train Loss: 0.0382, Train MAE: 0.0382,
                            Val Loss: 0.2941, Val Acc: 0.2941, Test MAE: 0.2569
2022-09-05 20:40:50,349:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 125/1000
2022-09-05 20:41:06,076:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.73s, LR: 0.00001, Train Loss: 0.0374, Train MAE: 0.0374,
                            Val Loss: 0.2938, Val Acc: 0.2938, Test MAE: 0.2567
2022-09-05 20:41:06,082:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 126/1000
2022-09-05 20:41:21,881:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.80s, LR: 0.00001, Train Loss: 0.0380, Train MAE: 0.0380,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2570
2022-09-05 20:41:21,888:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 127/1000
2022-09-05 20:41:37,519:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.63s, LR: 0.00001, Train Loss: 0.0367, Train MAE: 0.0367,
                            Val Loss: 0.2939, Val Acc: 0.2939, Test MAE: 0.2569
2022-09-05 20:41:37,525:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 128/1000
2022-09-05 20:41:53,256:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.73s, LR: 0.00001, Train Loss: 0.0366, Train MAE: 0.0366,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2568
2022-09-05 20:41:53,262:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 129/1000
2022-09-05 20:42:08,940:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.68s, LR: 0.00001, Train Loss: 0.0364, Train MAE: 0.0364,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2569
2022-09-05 20:42:08,946:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 130/1000
2022-09-05 20:42:25,218:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.27s, LR: 0.00001, Train Loss: 0.0366, Train MAE: 0.0366,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2571
2022-09-05 20:42:25,224:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 131/1000
2022-09-05 20:42:39,306:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.08s, LR: 0.00001, Train Loss: 0.0363, Train MAE: 0.0363,
                            Val Loss: 0.2943, Val Acc: 0.2943, Test MAE: 0.2569
2022-09-05 20:42:39,313:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 132/1000
2022-09-05 20:42:54,354:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.04s, LR: 0.00001, Train Loss: 0.0360, Train MAE: 0.0360,
                            Val Loss: 0.2939, Val Acc: 0.2939, Test MAE: 0.2573
2022-09-05 20:42:54,360:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 133/1000
2022-09-05 20:43:09,065:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.70s, LR: 0.00001, Train Loss: 0.0362, Train MAE: 0.0362,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2571
2022-09-05 20:43:09,070:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 134/1000
2022-09-05 20:43:25,729:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.66s, LR: 0.00001, Train Loss: 0.0356, Train MAE: 0.0356,
                            Val Loss: 0.2941, Val Acc: 0.2941, Test MAE: 0.2571
2022-09-05 20:43:25,735:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 135/1000
2022-09-05 20:43:42,084:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.35s, LR: 0.00001, Train Loss: 0.0350, Train MAE: 0.0350,
                            Val Loss: 0.2943, Val Acc: 0.2943, Test MAE: 0.2571
2022-09-05 20:43:42,089:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 136/1000
2022-09-05 20:43:57,111:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.02s, LR: 0.00001, Train Loss: 0.0345, Train MAE: 0.0345,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2571
2022-09-05 20:43:57,116:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 137/1000
2022-09-05 20:44:12,855:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.74s, LR: 0.00001, Train Loss: 0.0346, Train MAE: 0.0346,
                            Val Loss: 0.2943, Val Acc: 0.2943, Test MAE: 0.2571
2022-09-05 20:44:12,860:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 138/1000
2022-09-05 20:44:29,001:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00001, Train Loss: 0.0345, Train MAE: 0.0345,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2572
2022-09-05 20:44:29,007:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 139/1000
2022-09-05 20:44:43,599:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.59s, LR: 0.00001, Train Loss: 0.0349, Train MAE: 0.0349,
                            Val Loss: 0.2942, Val Acc: 0.2942, Test MAE: 0.2570
2022-09-05 20:44:43,606:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 140/1000
2022-09-05 20:44:58,682:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.08s, LR: 0.00001, Train Loss: 0.0340, Train MAE: 0.0340,
                            Val Loss: 0.2943, Val Acc: 0.2943, Test MAE: 0.2569
2022-09-05 20:44:58,688:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 141/1000
2022-09-05 20:45:13,003:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.31s, LR: 0.00001, Train Loss: 0.0339, Train MAE: 0.0339,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2571
2022-09-05 20:45:13,009:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 142/1000
2022-09-05 20:45:26,490:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 13.48s, LR: 0.00001, Train Loss: 0.0338, Train MAE: 0.0338,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2572
2022-09-05 20:45:26,495:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 143/1000
2022-09-05 20:45:41,090:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.59s, LR: 0.00001, Train Loss: 0.0338, Train MAE: 0.0338,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2571
2022-09-05 20:45:41,096:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 144/1000
2022-09-05 20:45:56,672:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.58s, LR: 0.00001, Train Loss: 0.0338, Train MAE: 0.0338,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2572
2022-09-05 20:45:56,679:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 145/1000
2022-09-05 20:46:12,484:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.81s, LR: 0.00001, Train Loss: 0.0347, Train MAE: 0.0347,
                            Val Loss: 0.2944, Val Acc: 0.2944, Test MAE: 0.2571
2022-09-05 20:46:12,489:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 146/1000
2022-09-05 20:46:28,010:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.52s, LR: 0.00000, Train Loss: 0.0333, Train MAE: 0.0333,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2571
2022-09-05 20:46:28,016:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 147/1000
2022-09-05 20:46:43,518:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.50s, LR: 0.00000, Train Loss: 0.0330, Train MAE: 0.0330,
                            Val Loss: 0.2944, Val Acc: 0.2944, Test MAE: 0.2571
2022-09-05 20:46:43,523:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 148/1000
2022-09-05 20:46:58,915:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.39s, LR: 0.00000, Train Loss: 0.0361, Train MAE: 0.0361,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2571
2022-09-05 20:46:58,923:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 149/1000
2022-09-05 20:47:14,649:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.73s, LR: 0.00000, Train Loss: 0.0330, Train MAE: 0.0330,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:47:14,655:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 150/1000
2022-09-05 20:47:30,432:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.78s, LR: 0.00000, Train Loss: 0.0329, Train MAE: 0.0329,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2571
2022-09-05 20:47:30,438:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 151/1000
2022-09-05 20:47:44,892:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.45s, LR: 0.00000, Train Loss: 0.0326, Train MAE: 0.0326,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2571
2022-09-05 20:47:44,898:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 152/1000
2022-09-05 20:47:58,852:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 13.95s, LR: 0.00000, Train Loss: 0.0327, Train MAE: 0.0327,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:47:58,857:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 153/1000
2022-09-05 20:48:12,620:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 13.76s, LR: 0.00000, Train Loss: 0.0326, Train MAE: 0.0326,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:48:12,626:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 154/1000
2022-09-05 20:48:27,553:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.93s, LR: 0.00000, Train Loss: 0.0405, Train MAE: 0.0405,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2572
2022-09-05 20:48:27,560:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 155/1000
2022-09-05 20:48:41,973:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.41s, LR: 0.00000, Train Loss: 0.0325, Train MAE: 0.0325,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2571
2022-09-05 20:48:41,979:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 156/1000
2022-09-05 20:48:56,995:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.02s, LR: 0.00000, Train Loss: 0.0325, Train MAE: 0.0325,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2571
2022-09-05 20:48:57,001:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 157/1000
2022-09-05 20:49:11,419:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.42s, LR: 0.00000, Train Loss: 0.0325, Train MAE: 0.0325,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:49:11,424:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 158/1000
2022-09-05 20:49:26,181:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.76s, LR: 0.00000, Train Loss: 0.0327, Train MAE: 0.0327,
                            Val Loss: 0.2945, Val Acc: 0.2945, Test MAE: 0.2572
2022-09-05 20:49:26,186:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 159/1000
2022-09-05 20:49:40,618:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.43s, LR: 0.00000, Train Loss: 0.0321, Train MAE: 0.0321,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:49:40,624:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 160/1000
2022-09-05 20:49:55,021:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.40s, LR: 0.00000, Train Loss: 0.0322, Train MAE: 0.0322,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:49:55,029:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 161/1000
2022-09-05 20:50:09,476:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.45s, LR: 0.00000, Train Loss: 0.0342, Train MAE: 0.0342,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:50:09,481:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 162/1000
2022-09-05 20:50:23,844:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.36s, LR: 0.00000, Train Loss: 0.0321, Train MAE: 0.0321,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:50:23,849:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 163/1000
2022-09-05 20:50:38,238:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.39s, LR: 0.00000, Train Loss: 0.0320, Train MAE: 0.0320,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:50:38,244:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 164/1000
2022-09-05 20:50:52,665:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.42s, LR: 0.00000, Train Loss: 0.0320, Train MAE: 0.0320,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:50:52,670:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 165/1000
2022-09-05 20:51:07,177:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.51s, LR: 0.00000, Train Loss: 0.0321, Train MAE: 0.0321,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:51:07,182:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 166/1000
2022-09-05 20:51:21,990:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.81s, LR: 0.00000, Train Loss: 0.0320, Train MAE: 0.0320,
                            Val Loss: 0.2946, Val Acc: 0.2946, Test MAE: 0.2572
2022-09-05 20:51:21,996:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 167/1000
2022-09-05 20:51:36,785:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 14.79s, LR: 0.00000, Train Loss: 0.0320, Train MAE: 0.0320,
                            Val Loss: 0.2947, Val Acc: 0.2947, Test MAE: 0.2572
2022-09-05 20:51:36,790:main_molecules_graph_regression.py:216 -   train_val_pipeline(): 
!! LR EQUAL TO MIN LR SET.
2022-09-05 20:51:44,889:main_molecules_graph_regression.py:235 -   train_val_pipeline(): Test MAE: 0.2572
2022-09-05 20:51:44,889:main_molecules_graph_regression.py:236 -   train_val_pipeline(): Best Test MAE: 0.2559
2022-09-05 20:51:44,889:main_molecules_graph_regression.py:237 -   train_val_pipeline(): Train MAE: 0.0319
2022-09-05 20:51:44,889:main_molecules_graph_regression.py:238 -   train_val_pipeline(): Best Train MAE Corresponding to Best Test MAE: 0.0519
2022-09-05 20:51:44,889:main_molecules_graph_regression.py:239 -   train_val_pipeline(): Convergence Time (Epochs): 166.0000
2022-09-05 20:51:44,889:main_molecules_graph_regression.py:240 -   train_val_pipeline(): TOTAL TIME TAKEN: 2611.7982s
2022-09-05 20:51:44,889:main_molecules_graph_regression.py:241 -   train_val_pipeline(): AVG TIME PER EPOCH: 15.4423s
2022-09-05 20:55:19,914:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 20:55:23,283:main_molecules_graph_regression.py:340 -                 main(): {'num_train_data': 7000, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'edge_feat': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': 'DEBUG.log', 'device': device(type='cpu'), 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-05 20:55:23,283:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'saev'}
2022-09-05 20:55:23,283:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 20:55:23,284:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 20:55:23,284:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 20:55:23,284:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 20:55:23,289:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 20:55:23,289:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526354
2022-09-05 20:55:23,290:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 20:55:23,290:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 20:55:23,290:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 20:55:23,290:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 20:55:23,295:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 20:55:46,006:main_molecules_graph_regression.py:68 -   train_val_pipeline(): Time PE:22.716439962387085
2022-09-05 20:55:46,021:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 20:55:46,021:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 20:55:46,021:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-05 20:55:46,023:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 20:56:03,299:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.5204024761915207
2022-09-05 20:56:03,300:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.28s, LR: 0.00070, Train Loss: 1.4456, Train MAE: 1.4456,
                            Val Loss: 1.4426, Val Acc: 1.4426, Test MAE: 1.5204
2022-09-05 20:56:03,306:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 20:56:21,207:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 17.90s, LR: 0.00070, Train Loss: 1.3967, Train MAE: 1.3967,
                            Val Loss: 1.6386, Val Acc: 1.6386, Test MAE: 1.7180
2022-09-05 20:56:21,214:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 20:56:37,048:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.83s, LR: 0.00070, Train Loss: 1.3907, Train MAE: 1.3907,
                            Val Loss: 3.1312, Val Acc: 3.1312, Test MAE: 3.1646
2022-09-05 20:56:37,055:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 20:56:52,897:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.84s, LR: 0.00070, Train Loss: 1.3788, Train MAE: 1.3788,
                            Val Loss: 3.1515, Val Acc: 3.1515, Test MAE: 3.1915
2022-09-05 20:56:52,904:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 20:57:08,860:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.4510637372732162
2022-09-05 20:57:08,861:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.96s, LR: 0.00070, Train Loss: 1.3619, Train MAE: 1.3619,
                            Val Loss: 1.3764, Val Acc: 1.3764, Test MAE: 1.4511
2022-09-05 20:57:08,867:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 20:57:24,768:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.90s, LR: 0.00070, Train Loss: 1.3456, Train MAE: 1.3456,
                            Val Loss: 1.8555, Val Acc: 1.8555, Test MAE: 1.9113
2022-09-05 20:57:24,774:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 20:57:40,752:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.375860258936882
2022-09-05 20:57:40,752:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.98s, LR: 0.00070, Train Loss: 1.3750, Train MAE: 1.3750,
                            Val Loss: 1.3193, Val Acc: 1.3193, Test MAE: 1.3759
2022-09-05 20:57:40,759:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 20:57:56,555:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.80s, LR: 0.00070, Train Loss: 1.3246, Train MAE: 1.3246,
                            Val Loss: 1.7645, Val Acc: 1.7645, Test MAE: 1.8246
2022-09-05 20:57:56,561:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 20:58:12,457:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.90s, LR: 0.00070, Train Loss: 1.3139, Train MAE: 1.3139,
                            Val Loss: 1.4095, Val Acc: 1.4095, Test MAE: 1.4820
2022-09-05 20:58:12,463:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 20:58:28,352:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.89s, LR: 0.00070, Train Loss: 1.3166, Train MAE: 1.3166,
                            Val Loss: 1.4416, Val Acc: 1.4416, Test MAE: 1.4827
2022-09-05 20:58:28,358:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 20:58:44,259:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.90s, LR: 0.00070, Train Loss: 1.2989, Train MAE: 1.2989,
                            Val Loss: 1.3233, Val Acc: 1.3233, Test MAE: 1.3847
2022-09-05 20:58:44,265:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 20:59:00,159:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.89s, LR: 0.00070, Train Loss: 1.2954, Train MAE: 1.2954,
                            Val Loss: 1.3248, Val Acc: 1.3248, Test MAE: 1.3835
2022-09-05 20:59:00,166:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 20:59:16,128:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.96s, LR: 0.00070, Train Loss: 1.2725, Train MAE: 1.2725,
                            Val Loss: 2.2527, Val Acc: 2.2527, Test MAE: 2.3425
2022-09-05 20:59:16,134:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 20:59:32,040:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.91s, LR: 0.00070, Train Loss: 1.2786, Train MAE: 1.2786,
                            Val Loss: 1.6248, Val Acc: 1.6248, Test MAE: 1.6377
2022-09-05 20:59:32,047:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 20:59:47,995:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.95s, LR: 0.00070, Train Loss: 1.2667, Train MAE: 1.2667,
                            Val Loss: 1.3474, Val Acc: 1.3474, Test MAE: 1.3893
2022-09-05 20:59:48,001:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 21:00:03,956:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.95s, LR: 0.00070, Train Loss: 1.2748, Train MAE: 1.2748,
                            Val Loss: 1.3670, Val Acc: 1.3670, Test MAE: 1.4536
2022-09-05 21:00:03,963:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 21:00:19,915:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.95s, LR: 0.00070, Train Loss: 1.2724, Train MAE: 1.2724,
                            Val Loss: 1.8223, Val Acc: 1.8223, Test MAE: 1.9123
2022-09-05 21:00:19,921:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 21:00:35,858:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.94s, LR: 0.00070, Train Loss: 1.2611, Train MAE: 1.2611,
                            Val Loss: 1.3318, Val Acc: 1.3318, Test MAE: 1.4108
2022-09-05 21:00:35,865:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 21:00:51,714:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.2923121452331543
2022-09-05 21:00:51,714:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.85s, LR: 0.00035, Train Loss: 1.2327, Train MAE: 1.2327,
                            Val Loss: 1.2377, Val Acc: 1.2377, Test MAE: 1.2923
2022-09-05 21:00:51,721:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 21:01:07,638:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.92s, LR: 0.00035, Train Loss: 1.2202, Train MAE: 1.2202,
                            Val Loss: 1.7251, Val Acc: 1.7251, Test MAE: 1.7217
2022-09-05 21:01:07,644:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 21:01:23,672:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.2650202065706253
2022-09-05 21:01:23,673:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.03s, LR: 0.00035, Train Loss: 1.2185, Train MAE: 1.2185,
                            Val Loss: 1.2411, Val Acc: 1.2411, Test MAE: 1.2650
2022-09-05 21:01:23,680:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 21:01:40,164:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.48s, LR: 0.00035, Train Loss: 1.2159, Train MAE: 1.2159,
                            Val Loss: 1.2674, Val Acc: 1.2674, Test MAE: 1.2909
2022-09-05 21:01:40,170:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 21:01:56,808:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.64s, LR: 0.00035, Train Loss: 1.1978, Train MAE: 1.1978,
                            Val Loss: 1.3017, Val Acc: 1.3017, Test MAE: 1.2996
2022-09-05 21:01:56,814:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 21:02:05,496:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 21:02:05,496:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 21:02:13,277:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 21:02:16,911:main_molecules_graph_regression.py:340 -                 main(): {'num_train_data': 7000, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'edge_feat': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': 'DEBUG.log', 'device': device(type='cpu'), 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-05 21:02:16,911:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'saev'}
2022-09-05 21:02:16,911:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 21:02:16,912:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 21:02:16,912:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 21:02:16,912:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 21:02:16,917:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 21:02:16,918:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-05 21:02:16,918:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 21:02:16,918:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 21:02:16,918:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 21:02:16,918:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 21:02:16,924:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 21:02:40,380:main_molecules_graph_regression.py:68 -   train_val_pipeline(): Time PE:23.462243795394897
2022-09-05 21:02:40,396:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 21:02:40,396:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 21:02:40,396:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-05 21:02:40,399:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 21:02:56,907:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 1.1213277652859688
2022-09-05 21:02:56,908:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.51s, LR: 0.00070, Train Loss: 0.9071, Train MAE: 0.9071,
                            Val Loss: 1.1033, Val Acc: 1.1033, Test MAE: 1.1213
2022-09-05 21:02:56,915:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 21:03:13,070:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5949043966829777
2022-09-05 21:03:13,071:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00070, Train Loss: 0.5890, Train MAE: 0.5890,
                            Val Loss: 0.5689, Val Acc: 0.5689, Test MAE: 0.5949
2022-09-05 21:03:13,077:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 21:03:29,000:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.92s, LR: 0.00070, Train Loss: 0.5476, Train MAE: 0.5476,
                            Val Loss: 0.5971, Val Acc: 0.5971, Test MAE: 0.6346
2022-09-05 21:03:29,007:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 21:03:44,892:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.89s, LR: 0.00070, Train Loss: 0.5314, Train MAE: 0.5314,
                            Val Loss: 0.5893, Val Acc: 0.5893, Test MAE: 0.6028
2022-09-05 21:03:44,899:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 21:04:00,907:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.559584017843008
2022-09-05 21:04:00,907:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.01s, LR: 0.00070, Train Loss: 0.5094, Train MAE: 0.5094,
                            Val Loss: 0.5245, Val Acc: 0.5245, Test MAE: 0.5596
2022-09-05 21:04:00,913:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 21:04:16,813:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5295811332762241
2022-09-05 21:04:16,814:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.90s, LR: 0.00070, Train Loss: 0.4913, Train MAE: 0.4913,
                            Val Loss: 0.5020, Val Acc: 0.5020, Test MAE: 0.5296
2022-09-05 21:04:16,820:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 21:04:32,852:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.03s, LR: 0.00070, Train Loss: 0.5106, Train MAE: 0.5106,
                            Val Loss: 0.5778, Val Acc: 0.5778, Test MAE: 0.6070
2022-09-05 21:04:32,858:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 21:04:48,771:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5113623738288879
2022-09-05 21:04:48,772:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.91s, LR: 0.00070, Train Loss: 0.4660, Train MAE: 0.4660,
                            Val Loss: 0.4873, Val Acc: 0.4873, Test MAE: 0.5114
2022-09-05 21:04:48,778:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 21:05:04,743:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.96s, LR: 0.00070, Train Loss: 0.4733, Train MAE: 0.4733,
                            Val Loss: 0.4962, Val Acc: 0.4962, Test MAE: 0.5339
2022-09-05 21:05:04,750:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 21:05:20,735:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.98s, LR: 0.00070, Train Loss: 0.4621, Train MAE: 0.4621,
                            Val Loss: 0.5199, Val Acc: 0.5199, Test MAE: 0.5454
2022-09-05 21:05:20,741:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 21:05:36,731:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.5111700780689716
2022-09-05 21:05:36,731:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.99s, LR: 0.00070, Train Loss: 0.4519, Train MAE: 0.4519,
                            Val Loss: 0.4831, Val Acc: 0.4831, Test MAE: 0.5112
2022-09-05 21:05:36,738:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 21:05:52,670:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4988994151353836
2022-09-05 21:05:52,671:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.93s, LR: 0.00070, Train Loss: 0.4498, Train MAE: 0.4498,
                            Val Loss: 0.4815, Val Acc: 0.4815, Test MAE: 0.4989
2022-09-05 21:05:52,677:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 21:06:08,561:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.88s, LR: 0.00070, Train Loss: 0.4395, Train MAE: 0.4395,
                            Val Loss: 0.5265, Val Acc: 0.5265, Test MAE: 0.5508
2022-09-05 21:06:08,567:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 21:06:24,902:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.33s, LR: 0.00070, Train Loss: 0.4401, Train MAE: 0.4401,
                            Val Loss: 0.4634, Val Acc: 0.4634, Test MAE: 0.4992
2022-09-05 21:06:24,909:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 21:06:40,921:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4831978976726532
2022-09-05 21:06:40,922:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.01s, LR: 0.00070, Train Loss: 0.4453, Train MAE: 0.4453,
                            Val Loss: 0.4760, Val Acc: 0.4760, Test MAE: 0.4832
2022-09-05 21:06:40,928:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 21:06:56,397:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.47s, LR: 0.00070, Train Loss: 0.4360, Train MAE: 0.4360,
                            Val Loss: 0.4899, Val Acc: 0.4899, Test MAE: 0.4982
2022-09-05 21:06:56,404:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 21:07:12,397:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.99s, LR: 0.00070, Train Loss: 0.4464, Train MAE: 0.4464,
                            Val Loss: 0.5292, Val Acc: 0.5292, Test MAE: 0.5398
2022-09-05 21:07:12,404:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 21:07:28,570:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00070, Train Loss: 0.4430, Train MAE: 0.4430,
                            Val Loss: 0.4737, Val Acc: 0.4737, Test MAE: 0.4937
2022-09-05 21:07:28,576:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 21:07:44,815:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00070, Train Loss: 0.4299, Train MAE: 0.4299,
                            Val Loss: 0.5392, Val Acc: 0.5392, Test MAE: 0.5675
2022-09-05 21:07:44,821:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 20/1000
2022-09-05 21:08:00,890:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.45312220230698586
2022-09-05 21:08:00,891:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00070, Train Loss: 0.4249, Train MAE: 0.4249,
                            Val Loss: 0.4413, Val Acc: 0.4413, Test MAE: 0.4531
2022-09-05 21:08:00,897:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 21/1000
2022-09-05 21:08:16,955:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.43545808270573616
2022-09-05 21:08:16,956:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00070, Train Loss: 0.4235, Train MAE: 0.4235,
                            Val Loss: 0.4290, Val Acc: 0.4290, Test MAE: 0.4355
2022-09-05 21:08:16,962:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 22/1000
2022-09-05 21:08:33,102:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00070, Train Loss: 0.4137, Train MAE: 0.4137,
                            Val Loss: 0.6984, Val Acc: 0.6984, Test MAE: 0.7109
2022-09-05 21:08:33,109:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 23/1000
2022-09-05 21:08:49,119:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.01s, LR: 0.00070, Train Loss: 0.4258, Train MAE: 0.4258,
                            Val Loss: 0.6274, Val Acc: 0.6274, Test MAE: 0.6496
2022-09-05 21:08:49,125:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 24/1000
2022-09-05 21:09:05,109:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.98s, LR: 0.00070, Train Loss: 0.4104, Train MAE: 0.4104,
                            Val Loss: 0.4725, Val Acc: 0.4725, Test MAE: 0.5001
2022-09-05 21:09:05,115:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 25/1000
2022-09-05 21:09:21,186:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00070, Train Loss: 0.4275, Train MAE: 0.4275,
                            Val Loss: 0.6191, Val Acc: 0.6191, Test MAE: 0.6476
2022-09-05 21:09:21,192:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 26/1000
2022-09-05 21:09:37,280:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00070, Train Loss: 0.4067, Train MAE: 0.4067,
                            Val Loss: 0.4921, Val Acc: 0.4921, Test MAE: 0.5228
2022-09-05 21:09:37,286:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 27/1000
2022-09-05 21:09:53,327:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.04s, LR: 0.00070, Train Loss: 0.4047, Train MAE: 0.4047,
                            Val Loss: 0.4815, Val Acc: 0.4815, Test MAE: 0.4986
2022-09-05 21:09:53,334:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 28/1000
2022-09-05 21:10:09,674:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.34s, LR: 0.00070, Train Loss: 0.3983, Train MAE: 0.3983,
                            Val Loss: 0.4480, Val Acc: 0.4480, Test MAE: 0.4449
2022-09-05 21:10:09,680:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 29/1000
2022-09-05 21:10:25,693:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.01s, LR: 0.00070, Train Loss: 0.3903, Train MAE: 0.3903,
                            Val Loss: 0.4289, Val Acc: 0.4289, Test MAE: 0.4416
2022-09-05 21:10:25,700:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 30/1000
2022-09-05 21:10:41,729:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.03s, LR: 0.00070, Train Loss: 0.3868, Train MAE: 0.3868,
                            Val Loss: 0.5123, Val Acc: 0.5123, Test MAE: 0.5309
2022-09-05 21:10:41,735:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 31/1000
2022-09-05 21:10:57,822:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00070, Train Loss: 0.3951, Train MAE: 0.3951,
                            Val Loss: 0.5455, Val Acc: 0.5455, Test MAE: 0.5527
2022-09-05 21:10:57,830:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 32/1000
2022-09-05 21:11:13,892:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00070, Train Loss: 0.3783, Train MAE: 0.3783,
                            Val Loss: 0.4930, Val Acc: 0.4930, Test MAE: 0.5110
2022-09-05 21:11:13,899:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 33/1000
2022-09-05 21:11:29,960:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00070, Train Loss: 0.3671, Train MAE: 0.3671,
                            Val Loss: 0.4489, Val Acc: 0.4489, Test MAE: 0.4669
2022-09-05 21:11:29,967:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 34/1000
2022-09-05 21:11:45,988:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.02s, LR: 0.00070, Train Loss: 0.3943, Train MAE: 0.3943,
                            Val Loss: 0.4426, Val Acc: 0.4426, Test MAE: 0.4685
2022-09-05 21:11:45,995:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 35/1000
2022-09-05 21:12:02,040:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.43017400801181793
2022-09-05 21:12:02,040:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.05s, LR: 0.00070, Train Loss: 0.3907, Train MAE: 0.3907,
                            Val Loss: 0.4061, Val Acc: 0.4061, Test MAE: 0.4302
2022-09-05 21:12:02,047:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 36/1000
2022-09-05 21:12:18,048:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.00s, LR: 0.00070, Train Loss: 0.3703, Train MAE: 0.3703,
                            Val Loss: 0.4491, Val Acc: 0.4491, Test MAE: 0.4693
2022-09-05 21:12:18,054:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 37/1000
2022-09-05 21:12:34,150:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.4085914082825184
2022-09-05 21:12:34,151:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00070, Train Loss: 0.3796, Train MAE: 0.3796,
                            Val Loss: 0.3892, Val Acc: 0.3892, Test MAE: 0.4086
2022-09-05 21:12:34,157:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 38/1000
2022-09-05 21:12:50,209:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.05s, LR: 0.00070, Train Loss: 0.3725, Train MAE: 0.3725,
                            Val Loss: 0.7648, Val Acc: 0.7648, Test MAE: 0.7805
2022-09-05 21:12:50,216:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 39/1000
2022-09-05 21:13:06,261:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.04s, LR: 0.00070, Train Loss: 0.3693, Train MAE: 0.3693,
                            Val Loss: 0.4183, Val Acc: 0.4183, Test MAE: 0.4318
2022-09-05 21:13:06,267:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 40/1000
2022-09-05 21:13:23,096:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.83s, LR: 0.00070, Train Loss: 0.3564, Train MAE: 0.3564,
                            Val Loss: 0.7216, Val Acc: 0.7216, Test MAE: 0.7142
2022-09-05 21:13:23,103:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 41/1000
2022-09-05 21:13:38,633:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.53s, LR: 0.00070, Train Loss: 0.3593, Train MAE: 0.3593,
                            Val Loss: 0.8063, Val Acc: 0.8063, Test MAE: 0.8122
2022-09-05 21:13:38,639:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 42/1000
2022-09-05 21:13:53,916:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.28s, LR: 0.00070, Train Loss: 0.3614, Train MAE: 0.3614,
                            Val Loss: 0.5111, Val Acc: 0.5111, Test MAE: 0.5108
2022-09-05 21:13:53,923:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 43/1000
2022-09-05 21:14:10,256:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.33s, LR: 0.00070, Train Loss: 0.3582, Train MAE: 0.3582,
                            Val Loss: 0.4574, Val Acc: 0.4574, Test MAE: 0.4527
2022-09-05 21:14:10,263:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 44/1000
2022-09-05 21:14:26,418:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00070, Train Loss: 0.3583, Train MAE: 0.3583,
                            Val Loss: 0.9555, Val Acc: 0.9555, Test MAE: 0.9457
2022-09-05 21:14:26,425:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 45/1000
2022-09-05 21:14:42,727:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.30s, LR: 0.00070, Train Loss: 0.3812, Train MAE: 0.3812,
                            Val Loss: 0.4989, Val Acc: 0.4989, Test MAE: 0.5084
2022-09-05 21:14:42,734:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 46/1000
2022-09-05 21:14:58,907:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00070, Train Loss: 0.3810, Train MAE: 0.3810,
                            Val Loss: 0.6328, Val Acc: 0.6328, Test MAE: 0.6124
2022-09-05 21:14:58,914:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 47/1000
2022-09-05 21:15:14,984:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00070, Train Loss: 0.3532, Train MAE: 0.3532,
                            Val Loss: 0.4201, Val Acc: 0.4201, Test MAE: 0.4094
2022-09-05 21:15:14,991:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 48/1000
2022-09-05 21:15:31,133:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00070, Train Loss: 0.3325, Train MAE: 0.3325,
                            Val Loss: 0.4900, Val Acc: 0.4900, Test MAE: 0.4774
2022-09-05 21:15:31,140:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 49/1000
2022-09-05 21:15:47,244:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.3542913720011711
2022-09-05 21:15:47,245:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00035, Train Loss: 0.3163, Train MAE: 0.3163,
                            Val Loss: 0.3823, Val Acc: 0.3823, Test MAE: 0.3543
2022-09-05 21:15:47,251:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 50/1000
2022-09-05 21:16:03,233:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.3142779916524887
2022-09-05 21:16:03,233:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 15.98s, LR: 0.00035, Train Loss: 0.2944, Train MAE: 0.2944,
                            Val Loss: 0.3562, Val Acc: 0.3562, Test MAE: 0.3143
2022-09-05 21:16:03,240:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 51/1000
2022-09-05 21:16:19,371:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.30835239216685295
2022-09-05 21:16:19,371:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00035, Train Loss: 0.2911, Train MAE: 0.2911,
                            Val Loss: 0.3456, Val Acc: 0.3456, Test MAE: 0.3084
2022-09-05 21:16:19,377:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 52/1000
2022-09-05 21:16:35,444:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2915, Train MAE: 0.2915,
                            Val Loss: 0.3781, Val Acc: 0.3781, Test MAE: 0.3429
2022-09-05 21:16:35,451:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 53/1000
2022-09-05 21:16:51,629:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.18s, LR: 0.00035, Train Loss: 0.2822, Train MAE: 0.2822,
                            Val Loss: 0.4351, Val Acc: 0.4351, Test MAE: 0.4095
2022-09-05 21:16:51,636:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 54/1000
2022-09-05 21:17:07,915:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.28s, LR: 0.00035, Train Loss: 0.2759, Train MAE: 0.2759,
                            Val Loss: 0.3736, Val Acc: 0.3736, Test MAE: 0.3250
2022-09-05 21:17:07,922:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 55/1000
2022-09-05 21:17:24,577:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.65s, LR: 0.00035, Train Loss: 0.2830, Train MAE: 0.2830,
                            Val Loss: 0.3875, Val Acc: 0.3875, Test MAE: 0.3525
2022-09-05 21:17:24,583:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 56/1000
2022-09-05 21:17:40,673:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00035, Train Loss: 0.2896, Train MAE: 0.2896,
                            Val Loss: 0.3682, Val Acc: 0.3682, Test MAE: 0.3261
2022-09-05 21:17:40,680:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 57/1000
2022-09-05 21:17:56,813:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00035, Train Loss: 0.2757, Train MAE: 0.2757,
                            Val Loss: 0.4106, Val Acc: 0.4106, Test MAE: 0.3687
2022-09-05 21:17:56,819:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 58/1000
2022-09-05 21:18:12,864:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.04s, LR: 0.00035, Train Loss: 0.2801, Train MAE: 0.2801,
                            Val Loss: 0.3644, Val Acc: 0.3644, Test MAE: 0.3362
2022-09-05 21:18:12,871:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 59/1000
2022-09-05 21:18:28,994:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.12s, LR: 0.00035, Train Loss: 0.2895, Train MAE: 0.2895,
                            Val Loss: 0.3722, Val Acc: 0.3722, Test MAE: 0.3380
2022-09-05 21:18:29,001:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 60/1000
2022-09-05 21:18:45,101:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00035, Train Loss: 0.2824, Train MAE: 0.2824,
                            Val Loss: 0.3800, Val Acc: 0.3800, Test MAE: 0.3455
2022-09-05 21:18:45,107:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 61/1000
2022-09-05 21:19:01,233:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00035, Train Loss: 0.2602, Train MAE: 0.2602,
                            Val Loss: 0.3508, Val Acc: 0.3508, Test MAE: 0.3129
2022-09-05 21:19:01,240:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 62/1000
2022-09-05 21:19:17,306:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2912953794002533
2022-09-05 21:19:17,307:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2737, Train MAE: 0.2737,
                            Val Loss: 0.3405, Val Acc: 0.3405, Test MAE: 0.2913
2022-09-05 21:19:17,313:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 63/1000
2022-09-05 21:19:33,480:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00035, Train Loss: 0.2798, Train MAE: 0.2798,
                            Val Loss: 0.3704, Val Acc: 0.3704, Test MAE: 0.3516
2022-09-05 21:19:33,487:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 64/1000
2022-09-05 21:19:49,572:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.08s, LR: 0.00035, Train Loss: 0.2681, Train MAE: 0.2681,
                            Val Loss: 0.3869, Val Acc: 0.3869, Test MAE: 0.3596
2022-09-05 21:19:49,579:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 65/1000
2022-09-05 21:20:05,636:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00035, Train Loss: 0.2611, Train MAE: 0.2611,
                            Val Loss: 0.3391, Val Acc: 0.3391, Test MAE: 0.3051
2022-09-05 21:20:05,642:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 66/1000
2022-09-05 21:20:21,702:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00035, Train Loss: 0.2600, Train MAE: 0.2600,
                            Val Loss: 0.3796, Val Acc: 0.3796, Test MAE: 0.3648
2022-09-05 21:20:21,709:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 67/1000
2022-09-05 21:20:37,865:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00035, Train Loss: 0.3375, Train MAE: 0.3375,
                            Val Loss: 0.3660, Val Acc: 0.3660, Test MAE: 0.3511
2022-09-05 21:20:37,872:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 68/1000
2022-09-05 21:20:53,996:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.12s, LR: 0.00035, Train Loss: 0.3013, Train MAE: 0.3013,
                            Val Loss: 0.3448, Val Acc: 0.3448, Test MAE: 0.3320
2022-09-05 21:20:54,002:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 69/1000
2022-09-05 21:21:10,113:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.11s, LR: 0.00035, Train Loss: 0.2828, Train MAE: 0.2828,
                            Val Loss: 0.3529, Val Acc: 0.3529, Test MAE: 0.3221
2022-09-05 21:21:10,120:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 70/1000
2022-09-05 21:21:26,178:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00035, Train Loss: 0.2696, Train MAE: 0.2696,
                            Val Loss: 0.3493, Val Acc: 0.3493, Test MAE: 0.3132
2022-09-05 21:21:26,185:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 71/1000
2022-09-05 21:21:42,272:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00035, Train Loss: 0.2551, Train MAE: 0.2551,
                            Val Loss: 0.3414, Val Acc: 0.3414, Test MAE: 0.3299
2022-09-05 21:21:42,278:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 72/1000
2022-09-05 21:21:58,377:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00035, Train Loss: 0.2663, Train MAE: 0.2663,
                            Val Loss: 0.3377, Val Acc: 0.3377, Test MAE: 0.3085
2022-09-05 21:21:58,384:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 73/1000
2022-09-05 21:22:14,486:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00035, Train Loss: 0.2573, Train MAE: 0.2573,
                            Val Loss: 0.3610, Val Acc: 0.3610, Test MAE: 0.3181
2022-09-05 21:22:14,493:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 74/1000
2022-09-05 21:22:30,557:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00035, Train Loss: 0.2555, Train MAE: 0.2555,
                            Val Loss: 0.3394, Val Acc: 0.3394, Test MAE: 0.2946
2022-09-05 21:22:30,564:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 75/1000
2022-09-05 21:22:46,679:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.12s, LR: 0.00035, Train Loss: 0.2494, Train MAE: 0.2494,
                            Val Loss: 0.3309, Val Acc: 0.3309, Test MAE: 0.2918
2022-09-05 21:22:46,686:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 76/1000
2022-09-05 21:23:02,706:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.02s, LR: 0.00035, Train Loss: 0.2468, Train MAE: 0.2468,
                            Val Loss: 0.3533, Val Acc: 0.3533, Test MAE: 0.3046
2022-09-05 21:23:02,712:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 77/1000
2022-09-05 21:23:18,788:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.08s, LR: 0.00035, Train Loss: 0.2484, Train MAE: 0.2484,
                            Val Loss: 0.3409, Val Acc: 0.3409, Test MAE: 0.3167
2022-09-05 21:23:18,794:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 78/1000
2022-09-05 21:23:34,891:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2897125966846943
2022-09-05 21:23:34,891:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00035, Train Loss: 0.2410, Train MAE: 0.2410,
                            Val Loss: 0.3277, Val Acc: 0.3277, Test MAE: 0.2897
2022-09-05 21:23:34,898:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 79/1000
2022-09-05 21:23:51,071:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.28846669383347034
2022-09-05 21:23:51,071:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00035, Train Loss: 0.2425, Train MAE: 0.2425,
                            Val Loss: 0.3337, Val Acc: 0.3337, Test MAE: 0.2885
2022-09-05 21:23:51,078:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 80/1000
2022-09-05 21:24:07,122:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.04s, LR: 0.00035, Train Loss: 0.2610, Train MAE: 0.2610,
                            Val Loss: 0.3656, Val Acc: 0.3656, Test MAE: 0.3351
2022-09-05 21:24:07,129:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 81/1000
2022-09-05 21:24:23,262:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00035, Train Loss: 0.2385, Train MAE: 0.2385,
                            Val Loss: 0.3432, Val Acc: 0.3432, Test MAE: 0.3150
2022-09-05 21:24:23,269:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 82/1000
2022-09-05 21:24:39,621:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.35s, LR: 0.00035, Train Loss: 0.2454, Train MAE: 0.2454,
                            Val Loss: 0.3445, Val Acc: 0.3445, Test MAE: 0.3073
2022-09-05 21:24:39,627:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 83/1000
2022-09-05 21:24:55,805:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.18s, LR: 0.00035, Train Loss: 0.2427, Train MAE: 0.2427,
                            Val Loss: 0.3693, Val Acc: 0.3693, Test MAE: 0.3173
2022-09-05 21:24:55,812:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 84/1000
2022-09-05 21:25:11,967:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2875324487686157
2022-09-05 21:25:11,968:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00035, Train Loss: 0.2464, Train MAE: 0.2464,
                            Val Loss: 0.3320, Val Acc: 0.3320, Test MAE: 0.2875
2022-09-05 21:25:11,974:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 85/1000
2022-09-05 21:25:28,050:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.28238120675086975
2022-09-05 21:25:28,051:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.08s, LR: 0.00035, Train Loss: 0.2368, Train MAE: 0.2368,
                            Val Loss: 0.3250, Val Acc: 0.3250, Test MAE: 0.2824
2022-09-05 21:25:28,057:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 86/1000
2022-09-05 21:25:44,129:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2273, Train MAE: 0.2273,
                            Val Loss: 0.3440, Val Acc: 0.3440, Test MAE: 0.3063
2022-09-05 21:25:44,136:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 87/1000
2022-09-05 21:26:00,204:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2302, Train MAE: 0.2302,
                            Val Loss: 0.3407, Val Acc: 0.3407, Test MAE: 0.2891
2022-09-05 21:26:00,211:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 88/1000
2022-09-05 21:26:16,345:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00035, Train Loss: 0.2327, Train MAE: 0.2327,
                            Val Loss: 0.3562, Val Acc: 0.3562, Test MAE: 0.3348
2022-09-05 21:26:16,352:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 89/1000
2022-09-05 21:26:32,458:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.11s, LR: 0.00035, Train Loss: 0.2305, Train MAE: 0.2305,
                            Val Loss: 0.3537, Val Acc: 0.3537, Test MAE: 0.3083
2022-09-05 21:26:32,465:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 90/1000
2022-09-05 21:26:48,588:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.12s, LR: 0.00035, Train Loss: 0.2203, Train MAE: 0.2203,
                            Val Loss: 0.3290, Val Acc: 0.3290, Test MAE: 0.2898
2022-09-05 21:26:48,594:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 91/1000
2022-09-05 21:27:04,686:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00035, Train Loss: 0.2285, Train MAE: 0.2285,
                            Val Loss: 0.3291, Val Acc: 0.3291, Test MAE: 0.2897
2022-09-05 21:27:04,693:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 92/1000
2022-09-05 21:27:20,855:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00035, Train Loss: 0.2176, Train MAE: 0.2176,
                            Val Loss: 0.3435, Val Acc: 0.3435, Test MAE: 0.2988
2022-09-05 21:27:20,862:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 93/1000
2022-09-05 21:27:36,902:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.04s, LR: 0.00035, Train Loss: 0.2315, Train MAE: 0.2315,
                            Val Loss: 0.3424, Val Acc: 0.3424, Test MAE: 0.2910
2022-09-05 21:27:36,909:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 94/1000
2022-09-05 21:27:53,115:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.21s, LR: 0.00035, Train Loss: 0.2249, Train MAE: 0.2249,
                            Val Loss: 0.3682, Val Acc: 0.3682, Test MAE: 0.3233
2022-09-05 21:27:53,122:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 95/1000
2022-09-05 21:28:09,210:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00035, Train Loss: 0.2245, Train MAE: 0.2245,
                            Val Loss: 0.3957, Val Acc: 0.3957, Test MAE: 0.3667
2022-09-05 21:28:09,216:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 96/1000
2022-09-05 21:28:25,343:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00035, Train Loss: 0.2305, Train MAE: 0.2305,
                            Val Loss: 0.3223, Val Acc: 0.3223, Test MAE: 0.2839
2022-09-05 21:28:25,350:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 97/1000
2022-09-05 21:28:41,512:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00035, Train Loss: 0.2243, Train MAE: 0.2243,
                            Val Loss: 0.3751, Val Acc: 0.3751, Test MAE: 0.3524
2022-09-05 21:28:41,519:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 98/1000
2022-09-05 21:28:57,714:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00035, Train Loss: 0.2261, Train MAE: 0.2261,
                            Val Loss: 0.3531, Val Acc: 0.3531, Test MAE: 0.3257
2022-09-05 21:28:57,721:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 99/1000
2022-09-05 21:29:13,806:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.08s, LR: 0.00035, Train Loss: 0.2203, Train MAE: 0.2203,
                            Val Loss: 0.3334, Val Acc: 0.3334, Test MAE: 0.2838
2022-09-05 21:29:13,812:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 100/1000
2022-09-05 21:29:30,034:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00035, Train Loss: 0.2219, Train MAE: 0.2219,
                            Val Loss: 0.3383, Val Acc: 0.3383, Test MAE: 0.3073
2022-09-05 21:29:30,041:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 101/1000
2022-09-05 21:29:46,108:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2164, Train MAE: 0.2164,
                            Val Loss: 0.3483, Val Acc: 0.3483, Test MAE: 0.3057
2022-09-05 21:29:46,114:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 102/1000
2022-09-05 21:30:02,259:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00035, Train Loss: 0.2220, Train MAE: 0.2220,
                            Val Loss: 0.3288, Val Acc: 0.3288, Test MAE: 0.2993
2022-09-05 21:30:02,266:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 103/1000
2022-09-05 21:30:18,336:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.26994249410927296
2022-09-05 21:30:18,337:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2201, Train MAE: 0.2201,
                            Val Loss: 0.3189, Val Acc: 0.3189, Test MAE: 0.2699
2022-09-05 21:30:18,343:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 104/1000
2022-09-05 21:30:34,528:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.18s, LR: 0.00035, Train Loss: 0.2255, Train MAE: 0.2255,
                            Val Loss: 0.3342, Val Acc: 0.3342, Test MAE: 0.3031
2022-09-05 21:30:34,534:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 105/1000
2022-09-05 21:30:50,636:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00035, Train Loss: 0.2011, Train MAE: 0.2011,
                            Val Loss: 0.3096, Val Acc: 0.3096, Test MAE: 0.2712
2022-09-05 21:30:50,643:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 106/1000
2022-09-05 21:31:06,809:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00035, Train Loss: 0.2056, Train MAE: 0.2056,
                            Val Loss: 0.3874, Val Acc: 0.3874, Test MAE: 0.3532
2022-09-05 21:31:06,815:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 107/1000
2022-09-05 21:31:22,883:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2112, Train MAE: 0.2112,
                            Val Loss: 0.3344, Val Acc: 0.3344, Test MAE: 0.2990
2022-09-05 21:31:22,889:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 108/1000
2022-09-05 21:31:39,060:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00035, Train Loss: 0.2070, Train MAE: 0.2070,
                            Val Loss: 0.3387, Val Acc: 0.3387, Test MAE: 0.3184
2022-09-05 21:31:39,066:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 109/1000
2022-09-05 21:31:55,134:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00035, Train Loss: 0.2092, Train MAE: 0.2092,
                            Val Loss: 0.3595, Val Acc: 0.3595, Test MAE: 0.3196
2022-09-05 21:31:55,141:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 110/1000
2022-09-05 21:32:11,574:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.43s, LR: 0.00035, Train Loss: 0.2234, Train MAE: 0.2234,
                            Val Loss: 0.3223, Val Acc: 0.3223, Test MAE: 0.2797
2022-09-05 21:32:11,581:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 111/1000
2022-09-05 21:32:27,693:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.11s, LR: 0.00035, Train Loss: 0.2117, Train MAE: 0.2117,
                            Val Loss: 0.3302, Val Acc: 0.3302, Test MAE: 0.3055
2022-09-05 21:32:27,700:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 112/1000
2022-09-05 21:32:43,806:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.11s, LR: 0.00035, Train Loss: 0.1985, Train MAE: 0.1985,
                            Val Loss: 0.3485, Val Acc: 0.3485, Test MAE: 0.3175
2022-09-05 21:32:43,812:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 113/1000
2022-09-05 21:32:59,860:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.05s, LR: 0.00035, Train Loss: 0.1978, Train MAE: 0.1978,
                            Val Loss: 0.3251, Val Acc: 0.3251, Test MAE: 0.2884
2022-09-05 21:32:59,866:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 114/1000
2022-09-05 21:33:15,991:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.12s, LR: 0.00035, Train Loss: 0.1925, Train MAE: 0.1925,
                            Val Loss: 0.3264, Val Acc: 0.3264, Test MAE: 0.2787
2022-09-05 21:33:15,998:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 115/1000
2022-09-05 21:33:32,073:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.08s, LR: 0.00035, Train Loss: 0.1915, Train MAE: 0.1915,
                            Val Loss: 0.4154, Val Acc: 0.4154, Test MAE: 0.3829
2022-09-05 21:33:32,080:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 116/1000
2022-09-05 21:33:48,245:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00035, Train Loss: 0.1973, Train MAE: 0.1973,
                            Val Loss: 0.3682, Val Acc: 0.3682, Test MAE: 0.3474
2022-09-05 21:33:48,251:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 117/1000
2022-09-05 21:34:04,397:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.26601272635161877
2022-09-05 21:34:04,397:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.15s, LR: 0.00017, Train Loss: 0.1803, Train MAE: 0.1803,
                            Val Loss: 0.3084, Val Acc: 0.3084, Test MAE: 0.2660
2022-09-05 21:34:04,404:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 118/1000
2022-09-05 21:34:20,560:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2647181898355484
2022-09-05 21:34:20,561:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00017, Train Loss: 0.1682, Train MAE: 0.1682,
                            Val Loss: 0.2992, Val Acc: 0.2992, Test MAE: 0.2647
2022-09-05 21:34:20,567:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 119/1000
2022-09-05 21:34:36,705:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.26138558611273766
2022-09-05 21:34:36,705:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00017, Train Loss: 0.1725, Train MAE: 0.1725,
                            Val Loss: 0.2971, Val Acc: 0.2971, Test MAE: 0.2614
2022-09-05 21:34:36,712:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 120/1000
2022-09-05 21:34:52,948:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00017, Train Loss: 0.1607, Train MAE: 0.1607,
                            Val Loss: 0.3080, Val Acc: 0.3080, Test MAE: 0.2698
2022-09-05 21:34:52,954:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 121/1000
2022-09-05 21:35:09,155:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00017, Train Loss: 0.1582, Train MAE: 0.1582,
                            Val Loss: 0.3007, Val Acc: 0.3007, Test MAE: 0.2654
2022-09-05 21:35:09,161:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 122/1000
2022-09-05 21:35:25,274:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2605080045759678
2022-09-05 21:35:25,275:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.11s, LR: 0.00017, Train Loss: 0.1731, Train MAE: 0.1731,
                            Val Loss: 0.3024, Val Acc: 0.3024, Test MAE: 0.2605
2022-09-05 21:35:25,281:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 123/1000
2022-09-05 21:35:41,355:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.07s, LR: 0.00017, Train Loss: 0.1654, Train MAE: 0.1654,
                            Val Loss: 0.3057, Val Acc: 0.3057, Test MAE: 0.2756
2022-09-05 21:35:41,362:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 124/1000
2022-09-05 21:35:57,424:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00017, Train Loss: 0.1672, Train MAE: 0.1672,
                            Val Loss: 0.3043, Val Acc: 0.3043, Test MAE: 0.2724
2022-09-05 21:35:57,430:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 125/1000
2022-09-05 21:36:13,626:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00017, Train Loss: 0.1599, Train MAE: 0.1599,
                            Val Loss: 0.3072, Val Acc: 0.3072, Test MAE: 0.2750
2022-09-05 21:36:13,632:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 126/1000
2022-09-05 21:36:29,653:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.02s, LR: 0.00017, Train Loss: 0.1493, Train MAE: 0.1493,
                            Val Loss: 0.2996, Val Acc: 0.2996, Test MAE: 0.2635
2022-09-05 21:36:29,660:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 127/1000
2022-09-05 21:36:45,793:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00017, Train Loss: 0.1620, Train MAE: 0.1620,
                            Val Loss: 0.3136, Val Acc: 0.3136, Test MAE: 0.2782
2022-09-05 21:36:45,799:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 128/1000
2022-09-05 21:37:01,949:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.15s, LR: 0.00017, Train Loss: 0.1676, Train MAE: 0.1676,
                            Val Loss: 0.3566, Val Acc: 0.3566, Test MAE: 0.3129
2022-09-05 21:37:01,956:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 129/1000
2022-09-05 21:37:18,328:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.2545028403401375
2022-09-05 21:37:18,329:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.37s, LR: 0.00017, Train Loss: 0.1564, Train MAE: 0.1564,
                            Val Loss: 0.3039, Val Acc: 0.3039, Test MAE: 0.2545
2022-09-05 21:37:18,337:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 130/1000
2022-09-05 21:37:34,399:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00017, Train Loss: 0.1696, Train MAE: 0.1696,
                            Val Loss: 0.3278, Val Acc: 0.3278, Test MAE: 0.2926
2022-09-05 21:37:34,406:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 131/1000
2022-09-05 21:37:50,587:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.18s, LR: 0.00009, Train Loss: 0.1409, Train MAE: 0.1409,
                            Val Loss: 0.3086, Val Acc: 0.3086, Test MAE: 0.2687
2022-09-05 21:37:50,594:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 132/1000
2022-09-05 21:38:06,684:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00009, Train Loss: 0.1415, Train MAE: 0.1415,
                            Val Loss: 0.3032, Val Acc: 0.3032, Test MAE: 0.2638
2022-09-05 21:38:06,691:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 133/1000
2022-09-05 21:38:22,886:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.19s, LR: 0.00009, Train Loss: 0.1487, Train MAE: 0.1487,
                            Val Loss: 0.3051, Val Acc: 0.3051, Test MAE: 0.2642
2022-09-05 21:38:22,892:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 134/1000
2022-09-05 21:38:38,986:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.09s, LR: 0.00009, Train Loss: 0.1411, Train MAE: 0.1411,
                            Val Loss: 0.3004, Val Acc: 0.3004, Test MAE: 0.2569
2022-09-05 21:38:38,993:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 135/1000
2022-09-05 21:38:55,259:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.27s, LR: 0.00009, Train Loss: 0.1410, Train MAE: 0.1410,
                            Val Loss: 0.3054, Val Acc: 0.3054, Test MAE: 0.2635
2022-09-05 21:38:55,265:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 136/1000
2022-09-05 21:39:11,437:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00009, Train Loss: 0.1428, Train MAE: 0.1428,
                            Val Loss: 0.3088, Val Acc: 0.3088, Test MAE: 0.2703
2022-09-05 21:39:11,443:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 137/1000
2022-09-05 21:39:27,950:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.51s, LR: 0.00009, Train Loss: 0.1438, Train MAE: 0.1438,
                            Val Loss: 0.3185, Val Acc: 0.3185, Test MAE: 0.2739
2022-09-05 21:39:27,957:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 138/1000
2022-09-05 21:39:44,022:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00009, Train Loss: 0.1274, Train MAE: 0.1274,
                            Val Loss: 0.3045, Val Acc: 0.3045, Test MAE: 0.2552
2022-09-05 21:39:44,028:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 139/1000
2022-09-05 21:40:00,223:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.19s, LR: 0.00009, Train Loss: 0.1397, Train MAE: 0.1397,
                            Val Loss: 0.3054, Val Acc: 0.3054, Test MAE: 0.2601
2022-09-05 21:40:00,229:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 140/1000
2022-09-05 21:40:16,332:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.10s, LR: 0.00009, Train Loss: 0.1344, Train MAE: 0.1344,
                            Val Loss: 0.2993, Val Acc: 0.2993, Test MAE: 0.2660
2022-09-05 21:40:16,339:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 141/1000
2022-09-05 21:40:32,503:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00009, Train Loss: 0.1319, Train MAE: 0.1319,
                            Val Loss: 0.2973, Val Acc: 0.2973, Test MAE: 0.2630
2022-09-05 21:40:32,510:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 142/1000
2022-09-05 21:40:48,642:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.13s, LR: 0.00004, Train Loss: 0.1205, Train MAE: 0.1205,
                            Val Loss: 0.2990, Val Acc: 0.2990, Test MAE: 0.2601
2022-09-05 21:40:48,649:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 143/1000
2022-09-05 21:41:04,887:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00004, Train Loss: 0.1326, Train MAE: 0.1326,
                            Val Loss: 0.2956, Val Acc: 0.2956, Test MAE: 0.2580
2022-09-05 21:41:04,895:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 144/1000
2022-09-05 21:41:21,061:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00004, Train Loss: 0.1228, Train MAE: 0.1228,
                            Val Loss: 0.2989, Val Acc: 0.2989, Test MAE: 0.2581
2022-09-05 21:41:21,068:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 145/1000
2022-09-05 21:41:37,314:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.25s, LR: 0.00004, Train Loss: 0.1188, Train MAE: 0.1188,
                            Val Loss: 0.3028, Val Acc: 0.3028, Test MAE: 0.2584
2022-09-05 21:41:37,320:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 146/1000
2022-09-05 21:41:53,441:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.12s, LR: 0.00004, Train Loss: 0.1236, Train MAE: 0.1236,
                            Val Loss: 0.2994, Val Acc: 0.2994, Test MAE: 0.2610
2022-09-05 21:41:53,448:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 147/1000
2022-09-05 21:42:09,698:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.25s, LR: 0.00004, Train Loss: 0.1153, Train MAE: 0.1153,
                            Val Loss: 0.3004, Val Acc: 0.3004, Test MAE: 0.2630
2022-09-05 21:42:09,705:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 148/1000
2022-09-05 21:42:25,853:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.15s, LR: 0.00004, Train Loss: 0.1278, Train MAE: 0.1278,
                            Val Loss: 0.3053, Val Acc: 0.3053, Test MAE: 0.2657
2022-09-05 21:42:25,860:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 149/1000
2022-09-05 21:42:42,030:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00004, Train Loss: 0.1313, Train MAE: 0.1313,
                            Val Loss: 0.3019, Val Acc: 0.3019, Test MAE: 0.2595
2022-09-05 21:42:42,036:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 150/1000
2022-09-05 21:42:58,204:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00004, Train Loss: 0.1257, Train MAE: 0.1257,
                            Val Loss: 0.2994, Val Acc: 0.2994, Test MAE: 0.2585
2022-09-05 21:42:58,210:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 151/1000
2022-09-05 21:43:14,422:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.21s, LR: 0.00004, Train Loss: 0.1248, Train MAE: 0.1248,
                            Val Loss: 0.3076, Val Acc: 0.3076, Test MAE: 0.2626
2022-09-05 21:43:14,429:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 152/1000
2022-09-05 21:43:30,571:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00004, Train Loss: 0.1209, Train MAE: 0.1209,
                            Val Loss: 0.3029, Val Acc: 0.3029, Test MAE: 0.2586
2022-09-05 21:43:30,578:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 153/1000
2022-09-05 21:43:46,800:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00004, Train Loss: 0.1216, Train MAE: 0.1216,
                            Val Loss: 0.3049, Val Acc: 0.3049, Test MAE: 0.2662
2022-09-05 21:43:46,807:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 154/1000
2022-09-05 21:44:02,869:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.06s, LR: 0.00004, Train Loss: 0.1236, Train MAE: 0.1236,
                            Val Loss: 0.3017, Val Acc: 0.3017, Test MAE: 0.2672
2022-09-05 21:44:02,875:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 155/1000
2022-09-05 21:44:19,097:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00002, Train Loss: 0.1192, Train MAE: 0.1192,
                            Val Loss: 0.3048, Val Acc: 0.3048, Test MAE: 0.2656
2022-09-05 21:44:19,105:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 156/1000
2022-09-05 21:44:35,296:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.19s, LR: 0.00002, Train Loss: 0.1121, Train MAE: 0.1121,
                            Val Loss: 0.2981, Val Acc: 0.2981, Test MAE: 0.2618
2022-09-05 21:44:35,302:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 157/1000
2022-09-05 21:44:51,531:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.23s, LR: 0.00002, Train Loss: 0.1176, Train MAE: 0.1176,
                            Val Loss: 0.3063, Val Acc: 0.3063, Test MAE: 0.2716
2022-09-05 21:44:51,538:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 158/1000
2022-09-05 21:45:07,676:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00002, Train Loss: 0.1146, Train MAE: 0.1146,
                            Val Loss: 0.3011, Val Acc: 0.3011, Test MAE: 0.2602
2022-09-05 21:45:07,682:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 159/1000
2022-09-05 21:45:23,932:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.25s, LR: 0.00002, Train Loss: 0.1131, Train MAE: 0.1131,
                            Val Loss: 0.3015, Val Acc: 0.3015, Test MAE: 0.2589
2022-09-05 21:45:23,939:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 160/1000
2022-09-05 21:45:40,055:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.12s, LR: 0.00002, Train Loss: 0.1069, Train MAE: 0.1069,
                            Val Loss: 0.3019, Val Acc: 0.3019, Test MAE: 0.2591
2022-09-05 21:45:40,062:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 161/1000
2022-09-05 21:45:56,277:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.21s, LR: 0.00002, Train Loss: 0.1110, Train MAE: 0.1110,
                            Val Loss: 0.3015, Val Acc: 0.3015, Test MAE: 0.2598
2022-09-05 21:45:56,283:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 162/1000
2022-09-05 21:46:12,425:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00002, Train Loss: 0.1125, Train MAE: 0.1125,
                            Val Loss: 0.3035, Val Acc: 0.3035, Test MAE: 0.2593
2022-09-05 21:46:12,432:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 163/1000
2022-09-05 21:46:28,584:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.15s, LR: 0.00002, Train Loss: 0.1074, Train MAE: 0.1074,
                            Val Loss: 0.2998, Val Acc: 0.2998, Test MAE: 0.2586
2022-09-05 21:46:28,590:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 164/1000
2022-09-05 21:46:44,779:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.19s, LR: 0.00002, Train Loss: 0.1149, Train MAE: 0.1149,
                            Val Loss: 0.3024, Val Acc: 0.3024, Test MAE: 0.2603
2022-09-05 21:46:44,786:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 165/1000
2022-09-05 21:47:01,209:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.42s, LR: 0.00002, Train Loss: 0.1146, Train MAE: 0.1146,
                            Val Loss: 0.3023, Val Acc: 0.3023, Test MAE: 0.2639
2022-09-05 21:47:01,216:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 166/1000
2022-09-05 21:47:17,504:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.29s, LR: 0.00001, Train Loss: 0.1085, Train MAE: 0.1085,
                            Val Loss: 0.3035, Val Acc: 0.3035, Test MAE: 0.2636
2022-09-05 21:47:17,510:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 167/1000
2022-09-05 21:47:33,680:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00001, Train Loss: 0.1093, Train MAE: 0.1093,
                            Val Loss: 0.3002, Val Acc: 0.3002, Test MAE: 0.2582
2022-09-05 21:47:33,687:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 168/1000
2022-09-05 21:47:49,982:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.29s, LR: 0.00001, Train Loss: 0.1079, Train MAE: 0.1079,
                            Val Loss: 0.3013, Val Acc: 0.3013, Test MAE: 0.2615
2022-09-05 21:47:49,990:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 169/1000
2022-09-05 21:48:06,126:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00001, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.3016, Val Acc: 0.3016, Test MAE: 0.2611
2022-09-05 21:48:06,132:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 170/1000
2022-09-05 21:48:22,362:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.23s, LR: 0.00001, Train Loss: 0.1072, Train MAE: 0.1072,
                            Val Loss: 0.3025, Val Acc: 0.3025, Test MAE: 0.2620
2022-09-05 21:48:22,369:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 171/1000
2022-09-05 21:48:38,530:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.16s, LR: 0.00001, Train Loss: 0.1063, Train MAE: 0.1063,
                            Val Loss: 0.3008, Val Acc: 0.3008, Test MAE: 0.2588
2022-09-05 21:48:38,537:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 172/1000
2022-09-05 21:48:54,811:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.27s, LR: 0.00001, Train Loss: 0.1092, Train MAE: 0.1092,
                            Val Loss: 0.3006, Val Acc: 0.3006, Test MAE: 0.2599
2022-09-05 21:48:54,818:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 173/1000
2022-09-05 21:49:10,991:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00001, Train Loss: 0.1150, Train MAE: 0.1150,
                            Val Loss: 0.3009, Val Acc: 0.3009, Test MAE: 0.2598
2022-09-05 21:49:10,998:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 174/1000
2022-09-05 21:49:27,266:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.27s, LR: 0.00001, Train Loss: 0.1142, Train MAE: 0.1142,
                            Val Loss: 0.3044, Val Acc: 0.3044, Test MAE: 0.2645
2022-09-05 21:49:27,272:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 175/1000
2022-09-05 21:49:43,477:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00001, Train Loss: 0.1078, Train MAE: 0.1078,
                            Val Loss: 0.3027, Val Acc: 0.3027, Test MAE: 0.2599
2022-09-05 21:49:43,484:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 176/1000
2022-09-05 21:49:59,649:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00001, Train Loss: 0.1135, Train MAE: 0.1135,
                            Val Loss: 0.3017, Val Acc: 0.3017, Test MAE: 0.2627
2022-09-05 21:49:59,656:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 177/1000
2022-09-05 21:50:15,873:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00001, Train Loss: 0.1139, Train MAE: 0.1139,
                            Val Loss: 0.3019, Val Acc: 0.3019, Test MAE: 0.2598
2022-09-05 21:50:15,880:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 178/1000
2022-09-05 21:50:32,084:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00001, Train Loss: 0.1126, Train MAE: 0.1126,
                            Val Loss: 0.3010, Val Acc: 0.3010, Test MAE: 0.2581
2022-09-05 21:50:32,091:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 179/1000
2022-09-05 21:50:48,311:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00001, Train Loss: 0.1151, Train MAE: 0.1151,
                            Val Loss: 0.3019, Val Acc: 0.3019, Test MAE: 0.2631
2022-09-05 21:50:48,318:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 180/1000
2022-09-05 21:51:04,607:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.29s, LR: 0.00001, Train Loss: 0.1027, Train MAE: 0.1027,
                            Val Loss: 0.3034, Val Acc: 0.3034, Test MAE: 0.2651
2022-09-05 21:51:04,614:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 181/1000
2022-09-05 21:51:20,807:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.19s, LR: 0.00001, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.3026, Val Acc: 0.3026, Test MAE: 0.2582
2022-09-05 21:51:20,814:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 182/1000
2022-09-05 21:51:37,037:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00001, Train Loss: 0.1149, Train MAE: 0.1149,
                            Val Loss: 0.3008, Val Acc: 0.3008, Test MAE: 0.2593
2022-09-05 21:51:37,044:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 183/1000
2022-09-05 21:51:53,282:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00001, Train Loss: 0.1116, Train MAE: 0.1116,
                            Val Loss: 0.3046, Val Acc: 0.3046, Test MAE: 0.2601
2022-09-05 21:51:53,290:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 184/1000
2022-09-05 21:52:09,968:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.68s, LR: 0.00001, Train Loss: 0.1027, Train MAE: 0.1027,
                            Val Loss: 0.3010, Val Acc: 0.3010, Test MAE: 0.2589
2022-09-05 21:52:09,975:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 185/1000
2022-09-05 21:52:26,493:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.52s, LR: 0.00001, Train Loss: 0.1127, Train MAE: 0.1127,
                            Val Loss: 0.3038, Val Acc: 0.3038, Test MAE: 0.2625
2022-09-05 21:52:26,499:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 186/1000
2022-09-05 21:52:43,305:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.81s, LR: 0.00001, Train Loss: 0.1051, Train MAE: 0.1051,
                            Val Loss: 0.3040, Val Acc: 0.3040, Test MAE: 0.2586
2022-09-05 21:52:43,312:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 187/1000
2022-09-05 21:52:59,512:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00001, Train Loss: 0.1085, Train MAE: 0.1085,
                            Val Loss: 0.3036, Val Acc: 0.3036, Test MAE: 0.2615
2022-09-05 21:52:59,518:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 188/1000
2022-09-05 21:53:15,736:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00000, Train Loss: 0.1039, Train MAE: 0.1039,
                            Val Loss: 0.3045, Val Acc: 0.3045, Test MAE: 0.2663
2022-09-05 21:53:15,743:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 189/1000
2022-09-05 21:53:31,884:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.14s, LR: 0.00000, Train Loss: 0.1038, Train MAE: 0.1038,
                            Val Loss: 0.3027, Val Acc: 0.3027, Test MAE: 0.2614
2022-09-05 21:53:31,891:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 190/1000
2022-09-05 21:53:48,181:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.29s, LR: 0.00000, Train Loss: 0.1079, Train MAE: 0.1079,
                            Val Loss: 0.3029, Val Acc: 0.3029, Test MAE: 0.2597
2022-09-05 21:53:48,188:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 191/1000
2022-09-05 21:54:04,375:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.19s, LR: 0.00000, Train Loss: 0.1081, Train MAE: 0.1081,
                            Val Loss: 0.3027, Val Acc: 0.3027, Test MAE: 0.2625
2022-09-05 21:54:04,382:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 192/1000
2022-09-05 21:54:20,624:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00000, Train Loss: 0.1083, Train MAE: 0.1083,
                            Val Loss: 0.3027, Val Acc: 0.3027, Test MAE: 0.2584
2022-09-05 21:54:20,630:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 193/1000
2022-09-05 21:54:37,032:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.40s, LR: 0.00000, Train Loss: 0.1118, Train MAE: 0.1118,
                            Val Loss: 0.3018, Val Acc: 0.3018, Test MAE: 0.2583
2022-09-05 21:54:37,039:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 194/1000
2022-09-05 21:54:53,279:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00000, Train Loss: 0.1109, Train MAE: 0.1109,
                            Val Loss: 0.3032, Val Acc: 0.3032, Test MAE: 0.2594
2022-09-05 21:54:53,285:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 195/1000
2022-09-05 21:55:09,523:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.24s, LR: 0.00000, Train Loss: 0.1065, Train MAE: 0.1065,
                            Val Loss: 0.3018, Val Acc: 0.3018, Test MAE: 0.2582
2022-09-05 21:55:09,530:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 196/1000
2022-09-05 21:55:25,731:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00000, Train Loss: 0.1040, Train MAE: 0.1040,
                            Val Loss: 0.3034, Val Acc: 0.3034, Test MAE: 0.2583
2022-09-05 21:55:25,737:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 197/1000
2022-09-05 21:55:41,932:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.19s, LR: 0.00000, Train Loss: 0.1043, Train MAE: 0.1043,
                            Val Loss: 0.3018, Val Acc: 0.3018, Test MAE: 0.2606
2022-09-05 21:55:41,939:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 198/1000
2022-09-05 21:55:58,152:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.21s, LR: 0.00000, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.3011, Val Acc: 0.3011, Test MAE: 0.2587
2022-09-05 21:55:58,159:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 199/1000
2022-09-05 21:56:14,369:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.21s, LR: 0.00000, Train Loss: 0.1060, Train MAE: 0.1060,
                            Val Loss: 0.3013, Val Acc: 0.3013, Test MAE: 0.2595
2022-09-05 21:56:14,375:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 200/1000
2022-09-05 21:56:30,526:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.15s, LR: 0.00000, Train Loss: 0.1133, Train MAE: 0.1133,
                            Val Loss: 0.3037, Val Acc: 0.3037, Test MAE: 0.2640
2022-09-05 21:56:30,532:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 201/1000
2022-09-05 21:56:46,789:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.26s, LR: 0.00000, Train Loss: 0.1056, Train MAE: 0.1056,
                            Val Loss: 0.3033, Val Acc: 0.3033, Test MAE: 0.2642
2022-09-05 21:56:46,796:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 202/1000
2022-09-05 21:57:03,041:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.25s, LR: 0.00000, Train Loss: 0.1102, Train MAE: 0.1102,
                            Val Loss: 0.3019, Val Acc: 0.3019, Test MAE: 0.2587
2022-09-05 21:57:03,048:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 203/1000
2022-09-05 21:57:19,218:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00000, Train Loss: 0.1020, Train MAE: 0.1020,
                            Val Loss: 0.3023, Val Acc: 0.3023, Test MAE: 0.2591
2022-09-05 21:57:19,225:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 204/1000
2022-09-05 21:57:35,431:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.21s, LR: 0.00000, Train Loss: 0.1054, Train MAE: 0.1054,
                            Val Loss: 0.3026, Val Acc: 0.3026, Test MAE: 0.2617
2022-09-05 21:57:35,439:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 205/1000
2022-09-05 21:57:51,658:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.22s, LR: 0.00000, Train Loss: 0.1077, Train MAE: 0.1077,
                            Val Loss: 0.3026, Val Acc: 0.3026, Test MAE: 0.2613
2022-09-05 21:57:51,665:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 206/1000
2022-09-05 21:58:07,833:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00000, Train Loss: 0.1006, Train MAE: 0.1006,
                            Val Loss: 0.3023, Val Acc: 0.3023, Test MAE: 0.2597
2022-09-05 21:58:07,840:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 207/1000
2022-09-05 21:58:24,044:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.20s, LR: 0.00000, Train Loss: 0.1055, Train MAE: 0.1055,
                            Val Loss: 0.3029, Val Acc: 0.3029, Test MAE: 0.2590
2022-09-05 21:58:24,051:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 208/1000
2022-09-05 21:58:40,217:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.17s, LR: 0.00000, Train Loss: 0.1047, Train MAE: 0.1047,
                            Val Loss: 0.3019, Val Acc: 0.3019, Test MAE: 0.2603
2022-09-05 21:58:40,224:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 209/1000
2022-09-05 21:58:56,409:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 16.18s, LR: 0.00000, Train Loss: 0.1048, Train MAE: 0.1048,
                            Val Loss: 0.3016, Val Acc: 0.3016, Test MAE: 0.2589
2022-09-05 21:58:56,416:main_molecules_graph_regression.py:216 -   train_val_pipeline(): 
!! LR EQUAL TO MIN LR SET.
2022-09-05 21:59:05,258:main_molecules_graph_regression.py:235 -   train_val_pipeline(): Test MAE: 0.2589
2022-09-05 21:59:05,258:main_molecules_graph_regression.py:236 -   train_val_pipeline(): Best Test MAE: 0.2545
2022-09-05 21:59:05,258:main_molecules_graph_regression.py:237 -   train_val_pipeline(): Train MAE: 0.0694
2022-09-05 21:59:05,258:main_molecules_graph_regression.py:238 -   train_val_pipeline(): Best Train MAE Corresponding to Best Test MAE: 0.1564
2022-09-05 21:59:05,258:main_molecules_graph_regression.py:239 -   train_val_pipeline(): Convergence Time (Epochs): 208.0000
2022-09-05 21:59:05,258:main_molecules_graph_regression.py:240 -   train_val_pipeline(): TOTAL TIME TAKEN: 3408.3404s
2022-09-05 21:59:05,258:main_molecules_graph_regression.py:241 -   train_val_pipeline(): AVG TIME PER EPOCH: 16.1469s
2022-09-05 22:12:36,139:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 22:12:39,745:main_molecules_graph_regression.py:340 -                 main(): {'num_train_data': 7000, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 32, 'edge_feat': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'RWK', 'pow_of_mat': 1, 'log_file': 'DEBUG.log', 'device': device(type='cpu'), 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-05 22:12:39,745:main_molecules_graph_regression.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41], 'save_name': 'saev'}
2022-09-05 22:12:39,745:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 22:12:39,746:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 22:12:39,746:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 22:12:39,746:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 22:12:39,751:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 22:12:39,752:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-05 22:12:39,752:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 22:12:39,753:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 22:12:39,753:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 22:12:39,753:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 22:12:39,758:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-05 22:13:02,730:main_molecules_graph_regression.py:68 -   train_val_pipeline(): Time PE:22.977906942367554
2022-09-05 22:13:02,730:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-05 22:13:27,115:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 24.384413957595825
2022-09-05 22:13:27,137:main_molecules_graph_regression.py:112 -   train_val_pipeline(): Training Graphs: 10000
2022-09-05 22:13:27,137:main_molecules_graph_regression.py:113 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 22:13:27,137:main_molecules_graph_regression.py:114 -   train_val_pipeline(): Test Graphs: 1000
2022-09-05 22:13:27,141:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 22:14:37,634:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.7490098550915718
2022-09-05 22:14:37,637:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 70.50s, LR: 0.00070, Train Loss: 0.7995, Train MAE: 0.7995,
                            Val Loss: 0.6975, Val Acc: 0.6975, Test MAE: 0.7490
2022-09-05 22:14:37,643:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 22:15:48,741:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 71.10s, LR: 0.00070, Train Loss: 0.7033, Train MAE: 0.7033,
                            Val Loss: 0.7299, Val Acc: 0.7299, Test MAE: 0.7636
2022-09-05 22:15:48,748:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 22:16:59,779:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.7360387854278088
2022-09-05 22:16:59,781:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 71.03s, LR: 0.00070, Train Loss: 0.6949, Train MAE: 0.6949,
                            Val Loss: 0.6811, Val Acc: 0.6811, Test MAE: 0.7360
2022-09-05 22:16:59,788:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 22:18:09,551:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6959400791674852
2022-09-05 22:18:09,552:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 69.76s, LR: 0.00070, Train Loss: 0.6769, Train MAE: 0.6769,
                            Val Loss: 0.6480, Val Acc: 0.6480, Test MAE: 0.6959
2022-09-05 22:18:09,558:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 22:19:21,219:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6930301515385509
2022-09-05 22:19:21,221:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 71.66s, LR: 0.00070, Train Loss: 0.6617, Train MAE: 0.6617,
                            Val Loss: 0.6168, Val Acc: 0.6168, Test MAE: 0.6930
2022-09-05 22:19:21,229:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 22:20:33,181:main_molecules_graph_regression.py:171 -   train_val_pipeline(): Best model with MAE 0.6601077243685722
2022-09-05 22:20:33,182:main_molecules_graph_regression.py:194 -   train_val_pipeline(): 	Time: 71.95s, LR: 0.00070, Train Loss: 0.6688, Train MAE: 0.6688,
                            Val Loss: 0.6194, Val Acc: 0.6194, Test MAE: 0.6601
2022-09-05 22:20:33,189:main_molecules_graph_regression.py:152 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 22:21:28,988:main_molecules_graph_regression.py:226 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 22:21:28,989:main_molecules_graph_regression.py:227 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 23:15:52,992:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 23:15:57,967:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': True, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'partial_rw_pos_enc': True, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 23:15:57,967:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 10}
2022-09-05 23:15:57,969:pe_layer.py:65 -             __init__(): partial_rw_pos_enc
2022-09-05 23:15:57,969:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 23:15:57,969:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:15:57,974:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 23:15:57,975:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522662
2022-09-05 23:15:57,975:pe_layer.py:65 -             __init__(): partial_rw_pos_enc
2022-09-05 23:15:57,975:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-05 23:15:57,975:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:15:57,980:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding partial random walk graph positional encoding (20).
2022-09-05 23:16:27,702:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:29.727109909057617
2022-09-05 23:16:27,702:main_CYCLES_graph_classification.py:95 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-05 23:19:07,755:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 23:19:07,756:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 23:19:07,756:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 23:19:07,756:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 23:19:07,759:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 23:20:48,465:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-prwpecheckpoints/GraphTransformer_CYCLES_GPU0_10_20_23h15m57s_on_Sep_05_2022/MODELS_
2022-09-05 23:20:48,468:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 100.71s, LR: 0.00050, Train Loss: 1.7923, Train Acc: 0.4650,
                        Val Loss: 1.8903, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:20:48,468:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 23:21:24,589:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 23:21:24,589:main_CYCLES_graph_classification.py:218 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 23:24:07,771:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 23:24:12,180:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': True, 'gape_softmax_before': True, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 23:24:12,180:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 23:24:12,181:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:24:12,182:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:24:12,182:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:24:12,182:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:24:12,188:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 23:24:12,189:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 540346
2022-09-05 23:24:12,190:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:24:12,191:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:24:12,191:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:24:12,191:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:24:12,196:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-05 23:24:12,196:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 23:24:53,557:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 23:24:57,832:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': True, 'gape_softmax_before': True, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 23:24:57,833:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 23:24:57,833:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:24:57,834:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:24:57,834:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:24:57,834:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:24:57,839:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 23:24:57,840:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524842
2022-09-05 23:24:57,840:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:24:57,841:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:24:57,841:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:24:57,841:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:24:57,846:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 23:24:57,846:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 23:28:26,419:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:208.5794961452484
2022-09-05 23:28:26,435:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 23:28:26,435:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 23:28:26,435:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 23:28:26,435:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 23:28:26,437:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 23:28:49,130:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h24m57s_on_Sep_05_2022/MODELS_
2022-09-05 23:28:49,131:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.69s, LR: 0.00050, Train Loss: 0.7456, Train Acc: 0.5900,
                        Val Loss: 0.7073, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:28:49,131:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 23:29:10,311:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.18s, LR: 0.00050, Train Loss: 0.6255, Train Acc: 0.6800,
                        Val Loss: 0.6947, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:29:10,312:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 23:29:32,554:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.24s, LR: 0.00050, Train Loss: 0.5694, Train Acc: 0.6850,
                        Val Loss: 0.6945, Val Acc: 0.4410, Test Acc: 0.4490
2022-09-05 23:29:32,555:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 23:29:55,000:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.44s, LR: 0.00050, Train Loss: 0.5101, Train Acc: 0.7550,
                        Val Loss: 0.9953, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:29:55,000:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 23:30:16,046:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.05s, LR: 0.00050, Train Loss: 0.5070, Train Acc: 0.7450,
                        Val Loss: 1.2662, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:30:16,047:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 23:30:37,431:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.38s, LR: 0.00050, Train Loss: 0.4787, Train Acc: 0.7750,
                        Val Loss: 1.1136, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:30:37,432:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 23:30:59,131:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.70s, LR: 0.00050, Train Loss: 0.4603, Train Acc: 0.8000,
                        Val Loss: 1.9037, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:30:59,131:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 23:31:22,783:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.65s, LR: 0.00050, Train Loss: 0.4339, Train Acc: 0.7800,
                        Val Loss: 1.0484, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:31:22,784:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 23:31:45,061:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.28s, LR: 0.00050, Train Loss: 0.3853, Train Acc: 0.8200,
                        Val Loss: 6.5345, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:31:45,062:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 23:32:06,560:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.50s, LR: 0.00050, Train Loss: 0.4518, Train Acc: 0.8250,
                        Val Loss: 13.1726, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:32:06,561:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 23:32:28,975:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.41s, LR: 0.00050, Train Loss: 0.3558, Train Acc: 0.8400,
                        Val Loss: 21.2973, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:32:28,975:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 23:32:51,840:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.86s, LR: 0.00050, Train Loss: 0.3612, Train Acc: 0.8500,
                        Val Loss: 31.3893, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:32:51,840:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 23:33:09,466:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 23:33:09,466:main_CYCLES_graph_classification.py:218 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 23:33:18,408:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 23:33:22,970:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': True, 'gape_softmax_before': True, 'gape_individual': True, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 23:33:22,970:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 23:33:22,970:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:33:22,971:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:33:22,971:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:33:22,971:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:33:22,976:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 23:33:22,977:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527562
2022-09-05 23:33:22,977:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:33:22,978:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:33:22,978:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:33:22,978:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:33:22,983:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 23:33:22,983:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 23:36:58,566:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:215.58914303779602
2022-09-05 23:36:58,583:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 23:36:58,583:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 23:36:58,583:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 23:36:58,583:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 23:36:58,585:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 23:37:21,362:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h33m22s_on_Sep_05_2022/MODELS_
2022-09-05 23:37:21,364:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.78s, LR: 0.00050, Train Loss: 0.7027, Train Acc: 0.5750,
                        Val Loss: 0.6927, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:37:21,364:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 23:37:44,592:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.23s, LR: 0.00050, Train Loss: 0.6156, Train Acc: 0.6500,
                        Val Loss: 0.8601, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:37:44,593:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 23:38:07,557:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.96s, LR: 0.00050, Train Loss: 0.5958, Train Acc: 0.6950,
                        Val Loss: 0.8896, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:38:07,557:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 23:38:31,089:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.53s, LR: 0.00050, Train Loss: 0.5271, Train Acc: 0.7450,
                        Val Loss: 0.9958, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:38:31,089:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 23:38:53,767:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.68s, LR: 0.00050, Train Loss: 0.5411, Train Acc: 0.7250,
                        Val Loss: 0.9285, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:38:53,768:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 23:39:17,133:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.37s, LR: 0.00050, Train Loss: 0.4874, Train Acc: 0.7600,
                        Val Loss: 0.7599, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:39:17,133:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 23:39:39,870:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.74s, LR: 0.00050, Train Loss: 0.4600, Train Acc: 0.7800,
                        Val Loss: 0.9608, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:39:39,871:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 23:40:04,988:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.12s, LR: 0.00050, Train Loss: 0.4870, Train Acc: 0.7300,
                        Val Loss: 1.5827, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:40:04,989:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 23:40:27,306:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.32s, LR: 0.00050, Train Loss: 0.4573, Train Acc: 0.7850,
                        Val Loss: 5.7667, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:40:27,307:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 23:40:49,925:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.62s, LR: 0.00050, Train Loss: 0.4607, Train Acc: 0.7750,
                        Val Loss: 17.0907, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:40:49,925:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 23:41:11,892:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.97s, LR: 0.00050, Train Loss: 0.4216, Train Acc: 0.7900,
                        Val Loss: 26.7686, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:41:11,893:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 23:41:34,703:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.81s, LR: 0.00050, Train Loss: 0.4340, Train Acc: 0.7950,
                        Val Loss: 11.2193, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:41:34,705:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 23:41:57,503:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.80s, LR: 0.00025, Train Loss: 0.4078, Train Acc: 0.8100,
                        Val Loss: 4.1719, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:41:57,504:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 23:42:19,669:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.17s, LR: 0.00025, Train Loss: 0.3745, Train Acc: 0.8250,
                        Val Loss: 53.1774, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:42:19,670:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 23:42:41,533:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.86s, LR: 0.00025, Train Loss: 0.3426, Train Acc: 0.8500,
                        Val Loss: 58.2596, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:42:41,534:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 23:43:04,102:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.57s, LR: 0.00025, Train Loss: 0.3200, Train Acc: 0.8500,
                        Val Loss: 67.2022, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-05 23:43:04,103:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 23:43:11,487:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 23:43:11,487:main_CYCLES_graph_classification.py:218 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 23:43:21,146:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 23:43:25,678:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 23:43:25,678:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 23:43:25,678:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:43:25,679:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:43:25,679:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:43:25,679:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:43:25,684:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 23:43:25,685:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527562
2022-09-05 23:43:25,686:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:43:25,686:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:43:25,687:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:43:25,687:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:43:25,692:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 23:43:25,692:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-05 23:46:59,322:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:213.6362931728363
2022-09-05 23:46:59,350:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-05 23:46:59,350:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-05 23:46:59,350:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-05 23:46:59,350:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-05 23:46:59,353:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-05 23:47:21,659:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5199 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 23:47:21,660:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.31s, LR: 0.00050, Train Loss: 1.2469, Train Acc: 0.5200,
                        Val Loss: 0.7670, Val Acc: 0.5330, Test Acc: 0.5199
2022-09-05 23:47:21,660:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-05 23:47:42,811:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.15s, LR: 0.00050, Train Loss: 0.8024, Train Acc: 0.5500,
                        Val Loss: 0.9895, Val Acc: 0.5330, Test Acc: 0.5170
2022-09-05 23:47:42,811:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-05 23:48:04,908:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.10s, LR: 0.00050, Train Loss: 0.8137, Train Acc: 0.5350,
                        Val Loss: 0.9325, Val Acc: 0.5190, Test Acc: 0.5100
2022-09-05 23:48:04,908:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-05 23:48:27,841:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.93s, LR: 0.00050, Train Loss: 0.7474, Train Acc: 0.5400,
                        Val Loss: 0.7851, Val Acc: 0.4960, Test Acc: 0.4920
2022-09-05 23:48:27,842:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-05 23:48:50,147:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.31s, LR: 0.00050, Train Loss: 0.6744, Train Acc: 0.5750,
                        Val Loss: 0.7092, Val Acc: 0.5340, Test Acc: 0.5159
2022-09-05 23:48:50,148:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-05 23:49:11,718:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.57s, LR: 0.00050, Train Loss: 0.7158, Train Acc: 0.5500,
                        Val Loss: 0.7359, Val Acc: 0.5300, Test Acc: 0.5121
2022-09-05 23:49:11,719:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-05 23:49:32,912:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.19s, LR: 0.00050, Train Loss: 0.6941, Train Acc: 0.5600,
                        Val Loss: 0.7535, Val Acc: 0.5060, Test Acc: 0.4990
2022-09-05 23:49:32,913:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-05 23:49:53,803:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5218 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 23:49:53,804:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.89s, LR: 0.00050, Train Loss: 0.6848, Train Acc: 0.5650,
                        Val Loss: 0.7450, Val Acc: 0.5270, Test Acc: 0.5218
2022-09-05 23:49:53,804:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-05 23:50:14,506:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5263 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 23:50:14,507:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.70s, LR: 0.00050, Train Loss: 0.6803, Train Acc: 0.5750,
                        Val Loss: 0.6986, Val Acc: 0.5410, Test Acc: 0.5263
2022-09-05 23:50:14,507:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-05 23:50:35,375:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.87s, LR: 0.00050, Train Loss: 0.6961, Train Acc: 0.5850,
                        Val Loss: 0.7261, Val Acc: 0.5470, Test Acc: 0.5192
2022-09-05 23:50:35,376:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-05 23:50:56,100:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.72s, LR: 0.00050, Train Loss: 0.6891, Train Acc: 0.5650,
                        Val Loss: 0.7156, Val Acc: 0.5300, Test Acc: 0.5213
2022-09-05 23:50:56,101:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-05 23:51:16,851:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5290 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 23:51:16,852:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.75s, LR: 0.00050, Train Loss: 0.6911, Train Acc: 0.5750,
                        Val Loss: 0.7212, Val Acc: 0.5200, Test Acc: 0.5290
2022-09-05 23:51:16,852:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-05 23:51:37,788:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.94s, LR: 0.00050, Train Loss: 0.6709, Train Acc: 0.5700,
                        Val Loss: 0.7336, Val Acc: 0.5180, Test Acc: 0.5172
2022-09-05 23:51:37,788:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-05 23:51:58,557:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.77s, LR: 0.00050, Train Loss: 0.7408, Train Acc: 0.5850,
                        Val Loss: 0.8425, Val Acc: 0.5240, Test Acc: 0.5119
2022-09-05 23:51:58,557:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-05 23:52:19,533:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5404 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h43m25s_on_Sep_05_2022/MODELS_
2022-09-05 23:52:19,534:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00050, Train Loss: 0.7757, Train Acc: 0.5350,
                        Val Loss: 0.7481, Val Acc: 0.5350, Test Acc: 0.5404
2022-09-05 23:52:19,534:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-05 23:52:40,349:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.81s, LR: 0.00050, Train Loss: 0.6535, Train Acc: 0.6000,
                        Val Loss: 0.7190, Val Acc: 0.5240, Test Acc: 0.5292
2022-09-05 23:52:40,349:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-05 23:53:01,090:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.74s, LR: 0.00050, Train Loss: 0.6423, Train Acc: 0.6250,
                        Val Loss: 0.7681, Val Acc: 0.5220, Test Acc: 0.5151
2022-09-05 23:53:01,091:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-05 23:53:21,877:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.79s, LR: 0.00050, Train Loss: 0.6726, Train Acc: 0.5600,
                        Val Loss: 0.7783, Val Acc: 0.5120, Test Acc: 0.5173
2022-09-05 23:53:21,877:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-05 23:53:29,229:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-05 23:53:29,229:main_CYCLES_graph_classification.py:218 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-05 23:53:36,017:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-05 23:53:40,351:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 6, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': True, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-05 23:53:40,351:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-05 23:53:40,351:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:53:40,353:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:53:40,353:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:53:40,353:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:53:40,359:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-05 23:53:40,359:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532461
2022-09-05 23:53:40,360:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-05 23:53:40,361:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-05 23:53:40,361:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-05 23:53:40,361:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-05 23:53:40,366:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-05 23:53:40,366:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 6 random automata.
2022-09-06 00:00:41,794:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:421.43407702445984
2022-09-06 00:00:41,814:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-06 00:00:41,814:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-06 00:00:41,814:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-06 00:00:41,814:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 00:00:41,818:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 00:01:05,466:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.4668 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m40s_on_Sep_05_2022/MODELS_
2022-09-06 00:01:05,467:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.65s, LR: 0.00050, Train Loss: 0.9509, Train Acc: 0.5050,
                        Val Loss: 1.6770, Val Acc: 0.4660, Test Acc: 0.4668
2022-09-06 00:01:05,467:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 00:01:28,465:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5072 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m40s_on_Sep_05_2022/MODELS_
2022-09-06 00:01:28,465:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.00s, LR: 0.00050, Train Loss: 0.8224, Train Acc: 0.4750,
                        Val Loss: 1.1748, Val Acc: 0.5240, Test Acc: 0.5072
2022-09-06 00:01:28,465:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 00:01:50,623:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.16s, LR: 0.00050, Train Loss: 0.7667, Train Acc: 0.5000,
                        Val Loss: 0.7582, Val Acc: 0.5130, Test Acc: 0.5047
2022-09-06 00:01:50,624:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 00:02:15,276:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.65s, LR: 0.00050, Train Loss: 0.7230, Train Acc: 0.5450,
                        Val Loss: 0.8052, Val Acc: 0.4750, Test Acc: 0.4893
2022-09-06 00:02:15,277:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 00:02:40,586:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.31s, LR: 0.00050, Train Loss: 0.6973, Train Acc: 0.5700,
                        Val Loss: 0.7974, Val Acc: 0.5160, Test Acc: 0.5000
2022-09-06 00:02:40,587:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 00:03:04,498:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5135 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m40s_on_Sep_05_2022/MODELS_
2022-09-06 00:03:04,499:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.91s, LR: 0.00050, Train Loss: 0.7064, Train Acc: 0.5350,
                        Val Loss: 0.6953, Val Acc: 0.5630, Test Acc: 0.5135
2022-09-06 00:03:04,499:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 00:03:28,674:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5161 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m40s_on_Sep_05_2022/MODELS_
2022-09-06 00:03:28,675:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00050, Train Loss: 0.7086, Train Acc: 0.5550,
                        Val Loss: 0.6995, Val Acc: 0.5520, Test Acc: 0.5161
2022-09-06 00:03:28,675:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 00:03:52,399:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5251 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m40s_on_Sep_05_2022/MODELS_
2022-09-06 00:03:52,400:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.72s, LR: 0.00050, Train Loss: 0.6829, Train Acc: 0.5750,
                        Val Loss: 0.8359, Val Acc: 0.5270, Test Acc: 0.5251
2022-09-06 00:03:52,400:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 00:04:16,022:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5267 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m40s_on_Sep_05_2022/MODELS_
2022-09-06 00:04:16,022:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.62s, LR: 0.00050, Train Loss: 0.7096, Train Acc: 0.5350,
                        Val Loss: 0.7243, Val Acc: 0.5240, Test Acc: 0.5267
2022-09-06 00:04:16,023:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 00:04:41,342:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.32s, LR: 0.00050, Train Loss: 0.6926, Train Acc: 0.5550,
                        Val Loss: 0.7023, Val Acc: 0.5370, Test Acc: 0.5220
2022-09-06 00:04:41,343:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 00:05:06,451:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.11s, LR: 0.00050, Train Loss: 0.6739, Train Acc: 0.5600,
                        Val Loss: 0.7358, Val Acc: 0.5530, Test Acc: 0.5198
2022-09-06 00:05:06,452:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 00:05:18,972:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 00:05:18,972:main_CYCLES_graph_classification.py:218 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 00:05:22,406:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 00:05:26,769:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 6, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 00:05:26,769:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-06 00:05:26,769:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 00:05:26,771:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 00:05:26,771:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 00:05:26,771:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 00:05:26,776:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 00:05:26,777:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525661
2022-09-06 00:05:26,778:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 00:05:26,779:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 00:05:26,779:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 00:05:26,779:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 00:05:26,785:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 00:05:26,785:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 6 random automata.
2022-09-06 00:12:25,165:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:418.38708305358887
2022-09-06 00:12:25,183:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-06 00:12:25,183:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-06 00:12:25,183:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-06 00:12:25,183:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 00:12:25,186:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 00:12:46,808:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:12:46,809:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.62s, LR: 0.00050, Train Loss: 0.7157, Train Acc: 0.5750,
                        Val Loss: 32.9806, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-06 00:12:46,809:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 00:13:09,483:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.67s, LR: 0.00050, Train Loss: 0.6298, Train Acc: 0.6500,
                        Val Loss: 7.4544, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-06 00:13:09,484:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 00:13:30,180:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.70s, LR: 0.00050, Train Loss: 0.5832, Train Acc: 0.7150,
                        Val Loss: 2.1130, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-06 00:13:30,180:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 00:13:50,703:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5010 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:13:50,703:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.52s, LR: 0.00050, Train Loss: 0.5552, Train Acc: 0.7350,
                        Val Loss: 1.7994, Val Acc: 0.5000, Test Acc: 0.5010
2022-09-06 00:13:50,703:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 00:14:12,800:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.10s, LR: 0.00050, Train Loss: 0.5575, Train Acc: 0.7150,
                        Val Loss: 2.2151, Val Acc: 0.5000, Test Acc: 0.5002
2022-09-06 00:14:12,801:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 00:14:33,942:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5794 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:14:33,942:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.14s, LR: 0.00050, Train Loss: 0.5179, Train Acc: 0.7600,
                        Val Loss: 0.9008, Val Acc: 0.6040, Test Acc: 0.5794
2022-09-06 00:14:33,942:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 00:14:53,605:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5909 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:14:53,606:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 19.66s, LR: 0.00050, Train Loss: 0.4955, Train Acc: 0.7400,
                        Val Loss: 0.9086, Val Acc: 0.5980, Test Acc: 0.5909
2022-09-06 00:14:53,606:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 00:15:13,879:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.27s, LR: 0.00050, Train Loss: 0.4746, Train Acc: 0.7850,
                        Val Loss: 3.8719, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-06 00:15:13,880:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 00:15:34,802:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.92s, LR: 0.00050, Train Loss: 0.4780, Train Acc: 0.7600,
                        Val Loss: 1.9584, Val Acc: 0.5020, Test Acc: 0.5002
2022-09-06 00:15:34,803:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 00:15:55,906:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.10s, LR: 0.00050, Train Loss: 0.4906, Train Acc: 0.7500,
                        Val Loss: 3.4136, Val Acc: 0.5070, Test Acc: 0.5067
2022-09-06 00:15:55,907:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 00:16:16,720:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6708 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:16:16,720:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.81s, LR: 0.00050, Train Loss: 0.4488, Train Acc: 0.7850,
                        Val Loss: 0.7697, Val Acc: 0.6770, Test Acc: 0.6708
2022-09-06 00:16:16,720:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 00:16:38,071:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.6769 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:16:38,072:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.35s, LR: 0.00050, Train Loss: 0.4226, Train Acc: 0.7900,
                        Val Loss: 0.5971, Val Acc: 0.6840, Test Acc: 0.6769
2022-09-06 00:16:38,073:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 00:17:00,638:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.57s, LR: 0.00050, Train Loss: 0.4214, Train Acc: 0.7800,
                        Val Loss: 1.4917, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-06 00:17:00,639:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 00:17:20,484:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 19.84s, LR: 0.00050, Train Loss: 0.3936, Train Acc: 0.8150,
                        Val Loss: 1.6752, Val Acc: 0.5010, Test Acc: 0.5005
2022-09-06 00:17:20,484:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 00:17:41,776:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.29s, LR: 0.00050, Train Loss: 0.4068, Train Acc: 0.7800,
                        Val Loss: 1.6004, Val Acc: 0.5090, Test Acc: 0.5113
2022-09-06 00:17:41,778:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 00:18:04,331:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7099 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:18:04,331:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.55s, LR: 0.00050, Train Loss: 0.3611, Train Acc: 0.8350,
                        Val Loss: 0.5558, Val Acc: 0.7200, Test Acc: 0.7099
2022-09-06 00:18:04,331:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 00:18:25,770:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.44s, LR: 0.00050, Train Loss: 0.3856, Train Acc: 0.8650,
                        Val Loss: 0.7385, Val Acc: 0.5710, Test Acc: 0.5628
2022-09-06 00:18:25,770:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 00:18:48,368:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.60s, LR: 0.00050, Train Loss: 0.3625, Train Acc: 0.8350,
                        Val Loss: 1.1398, Val Acc: 0.5370, Test Acc: 0.5160
2022-09-06 00:18:48,370:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 00:19:10,586:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.22s, LR: 0.00050, Train Loss: 0.3508, Train Acc: 0.8400,
                        Val Loss: 0.9901, Val Acc: 0.5320, Test Acc: 0.5282
2022-09-06 00:19:10,587:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 00:19:32,069:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.48s, LR: 0.00050, Train Loss: 0.3345, Train Acc: 0.8650,
                        Val Loss: 3.0948, Val Acc: 0.5020, Test Acc: 0.5012
2022-09-06 00:19:32,071:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 00:19:53,678:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.61s, LR: 0.00050, Train Loss: 0.3873, Train Acc: 0.8300,
                        Val Loss: 0.7132, Val Acc: 0.6980, Test Acc: 0.6922
2022-09-06 00:19:53,678:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 00:20:16,027:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.35s, LR: 0.00050, Train Loss: 0.3688, Train Acc: 0.8000,
                        Val Loss: 1.4694, Val Acc: 0.5360, Test Acc: 0.5312
2022-09-06 00:20:16,028:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 00:20:36,415:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.39s, LR: 0.00050, Train Loss: 0.3389, Train Acc: 0.8300,
                        Val Loss: 0.9376, Val Acc: 0.6530, Test Acc: 0.6315
2022-09-06 00:20:36,416:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-06 00:20:56,488:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.07s, LR: 0.00050, Train Loss: 0.2925, Train Acc: 0.8550,
                        Val Loss: 2.1542, Val Acc: 0.5380, Test Acc: 0.5402
2022-09-06 00:20:56,488:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 25/1000
2022-09-06 00:21:18,630:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.14s, LR: 0.00050, Train Loss: 0.2753, Train Acc: 0.8600,
                        Val Loss: 1.2358, Val Acc: 0.6240, Test Acc: 0.6367
2022-09-06 00:21:18,631:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 26/1000
2022-09-06 00:21:41,214:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.58s, LR: 0.00050, Train Loss: 0.2598, Train Acc: 0.9100,
                        Val Loss: 1.4571, Val Acc: 0.6140, Test Acc: 0.6055
2022-09-06 00:21:41,215:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 27/1000
2022-09-06 00:22:03,798:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.58s, LR: 0.00050, Train Loss: 0.2649, Train Acc: 0.8900,
                        Val Loss: 3.2679, Val Acc: 0.5200, Test Acc: 0.5149
2022-09-06 00:22:03,798:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 28/1000
2022-09-06 00:22:24,679:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.88s, LR: 0.00025, Train Loss: 0.2224, Train Acc: 0.8950,
                        Val Loss: 3.0292, Val Acc: 0.5300, Test Acc: 0.5291
2022-09-06 00:22:24,679:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 29/1000
2022-09-06 00:22:47,973:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7474 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:22:47,974:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.30s, LR: 0.00025, Train Loss: 0.2079, Train Acc: 0.9200,
                        Val Loss: 0.6265, Val Acc: 0.7460, Test Acc: 0.7474
2022-09-06 00:22:47,974:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 30/1000
2022-09-06 00:23:09,302:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.33s, LR: 0.00025, Train Loss: 0.2071, Train Acc: 0.9050,
                        Val Loss: 0.9101, Val Acc: 0.6790, Test Acc: 0.6898
2022-09-06 00:23:09,302:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 31/1000
2022-09-06 00:23:29,414:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.11s, LR: 0.00025, Train Loss: 0.1941, Train Acc: 0.9250,
                        Val Loss: 1.1005, Val Acc: 0.6930, Test Acc: 0.6849
2022-09-06 00:23:29,414:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 32/1000
2022-09-06 00:23:50,378:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.96s, LR: 0.00025, Train Loss: 0.1833, Train Acc: 0.9350,
                        Val Loss: 1.2023, Val Acc: 0.6780, Test Acc: 0.6663
2022-09-06 00:23:50,378:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 33/1000
2022-09-06 00:24:11,279:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.90s, LR: 0.00025, Train Loss: 0.1572, Train Acc: 0.9500,
                        Val Loss: 1.0639, Val Acc: 0.6890, Test Acc: 0.6742
2022-09-06 00:24:11,279:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 34/1000
2022-09-06 00:24:32,157:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.88s, LR: 0.00025, Train Loss: 0.1551, Train Acc: 0.9500,
                        Val Loss: 0.5910, Val Acc: 0.7560, Test Acc: 0.7416
2022-09-06 00:24:32,158:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 35/1000
2022-09-06 00:24:55,014:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.86s, LR: 0.00025, Train Loss: 0.1435, Train Acc: 0.9400,
                        Val Loss: 0.7101, Val Acc: 0.7400, Test Acc: 0.7199
2022-09-06 00:24:55,015:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 36/1000
2022-09-06 00:25:17,396:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.38s, LR: 0.00025, Train Loss: 0.1846, Train Acc: 0.9300,
                        Val Loss: 1.6705, Val Acc: 0.6320, Test Acc: 0.6392
2022-09-06 00:25:17,396:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 37/1000
2022-09-06 00:25:39,567:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.17s, LR: 0.00025, Train Loss: 0.1884, Train Acc: 0.9400,
                        Val Loss: 0.7226, Val Acc: 0.6860, Test Acc: 0.6734
2022-09-06 00:25:39,567:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 38/1000
2022-09-06 00:26:00,413:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.85s, LR: 0.00025, Train Loss: 0.2239, Train Acc: 0.9050,
                        Val Loss: 3.9605, Val Acc: 0.5200, Test Acc: 0.5195
2022-09-06 00:26:00,413:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 39/1000
2022-09-06 00:26:20,849:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.44s, LR: 0.00013, Train Loss: 0.1317, Train Acc: 0.9350,
                        Val Loss: 1.5253, Val Acc: 0.6190, Test Acc: 0.6171
2022-09-06 00:26:20,849:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 40/1000
2022-09-06 00:26:43,821:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.97s, LR: 0.00013, Train Loss: 0.1362, Train Acc: 0.9500,
                        Val Loss: 0.9144, Val Acc: 0.6920, Test Acc: 0.6792
2022-09-06 00:26:43,822:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 41/1000
2022-09-06 00:27:05,807:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.98s, LR: 0.00013, Train Loss: 0.1445, Train Acc: 0.9350,
                        Val Loss: 0.8413, Val Acc: 0.7190, Test Acc: 0.7037
2022-09-06 00:27:05,808:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 42/1000
2022-09-06 00:27:28,362:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7724 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:27:28,363:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.55s, LR: 0.00013, Train Loss: 0.1200, Train Acc: 0.9650,
                        Val Loss: 0.6420, Val Acc: 0.7820, Test Acc: 0.7724
2022-09-06 00:27:28,363:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 43/1000
2022-09-06 00:27:51,239:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.7761 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h05m26s_on_Sep_06_2022/MODELS_
2022-09-06 00:27:51,239:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.88s, LR: 0.00013, Train Loss: 0.1134, Train Acc: 0.9550,
                        Val Loss: 0.6122, Val Acc: 0.7910, Test Acc: 0.7761
2022-09-06 00:27:51,239:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 44/1000
2022-09-06 00:28:12,001:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.76s, LR: 0.00013, Train Loss: 0.1163, Train Acc: 0.9650,
                        Val Loss: 0.6416, Val Acc: 0.7870, Test Acc: 0.7671
2022-09-06 00:28:12,001:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 45/1000
2022-09-06 00:28:32,598:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.60s, LR: 0.00013, Train Loss: 0.1281, Train Acc: 0.9600,
                        Val Loss: 0.6836, Val Acc: 0.7730, Test Acc: 0.7570
2022-09-06 00:28:32,600:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 46/1000
2022-09-06 00:28:54,777:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.18s, LR: 0.00013, Train Loss: 0.1158, Train Acc: 0.9700,
                        Val Loss: 0.7404, Val Acc: 0.7710, Test Acc: 0.7465
2022-09-06 00:28:54,777:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 47/1000
2022-09-06 00:29:17,539:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.76s, LR: 0.00013, Train Loss: 0.1098, Train Acc: 0.9600,
                        Val Loss: 0.6879, Val Acc: 0.7850, Test Acc: 0.7547
2022-09-06 00:29:17,540:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 48/1000
2022-09-06 00:29:38,096:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.56s, LR: 0.00013, Train Loss: 0.1089, Train Acc: 0.9650,
                        Val Loss: 0.8244, Val Acc: 0.7360, Test Acc: 0.7138
2022-09-06 00:29:38,097:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 49/1000
2022-09-06 00:29:57,835:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 19.74s, LR: 0.00013, Train Loss: 0.1066, Train Acc: 0.9550,
                        Val Loss: 0.6672, Val Acc: 0.7710, Test Acc: 0.7594
2022-09-06 00:29:57,835:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 50/1000
2022-09-06 00:30:11,711:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 00:30:11,711:main_CYCLES_graph_classification.py:218 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 00:30:23,818:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 00:30:28,536:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 24, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 6, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 00:30:28,537:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-06 00:30:28,537:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 00:30:28,538:pe_layer.py:129 -             __init__(): Using 24 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 00:30:28,539:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 00:30:28,539:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 00:30:28,543:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 00:30:28,544:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 528269
2022-09-06 00:30:28,545:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 00:30:28,545:pe_layer.py:129 -             __init__(): Using 24 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 00:30:28,545:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 00:30:28,546:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 00:30:28,551:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (24).
2022-09-06 00:30:28,551:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 6 random automata.
2022-09-06 00:37:36,797:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:428.25266671180725
2022-09-06 00:37:36,817:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-06 00:37:36,818:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-06 00:37:36,818:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-06 00:37:36,818:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 00:37:36,820:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 00:37:59,814:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.4769 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:37:59,816:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.00s, LR: 0.00050, Train Loss: 1.2428, Train Acc: 0.4350,
                        Val Loss: 0.8041, Val Acc: 0.4870, Test Acc: 0.4769
2022-09-06 00:37:59,816:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 00:38:23,580:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5060 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:38:23,581:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.76s, LR: 0.00050, Train Loss: 0.7593, Train Acc: 0.5000,
                        Val Loss: 0.7982, Val Acc: 0.5280, Test Acc: 0.5060
2022-09-06 00:38:23,581:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 00:38:46,593:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5077 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:38:46,594:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.01s, LR: 0.00050, Train Loss: 0.7222, Train Acc: 0.5250,
                        Val Loss: 0.8080, Val Acc: 0.5190, Test Acc: 0.5077
2022-09-06 00:38:46,594:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 00:39:10,445:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.85s, LR: 0.00050, Train Loss: 0.6875, Train Acc: 0.5550,
                        Val Loss: 0.7312, Val Acc: 0.5200, Test Acc: 0.5059
2022-09-06 00:39:10,445:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 00:39:34,034:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5086 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:39:34,034:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.59s, LR: 0.00050, Train Loss: 0.6775, Train Acc: 0.5750,
                        Val Loss: 0.7780, Val Acc: 0.4960, Test Acc: 0.5086
2022-09-06 00:39:34,034:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 00:39:56,411:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5188 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:39:56,412:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.38s, LR: 0.00050, Train Loss: 0.7251, Train Acc: 0.5200,
                        Val Loss: 0.7259, Val Acc: 0.5120, Test Acc: 0.5188
2022-09-06 00:39:56,412:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 00:40:19,793:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.38s, LR: 0.00050, Train Loss: 0.6805, Train Acc: 0.5650,
                        Val Loss: 0.7251, Val Acc: 0.5210, Test Acc: 0.5094
2022-09-06 00:40:19,793:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 00:40:41,567:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.77s, LR: 0.00050, Train Loss: 0.6806, Train Acc: 0.5650,
                        Val Loss: 0.7236, Val Acc: 0.5180, Test Acc: 0.5172
2022-09-06 00:40:41,567:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 00:41:02,714:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5235 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:41:02,714:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.15s, LR: 0.00050, Train Loss: 0.6912, Train Acc: 0.5700,
                        Val Loss: 0.7623, Val Acc: 0.5150, Test Acc: 0.5235
2022-09-06 00:41:02,714:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 00:41:23,808:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.09s, LR: 0.00050, Train Loss: 0.6850, Train Acc: 0.5750,
                        Val Loss: 0.7438, Val Acc: 0.5260, Test Acc: 0.5161
2022-09-06 00:41:23,808:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 00:41:45,665:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5291 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:41:45,665:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.86s, LR: 0.00050, Train Loss: 0.6955, Train Acc: 0.5450,
                        Val Loss: 0.7121, Val Acc: 0.5390, Test Acc: 0.5291
2022-09-06 00:41:45,665:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 00:42:06,642:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00050, Train Loss: 0.6606, Train Acc: 0.5650,
                        Val Loss: 0.7036, Val Acc: 0.5360, Test Acc: 0.5257
2022-09-06 00:42:06,642:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 00:42:27,802:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5308 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:42:27,802:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.16s, LR: 0.00050, Train Loss: 0.6685, Train Acc: 0.6050,
                        Val Loss: 0.7236, Val Acc: 0.5290, Test Acc: 0.5308
2022-09-06 00:42:27,802:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 00:42:48,909:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.11s, LR: 0.00050, Train Loss: 0.7185, Train Acc: 0.5850,
                        Val Loss: 0.8084, Val Acc: 0.5330, Test Acc: 0.5198
2022-09-06 00:42:48,909:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 00:43:09,938:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5325 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:43:09,939:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.03s, LR: 0.00050, Train Loss: 0.7325, Train Acc: 0.5550,
                        Val Loss: 0.7204, Val Acc: 0.5320, Test Acc: 0.5325
2022-09-06 00:43:09,939:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 00:43:30,988:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.05s, LR: 0.00050, Train Loss: 0.6592, Train Acc: 0.6150,
                        Val Loss: 0.7267, Val Acc: 0.5260, Test Acc: 0.5166
2022-09-06 00:43:30,989:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 00:43:52,013:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5402 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:43:52,014:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.02s, LR: 0.00050, Train Loss: 0.6425, Train Acc: 0.6400,
                        Val Loss: 0.7452, Val Acc: 0.5300, Test Acc: 0.5402
2022-09-06 00:43:52,014:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 00:44:13,342:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5453 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:44:13,342:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.33s, LR: 0.00050, Train Loss: 0.6489, Train Acc: 0.6000,
                        Val Loss: 0.7262, Val Acc: 0.5340, Test Acc: 0.5453
2022-09-06 00:44:13,342:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 00:44:35,690:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.35s, LR: 0.00050, Train Loss: 0.6835, Train Acc: 0.5700,
                        Val Loss: 0.7119, Val Acc: 0.5230, Test Acc: 0.5272
2022-09-06 00:44:35,690:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 00:44:59,104:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.41s, LR: 0.00050, Train Loss: 0.6304, Train Acc: 0.6250,
                        Val Loss: 0.7202, Val Acc: 0.5310, Test Acc: 0.5281
2022-09-06 00:44:59,104:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 00:45:21,973:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.87s, LR: 0.00050, Train Loss: 0.6656, Train Acc: 0.6050,
                        Val Loss: 0.7130, Val Acc: 0.5450, Test Acc: 0.5303
2022-09-06 00:45:21,974:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 00:45:44,259:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5460 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:45:44,260:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.29s, LR: 0.00050, Train Loss: 0.6358, Train Acc: 0.6350,
                        Val Loss: 0.7259, Val Acc: 0.5330, Test Acc: 0.5460
2022-09-06 00:45:44,260:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 00:46:06,912:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.65s, LR: 0.00050, Train Loss: 0.6485, Train Acc: 0.6250,
                        Val Loss: 0.7142, Val Acc: 0.5350, Test Acc: 0.5415
2022-09-06 00:46:06,913:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 24/1000
2022-09-06 00:46:28,365:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 21.45s, LR: 0.00025, Train Loss: 0.6616, Train Acc: 0.6200,
                        Val Loss: 0.7083, Val Acc: 0.5340, Test Acc: 0.5359
2022-09-06 00:46:28,366:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 25/1000
2022-09-06 00:46:50,420:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.05s, LR: 0.00025, Train Loss: 0.6427, Train Acc: 0.6650,
                        Val Loss: 0.7154, Val Acc: 0.5320, Test Acc: 0.5379
2022-09-06 00:46:50,420:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 26/1000
2022-09-06 00:47:15,398:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.98s, LR: 0.00025, Train Loss: 0.6150, Train Acc: 0.6350,
                        Val Loss: 0.7061, Val Acc: 0.5360, Test Acc: 0.5334
2022-09-06 00:47:15,400:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 27/1000
2022-09-06 00:47:39,825:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.43s, LR: 0.00025, Train Loss: 0.6211, Train Acc: 0.6300,
                        Val Loss: 0.6978, Val Acc: 0.5410, Test Acc: 0.5442
2022-09-06 00:47:39,826:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 28/1000
2022-09-06 00:48:03,804:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5534 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:48:03,805:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.98s, LR: 0.00025, Train Loss: 0.6438, Train Acc: 0.6250,
                        Val Loss: 0.7074, Val Acc: 0.5480, Test Acc: 0.5534
2022-09-06 00:48:03,805:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 29/1000
2022-09-06 00:48:30,158:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 26.35s, LR: 0.00025, Train Loss: 0.6486, Train Acc: 0.6050,
                        Val Loss: 0.7276, Val Acc: 0.5440, Test Acc: 0.5459
2022-09-06 00:48:30,158:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 30/1000
2022-09-06 00:48:54,982:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.82s, LR: 0.00025, Train Loss: 0.6309, Train Acc: 0.6150,
                        Val Loss: 0.6951, Val Acc: 0.5370, Test Acc: 0.5391
2022-09-06 00:48:54,984:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 31/1000
2022-09-06 00:49:19,781:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.80s, LR: 0.00025, Train Loss: 0.6352, Train Acc: 0.6300,
                        Val Loss: 0.6846, Val Acc: 0.5570, Test Acc: 0.5515
2022-09-06 00:49:19,782:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 32/1000
2022-09-06 00:49:44,711:main_CYCLES_graph_classification.py:164 -   train_val_pipeline(): Saving best model with test accuracy: 0.5614 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_24_00h30m28s_on_Sep_06_2022/MODELS_
2022-09-06 00:49:44,711:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.93s, LR: 0.00025, Train Loss: 0.6227, Train Acc: 0.6400,
                        Val Loss: 0.6896, Val Acc: 0.5690, Test Acc: 0.5614
2022-09-06 00:49:44,711:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 33/1000
2022-09-06 00:50:08,961:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.25s, LR: 0.00025, Train Loss: 0.6096, Train Acc: 0.6500,
                        Val Loss: 0.6947, Val Acc: 0.5580, Test Acc: 0.5454
2022-09-06 00:50:08,961:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 34/1000
2022-09-06 00:50:34,173:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 25.21s, LR: 0.00025, Train Loss: 0.6130, Train Acc: 0.6650,
                        Val Loss: 0.7004, Val Acc: 0.5390, Test Acc: 0.5564
2022-09-06 00:50:34,173:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 35/1000
2022-09-06 00:50:58,677:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 24.50s, LR: 0.00025, Train Loss: 0.5997, Train Acc: 0.6700,
                        Val Loss: 0.7030, Val Acc: 0.5710, Test Acc: 0.5564
2022-09-06 00:50:58,677:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 36/1000
2022-09-06 00:51:21,685:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.01s, LR: 0.00025, Train Loss: 0.5962, Train Acc: 0.6550,
                        Val Loss: 0.7442, Val Acc: 0.5540, Test Acc: 0.5500
2022-09-06 00:51:21,686:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 37/1000
2022-09-06 00:51:43,743:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 22.06s, LR: 0.00025, Train Loss: 0.6001, Train Acc: 0.6700,
                        Val Loss: 0.7025, Val Acc: 0.5370, Test Acc: 0.5566
2022-09-06 00:51:43,744:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 38/1000
2022-09-06 00:52:06,815:main_CYCLES_graph_classification.py:186 -   train_val_pipeline(): 	Time: 23.07s, LR: 0.00025, Train Loss: 0.5895, Train Acc: 0.6800,
                        Val Loss: 0.7268, Val Acc: 0.5440, Test Acc: 0.5403
2022-09-06 00:52:06,816:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 39/1000
2022-09-06 00:52:10,132:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 00:52:10,132:main_CYCLES_graph_classification.py:218 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 00:54:30,771:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 00:54:35,054:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': True, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 24, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'n_gape': 6, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 00:54:35,054:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-06 00:54:35,054:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 00:54:35,056:pe_layer.py:129 -             __init__(): Using 24 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 00:54:35,056:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 00:54:35,056:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 00:54:35,061:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 00:54:35,062:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 528269
2022-09-06 00:54:35,063:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 00:54:35,064:pe_layer.py:129 -             __init__(): Using 24 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 00:54:35,064:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 00:54:35,064:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 00:54:35,069:main_CYCLES_graph_classification.py:66 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (24).
2022-09-06 00:54:35,069:main_CYCLES_graph_classification.py:70 -   train_val_pipeline(): [!] Using 6 random automata.
2022-09-06 01:01:39,198:main_CYCLES_graph_classification.py:74 -   train_val_pipeline(): Time PE:424.1357901096344
2022-09-06 01:01:39,198:main_CYCLES_graph_classification.py:95 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:04:05,313:main_CYCLES_graph_classification.py:120 -   train_val_pipeline(): Training Graphs: 200
2022-09-06 01:04:05,313:main_CYCLES_graph_classification.py:121 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-06 01:04:05,313:main_CYCLES_graph_classification.py:122 -   train_val_pipeline(): Test Graphs: 10000
2022-09-06 01:04:05,313:main_CYCLES_graph_classification.py:123 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 01:04:05,316:main_CYCLES_graph_classification.py:148 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 01:20:33,666:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:20:38,237:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:20:38,237:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:20:38,243:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:20:38,244:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 660182
2022-09-06 01:20:38,251:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:22:19,000:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:22:23,804:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:22:23,804:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:22:23,811:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:22:23,811:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 660182
2022-09-06 01:22:23,818:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:23:02,049:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:23:06,404:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 12, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:23:06,404:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:23:06,410:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:23:06,411:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 640982
2022-09-06 01:23:06,417:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:23:27,571:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:23:32,124:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 4, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:23:32,125:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:23:32,131:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:23:32,132:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 660182
2022-09-06 01:23:32,138:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:24:10,270:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:24:14,981:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:24:14,981:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:24:14,988:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:24:14,989:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 592958
2022-09-06 01:24:14,995:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:26:25,376:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:26:29,934:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:26:29,934:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:26:29,940:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:26:29,941:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 494252
2022-09-06 01:26:29,948:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:26:47,622:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:26:52,279:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:26:52,279:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:26:52,286:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:26:52,286:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 561476
2022-09-06 01:26:52,293:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:26:59,018:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:27:03,602:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 20, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:27:03,602:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:27:03,608:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:27:03,609:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 595472
2022-09-06 01:27:03,615:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:27:22,485:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:27:26,968:main_CYCLES_graph_classification.py:336 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'lpe_layers': 2, 'pos_enc_dim': 20, 'lpe_n_heads': 4, 'edge_feat': False, 'pos_enc': False, 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-06 01:27:26,968:main_CYCLES_graph_classification.py:337 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:27:26,974:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:27:26,975:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 507086
2022-09-06 01:27:26,981:main_CYCLES_graph_classification.py:83 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:33:58,778:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:34:04,122:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 10, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 01:34:04,123:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 10}
2022-09-06 01:36:48,142:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:36:53,192:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 8, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 01:36:53,193:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:36:53,199:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:36:53,200:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 558258
2022-09-06 01:36:53,490:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:36:55,593:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.381098985671997
2022-09-06 01:36:55,593:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:37:00,962:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:37:05,622:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 01:37:05,622:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:37:05,629:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:37:05,630:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 591834
2022-09-06 01:37:05,972:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:37:08,069:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.4318599700927734
2022-09-06 01:37:08,070:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:38:00,184:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:38:04,554:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 01:38:04,554:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:38:04,565:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:38:04,567:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 591834
2022-09-06 01:38:04,832:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:38:06,389:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:1.812608003616333
2022-09-06 01:38:06,389:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:38:30,911:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:38:35,351:main_SBMs_node_classification.py:340 -                 main(): {'L': 16, 'n_heads': 8, 'hidden_dim': 48, 'out_dim': 48, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 01:38:35,351:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:38:35,358:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:38:35,359:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 371634
2022-09-06 01:38:35,641:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:38:37,480:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.1134090423583984
2022-09-06 01:38:37,480:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:39:08,719:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:39:13,181:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 01:39:13,181:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:39:13,187:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:39:13,188:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 591834
2022-09-06 01:39:13,439:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:39:15,651:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.4572489261627197
2022-09-06 01:39:15,651:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:39:22,175:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:39:26,670:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 72, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 01:39:26,670:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 8}
2022-09-06 01:39:26,675:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:39:26,676:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 493080
2022-09-06 01:39:26,944:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:39:29,117:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.4347760677337646
2022-09-06 01:39:29,117:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:42:34,550:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:42:40,717:main_SBMs_node_classification.py:340 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:42:40,717:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:42:40,722:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:42:40,722:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 417958
2022-09-06 01:42:41,219:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:42:47,592:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:6.864823818206787
2022-09-06 01:42:47,592:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:42:59,408:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 01:42:59,408:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 01:42:59,408:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 01:42:59,408:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 01:42:59,410:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 01:44:28,522:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:44:34,595:main_SBMs_node_classification.py:340 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:44:34,595:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:44:34,600:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:44:34,600:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 417958
2022-09-06 01:44:35,118:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:44:36,980:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.3753881454467773
2022-09-06 01:44:36,980:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:44:48,762:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 01:44:48,763:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 01:44:48,763:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 01:44:48,763:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 01:44:48,764:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 01:45:13,243:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:45:18,829:main_SBMs_node_classification.py:340 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:45:18,829:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:45:18,834:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:45:18,834:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 417958
2022-09-06 01:45:19,270:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:45:20,461:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:1.6225059032440186
2022-09-06 01:45:20,462:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:45:32,107:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 01:45:32,108:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 01:45:32,108:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 01:45:32,108:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 01:45:32,109:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 01:45:39,353:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 01:45:39,353:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 01:46:20,389:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:46:26,128:main_SBMs_node_classification.py:340 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:46:26,129:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:46:26,133:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:46:26,134:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 417958
2022-09-06 01:46:26,650:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:46:28,613:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.4743130207061768
2022-09-06 01:46:28,613:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:46:51,725:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:46:57,465:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:46:57,466:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:46:57,474:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:46:57,475:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 728998
2022-09-06 01:46:58,005:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:47:00,535:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:3.053194999694824
2022-09-06 01:47:00,535:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:47:14,945:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:47:20,561:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:47:20,562:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:47:20,569:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:47:20,570:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 728998
2022-09-06 01:47:21,039:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:47:22,811:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.2340762615203857
2022-09-06 01:47:22,811:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:47:34,736:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 01:47:34,736:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 01:47:34,737:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 01:47:34,737:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 01:47:34,738:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 01:47:57,388:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:48:03,312:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:48:03,312:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:48:03,320:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:48:03,321:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 719684
2022-09-06 01:48:03,809:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:48:05,812:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.483397960662842
2022-09-06 01:48:05,812:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:48:17,261:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:48:22,915:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:48:22,915:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:48:22,922:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:48:22,923:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 720164
2022-09-06 01:48:23,459:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:48:25,583:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.6541318893432617
2022-09-06 01:48:25,583:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:48:48,436:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:48:54,083:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:48:54,084:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:48:54,091:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:48:54,092:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 711090
2022-09-06 01:48:54,571:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:48:56,803:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.7040019035339355
2022-09-06 01:48:56,803:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:49:06,344:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:49:12,066:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 56, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:49:12,066:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:49:12,073:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:49:12,074:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 703216
2022-09-06 01:49:12,546:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:49:14,675:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.5943281650543213
2022-09-06 01:49:14,676:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:49:31,160:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:49:36,733:main_SBMs_node_classification.py:340 -                 main(): {'L': 8, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 8, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:49:36,734:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:49:36,743:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:49:36,744:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 569812
2022-09-06 01:49:37,239:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:49:39,061:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.310737133026123
2022-09-06 01:49:39,061:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:50:02,137:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:50:07,925:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 72, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:50:07,927:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:50:07,934:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:50:07,935:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 651412
2022-09-06 01:50:08,431:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:50:10,931:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.9886693954467773
2022-09-06 01:50:10,931:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:50:22,145:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:50:27,874:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 64, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 2, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:50:27,874:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:50:27,882:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:50:27,883:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 643298
2022-09-06 01:50:28,362:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:50:30,567:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.676651954650879
2022-09-06 01:50:30,567:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:52:16,372:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:52:22,280:main_SBMs_node_classification.py:340 -                 main(): {'L': 4, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:52:22,280:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:52:22,285:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:52:22,285:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 417958
2022-09-06 01:52:22,800:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:52:24,996:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:2.7053732872009277
2022-09-06 01:52:24,996:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:52:34,672:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:52:40,467:main_SBMs_node_classification.py:340 -                 main(): {'L': 5, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:52:40,469:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:52:40,473:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:52:40,474:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 469798
2022-09-06 01:52:40,959:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 01:52:43,484:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:3.005049228668213
2022-09-06 01:52:43,484:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 01:52:47,821:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 01:52:53,609:main_SBMs_node_classification.py:340 -                 main(): {'L': 6, 'n_heads': 10, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 3, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 16, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-06 01:52:53,609:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 16, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 01:52:53,615:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 01:52:53,615:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 521638
2022-09-06 01:52:54,161:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 02:03:40,443:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 02:03:45,026:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': True, 'lpe_layers': 1, 'pos_enc_dim': 16, 'lpe_n_heads': 4, 'gpu_id': 0, 'batch_size': 10, 'rand_pos_enc': False, 'pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': True, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 7, 'n_classes': 6}
2022-09-06 02:03:45,026:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 10, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 02:03:45,033:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 02:03:45,034:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: SAGraphTransformer, 591834
2022-09-06 02:03:45,341:main_SBMs_node_classification.py:96 -   train_val_pipeline(): [!] Adding Laplacian decompositions for spectral attention.
2022-09-06 02:03:51,651:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:6.610934019088745
2022-09-06 02:03:51,651:main_SBMs_node_classification.py:107 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-06 03:30:09,966:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:30:16,457:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:30:16,457:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:30:16,458:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:30:16,479:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:30:16,480:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:30:16,480:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:30:16,490:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:30:16,494:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 03:30:16,494:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:30:16,495:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:30:16,495:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:30:16,495:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:30:17,017:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 03:30:49,104:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:32.5980429649353
2022-09-06 03:30:49,105:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:30:49,106:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:30:49,106:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:30:49,106:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:30:49,107:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:30:56,752:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.3789 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h30m16s_on_Sep_06_2022/MODELS_
2022-09-06 03:30:56,752:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.5809, Train Acc: 84.9638,
                        Val Loss: 0.8208, Val Acc: 50.2756, Test Acc: 50.3789
2022-09-06 03:30:56,752:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:31:04,559:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 51.2317 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h30m16s_on_Sep_06_2022/MODELS_
2022-09-06 03:31:04,560:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.81s, LR: 0.00050, Train Loss: 0.4985, Train Acc: 85.9982,
                        Val Loss: 0.7742, Val Acc: 51.1445, Test Acc: 51.2317
2022-09-06 03:31:04,560:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:31:11,967:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.0230 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h30m16s_on_Sep_06_2022/MODELS_
2022-09-06 03:31:11,967:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.41s, LR: 0.00050, Train Loss: 0.4619, Train Acc: 86.3604,
                        Val Loss: 0.4168, Val Acc: 85.1939, Test Acc: 84.0230
2022-09-06 03:31:11,967:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:31:19,529:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 0.4519, Train Acc: 85.9792,
                        Val Loss: 1.1250, Val Acc: 51.8166, Test Acc: 51.8896
2022-09-06 03:31:19,529:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:31:27,321:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.4357, Train Acc: 86.2484,
                        Val Loss: 1.3950, Val Acc: 50.0684, Test Acc: 50.1189
2022-09-06 03:31:27,321:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:31:34,966:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.4119, Train Acc: 87.1254,
                        Val Loss: 1.4142, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:31:34,966:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:31:42,539:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.3962, Train Acc: 87.5904,
                        Val Loss: 1.8241, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:31:42,539:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:31:50,069:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.3872, Train Acc: 86.5231,
                        Val Loss: 1.5304, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:31:50,069:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 03:31:59,162:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:32:04,983:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:32:04,983:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:32:04,984:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:32:04,984:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:32:04,984:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:32:04,984:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:32:04,989:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:32:04,990:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 03:32:04,991:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:32:04,991:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:32:04,991:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:32:04,991:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:32:05,461:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 03:32:37,430:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:32.433286905288696
2022-09-06 03:32:37,433:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:32:37,433:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:32:37,433:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:32:37,433:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:32:37,435:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:32:45,027:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h32m04s_on_Sep_06_2022/MODELS_
2022-09-06 03:32:45,027:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.6416, Train Acc: 69.8774,
                        Val Loss: 3.4396, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:32:45,027:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:32:52,733:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.71s, LR: 0.00050, Train Loss: 0.5587, Train Acc: 85.1018,
                        Val Loss: 4.8974, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:32:52,733:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:33:00,257:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.52s, LR: 0.00050, Train Loss: 0.4983, Train Acc: 86.5841,
                        Val Loss: 3.1604, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:33:00,257:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:33:07,868:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.61s, LR: 0.00050, Train Loss: 0.4745, Train Acc: 85.7843,
                        Val Loss: 2.2788, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:33:07,868:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:33:15,303:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.43s, LR: 0.00050, Train Loss: 0.4486, Train Acc: 85.8244,
                        Val Loss: 2.2193, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:33:15,303:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:33:22,892:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.4135, Train Acc: 86.8356,
                        Val Loss: 2.6121, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:33:22,892:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:33:26,401:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 03:33:26,401:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 03:33:35,660:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:33:41,574:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:33:41,575:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:33:41,575:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:33:41,576:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:33:41,576:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:33:41,576:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:33:41,581:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:33:41,582:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 03:33:41,583:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:33:41,583:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:33:41,583:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:33:41,583:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:33:42,090:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 03:34:10,547:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:28.958116054534912
2022-09-06 03:34:10,550:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:34:10,550:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:34:10,550:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:34:10,551:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:34:10,552:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:34:18,196:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0439 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:34:18,197:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.6162, Train Acc: 69.4244,
                        Val Loss: 0.8344, Val Acc: 50.0000, Test Acc: 50.0439
2022-09-06 03:34:18,197:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:34:26,115:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 52.0061 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:34:26,115:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.92s, LR: 0.00050, Train Loss: 0.4759, Train Acc: 85.6163,
                        Val Loss: 0.7870, Val Acc: 52.0201, Test Acc: 52.0061
2022-09-06 03:34:26,115:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:34:33,722:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 68.5746 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:34:33,722:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.61s, LR: 0.00050, Train Loss: 0.4047, Train Acc: 87.3885,
                        Val Loss: 0.5896, Val Acc: 67.4212, Test Acc: 68.5746
2022-09-06 03:34:33,722:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:34:41,339:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 81.0096 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:34:41,340:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.3838, Train Acc: 86.6331,
                        Val Loss: 0.4377, Val Acc: 81.0978, Test Acc: 81.0096
2022-09-06 03:34:41,340:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:34:49,035:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.2459 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:34:49,035:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.3599, Train Acc: 86.2221,
                        Val Loss: 0.3605, Val Acc: 86.0524, Test Acc: 84.2459
2022-09-06 03:34:49,035:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:34:56,622:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.4137 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:34:56,622:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.3287, Train Acc: 88.4271,
                        Val Loss: 0.3578, Val Acc: 85.0581, Test Acc: 84.4137
2022-09-06 03:34:56,622:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:35:04,090:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.0245 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:35:04,090:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.47s, LR: 0.00050, Train Loss: 0.3113, Train Acc: 88.2447,
                        Val Loss: 0.3446, Val Acc: 85.6787, Test Acc: 85.0245
2022-09-06 03:35:04,090:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:35:11,903:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.5623 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h33m41s_on_Sep_06_2022/MODELS_
2022-09-06 03:35:11,904:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.81s, LR: 0.00050, Train Loss: 0.3099, Train Acc: 87.5093,
                        Val Loss: 0.3342, Val Acc: 85.9093, Test Acc: 85.5623
2022-09-06 03:35:11,904:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 03:35:19,458:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.2970, Train Acc: 88.1168,
                        Val Loss: 0.3338, Val Acc: 85.9353, Test Acc: 85.3542
2022-09-06 03:35:19,458:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 03:35:27,082:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.2831, Train Acc: 88.6373,
                        Val Loss: 0.3362, Val Acc: 85.7112, Test Acc: 85.2990
2022-09-06 03:35:27,082:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 03:35:34,568:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.49s, LR: 0.00050, Train Loss: 0.2915, Train Acc: 87.7938,
                        Val Loss: 0.3475, Val Acc: 85.2355, Test Acc: 85.1046
2022-09-06 03:35:34,568:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 03:35:42,142:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.2867, Train Acc: 88.2799,
                        Val Loss: 0.3458, Val Acc: 85.1476, Test Acc: 84.7728
2022-09-06 03:35:42,142:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 03:35:49,729:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.3003, Train Acc: 87.1898,
                        Val Loss: 0.3435, Val Acc: 84.7526, Test Acc: 84.6467
2022-09-06 03:35:49,729:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 03:35:57,209:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.48s, LR: 0.00050, Train Loss: 0.2850, Train Acc: 87.8487,
                        Val Loss: 0.3459, Val Acc: 84.7101, Test Acc: 83.6081
2022-09-06 03:35:57,209:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 03:36:05,056:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.85s, LR: 0.00050, Train Loss: 0.2785, Train Acc: 88.7814,
                        Val Loss: 0.3428, Val Acc: 84.7648, Test Acc: 84.2350
2022-09-06 03:36:05,056:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 03:36:12,619:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 0.2910, Train Acc: 87.9254,
                        Val Loss: 0.3797, Val Acc: 82.7770, Test Acc: 81.4559
2022-09-06 03:36:12,619:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 03:36:19,852:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.23s, LR: 0.00050, Train Loss: 0.2787, Train Acc: 88.2414,
                        Val Loss: 0.3687, Val Acc: 83.7090, Test Acc: 83.4412
2022-09-06 03:36:19,852:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 03:36:27,429:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.58s, LR: 0.00050, Train Loss: 0.2772, Train Acc: 88.2532,
                        Val Loss: 0.4384, Val Acc: 79.3117, Test Acc: 79.0236
2022-09-06 03:36:27,429:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 03:36:34,830:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.40s, LR: 0.00050, Train Loss: 0.2722, Train Acc: 88.7772,
                        Val Loss: 0.4557, Val Acc: 78.0549, Test Acc: 78.2391
2022-09-06 03:36:34,831:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 03:36:42,287:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.46s, LR: 0.00050, Train Loss: 0.2792, Train Acc: 88.1467,
                        Val Loss: 0.5402, Val Acc: 74.9652, Test Acc: 75.4513
2022-09-06 03:36:42,287:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 03:36:45,830:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 03:36:45,830:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 03:36:55,004:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:37:00,747:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:37:00,748:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:37:00,748:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:37:00,749:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:37:00,749:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:37:00,749:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:37:00,754:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:37:00,755:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 03:37:00,755:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:37:00,756:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:37:00,756:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:37:00,756:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:37:01,259:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 03:37:32,797:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:32.03262686729431
2022-09-06 03:37:32,799:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:37:32,799:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:37:32,799:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:37:32,799:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:37:32,801:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:37:40,470:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0439 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:37:40,470:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.67s, LR: 0.00050, Train Loss: 0.5931, Train Acc: 70.4772,
                        Val Loss: 0.7062, Val Acc: 50.0000, Test Acc: 50.0439
2022-09-06 03:37:40,470:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:37:48,156:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 58.9269 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:37:48,156:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.4710, Train Acc: 83.9048,
                        Val Loss: 0.6629, Val Acc: 58.6132, Test Acc: 58.9269
2022-09-06 03:37:48,157:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:37:55,936:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 69.7656 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:37:55,936:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.78s, LR: 0.00050, Train Loss: 0.4154, Train Acc: 86.6085,
                        Val Loss: 0.5657, Val Acc: 69.5119, Test Acc: 69.7656
2022-09-06 03:37:55,936:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:38:03,571:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 80.1030 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:38:03,571:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.3977, Train Acc: 86.6573,
                        Val Loss: 0.4557, Val Acc: 80.2808, Test Acc: 80.1030
2022-09-06 03:38:03,571:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:38:11,095:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 81.4441 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:38:11,095:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.52s, LR: 0.00050, Train Loss: 0.3759, Train Acc: 86.6983,
                        Val Loss: 0.4317, Val Acc: 82.0433, Test Acc: 81.4441
2022-09-06 03:38:11,095:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:38:18,469:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.2169 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:38:18,469:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.3444, Train Acc: 87.9986,
                        Val Loss: 0.3784, Val Acc: 84.8973, Test Acc: 84.2169
2022-09-06 03:38:18,469:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:38:25,777:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.31s, LR: 0.00050, Train Loss: 0.3259, Train Acc: 88.3717,
                        Val Loss: 0.3763, Val Acc: 83.9357, Test Acc: 83.0230
2022-09-06 03:38:25,777:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:38:33,564:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.9601 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:38:33,564:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.79s, LR: 0.00050, Train Loss: 0.3219, Train Acc: 87.1362,
                        Val Loss: 0.3437, Val Acc: 86.0291, Test Acc: 84.9601
2022-09-06 03:38:33,564:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 03:38:41,219:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.3286 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h37m00s_on_Sep_06_2022/MODELS_
2022-09-06 03:38:41,219:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.3038, Train Acc: 88.3208,
                        Val Loss: 0.3356, Val Acc: 85.9798, Test Acc: 85.3286
2022-09-06 03:38:41,219:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 03:38:49,035:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.82s, LR: 0.00050, Train Loss: 0.2903, Train Acc: 88.7820,
                        Val Loss: 0.3365, Val Acc: 85.7999, Test Acc: 84.8448
2022-09-06 03:38:49,036:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 03:38:56,689:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.2965, Train Acc: 87.7075,
                        Val Loss: 0.3326, Val Acc: 86.2019, Test Acc: 85.1892
2022-09-06 03:38:56,689:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 03:39:04,243:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.2899, Train Acc: 88.2159,
                        Val Loss: 0.3349, Val Acc: 85.9507, Test Acc: 85.0429
2022-09-06 03:39:04,244:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 03:39:11,746:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.50s, LR: 0.00050, Train Loss: 0.3043, Train Acc: 87.0675,
                        Val Loss: 0.3378, Val Acc: 85.5089, Test Acc: 84.6320
2022-09-06 03:39:11,746:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 03:39:19,480:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.2883, Train Acc: 87.9299,
                        Val Loss: 0.3359, Val Acc: 85.3476, Test Acc: 84.4285
2022-09-06 03:39:19,480:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 03:39:27,221:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.2810, Train Acc: 88.3993,
                        Val Loss: 0.3457, Val Acc: 84.7629, Test Acc: 84.0025
2022-09-06 03:39:27,221:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 03:39:34,877:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.2929, Train Acc: 87.7776,
                        Val Loss: 0.3721, Val Acc: 83.9536, Test Acc: 82.7648
2022-09-06 03:39:34,878:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 03:39:42,453:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.2830, Train Acc: 88.1089,
                        Val Loss: 0.3423, Val Acc: 85.3509, Test Acc: 83.8426
2022-09-06 03:39:42,453:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 03:39:50,075:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.2790, Train Acc: 88.3222,
                        Val Loss: 0.3858, Val Acc: 83.6174, Test Acc: 82.4754
2022-09-06 03:39:50,075:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 03:39:57,605:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.2736, Train Acc: 88.9424,
                        Val Loss: 0.3765, Val Acc: 84.1874, Test Acc: 83.0050
2022-09-06 03:39:57,605:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 03:40:05,321:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.2828, Train Acc: 87.6950,
                        Val Loss: 0.4050, Val Acc: 83.1425, Test Acc: 81.5285
2022-09-06 03:40:05,321:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 03:40:13,039:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.2740, Train Acc: 88.6189,
                        Val Loss: 0.3905, Val Acc: 83.0283, Test Acc: 81.7147
2022-09-06 03:40:13,039:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 03:40:20,644:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.3013, Train Acc: 87.4757,
                        Val Loss: 0.3726, Val Acc: 83.9717, Test Acc: 82.7062
2022-09-06 03:40:20,644:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 03:40:28,534:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.89s, LR: 0.00025, Train Loss: 0.2775, Train Acc: 87.9428,
                        Val Loss: 0.3755, Val Acc: 83.7352, Test Acc: 82.3074
2022-09-06 03:40:28,534:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-06 03:40:36,245:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.71s, LR: 0.00025, Train Loss: 0.2873, Train Acc: 87.3471,
                        Val Loss: 0.3860, Val Acc: 82.6080, Test Acc: 81.3905
2022-09-06 03:40:36,245:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-06 03:40:46,312:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:40:52,141:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:40:52,141:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:40:52,142:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:40:52,142:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:40:52,142:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:40:52,143:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:40:52,147:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:40:52,148:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-06 03:40:52,148:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:40:52,149:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:40:52,149:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:40:52,149:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:40:52,589:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-06 03:41:14,624:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:22.46985101699829
2022-09-06 03:41:14,627:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:41:14,627:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:41:14,627:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:41:14,627:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:41:14,630:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:41:22,232:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:41:22,232:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.6619, Train Acc: 60.1567,
                        Val Loss: 0.7299, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:41:22,232:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:41:29,886:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.3857 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:41:29,886:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.5838, Train Acc: 71.9360,
                        Val Loss: 0.6915, Val Acc: 50.3936, Test Acc: 50.3857
2022-09-06 03:41:29,886:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:41:37,326:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 69.6528 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:41:37,326:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.44s, LR: 0.00050, Train Loss: 0.5261, Train Acc: 79.6537,
                        Val Loss: 0.6354, Val Acc: 66.8323, Test Acc: 69.6528
2022-09-06 03:41:37,326:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:41:44,823:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 76.2058 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:41:44,823:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.50s, LR: 0.00050, Train Loss: 0.5106, Train Acc: 79.8368,
                        Val Loss: 0.5966, Val Acc: 78.2130, Test Acc: 76.2058
2022-09-06 03:41:44,823:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:41:52,258:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.43s, LR: 0.00050, Train Loss: 0.4941, Train Acc: 81.0719,
                        Val Loss: 0.5613, Val Acc: 77.0549, Test Acc: 75.8675
2022-09-06 03:41:52,258:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:41:59,713:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.8871 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:41:59,713:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.4659, Train Acc: 84.5245,
                        Val Loss: 0.5259, Val Acc: 79.8238, Test Acc: 78.8871
2022-09-06 03:41:59,713:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:42:07,099:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.39s, LR: 0.00050, Train Loss: 0.4585, Train Acc: 80.0335,
                        Val Loss: 0.5326, Val Acc: 78.8433, Test Acc: 77.8653
2022-09-06 03:42:07,099:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:42:14,792:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 81.8164 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:42:14,793:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.4157, Train Acc: 85.3211,
                        Val Loss: 0.4996, Val Acc: 81.6372, Test Acc: 81.8164
2022-09-06 03:42:14,793:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 03:42:22,166:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.3875, Train Acc: 86.2230,
                        Val Loss: 0.4538, Val Acc: 81.7453, Test Acc: 81.8093
2022-09-06 03:42:22,166:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 03:42:29,672:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.6726 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:42:29,672:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.51s, LR: 0.00050, Train Loss: 0.3764, Train Acc: 86.7050,
                        Val Loss: 0.4350, Val Acc: 84.9062, Test Acc: 83.6726
2022-09-06 03:42:29,673:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 03:42:37,292:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.0588 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:42:37,292:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.3640, Train Acc: 86.0781,
                        Val Loss: 0.4091, Val Acc: 86.2447, Test Acc: 85.0588
2022-09-06 03:42:37,292:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 03:42:44,849:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 0.3478, Train Acc: 87.3640,
                        Val Loss: 0.3887, Val Acc: 85.0508, Test Acc: 84.5174
2022-09-06 03:42:44,849:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 03:42:52,287:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.44s, LR: 0.00050, Train Loss: 0.3527, Train Acc: 86.0811,
                        Val Loss: 0.3868, Val Acc: 83.8388, Test Acc: 83.1235
2022-09-06 03:42:52,287:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 03:42:59,900:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.61s, LR: 0.00050, Train Loss: 0.3377, Train Acc: 86.7764,
                        Val Loss: 0.3825, Val Acc: 82.9366, Test Acc: 82.2352
2022-09-06 03:42:59,901:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 03:43:07,389:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.2965 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h40m52s_on_Sep_06_2022/MODELS_
2022-09-06 03:43:07,389:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.49s, LR: 0.00050, Train Loss: 0.3291, Train Acc: 87.1796,
                        Val Loss: 0.3611, Val Acc: 85.2518, Test Acc: 85.2965
2022-09-06 03:43:07,389:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 03:43:14,980:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.3286, Train Acc: 86.4095,
                        Val Loss: 0.3558, Val Acc: 85.5258, Test Acc: 84.7828
2022-09-06 03:43:14,980:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 03:43:22,463:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.48s, LR: 0.00050, Train Loss: 0.3135, Train Acc: 87.5931,
                        Val Loss: 0.3422, Val Acc: 86.3510, Test Acc: 85.0467
2022-09-06 03:43:22,463:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 03:43:29,888:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.43s, LR: 0.00050, Train Loss: 0.3473, Train Acc: 86.0141,
                        Val Loss: 0.3631, Val Acc: 84.4811, Test Acc: 85.2298
2022-09-06 03:43:29,888:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 03:43:37,250:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.36s, LR: 0.00050, Train Loss: 0.3053, Train Acc: 87.3396,
                        Val Loss: 0.3555, Val Acc: 85.1264, Test Acc: 84.2998
2022-09-06 03:43:37,250:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 03:43:44,721:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.47s, LR: 0.00050, Train Loss: 0.3082, Train Acc: 86.9943,
                        Val Loss: 0.3392, Val Acc: 86.2404, Test Acc: 84.6103
2022-09-06 03:43:44,722:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 03:43:52,488:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.77s, LR: 0.00050, Train Loss: 0.3118, Train Acc: 86.8196,
                        Val Loss: 0.3477, Val Acc: 85.8474, Test Acc: 85.1479
2022-09-06 03:43:52,488:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 03:44:00,079:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.5086, Train Acc: 78.9081,
                        Val Loss: 0.3811, Val Acc: 84.2256, Test Acc: 83.5879
2022-09-06 03:44:00,079:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 03:44:07,651:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.3607, Train Acc: 83.5041,
                        Val Loss: 0.4788, Val Acc: 82.0633, Test Acc: 83.2270
2022-09-06 03:44:07,652:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-06 03:44:15,231:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.58s, LR: 0.00050, Train Loss: 0.3622, Train Acc: 83.8260,
                        Val Loss: 0.4415, Val Acc: 81.8453, Test Acc: 82.3676
2022-09-06 03:44:15,231:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-06 03:44:22,682:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.3080, Train Acc: 87.9385,
                        Val Loss: 0.4293, Val Acc: 84.4310, Test Acc: 84.0746
2022-09-06 03:44:22,682:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-06 03:44:29,970:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.29s, LR: 0.00050, Train Loss: 0.4365, Train Acc: 80.0268,
                        Val Loss: 0.4456, Val Acc: 83.1680, Test Acc: 83.4411
2022-09-06 03:44:29,970:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-06 03:44:42,290:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:44:47,992:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:44:47,993:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:44:47,993:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:44:47,995:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:44:47,995:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:44:47,995:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:44:47,999:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:44:48,000:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-06 03:44:48,000:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:44:48,001:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:44:48,001:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:44:48,001:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:44:48,471:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-06 03:45:10,286:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:22.279573917388916
2022-09-06 03:45:10,290:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:45:10,290:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:45:10,290:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:45:10,290:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:45:10,291:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:45:17,827:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h44m47s_on_Sep_06_2022/MODELS_
2022-09-06 03:45:17,827:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.54s, LR: 0.00050, Train Loss: 0.6433, Train Acc: 65.5664,
                        Val Loss: 1.6128, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:45:17,827:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:45:25,111:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 78.0262 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h44m47s_on_Sep_06_2022/MODELS_
2022-09-06 03:45:25,111:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.28s, LR: 0.00050, Train Loss: 0.5232, Train Acc: 85.5483,
                        Val Loss: 0.5143, Val Acc: 76.7754, Test Acc: 78.0262
2022-09-06 03:45:25,111:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:45:32,558:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.7327 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h44m47s_on_Sep_06_2022/MODELS_
2022-09-06 03:45:32,558:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.4521, Train Acc: 86.5637,
                        Val Loss: 0.4889, Val Acc: 85.0018, Test Acc: 83.7327
2022-09-06 03:45:32,558:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:45:39,925:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.4242, Train Acc: 85.4716,
                        Val Loss: 0.9937, Val Acc: 50.0000, Test Acc: 50.0078
2022-09-06 03:45:39,925:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:45:47,675:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.75s, LR: 0.00050, Train Loss: 0.3951, Train Acc: 85.3872,
                        Val Loss: 1.7069, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:45:47,676:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:45:54,916:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.24s, LR: 0.00050, Train Loss: 0.3590, Train Acc: 86.9293,
                        Val Loss: 2.1884, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:45:54,916:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:46:05,257:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:46:10,869:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:46:10,869:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:46:10,869:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:46:10,870:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:46:10,870:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:46:10,870:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:46:10,875:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:46:10,876:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-06 03:46:10,876:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:46:10,877:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:46:10,877:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:46:10,877:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:46:11,344:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-06 03:46:33,520:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:22.638000965118408
2022-09-06 03:46:33,523:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:46:33,523:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:46:33,523:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:46:33,523:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:46:33,525:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:46:41,252:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h46m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:46:41,252:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.5684, Train Acc: 78.5534,
                        Val Loss: 3.8556, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:46:41,252:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:46:49,102:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.85s, LR: 0.00050, Train Loss: 0.4805, Train Acc: 85.9500,
                        Val Loss: 3.0611, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:46:49,102:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:46:56,517:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.41s, LR: 0.00050, Train Loss: 0.4443, Train Acc: 86.4003,
                        Val Loss: 3.2799, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:46:56,517:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:47:03,901:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.38s, LR: 0.00050, Train Loss: 0.4295, Train Acc: 85.6716,
                        Val Loss: 3.2312, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:47:03,902:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:47:07,198:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 03:47:07,198:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 03:47:13,930:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:47:19,638:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:47:19,638:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:47:19,638:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:47:19,639:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:47:19,639:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:47:19,639:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:47:19,644:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:47:19,645:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-06 03:47:19,645:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:47:19,646:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:47:19,646:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:47:19,646:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:47:20,131:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-06 03:47:42,503:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:22.852910041809082
2022-09-06 03:47:42,506:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:47:42,506:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:47:42,506:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:47:42,506:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:47:42,508:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:47:50,244:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:47:50,244:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.6856, Train Acc: 50.0000,
                        Val Loss: 0.7034, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:47:50,244:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:47:57,803:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 0.6283, Train Acc: 52.6556,
                        Val Loss: 0.6770, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:47:57,803:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:48:05,269:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 62.8151 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:48:05,269:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.47s, LR: 0.00050, Train Loss: 0.5853, Train Acc: 65.5320,
                        Val Loss: 0.6510, Val Acc: 63.0215, Test Acc: 62.8151
2022-09-06 03:48:05,269:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:48:12,886:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.5563, Train Acc: 70.5423,
                        Val Loss: 0.6065, Val Acc: 60.5435, Test Acc: 60.8139
2022-09-06 03:48:12,886:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:48:20,564:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 76.5737 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:48:20,564:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.68s, LR: 0.00050, Train Loss: 0.5209, Train Acc: 80.7233,
                        Val Loss: 0.5380, Val Acc: 75.8588, Test Acc: 76.5737
2022-09-06 03:48:20,564:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:48:28,053:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 79.7668 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:48:28,053:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.49s, LR: 0.00050, Train Loss: 0.4832, Train Acc: 85.5647,
                        Val Loss: 0.5025, Val Acc: 78.7019, Test Acc: 79.7668
2022-09-06 03:48:28,053:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:48:35,441:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 80.6427 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:48:35,441:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.39s, LR: 0.00050, Train Loss: 0.4440, Train Acc: 87.5984,
                        Val Loss: 0.4628, Val Acc: 80.2143, Test Acc: 80.6427
2022-09-06 03:48:35,441:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:48:42,882:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.44s, LR: 0.00050, Train Loss: 0.4099, Train Acc: 86.3285,
                        Val Loss: 0.4538, Val Acc: 79.5271, Test Acc: 80.3335
2022-09-06 03:48:42,882:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 03:48:50,309:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 81.5984 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:48:50,309:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.43s, LR: 0.00050, Train Loss: 0.3749, Train Acc: 87.7664,
                        Val Loss: 0.4314, Val Acc: 81.2017, Test Acc: 81.5984
2022-09-06 03:48:50,310:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 03:48:57,982:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.7178 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:48:57,983:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.67s, LR: 0.00050, Train Loss: 0.3438, Train Acc: 88.2667,
                        Val Loss: 0.4054, Val Acc: 82.3388, Test Acc: 82.7178
2022-09-06 03:48:57,983:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 03:49:05,526:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.9402 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:49:05,526:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.54s, LR: 0.00050, Train Loss: 0.3337, Train Acc: 87.3942,
                        Val Loss: 0.3797, Val Acc: 83.9921, Test Acc: 83.9402
2022-09-06 03:49:05,526:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 03:49:12,941:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.0942 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:49:12,941:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.41s, LR: 0.00050, Train Loss: 0.3140, Train Acc: 88.0539,
                        Val Loss: 0.3617, Val Acc: 84.8863, Test Acc: 85.0942
2022-09-06 03:49:12,941:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 03:49:20,223:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.1779 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_8_03h47m19s_on_Sep_06_2022/MODELS_
2022-09-06 03:49:20,223:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.28s, LR: 0.00050, Train Loss: 0.3180, Train Acc: 86.3825,
                        Val Loss: 0.3490, Val Acc: 85.4116, Test Acc: 85.1779
2022-09-06 03:49:20,224:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 03:49:27,677:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.2985, Train Acc: 87.7768,
                        Val Loss: 0.3356, Val Acc: 85.8410, Test Acc: 84.8156
2022-09-06 03:49:27,677:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 03:49:35,065:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.39s, LR: 0.00050, Train Loss: 0.2879, Train Acc: 88.5182,
                        Val Loss: 0.3456, Val Acc: 85.4515, Test Acc: 84.8143
2022-09-06 03:49:35,065:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 03:49:42,455:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.39s, LR: 0.00050, Train Loss: 0.2974, Train Acc: 87.2838,
                        Val Loss: 0.3874, Val Acc: 83.7939, Test Acc: 82.8037
2022-09-06 03:49:42,455:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 03:49:49,842:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.39s, LR: 0.00050, Train Loss: 0.2860, Train Acc: 88.1020,
                        Val Loss: 0.3444, Val Acc: 85.2825, Test Acc: 84.2989
2022-09-06 03:49:49,842:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 03:49:57,258:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.42s, LR: 0.00050, Train Loss: 0.2819, Train Acc: 87.8318,
                        Val Loss: 0.3834, Val Acc: 84.2222, Test Acc: 82.9344
2022-09-06 03:49:57,258:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 03:50:04,597:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.34s, LR: 0.00050, Train Loss: 0.2760, Train Acc: 88.3153,
                        Val Loss: 0.4500, Val Acc: 82.8428, Test Acc: 81.6625
2022-09-06 03:50:04,597:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 03:50:11,698:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.10s, LR: 0.00050, Train Loss: 0.2865, Train Acc: 87.5170,
                        Val Loss: 0.4298, Val Acc: 83.6146, Test Acc: 82.1490
2022-09-06 03:50:11,698:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 03:50:19,144:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.2755, Train Acc: 88.6212,
                        Val Loss: 0.3966, Val Acc: 83.9418, Test Acc: 82.4131
2022-09-06 03:50:19,145:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 03:50:26,675:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.3029, Train Acc: 87.4593,
                        Val Loss: 0.3787, Val Acc: 83.9580, Test Acc: 83.7976
2022-09-06 03:50:26,675:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 03:50:34,245:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.2809, Train Acc: 87.9731,
                        Val Loss: 0.4560, Val Acc: 79.0158, Test Acc: 77.7412
2022-09-06 03:50:34,245:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-06 03:50:41,849:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.2912, Train Acc: 87.0057,
                        Val Loss: 0.4650, Val Acc: 77.0279, Test Acc: 76.1960
2022-09-06 03:50:41,849:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-06 03:51:02,317:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:51:08,297:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 8, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:51:08,297:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:51:08,297:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:51:08,298:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:51:08,298:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:51:08,298:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:51:08,303:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:51:08,304:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523535
2022-09-06 03:51:08,305:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:51:08,305:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:51:08,305:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:51:08,305:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:51:08,829:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-06 03:51:21,769:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:51:27,473:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:51:27,473:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:51:27,473:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:51:27,474:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:51:27,474:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:51:27,474:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:51:27,480:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:51:27,480:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 03:51:27,481:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:51:27,481:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:51:27,481:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:51:27,481:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:51:27,969:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 03:52:10,820:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:43.33383297920227
2022-09-06 03:52:10,824:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:52:10,824:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:52:10,824:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:52:10,824:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:52:10,825:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:52:18,444:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.1242 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h51m27s_on_Sep_06_2022/MODELS_
2022-09-06 03:52:18,444:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.6459, Train Acc: 69.1468,
                        Val Loss: 0.6751, Val Acc: 50.1267, Test Acc: 50.1242
2022-09-06 03:52:18,444:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:52:25,891:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.5177 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h51m27s_on_Sep_06_2022/MODELS_
2022-09-06 03:52:25,891:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.5620, Train Acc: 83.2560,
                        Val Loss: 0.6381, Val Acc: 84.5819, Test Acc: 84.5177
2022-09-06 03:52:25,891:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:52:32,980:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.09s, LR: 0.00050, Train Loss: 0.5016, Train Acc: 86.0231,
                        Val Loss: 0.5797, Val Acc: 82.2592, Test Acc: 81.6673
2022-09-06 03:52:32,980:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:52:40,512:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.4677, Train Acc: 85.6375,
                        Val Loss: 0.5267, Val Acc: 80.0878, Test Acc: 80.6010
2022-09-06 03:52:40,512:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:52:48,049:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.54s, LR: 0.00050, Train Loss: 0.4310, Train Acc: 86.0500,
                        Val Loss: 0.4664, Val Acc: 85.5991, Test Acc: 84.3094
2022-09-06 03:52:48,049:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:52:55,265:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.7585 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h51m27s_on_Sep_06_2022/MODELS_
2022-09-06 03:52:55,265:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.22s, LR: 0.00050, Train Loss: 0.3934, Train Acc: 87.4539,
                        Val Loss: 0.4217, Val Acc: 85.0326, Test Acc: 84.7585
2022-09-06 03:52:55,265:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:53:02,634:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.8507 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h51m27s_on_Sep_06_2022/MODELS_
2022-09-06 03:53:02,634:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.3617, Train Acc: 88.0512,
                        Val Loss: 0.3890, Val Acc: 84.7227, Test Acc: 84.8507
2022-09-06 03:53:02,634:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:53:10,317:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4722 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h51m27s_on_Sep_06_2022/MODELS_
2022-09-06 03:53:10,317:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.68s, LR: 0.00050, Train Loss: 0.3445, Train Acc: 87.1721,
                        Val Loss: 0.3542, Val Acc: 84.7669, Test Acc: 85.4722
2022-09-06 03:53:10,317:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 03:53:17,484:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.17s, LR: 0.00050, Train Loss: 0.3178, Train Acc: 88.1694,
                        Val Loss: 0.3474, Val Acc: 85.1965, Test Acc: 84.7916
2022-09-06 03:53:17,484:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 03:53:24,909:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.6107 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h51m27s_on_Sep_06_2022/MODELS_
2022-09-06 03:53:24,909:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.42s, LR: 0.00050, Train Loss: 0.2980, Train Acc: 88.2892,
                        Val Loss: 0.3315, Val Acc: 85.8974, Test Acc: 85.6107
2022-09-06 03:53:24,909:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 03:53:32,403:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.49s, LR: 0.00050, Train Loss: 0.2986, Train Acc: 87.8081,
                        Val Loss: 0.3325, Val Acc: 85.7577, Test Acc: 85.5584
2022-09-06 03:53:32,403:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 03:53:39,788:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.38s, LR: 0.00050, Train Loss: 0.2917, Train Acc: 88.2464,
                        Val Loss: 0.3315, Val Acc: 85.8901, Test Acc: 85.4630
2022-09-06 03:53:39,788:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 03:53:47,273:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.48s, LR: 0.00050, Train Loss: 0.3037, Train Acc: 87.1158,
                        Val Loss: 0.3408, Val Acc: 85.2189, Test Acc: 85.4840
2022-09-06 03:53:47,274:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 03:53:54,992:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.2887, Train Acc: 87.8154,
                        Val Loss: 0.3429, Val Acc: 85.4208, Test Acc: 83.9057
2022-09-06 03:53:54,992:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 03:54:02,701:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.71s, LR: 0.00050, Train Loss: 0.2817, Train Acc: 88.2444,
                        Val Loss: 0.3449, Val Acc: 84.1751, Test Acc: 84.0505
2022-09-06 03:54:02,701:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 03:54:10,257:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 0.2945, Train Acc: 87.7130,
                        Val Loss: 0.3871, Val Acc: 82.8629, Test Acc: 81.8187
2022-09-06 03:54:10,257:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 03:54:14,095:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 03:54:14,096:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 03:54:20,665:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:54:26,515:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:54:26,516:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:54:26,516:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:54:26,517:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:54:26,517:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:54:26,517:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:54:26,522:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:54:26,522:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 03:54:26,523:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:54:26,523:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:54:26,523:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:54:26,523:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:54:26,988:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 03:54:58,661:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:32.13224196434021
2022-09-06 03:54:58,664:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:54:58,664:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:54:58,664:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:54:58,664:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:54:58,665:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:55:06,324:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h54m26s_on_Sep_06_2022/MODELS_
2022-09-06 03:55:06,325:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.6172, Train Acc: 72.5939,
                        Val Loss: 5.1015, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:55:06,325:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:55:13,910:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0078 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h54m26s_on_Sep_06_2022/MODELS_
2022-09-06 03:55:13,910:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.59s, LR: 0.00050, Train Loss: 0.5260, Train Acc: 85.9292,
                        Val Loss: 1.0203, Val Acc: 50.0000, Test Acc: 50.0078
2022-09-06 03:55:13,910:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:55:21,431:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 52.3834 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h54m26s_on_Sep_06_2022/MODELS_
2022-09-06 03:55:21,431:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.52s, LR: 0.00050, Train Loss: 0.4648, Train Acc: 86.7068,
                        Val Loss: 0.6599, Val Acc: 52.3747, Test Acc: 52.3834
2022-09-06 03:55:21,431:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:55:28,914:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.48s, LR: 0.00050, Train Loss: 0.4321, Train Acc: 85.7795,
                        Val Loss: 0.8523, Val Acc: 50.0760, Test Acc: 50.1230
2022-09-06 03:55:28,914:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:55:36,634:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.72s, LR: 0.00050, Train Loss: 0.3988, Train Acc: 85.7467,
                        Val Loss: 1.1285, Val Acc: 50.0000, Test Acc: 50.0554
2022-09-06 03:55:36,634:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:55:44,401:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.77s, LR: 0.00050, Train Loss: 0.3594, Train Acc: 87.1399,
                        Val Loss: 1.6313, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:55:44,402:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:55:52,128:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.73s, LR: 0.00050, Train Loss: 0.3340, Train Acc: 87.4951,
                        Val Loss: 2.1521, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 03:55:52,128:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:56:04,702:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 03:56:10,338:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 03:56:10,338:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 03:56:10,338:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:56:10,339:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:56:10,339:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:56:10,339:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:56:10,344:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 03:56:10,345:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 03:56:10,345:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 03:56:10,346:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 03:56:10,346:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 03:56:10,346:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 03:56:10,847:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 03:56:42,890:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:32.539494037628174
2022-09-06 03:56:42,893:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 03:56:42,893:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 03:56:42,893:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 03:56:42,893:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 03:56:42,895:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 03:56:50,803:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 51.9979 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h56m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:56:50,804:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.91s, LR: 0.00050, Train Loss: 0.6888, Train Acc: 50.0000,
                        Val Loss: 0.6846, Val Acc: 52.7263, Test Acc: 51.9979
2022-09-06 03:56:50,804:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 03:56:58,492:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 66.0550 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h56m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:56:58,492:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 0.6262, Train Acc: 66.6003,
                        Val Loss: 0.6471, Val Acc: 65.4413, Test Acc: 66.0550
2022-09-06 03:56:58,492:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 03:57:06,039:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 70.3929 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h56m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:57:06,039:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.5586, Train Acc: 84.3293,
                        Val Loss: 0.5864, Val Acc: 69.6470, Test Acc: 70.3929
2022-09-06 03:57:06,039:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 03:57:13,659:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 77.0603 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h56m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:57:13,659:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.62s, LR: 0.00050, Train Loss: 0.5079, Train Acc: 85.1174,
                        Val Loss: 0.5074, Val Acc: 77.3726, Test Acc: 77.0603
2022-09-06 03:57:13,659:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 03:57:21,594:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 83.7449 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h56m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:57:21,594:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.93s, LR: 0.00050, Train Loss: 0.4620, Train Acc: 85.3275,
                        Val Loss: 0.4275, Val Acc: 84.0618, Test Acc: 83.7449
2022-09-06 03:57:21,594:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 03:57:29,168:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 84.6761 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h56m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:57:29,168:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.4178, Train Acc: 87.2106,
                        Val Loss: 0.3886, Val Acc: 86.1425, Test Acc: 84.6761
2022-09-06 03:57:29,168:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 03:57:36,633:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.46s, LR: 0.00050, Train Loss: 0.3828, Train Acc: 88.0391,
                        Val Loss: 0.3658, Val Acc: 85.4328, Test Acc: 84.5698
2022-09-06 03:57:36,633:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 03:57:44,655:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.9687 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_03h56m10s_on_Sep_06_2022/MODELS_
2022-09-06 03:57:44,656:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 8.02s, LR: 0.00050, Train Loss: 0.3628, Train Acc: 87.2206,
                        Val Loss: 0.3411, Val Acc: 85.6953, Test Acc: 85.9687
2022-09-06 03:57:44,656:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 03:57:52,287:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.63s, LR: 0.00050, Train Loss: 0.3381, Train Acc: 87.7547,
                        Val Loss: 0.3400, Val Acc: 85.5593, Test Acc: 85.3342
2022-09-06 03:57:52,287:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 03:58:00,129:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.84s, LR: 0.00050, Train Loss: 0.3162, Train Acc: 88.1667,
                        Val Loss: 0.3378, Val Acc: 85.3851, Test Acc: 85.3139
2022-09-06 03:58:00,129:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 03:58:07,829:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.3171, Train Acc: 87.5025,
                        Val Loss: 0.3348, Val Acc: 85.7514, Test Acc: 85.7151
2022-09-06 03:58:07,829:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 03:58:15,568:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.74s, LR: 0.00050, Train Loss: 0.3036, Train Acc: 88.2348,
                        Val Loss: 0.3388, Val Acc: 85.5555, Test Acc: 84.6061
2022-09-06 03:58:15,568:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 03:58:23,215:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.3120, Train Acc: 86.9384,
                        Val Loss: 0.3352, Val Acc: 85.7596, Test Acc: 84.6050
2022-09-06 03:58:23,215:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 03:58:30,776:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 0.2965, Train Acc: 87.6717,
                        Val Loss: 0.3468, Val Acc: 85.3981, Test Acc: 83.8484
2022-09-06 03:58:30,776:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 03:58:38,351:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.2865, Train Acc: 88.5191,
                        Val Loss: 0.3394, Val Acc: 85.5458, Test Acc: 84.7713
2022-09-06 03:58:38,351:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 03:58:46,104:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.75s, LR: 0.00050, Train Loss: 0.2960, Train Acc: 87.4990,
                        Val Loss: 0.3904, Val Acc: 83.1097, Test Acc: 82.1514
2022-09-06 03:58:46,104:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 03:58:53,706:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.60s, LR: 0.00050, Train Loss: 0.2854, Train Acc: 87.9484,
                        Val Loss: 0.3378, Val Acc: 85.5628, Test Acc: 84.4916
2022-09-06 03:58:53,706:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 03:59:01,349:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.2838, Train Acc: 88.0584,
                        Val Loss: 0.4144, Val Acc: 81.6745, Test Acc: 80.6754
2022-09-06 03:59:01,349:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 03:59:09,154:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.81s, LR: 0.00050, Train Loss: 0.2757, Train Acc: 88.9043,
                        Val Loss: 0.3925, Val Acc: 83.5987, Test Acc: 82.8161
2022-09-06 03:59:09,154:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 03:59:16,697:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.54s, LR: 0.00050, Train Loss: 0.2856, Train Acc: 87.3172,
                        Val Loss: 0.4996, Val Acc: 77.2878, Test Acc: 77.1825
2022-09-06 03:59:16,698:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 03:59:24,346:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.65s, LR: 0.00050, Train Loss: 0.2753, Train Acc: 88.4781,
                        Val Loss: 0.5190, Val Acc: 75.4934, Test Acc: 75.4988
2022-09-06 03:59:24,346:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 03:59:32,006:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.3023, Train Acc: 87.6380,
                        Val Loss: 0.4935, Val Acc: 75.6973, Test Acc: 75.7286
2022-09-06 03:59:32,006:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 03:59:57,008:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 04:00:02,995:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 04:00:02,995:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 04:00:02,995:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:00:02,996:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:00:02,996:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:00:02,996:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:00:03,001:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 04:00:03,002:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 04:00:03,002:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:00:03,003:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:00:03,003:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:00:03,003:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:00:03,508:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 04:00:32,700:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:29.692325830459595
2022-09-06 04:00:32,703:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 04:00:32,703:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 04:00:32,703:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 04:00:32,703:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 04:00:32,704:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 04:00:40,279:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h00m02s_on_Sep_06_2022/MODELS_
2022-09-06 04:00:40,279:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.5658, Train Acc: 55.1472,
                        Val Loss: 4.5112, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:00:40,279:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 04:00:47,664:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.38s, LR: 0.00050, Train Loss: 0.5047, Train Acc: 77.0510,
                        Val Loss: 4.1713, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:00:47,664:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 04:00:54,722:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.06s, LR: 0.00050, Train Loss: 0.4770, Train Acc: 85.6869,
                        Val Loss: 3.4744, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:00:54,722:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 04:01:01,939:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0040 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h00m02s_on_Sep_06_2022/MODELS_
2022-09-06 04:01:01,939:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.22s, LR: 0.00050, Train Loss: 0.4704, Train Acc: 85.7719,
                        Val Loss: 3.1321, Val Acc: 50.0000, Test Acc: 50.0040
2022-09-06 04:01:01,939:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 04:01:09,133:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.19s, LR: 0.00050, Train Loss: 0.4542, Train Acc: 85.8361,
                        Val Loss: 3.6789, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:01:09,133:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 04:01:16,264:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.13s, LR: 0.00050, Train Loss: 0.4284, Train Acc: 87.0724,
                        Val Loss: 3.7729, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:01:16,264:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 04:01:23,285:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.02s, LR: 0.00050, Train Loss: 0.4112, Train Acc: 87.4033,
                        Val Loss: 2.8205, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:01:23,285:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 04:01:30,651:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.37s, LR: 0.00050, Train Loss: 0.3984, Train Acc: 86.3756,
                        Val Loss: 1.9075, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:01:30,651:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 04:01:37,968:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.32s, LR: 0.00050, Train Loss: 0.3764, Train Acc: 87.0964,
                        Val Loss: 2.5637, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:01:37,968:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 04:01:45,368:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.40s, LR: 0.00050, Train Loss: 0.3562, Train Acc: 88.2117,
                        Val Loss: 3.1466, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:01:45,368:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 04:01:52,725:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.36s, LR: 0.00050, Train Loss: 0.3512, Train Acc: 87.2998,
                        Val Loss: 2.2046, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:01:52,725:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 04:02:00,051:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.33s, LR: 0.00050, Train Loss: 0.3334, Train Acc: 87.9282,
                        Val Loss: 1.9323, Val Acc: 50.0000, Test Acc: 50.0040
2022-09-06 04:02:00,051:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 04:02:07,194:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.14s, LR: 0.00050, Train Loss: 0.3385, Train Acc: 86.9644,
                        Val Loss: 2.5664, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:02:07,194:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 04:02:14,356:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.1035 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h00m02s_on_Sep_06_2022/MODELS_
2022-09-06 04:02:14,356:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.16s, LR: 0.00050, Train Loss: 0.3199, Train Acc: 87.1106,
                        Val Loss: 2.3087, Val Acc: 50.0119, Test Acc: 50.1035
2022-09-06 04:02:14,356:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 04:02:21,458:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.2175 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h00m02s_on_Sep_06_2022/MODELS_
2022-09-06 04:02:21,458:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.10s, LR: 0.00050, Train Loss: 0.3073, Train Acc: 87.6080,
                        Val Loss: 1.8761, Val Acc: 50.1522, Test Acc: 50.2175
2022-09-06 04:02:21,458:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 04:02:28,804:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.35s, LR: 0.00050, Train Loss: 0.3121, Train Acc: 86.9961,
                        Val Loss: 3.1058, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:02:28,804:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 04:02:36,034:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.23s, LR: 0.00050, Train Loss: 0.3009, Train Acc: 87.3298,
                        Val Loss: 2.4585, Val Acc: 50.0000, Test Acc: 50.0079
2022-09-06 04:02:36,034:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 04:02:43,222:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.2303 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h00m02s_on_Sep_06_2022/MODELS_
2022-09-06 04:02:43,222:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.19s, LR: 0.00050, Train Loss: 0.2928, Train Acc: 87.6212,
                        Val Loss: 2.0022, Val Acc: 50.0842, Test Acc: 50.2303
2022-09-06 04:02:43,222:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 04:02:50,304:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.08s, LR: 0.00050, Train Loss: 0.2902, Train Acc: 87.7485,
                        Val Loss: 2.6224, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:02:50,304:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 04:02:57,270:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 6.97s, LR: 0.00050, Train Loss: 0.2959, Train Acc: 87.3389,
                        Val Loss: 3.5981, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:02:57,270:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 04:03:04,376:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.11s, LR: 0.00050, Train Loss: 0.2870, Train Acc: 88.1295,
                        Val Loss: 4.0652, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:03:04,377:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 04:03:11,419:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.04s, LR: 0.00050, Train Loss: 0.3123, Train Acc: 87.2767,
                        Val Loss: 3.7993, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:03:11,419:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 04:03:18,907:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.49s, LR: 0.00050, Train Loss: 0.2919, Train Acc: 87.3888,
                        Val Loss: 2.2047, Val Acc: 50.0489, Test Acc: 50.0998
2022-09-06 04:03:18,907:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-06 04:03:26,329:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.42s, LR: 0.00050, Train Loss: 0.3107, Train Acc: 86.1397,
                        Val Loss: 3.2797, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:03:26,330:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-06 04:03:33,596:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.27s, LR: 0.00050, Train Loss: 0.2796, Train Acc: 88.5825,
                        Val Loss: 1.8912, Val Acc: 50.0687, Test Acc: 50.1904
2022-09-06 04:03:33,596:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-06 04:03:40,926:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 68.3396 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h00m02s_on_Sep_06_2022/MODELS_
2022-09-06 04:03:40,926:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.33s, LR: 0.00050, Train Loss: 0.2735, Train Acc: 88.6767,
                        Val Loss: 0.6839, Val Acc: 68.1868, Test Acc: 68.3396
2022-09-06 04:03:40,926:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-06 04:03:48,212:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.29s, LR: 0.00050, Train Loss: 0.2845, Train Acc: 87.8304,
                        Val Loss: 3.6904, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:03:48,212:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-06 04:03:55,469:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.26s, LR: 0.00050, Train Loss: 0.2736, Train Acc: 88.4250,
                        Val Loss: 3.3485, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:03:55,470:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-06 04:04:02,999:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.53s, LR: 0.00050, Train Loss: 0.3038, Train Acc: 87.6992,
                        Val Loss: 1.2940, Val Acc: 50.1606, Test Acc: 50.2212
2022-09-06 04:04:02,999:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-06 04:04:10,672:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 04:04:16,345:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 04:04:16,346:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 04:04:16,347:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:04:16,348:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:04:16,348:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:04:16,348:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:04:16,353:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 04:04:16,353:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 04:04:16,354:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:04:16,354:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:04:16,354:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:04:16,354:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:04:16,868:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 04:04:48,706:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:32.34720182418823
2022-09-06 04:04:48,709:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 04:04:48,709:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 04:04:48,709:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 04:04:48,709:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 04:04:48,710:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 04:04:56,566:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 80.4520 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h04m16s_on_Sep_06_2022/MODELS_
2022-09-06 04:04:56,566:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.86s, LR: 0.00050, Train Loss: 0.6322, Train Acc: 67.4474,
                        Val Loss: 0.5272, Val Acc: 80.3028, Test Acc: 80.4520
2022-09-06 04:04:56,566:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 04:05:04,465:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.90s, LR: 0.00050, Train Loss: 0.5520, Train Acc: 84.9385,
                        Val Loss: 0.4714, Val Acc: 78.1531, Test Acc: 79.4908
2022-09-06 04:05:04,465:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 04:05:11,914:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.45s, LR: 0.00050, Train Loss: 0.5007, Train Acc: 85.8642,
                        Val Loss: 0.5388, Val Acc: 68.1057, Test Acc: 67.9174
2022-09-06 04:05:11,914:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 04:05:19,621:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.71s, LR: 0.00050, Train Loss: 0.4696, Train Acc: 85.7096,
                        Val Loss: 1.5132, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:05:19,621:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 04:05:27,205:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.58s, LR: 0.00050, Train Loss: 0.4359, Train Acc: 85.5764,
                        Val Loss: 2.0500, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:05:27,205:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 04:05:34,536:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.33s, LR: 0.00050, Train Loss: 0.3968, Train Acc: 87.0381,
                        Val Loss: 2.0541, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:05:34,537:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 04:05:50,523:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 04:05:56,120:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 04:05:56,120:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 04:05:56,120:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:05:56,121:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:05:56,121:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:05:56,121:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:05:56,126:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 04:05:56,127:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 04:05:56,127:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:05:56,128:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:05:56,128:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:05:56,128:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:05:56,630:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 04:06:24,819:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:28.683545112609863
2022-09-06 04:06:24,822:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 04:06:24,822:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 04:06:24,822:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 04:06:24,822:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 04:06:24,823:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 04:06:32,531:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h05m56s_on_Sep_06_2022/MODELS_
2022-09-06 04:06:32,531:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.71s, LR: 0.00050, Train Loss: 0.5992, Train Acc: 68.7667,
                        Val Loss: 1.0827, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:06:32,531:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 04:06:40,355:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.1953 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h05m56s_on_Sep_06_2022/MODELS_
2022-09-06 04:06:40,355:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.82s, LR: 0.00050, Train Loss: 0.4884, Train Acc: 82.8283,
                        Val Loss: 0.9497, Val Acc: 50.0194, Test Acc: 50.1953
2022-09-06 04:06:40,355:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 04:06:47,992:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 64.5777 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h05m56s_on_Sep_06_2022/MODELS_
2022-09-06 04:06:47,993:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.4241, Train Acc: 86.0032,
                        Val Loss: 0.6275, Val Acc: 63.8885, Test Acc: 64.5777
2022-09-06 04:06:47,993:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 04:06:55,563:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.5007 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h05m56s_on_Sep_06_2022/MODELS_
2022-09-06 04:06:55,563:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.57s, LR: 0.00050, Train Loss: 0.4042, Train Acc: 86.5797,
                        Val Loss: 0.4227, Val Acc: 82.7013, Test Acc: 82.5007
2022-09-06 04:06:55,563:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 04:07:03,263:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.0428 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h05m56s_on_Sep_06_2022/MODELS_
2022-09-06 04:07:03,263:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.70s, LR: 0.00050, Train Loss: 0.3819, Train Acc: 86.5301,
                        Val Loss: 0.3832, Val Acc: 85.8571, Test Acc: 85.0428
2022-09-06 04:07:03,263:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 04:07:11,096:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.2361 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h05m56s_on_Sep_06_2022/MODELS_
2022-09-06 04:07:11,096:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.83s, LR: 0.00050, Train Loss: 0.3517, Train Acc: 88.1563,
                        Val Loss: 0.3740, Val Acc: 85.5116, Test Acc: 85.2361
2022-09-06 04:07:11,096:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 04:07:18,617:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.52s, LR: 0.00050, Train Loss: 0.3341, Train Acc: 88.2357,
                        Val Loss: 0.3677, Val Acc: 85.0659, Test Acc: 84.6225
2022-09-06 04:07:18,617:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 04:07:26,383:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.77s, LR: 0.00050, Train Loss: 0.3285, Train Acc: 87.5741,
                        Val Loss: 0.3616, Val Acc: 85.1088, Test Acc: 84.4916
2022-09-06 04:07:26,383:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 04:07:33,935:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.3118, Train Acc: 88.0258,
                        Val Loss: 0.3669, Val Acc: 84.4048, Test Acc: 84.0027
2022-09-06 04:07:33,935:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 04:07:41,595:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 0.2957, Train Acc: 88.5384,
                        Val Loss: 0.4028, Val Acc: 82.1472, Test Acc: 80.7555
2022-09-06 04:07:41,595:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 04:07:49,148:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.2992, Train Acc: 87.5883,
                        Val Loss: 0.4530, Val Acc: 79.4705, Test Acc: 79.1324
2022-09-06 04:07:49,149:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 04:07:56,696:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.55s, LR: 0.00050, Train Loss: 0.2933, Train Acc: 88.1696,
                        Val Loss: 0.5078, Val Acc: 74.9266, Test Acc: 75.0400
2022-09-06 04:07:56,696:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 04:08:03,997:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.30s, LR: 0.00050, Train Loss: 0.3034, Train Acc: 87.2256,
                        Val Loss: 0.5950, Val Acc: 68.1825, Test Acc: 69.2385
2022-09-06 04:08:03,997:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 04:08:11,495:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.50s, LR: 0.00050, Train Loss: 0.2865, Train Acc: 87.8567,
                        Val Loss: 0.8964, Val Acc: 62.3214, Test Acc: 62.7853
2022-09-06 04:08:11,495:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 04:08:19,135:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 0.2790, Train Acc: 88.7158,
                        Val Loss: 1.5560, Val Acc: 54.6186, Test Acc: 54.8291
2022-09-06 04:08:19,136:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 04:08:20,528:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 04:08:20,528:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 04:08:36,694:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 04:08:42,240:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 04:08:42,240:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 04:08:42,240:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:08:42,241:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:08:42,241:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:08:42,241:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:08:42,246:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 04:08:42,247:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 04:08:42,248:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:08:42,248:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:08:42,248:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:08:42,248:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:08:42,719:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 04:09:32,397:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:50.142985820770264
2022-09-06 04:09:32,399:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 100
2022-09-06 04:09:32,399:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 100
2022-09-06 04:09:32,399:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 100
2022-09-06 04:09:32,400:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 04:09:32,401:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 04:09:40,161:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h08m42s_on_Sep_06_2022/MODELS_
2022-09-06 04:09:40,161:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.76s, LR: 0.00050, Train Loss: 0.5973, Train Acc: 77.2522,
                        Val Loss: 2.0673, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:09:40,161:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 04:09:47,977:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.82s, LR: 0.00050, Train Loss: 0.4956, Train Acc: 85.9745,
                        Val Loss: 1.1263, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-06 04:09:47,977:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 04:09:55,296:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 56.1513 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h08m42s_on_Sep_06_2022/MODELS_
2022-09-06 04:09:55,296:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.32s, LR: 0.00050, Train Loss: 0.4525, Train Acc: 86.6317,
                        Val Loss: 0.7475, Val Acc: 56.0158, Test Acc: 56.1513
2022-09-06 04:09:55,296:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 04:10:02,752:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.46s, LR: 0.00050, Train Loss: 0.4435, Train Acc: 86.0830,
                        Val Loss: 1.1653, Val Acc: 50.1406, Test Acc: 50.1539
2022-09-06 04:10:02,752:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 04:10:10,693:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.94s, LR: 0.00050, Train Loss: 0.4307, Train Acc: 86.1001,
                        Val Loss: 1.4886, Val Acc: 50.0000, Test Acc: 50.0040
2022-09-06 04:10:10,693:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 04:10:18,368:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.67s, LR: 0.00050, Train Loss: 0.4050, Train Acc: 87.0347,
                        Val Loss: 1.5980, Val Acc: 50.0000, Test Acc: 50.0040
2022-09-06 04:10:18,368:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 04:10:26,044:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 7.68s, LR: 0.00050, Train Loss: 0.3905, Train Acc: 87.4435,
                        Val Loss: 1.6691, Val Acc: 50.0000, Test Acc: 50.0040
2022-09-06 04:10:26,045:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 04:10:29,353:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 04:10:29,353:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-06 04:10:43,549:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-06 04:10:49,477:main_SBMs_node_classification.py:340 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 16, 'in_dim': 3, 'n_classes': 2}
2022-09-06 04:10:49,477:main_SBMs_node_classification.py:341 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 16}
2022-09-06 04:10:49,477:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:10:49,478:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:10:49,478:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:10:49,478:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:10:49,484:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-06 04:10:49,484:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-06 04:10:49,485:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-06 04:10:49,485:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-06 04:10:49,485:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-06 04:10:49,485:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-06 04:10:49,491:main_SBMs_node_classification.py:85 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-06 04:39:12,441:main_SBMs_node_classification.py:93 -   train_val_pipeline(): Time PE:1702.9501979351044
2022-09-06 04:39:12,451:main_SBMs_node_classification.py:129 -   train_val_pipeline(): Training Graphs: 10000
2022-09-06 04:39:12,451:main_SBMs_node_classification.py:130 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-06 04:39:12,451:main_SBMs_node_classification.py:131 -   train_val_pipeline(): Test Graphs: 2000
2022-09-06 04:39:12,451:main_SBMs_node_classification.py:132 -   train_val_pipeline(): Number of Classes: 2
2022-09-06 04:39:12,454:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 1/1000
2022-09-06 04:47:32,229:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 82.2008 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 04:47:32,230:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 499.78s, LR: 0.00050, Train Loss: 0.3597, Train Acc: 84.6764,
                        Val Loss: 0.3975, Val Acc: 81.9486, Test Acc: 82.2008
2022-09-06 04:47:32,230:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 2/1000
2022-09-06 04:55:49,002:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.3505 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 04:55:49,003:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 496.77s, LR: 0.00050, Train Loss: 0.3326, Train Acc: 85.4005,
                        Val Loss: 0.3405, Val Acc: 85.0554, Test Acc: 85.3505
2022-09-06 04:55:49,003:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 3/1000
2022-09-06 05:04:05,977:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4358 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 05:04:05,978:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 496.98s, LR: 0.00050, Train Loss: 0.3311, Train Acc: 85.4815,
                        Val Loss: 0.3347, Val Acc: 85.3226, Test Acc: 85.4358
2022-09-06 05:04:05,978:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 4/1000
2022-09-06 05:12:20,990:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 495.01s, LR: 0.00050, Train Loss: 0.3300, Train Acc: 85.5088,
                        Val Loss: 0.3670, Val Acc: 84.2028, Test Acc: 84.3023
2022-09-06 05:12:20,993:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 5/1000
2022-09-06 05:20:39,691:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4733 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 05:20:39,692:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 498.70s, LR: 0.00050, Train Loss: 0.3296, Train Acc: 85.5115,
                        Val Loss: 0.3359, Val Acc: 85.3141, Test Acc: 85.4733
2022-09-06 05:20:39,692:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 6/1000
2022-09-06 05:28:57,226:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 497.53s, LR: 0.00050, Train Loss: 0.3292, Train Acc: 85.5221,
                        Val Loss: 0.3399, Val Acc: 85.1905, Test Acc: 85.3815
2022-09-06 05:28:57,228:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 7/1000
2022-09-06 05:37:14,524:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 497.30s, LR: 0.00050, Train Loss: 0.3289, Train Acc: 85.5452,
                        Val Loss: 0.3394, Val Acc: 84.9320, Test Acc: 85.0955
2022-09-06 05:37:14,526:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 8/1000
2022-09-06 05:45:33,261:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 498.74s, LR: 0.00050, Train Loss: 0.3283, Train Acc: 85.5963,
                        Val Loss: 0.3360, Val Acc: 85.2558, Test Acc: 85.3787
2022-09-06 05:45:33,263:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 9/1000
2022-09-06 05:53:51,851:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 498.59s, LR: 0.00050, Train Loss: 0.3281, Train Acc: 85.5786,
                        Val Loss: 0.3423, Val Acc: 84.9232, Test Acc: 85.0522
2022-09-06 05:53:51,854:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 10/1000
2022-09-06 06:02:16,287:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.4987 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 06:02:16,288:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 504.43s, LR: 0.00050, Train Loss: 0.3275, Train Acc: 85.6153,
                        Val Loss: 0.3365, Val Acc: 85.3410, Test Acc: 85.4987
2022-09-06 06:02:16,288:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 11/1000
2022-09-06 06:10:34,774:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 498.49s, LR: 0.00050, Train Loss: 0.3275, Train Acc: 85.6154,
                        Val Loss: 0.3792, Val Acc: 83.5697, Test Acc: 83.8849
2022-09-06 06:10:34,776:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 12/1000
2022-09-06 06:18:53,989:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 499.21s, LR: 0.00050, Train Loss: 0.3271, Train Acc: 85.6069,
                        Val Loss: 0.4506, Val Acc: 78.8979, Test Acc: 79.1840
2022-09-06 06:18:53,991:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 13/1000
2022-09-06 06:27:05,960:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.7355 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 06:27:05,961:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 491.97s, LR: 0.00050, Train Loss: 0.3266, Train Acc: 85.6379,
                        Val Loss: 0.3366, Val Acc: 85.5715, Test Acc: 85.7355
2022-09-06 06:27:05,961:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 14/1000
2022-09-06 06:35:16,258:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 490.30s, LR: 0.00050, Train Loss: 0.3264, Train Acc: 85.6504,
                        Val Loss: 0.3746, Val Acc: 83.5197, Test Acc: 83.8016
2022-09-06 06:35:16,260:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 15/1000
2022-09-06 06:43:28,143:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 491.88s, LR: 0.00025, Train Loss: 0.3237, Train Acc: 85.7787,
                        Val Loss: 0.3580, Val Acc: 84.1239, Test Acc: 84.3343
2022-09-06 06:43:28,145:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 16/1000
2022-09-06 06:51:44,969:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 496.82s, LR: 0.00025, Train Loss: 0.3229, Train Acc: 85.8206,
                        Val Loss: 0.3766, Val Acc: 84.6524, Test Acc: 84.8262
2022-09-06 06:51:44,971:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 17/1000
2022-09-06 06:59:57,247:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 492.28s, LR: 0.00025, Train Loss: 0.3219, Train Acc: 85.8606,
                        Val Loss: 0.3463, Val Acc: 85.3824, Test Acc: 85.5180
2022-09-06 06:59:57,248:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 18/1000
2022-09-06 07:08:09,633:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 492.38s, LR: 0.00025, Train Loss: 0.3213, Train Acc: 85.8861,
                        Val Loss: 0.3547, Val Acc: 85.2743, Test Acc: 85.3604
2022-09-06 07:08:09,634:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 19/1000
2022-09-06 07:16:25,104:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 495.47s, LR: 0.00025, Train Loss: 0.3205, Train Acc: 85.9610,
                        Val Loss: 0.3788, Val Acc: 84.9343, Test Acc: 85.0349
2022-09-06 07:16:25,104:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 20/1000
2022-09-06 07:24:37,278:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 492.17s, LR: 0.00025, Train Loss: 0.3194, Train Acc: 85.9808,
                        Val Loss: 0.3727, Val Acc: 84.4077, Test Acc: 84.6513
2022-09-06 07:24:37,280:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 21/1000
2022-09-06 07:32:50,586:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.7691 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 07:32:50,587:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.31s, LR: 0.00025, Train Loss: 0.3183, Train Acc: 86.0535,
                        Val Loss: 0.3275, Val Acc: 85.7417, Test Acc: 85.7691
2022-09-06 07:32:50,587:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 22/1000
2022-09-06 07:41:04,153:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 85.7820 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 07:41:04,154:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.57s, LR: 0.00025, Train Loss: 0.3169, Train Acc: 86.1174,
                        Val Loss: 0.3305, Val Acc: 85.6965, Test Acc: 85.7820
2022-09-06 07:41:04,154:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 23/1000
2022-09-06 07:49:22,740:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 498.59s, LR: 0.00025, Train Loss: 0.3153, Train Acc: 86.1953,
                        Val Loss: 0.3343, Val Acc: 85.6082, Test Acc: 85.7689
2022-09-06 07:49:22,742:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 24/1000
2022-09-06 07:57:37,836:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 495.09s, LR: 0.00025, Train Loss: 0.3139, Train Acc: 86.2820,
                        Val Loss: 0.3572, Val Acc: 84.2512, Test Acc: 84.5503
2022-09-06 07:57:37,839:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 25/1000
2022-09-06 08:05:51,368:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.53s, LR: 0.00025, Train Loss: 0.3124, Train Acc: 86.3242,
                        Val Loss: 0.3327, Val Acc: 85.5585, Test Acc: 85.7041
2022-09-06 08:05:51,370:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 26/1000
2022-09-06 08:14:08,669:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 497.30s, LR: 0.00025, Train Loss: 0.3111, Train Acc: 86.4196,
                        Val Loss: 0.3486, Val Acc: 84.6052, Test Acc: 84.7785
2022-09-06 08:14:08,671:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 27/1000
2022-09-06 08:22:21,735:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.06s, LR: 0.00025, Train Loss: 0.3096, Train Acc: 86.4636,
                        Val Loss: 0.3320, Val Acc: 85.4889, Test Acc: 85.4999
2022-09-06 08:22:21,738:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 28/1000
2022-09-06 08:30:37,519:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 495.78s, LR: 0.00025, Train Loss: 0.3088, Train Acc: 86.4853,
                        Val Loss: 0.3486, Val Acc: 84.3771, Test Acc: 84.5847
2022-09-06 08:30:37,521:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 29/1000
2022-09-06 08:38:52,009:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 494.49s, LR: 0.00025, Train Loss: 0.3074, Train Acc: 86.5796,
                        Val Loss: 0.4328, Val Acc: 81.2451, Test Acc: 81.4467
2022-09-06 08:38:52,011:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 30/1000
2022-09-06 08:47:06,858:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 494.85s, LR: 0.00025, Train Loss: 0.3066, Train Acc: 86.6015,
                        Val Loss: 0.3674, Val Acc: 85.4934, Test Acc: 85.6609
2022-09-06 08:47:06,861:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 31/1000
2022-09-06 08:55:19,168:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 492.31s, LR: 0.00025, Train Loss: 0.3057, Train Acc: 86.6422,
                        Val Loss: 0.3665, Val Acc: 83.4746, Test Acc: 83.5860
2022-09-06 08:55:19,170:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 32/1000
2022-09-06 09:03:35,014:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 495.84s, LR: 0.00025, Train Loss: 0.3047, Train Acc: 86.7009,
                        Val Loss: 0.3604, Val Acc: 84.0092, Test Acc: 84.2164
2022-09-06 09:03:35,017:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 33/1000
2022-09-06 09:11:49,057:main_SBMs_node_classification.py:186 -   train_val_pipeline(): Saving best model with test accuracy: 86.0083 to out/SBMs_node_classification_b32-bnorm-alt-rwkcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_16_16_04h10m49s_on_Sep_06_2022/MODELS_
2022-09-06 09:11:49,058:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 494.04s, LR: 0.00013, Train Loss: 0.3008, Train Acc: 86.8518,
                        Val Loss: 0.3236, Val Acc: 85.9063, Test Acc: 86.0083
2022-09-06 09:11:49,058:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 34/1000
2022-09-06 09:20:03,038:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.98s, LR: 0.00013, Train Loss: 0.2996, Train Acc: 86.9013,
                        Val Loss: 0.4079, Val Acc: 79.8161, Test Acc: 79.7849
2022-09-06 09:20:03,040:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 35/1000
2022-09-06 09:28:16,912:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.87s, LR: 0.00013, Train Loss: 0.2988, Train Acc: 86.9349,
                        Val Loss: 0.3833, Val Acc: 81.8069, Test Acc: 81.9079
2022-09-06 09:28:16,915:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 36/1000
2022-09-06 09:36:31,258:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 494.34s, LR: 0.00013, Train Loss: 0.2979, Train Acc: 86.9719,
                        Val Loss: 0.3536, Val Acc: 83.6685, Test Acc: 83.8012
2022-09-06 09:36:31,260:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 37/1000
2022-09-06 09:44:44,990:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.73s, LR: 0.00013, Train Loss: 0.2970, Train Acc: 86.9908,
                        Val Loss: 0.3253, Val Acc: 85.8392, Test Acc: 85.9552
2022-09-06 09:44:44,992:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 38/1000
2022-09-06 09:52:57,979:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 492.99s, LR: 0.00013, Train Loss: 0.2963, Train Acc: 87.0109,
                        Val Loss: 0.3622, Val Acc: 83.4989, Test Acc: 83.5509
2022-09-06 09:52:57,980:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 39/1000
2022-09-06 10:01:12,278:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 494.30s, LR: 0.00013, Train Loss: 0.2956, Train Acc: 87.0619,
                        Val Loss: 0.3434, Val Acc: 84.5391, Test Acc: 84.6729
2022-09-06 10:01:12,280:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 40/1000
2022-09-06 10:09:25,564:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.28s, LR: 0.00013, Train Loss: 0.2942, Train Acc: 87.0490,
                        Val Loss: 0.3455, Val Acc: 84.9358, Test Acc: 84.9984
2022-09-06 10:09:25,567:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 41/1000
2022-09-06 10:17:39,336:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 493.77s, LR: 0.00013, Train Loss: 0.2934, Train Acc: 87.1045,
                        Val Loss: 0.3539, Val Acc: 84.8901, Test Acc: 85.0732
2022-09-06 10:17:39,338:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 42/1000
2022-09-06 10:25:54,038:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 494.70s, LR: 0.00013, Train Loss: 0.2924, Train Acc: 87.1523,
                        Val Loss: 0.3468, Val Acc: 85.0425, Test Acc: 85.0053
2022-09-06 10:25:54,041:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 43/1000
2022-09-06 10:34:09,821:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 495.78s, LR: 0.00013, Train Loss: 0.2913, Train Acc: 87.1705,
                        Val Loss: 0.3689, Val Acc: 85.3184, Test Acc: 85.3548
2022-09-06 10:34:09,823:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 44/1000
2022-09-06 10:42:25,598:main_SBMs_node_classification.py:208 -   train_val_pipeline(): 	Time: 495.77s, LR: 0.00013, Train Loss: 0.2902, Train Acc: 87.1994,
                        Val Loss: 0.3472, Val Acc: 85.6340, Test Acc: 85.6352
2022-09-06 10:42:25,600:main_SBMs_node_classification.py:166 -   train_val_pipeline(): Epoch 45/1000
2022-09-06 10:43:09,073:main_SBMs_node_classification.py:239 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-06 10:43:09,075:main_SBMs_node_classification.py:240 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-07 02:32:34,443:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:32:37,794:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:32:37,794:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 4}
2022-09-07 02:32:37,795:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:32:37,811:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:32:37,811:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:32:37,811:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:32:37,817:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 02:32:37,818:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 338578
2022-09-07 02:32:37,818:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:32:37,819:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:32:37,819:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:32:37,819:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:32:37,824:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 02:32:53,961:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:32:57,630:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:32:57,631:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 4}
2022-09-07 02:32:57,631:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:32:57,632:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:32:57,632:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:32:57,632:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:32:57,637:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 02:32:57,638:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 338578
2022-09-07 02:32:57,638:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:32:57,638:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:32:57,638:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:32:57,638:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:32:57,643:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 02:33:48,032:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:34:22,741:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:34:26,024:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:34:26,024:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 4}
2022-09-07 02:34:26,025:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:34:26,026:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:34:26,026:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:34:26,026:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:34:26,030:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 02:34:26,031:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 338578
2022-09-07 02:34:26,031:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:34:26,031:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:34:26,031:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:34:26,031:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:34:26,036:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 02:34:54,252:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:34:57,481:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:34:57,481:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 4}
2022-09-07 02:34:57,481:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:34:57,482:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:34:57,482:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:34:57,482:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:34:57,487:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 02:34:57,488:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 338578
2022-09-07 02:34:57,488:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:34:57,488:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:34:57,488:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:34:57,488:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:34:57,493:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 02:35:01,224:main_molecules_graph_regression.py:68 -   train_val_pipeline(): Time PE:3.7357120513916016
2022-09-07 02:35:01,224:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 02:35:22,670:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 21.446648836135864
2022-09-07 02:35:22,689:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 02:35:22,689:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 02:35:22,689:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 02:35:22,692:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 02:36:03,317:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 0.7161936908960342
2022-09-07 02:36:03,318:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 40.63s, LR: 0.00070, Train Loss: 0.9181, Train MAE: 0.9181,
                            Val Loss: 0.6545, Val Acc: 0.6545, Test MAE: 0.7162
2022-09-07 02:36:03,327:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 02:36:43,691:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 40.36s, LR: 0.00070, Train Loss: 0.6541, Train MAE: 0.6541,
                            Val Loss: 0.7866, Val Acc: 0.7866, Test MAE: 0.8702
2022-09-07 02:36:43,698:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 02:37:23,575:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 0.6491644755005836
2022-09-07 02:37:23,576:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 39.88s, LR: 0.00070, Train Loss: 0.6280, Train MAE: 0.6280,
                            Val Loss: 0.5828, Val Acc: 0.5828, Test MAE: 0.6492
2022-09-07 02:37:23,582:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 02:37:23,919:main_molecules_graph_regression.py:230 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-07 02:37:23,919:main_molecules_graph_regression.py:231 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-07 02:37:27,095:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:37:30,345:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:37:30,346:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 4}
2022-09-07 02:37:30,346:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:37:30,347:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:37:30,347:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:37:30,347:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:37:30,351:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 02:37:30,352:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 338578
2022-09-07 02:37:30,352:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:37:30,352:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:37:30,352:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 02:37:30,352:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:37:30,357:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 02:37:34,097:main_molecules_graph_regression.py:68 -   train_val_pipeline(): Time PE:3.74532413482666
2022-09-07 02:37:34,097:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 02:37:54,895:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 20.797275066375732
2022-09-07 02:37:54,913:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 02:37:54,914:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 02:37:54,914:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 02:37:54,916:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 02:38:36,013:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 1.610301524400711
2022-09-07 02:38:36,014:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 41.10s, LR: 0.00070, Train Loss: 1.4847, Train MAE: 1.4847,
                            Val Loss: 1.5331, Val Acc: 1.5331, Test MAE: 1.6103
2022-09-07 02:38:36,020:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 02:39:16,335:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 40.32s, LR: 0.00070, Train Loss: 1.2951, Train MAE: 1.2951,
                            Val Loss: 1.7563, Val Acc: 1.7563, Test MAE: 1.8113
2022-09-07 02:39:16,343:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 02:39:55,660:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 1.551300972700119
2022-09-07 02:39:55,660:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 39.32s, LR: 0.00070, Train Loss: 1.0434, Train MAE: 1.0434,
                            Val Loss: 1.4620, Val Acc: 1.4620, Test MAE: 1.5513
2022-09-07 02:39:55,668:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 02:40:35,009:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 39.34s, LR: 0.00070, Train Loss: 0.9216, Train MAE: 0.9216,
                            Val Loss: 1.7992, Val Acc: 1.7992, Test MAE: 1.8442
2022-09-07 02:40:35,015:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 5/1000
2022-09-07 02:41:14,272:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 39.26s, LR: 0.00070, Train Loss: 0.8762, Train MAE: 0.8762,
                            Val Loss: 2.1138, Val Acc: 2.1138, Test MAE: 2.1460
2022-09-07 02:41:14,278:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 6/1000
2022-09-07 02:41:53,915:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 39.64s, LR: 0.00070, Train Loss: 0.8475, Train MAE: 0.8475,
                            Val Loss: 2.0970, Val Acc: 2.0970, Test MAE: 2.1271
2022-09-07 02:41:53,922:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 7/1000
2022-09-07 02:42:13,748:main_molecules_graph_regression.py:230 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-07 02:42:13,748:main_molecules_graph_regression.py:231 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-07 02:42:19,292:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:42:22,570:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:42:22,570:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 4}
2022-09-07 02:42:22,570:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:42:22,571:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:42:22,571:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 02:42:22,571:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:42:22,576:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 02:42:22,576:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 338578
2022-09-07 02:42:22,577:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:42:22,577:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:42:22,577:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 02:42:22,577:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:42:22,582:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 02:42:37,318:main_molecules_graph_regression.py:68 -   train_val_pipeline(): Time PE:14.741199970245361
2022-09-07 02:42:37,318:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 02:42:58,163:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 20.844684839248657
2022-09-07 02:42:58,180:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 02:42:58,180:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 02:42:58,180:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 02:42:58,182:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 02:43:39,168:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 1.5536168217658997
2022-09-07 02:43:39,170:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 40.99s, LR: 0.00070, Train Loss: 1.5028, Train MAE: 1.5028,
                            Val Loss: 1.4396, Val Acc: 1.4396, Test MAE: 1.5536
2022-09-07 02:43:39,176:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 02:44:19,644:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 40.47s, LR: 0.00070, Train Loss: 1.4702, Train MAE: 1.4702,
                            Val Loss: 1.4410, Val Acc: 1.4410, Test MAE: 1.5649
2022-09-07 02:44:19,650:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 02:44:59,833:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 1.524060606956482
2022-09-07 02:44:59,834:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 40.18s, LR: 0.00070, Train Loss: 1.4604, Train MAE: 1.4604,
                            Val Loss: 1.3997, Val Acc: 1.3997, Test MAE: 1.5241
2022-09-07 02:44:59,840:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 02:45:30,095:main_molecules_graph_regression.py:230 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-07 02:45:30,095:main_molecules_graph_regression.py:231 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-07 02:59:01,364:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 02:59:04,723:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 64, 'out_dim': 64, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': True, 'gpu_id': 0, 'batch_size': 128, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'n_gape': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 02:59:04,723:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 4}
2022-09-07 02:59:04,723:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:59:04,724:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:59:04,724:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 02:59:04,724:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:59:04,728:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 02:59:04,729:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 338578
2022-09-07 02:59:04,729:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 02:59:04,730:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 02:59:04,730:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 02:59:04,730:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 02:59:04,735:main_molecules_graph_regression.py:62 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 03:07:55,845:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:07:59,011:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': True, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:07:59,011:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:07:59,017:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:07:59,017:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:07:59,023:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:08:14,557:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.53938627243042
2022-09-07 03:08:14,557:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:08:35,650:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 21.09343719482422
2022-09-07 03:08:35,651:main_molecules_graph_regression.py:95 -   train_val_pipeline(): [!] Adding graph self-loops for GCN/GAT models (central node trick).
2022-09-07 03:09:06,513:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:09:09,718:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': True, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:09:09,718:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:09:09,723:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:09:09,724:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:09:09,729:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:09:25,043:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.318208932876587
2022-09-07 03:09:25,043:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:09:45,648:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 20.60499095916748
2022-09-07 03:09:45,648:main_molecules_graph_regression.py:95 -   train_val_pipeline(): [!] Adding graph self-loops for GCN/GAT models (central node trick).
2022-09-07 03:09:53,429:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 03:09:53,429:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:09:53,429:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 03:09:53,432:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:11:16,252:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 1.4619333446025848
2022-09-07 03:11:16,253:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 82.82s, LR: 0.00070, Train Loss: 1.4384, Train MAE: 1.4384,
                            Val Loss: 1.3718, Val Acc: 1.3718, Test MAE: 1.4619
2022-09-07 03:11:16,260:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 03:12:04,315:main_molecules_graph_regression.py:230 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-07 03:12:04,315:main_molecules_graph_regression.py:231 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-07 03:12:16,675:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:12:19,862:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:12:19,862:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:12:19,867:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:12:19,868:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:12:19,873:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:12:35,441:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.57301926612854
2022-09-07 03:12:35,441:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:12:57,005:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 21.56329107284546
2022-09-07 03:12:57,021:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 03:12:57,021:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:12:57,021:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 03:12:57,023:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:14:21,092:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 1.4606868475675583
2022-09-07 03:14:21,093:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 84.07s, LR: 0.00070, Train Loss: 1.4183, Train MAE: 1.4183,
                            Val Loss: 1.3678, Val Acc: 1.3678, Test MAE: 1.4607
2022-09-07 03:14:21,099:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 03:15:43,376:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 82.28s, LR: 0.00070, Train Loss: 1.3985, Train MAE: 1.3985,
                            Val Loss: 1.3693, Val Acc: 1.3693, Test MAE: 1.4628
2022-09-07 03:15:43,382:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 03:15:52,292:main_molecules_graph_regression.py:230 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-07 03:15:52,292:main_molecules_graph_regression.py:231 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-07 03:15:55,466:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:15:58,747:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:15:58,747:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:15:58,753:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:15:58,753:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:15:58,759:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:16:14,406:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.652355909347534
2022-09-07 03:16:14,406:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:16:35,871:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 21.464510917663574
2022-09-07 03:16:35,887:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 03:16:35,887:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:16:35,887:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 03:16:35,890:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:17:44,084:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:17:47,313:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:17:47,313:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:17:47,319:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:17:47,320:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:17:47,325:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:18:02,331:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.010844945907593
2022-09-07 03:18:02,331:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:18:23,216:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 20.884796857833862
2022-09-07 03:18:23,230:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 03:18:23,230:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:18:23,231:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 03:18:23,232:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:19:44,881:main_molecules_graph_regression.py:175 -   train_val_pipeline(): Best model with MAE 1.4678821563720703
2022-09-07 03:19:44,883:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 81.65s, LR: 0.00070, Train Loss: 1.4220, Train MAE: 1.4220,
                            Val Loss: 1.3884, Val Acc: 1.3884, Test MAE: 1.4679
2022-09-07 03:19:44,888:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 03:21:07,495:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 82.61s, LR: 0.00070, Train Loss: 1.4000, Train MAE: 1.4000,
                            Val Loss: 1.3839, Val Acc: 1.3839, Test MAE: 1.4838
2022-09-07 03:21:07,501:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 03:22:30,301:main_molecules_graph_regression.py:198 -   train_val_pipeline(): 	Time: 82.80s, LR: 0.00070, Train Loss: 1.4030, Train MAE: 1.4030,
                            Val Loss: 1.4028, Val Acc: 1.4028, Test MAE: 1.4876
2022-09-07 03:22:30,307:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 03:23:04,225:main_molecules_graph_regression.py:230 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-07 03:23:04,225:main_molecules_graph_regression.py:231 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-07 03:23:06,740:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:23:10,021:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:23:10,021:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:23:10,026:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:23:10,027:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:23:10,032:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:23:25,467:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.439512252807617
2022-09-07 03:23:25,467:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:23:46,767:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 21.299987077713013
2022-09-07 03:23:46,786:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 03:23:46,787:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:23:46,787:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 03:23:46,789:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:24:20,521:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:24:23,874:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:24:23,874:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:24:23,880:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:24:23,880:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:24:23,886:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:24:38,906:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:15.025743961334229
2022-09-07 03:24:38,906:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:25:00,542:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 21.635602951049805
2022-09-07 03:25:00,558:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 03:25:00,559:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:25:00,559:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 03:25:00,561:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:30:57,337:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:31:00,552:main_molecules_graph_regression.py:344 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': True, 'batch_norm': False, 'self_loop': False, 'wl_pos_enc': False, 'pos_enc': False, 'full_graph': True, 'in_deg_centrality': 64, 'out_deg_centrality': 64, 'spd_len': 128, 'gpu_id': 0, 'batch_size': 128, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 1, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-07 03:31:00,552:main_molecules_graph_regression.py:345 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'save', 'job_num': 1}
2022-09-07 03:31:00,557:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:31:00,558:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: PseudoGraphormer, 535985
2022-09-07 03:31:00,563:main_molecules_graph_regression.py:84 -   train_val_pipeline(): [!] Adding shortest path distance encodings using the Floyd-Warshall algorithm.
2022-09-07 03:31:15,489:main_molecules_graph_regression.py:86 -   train_val_pipeline(): Time PE:14.930775165557861
2022-09-07 03:31:15,489:main_molecules_graph_regression.py:90 -   train_val_pipeline(): [!] Converting the given graphs to full graphs..
2022-09-07 03:31:36,109:main_molecules_graph_regression.py:92 -   train_val_pipeline(): Time taken to convert to full graphs: 20.62010908126831
2022-09-07 03:31:36,124:main_molecules_graph_regression.py:116 -   train_val_pipeline(): Training Graphs: 10000
2022-09-07 03:31:36,124:main_molecules_graph_regression.py:117 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:31:36,125:main_molecules_graph_regression.py:118 -   train_val_pipeline(): Test Graphs: 1000
2022-09-07 03:31:36,126:main_molecules_graph_regression.py:156 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:44:22,223:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:44:26,731:main_CYCLES_graph_classification.py:350 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 2, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 03:44:26,731:main_CYCLES_graph_classification.py:351 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 03:44:26,732:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:44:26,732:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:44:26,732:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:44:26,732:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:44:26,738:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:44:26,739:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522909
2022-09-07 03:44:26,739:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:44:26,740:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:44:26,740:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:44:26,740:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:44:26,746:main_CYCLES_graph_classification.py:71 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:44:35,762:main_CYCLES_graph_classification.py:79 -   train_val_pipeline(): Time PE:9.022737264633179
2022-09-07 03:44:35,776:main_CYCLES_graph_classification.py:125 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 03:44:35,776:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:44:35,776:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 03:44:35,776:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 03:44:35,779:main_CYCLES_graph_classification.py:153 -   train_val_pipeline(): Epoch 1/1
2022-09-07 03:46:55,437:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:46:59,987:main_CYCLES_graph_classification.py:350 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 2, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 03:46:59,987:main_CYCLES_graph_classification.py:351 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 03:46:59,987:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:46:59,988:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:46:59,988:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:46:59,988:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:46:59,993:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:46:59,993:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522909
2022-09-07 03:46:59,994:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:46:59,994:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:46:59,994:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:46:59,994:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:46:59,999:main_CYCLES_graph_classification.py:71 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:47:08,673:main_CYCLES_graph_classification.py:79 -   train_val_pipeline(): Time PE:8.679329872131348
2022-09-07 03:47:08,688:main_CYCLES_graph_classification.py:125 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 03:47:08,688:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:47:08,688:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 03:47:08,688:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 03:47:08,690:main_CYCLES_graph_classification.py:153 -   train_val_pipeline(): Epoch 1/1
2022-09-07 03:47:31,586:main_CYCLES_graph_classification.py:169 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h46m59s_on_Sep_07_2022/MODELS_
2022-09-07 03:47:31,587:main_CYCLES_graph_classification.py:191 -   train_val_pipeline(): 	Time: 22.90s, LR: 0.00050, Train Loss: 0.7913, Train Acc: 0.5550,
                            Val Loss: 2.1561, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 03:47:51,173:main_CYCLES_graph_classification.py:231 -   train_val_pipeline(): Test Accuracy: 0.5000
2022-09-07 03:47:51,173:main_CYCLES_graph_classification.py:232 -   train_val_pipeline(): Best Test Accuracy: 0.5000
2022-09-07 03:47:51,173:main_CYCLES_graph_classification.py:233 -   train_val_pipeline(): Train Accuracy: 0.5000
2022-09-07 03:47:51,173:main_CYCLES_graph_classification.py:234 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 0.5550
2022-09-07 03:47:51,173:main_CYCLES_graph_classification.py:235 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 03:47:51,173:main_CYCLES_graph_classification.py:236 -   train_val_pipeline(): TOTAL TIME TAKEN: 51.1796s
2022-09-07 03:47:51,173:main_CYCLES_graph_classification.py:237 -   train_val_pipeline(): AVG TIME PER EPOCH: 22.8971s
2022-09-07 03:48:21,048:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:48:25,442:main_CYCLES_graph_classification.py:351 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 2, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 03:48:25,442:main_CYCLES_graph_classification.py:352 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 03:48:25,442:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:48:25,443:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:48:25,443:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:48:25,443:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:48:25,448:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:48:25,449:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522909
2022-09-07 03:48:25,449:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41...
2022-09-07 03:48:25,449:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:48:25,450:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:48:25,450:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:48:25,450:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:48:25,455:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:48:39,735:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:48:44,020:main_CYCLES_graph_classification.py:351 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 2, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 03:48:44,020:main_CYCLES_graph_classification.py:352 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41, 95, 22, 35], 'job_num': 2}
2022-09-07 03:48:44,020:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:48:44,021:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:48:44,021:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:48:44,021:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:48:44,026:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:48:44,027:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522909
2022-09-07 03:48:44,027:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41...
2022-09-07 03:48:44,027:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:48:44,027:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:48:44,027:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:48:44,027:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:48:44,032:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:48:52,356:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:8.329593181610107
2022-09-07 03:48:52,371:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 03:48:52,371:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:48:52,372:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 03:48:52,372:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 03:48:52,374:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 03:49:13,346:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h48m44s_on_Sep_07_2022/MODELS_
2022-09-07 03:49:13,347:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 20.97s, LR: 0.00050, Train Loss: 0.8741, Train Acc: 0.5050,
                            Val Loss: 1.7217, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 03:49:13,348:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 03:49:34,842:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5329 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h48m44s_on_Sep_07_2022/MODELS_
2022-09-07 03:49:34,842:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.49s, LR: 0.00050, Train Loss: 0.6557, Train Acc: 0.6450,
                            Val Loss: 0.8433, Val Acc: 0.5410, Test Acc: 0.5329
2022-09-07 03:49:34,842:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 03:49:55,997:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6846 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h48m44s_on_Sep_07_2022/MODELS_
2022-09-07 03:49:55,997:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.16s, LR: 0.00050, Train Loss: 0.5896, Train Acc: 0.7100,
                            Val Loss: 0.5906, Val Acc: 0.6860, Test Acc: 0.6846
2022-09-07 03:49:55,997:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 03:50:17,128:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.7033 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h48m44s_on_Sep_07_2022/MODELS_
2022-09-07 03:50:17,129:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.13s, LR: 0.00050, Train Loss: 0.5717, Train Acc: 0.7050,
                            Val Loss: 0.6011, Val Acc: 0.6930, Test Acc: 0.7033
2022-09-07 03:50:17,129:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-07 03:50:25,110:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 03:50:29,467:main_CYCLES_graph_classification.py:351 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 2, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 03:50:29,467:main_CYCLES_graph_classification.py:352 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41, 95, 22, 35], 'job_num': 2}
2022-09-07 03:50:29,468:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:50:29,468:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:50:29,469:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:50:29,469:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:50:29,474:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 03:50:29,475:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522909
2022-09-07 03:50:29,475:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41...
2022-09-07 03:50:29,475:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:50:29,475:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:50:29,475:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:50:29,476:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:50:29,481:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:50:37,872:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:8.397397994995117
2022-09-07 03:50:37,886:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 03:50:37,886:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:50:37,886:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 03:50:37,886:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 03:50:37,889:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1
2022-09-07 03:50:59,276:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h50m29s_on_Sep_07_2022/MODELS_
2022-09-07 03:50:59,278:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.39s, LR: 0.00050, Train Loss: 0.7282, Train Acc: 0.5950,
                            Val Loss: 0.8855, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 03:51:18,981:main_CYCLES_graph_classification.py:232 -   train_val_pipeline(): Test Accuracy: 0.5000
2022-09-07 03:51:18,981:main_CYCLES_graph_classification.py:233 -   train_val_pipeline(): Best Test Accuracy: 0.5000
2022-09-07 03:51:18,981:main_CYCLES_graph_classification.py:234 -   train_val_pipeline(): Train Accuracy: 0.5000
2022-09-07 03:51:18,981:main_CYCLES_graph_classification.py:235 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 0.5950
2022-09-07 03:51:18,981:main_CYCLES_graph_classification.py:236 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 03:51:18,981:main_CYCLES_graph_classification.py:237 -   train_val_pipeline(): TOTAL TIME TAKEN: 49.5062s
2022-09-07 03:51:18,981:main_CYCLES_graph_classification.py:238 -   train_val_pipeline(): AVG TIME PER EPOCH: 21.3894s
2022-09-07 03:51:18,982:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 95...
2022-09-07 03:51:18,982:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:51:18,982:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:51:18,982:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:51:18,982:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:51:18,988:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:51:27,665:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:8.683665752410889
2022-09-07 03:51:27,666:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 03:51:27,666:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:51:27,666:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 03:51:27,666:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 03:51:27,667:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1
2022-09-07 03:51:48,641:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5041 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h50m29s_on_Sep_07_2022/MODELS_
2022-09-07 03:51:48,643:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 20.98s, LR: 0.00050, Train Loss: 0.7443, Train Acc: 0.5300,
                            Val Loss: 1.3747, Val Acc: 0.4970, Test Acc: 0.5041
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:232 -   train_val_pipeline(): Test Accuracy: 0.5041
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:233 -   train_val_pipeline(): Best Test Accuracy: 0.5041
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:234 -   train_val_pipeline(): Train Accuracy: 0.4900
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:235 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 0.5300
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:236 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:237 -   train_val_pipeline(): TOTAL TIME TAKEN: 48.8442s
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:238 -   train_val_pipeline(): AVG TIME PER EPOCH: 20.9752s
2022-09-07 03:52:07,826:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 22...
2022-09-07 03:52:07,826:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:52:07,827:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:52:07,827:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:52:07,827:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:52:07,832:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:52:16,483:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:8.656686067581177
2022-09-07 03:52:16,484:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 03:52:16,484:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:52:16,484:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 03:52:16,484:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 03:52:16,486:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1
2022-09-07 03:52:38,843:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6659 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h50m29s_on_Sep_07_2022/MODELS_
2022-09-07 03:52:38,845:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.36s, LR: 0.00050, Train Loss: 0.8555, Train Acc: 0.5750,
                            Val Loss: 0.6507, Val Acc: 0.6570, Test Acc: 0.6659
2022-09-07 03:52:58,228:main_CYCLES_graph_classification.py:232 -   train_val_pipeline(): Test Accuracy: 0.6659
2022-09-07 03:52:58,228:main_CYCLES_graph_classification.py:233 -   train_val_pipeline(): Best Test Accuracy: 0.6659
2022-09-07 03:52:58,228:main_CYCLES_graph_classification.py:234 -   train_val_pipeline(): Train Accuracy: 0.6500
2022-09-07 03:52:58,228:main_CYCLES_graph_classification.py:235 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 0.5750
2022-09-07 03:52:58,228:main_CYCLES_graph_classification.py:236 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 03:52:58,228:main_CYCLES_graph_classification.py:237 -   train_val_pipeline(): TOTAL TIME TAKEN: 50.4017s
2022-09-07 03:52:58,228:main_CYCLES_graph_classification.py:238 -   train_val_pipeline(): AVG TIME PER EPOCH: 22.3588s
2022-09-07 03:52:58,229:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 35...
2022-09-07 03:52:58,229:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 03:52:58,229:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 03:52:58,229:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 03:52:58,229:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 03:52:58,235:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 03:53:07,025:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:8.795915126800537
2022-09-07 03:53:07,026:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 03:53:07,026:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 03:53:07,026:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 03:53:07,026:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 03:53:07,027:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1
2022-09-07 03:53:28,657:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5181 to out/CYCLES_graph_classification_b25-bnorm-alt-studycheckpoints/GraphTransformer_CYCLES_GPU0_2_2_03h50m29s_on_Sep_07_2022/MODELS_
2022-09-07 03:53:28,659:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.63s, LR: 0.00050, Train Loss: 0.8588, Train Acc: 0.5450,
                            Val Loss: 1.2258, Val Acc: 0.4980, Test Acc: 0.5181
2022-09-07 03:53:47,149:main_CYCLES_graph_classification.py:232 -   train_val_pipeline(): Test Accuracy: 0.5181
2022-09-07 03:53:47,150:main_CYCLES_graph_classification.py:233 -   train_val_pipeline(): Best Test Accuracy: 0.5181
2022-09-07 03:53:47,150:main_CYCLES_graph_classification.py:234 -   train_val_pipeline(): Train Accuracy: 0.4800
2022-09-07 03:53:47,150:main_CYCLES_graph_classification.py:235 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 0.5450
2022-09-07 03:53:47,150:main_CYCLES_graph_classification.py:236 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 03:53:47,150:main_CYCLES_graph_classification.py:237 -   train_val_pipeline(): TOTAL TIME TAKEN: 48.9210s
2022-09-07 03:53:47,150:main_CYCLES_graph_classification.py:238 -   train_val_pipeline(): AVG TIME PER EPOCH: 21.6313s
2022-09-07 11:36:45,896:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 11:36:52,324:main_SBMs_node_classification.py:351 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 2, 'in_dim': 3, 'n_classes': 2}
2022-09-07 11:36:52,324:main_SBMs_node_classification.py:352 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 11:36:52,325:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:36:52,339:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:36:52,339:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:36:52,339:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:36:52,347:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 11:36:52,348:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522989
2022-09-07 11:36:52,349:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:36:52,349:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:36:52,349:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:36:52,349:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:36:52,855:main_SBMs_node_classification.py:89 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:36:53,280:main_SBMs_node_classification.py:97 -   train_val_pipeline(): Time PE:0.9226667881011963
2022-09-07 11:36:53,282:main_SBMs_node_classification.py:133 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:36:53,282:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:36:53,282:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:36:53,282:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:36:53,284:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 11:36:54,337:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 57.1828 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h36m52s_on_Sep_07_2022/MODELS_
2022-09-07 11:36:54,337:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 1.05s, LR: 0.00050, Train Loss: 0.6974, Train Acc: 50.5484,
                            Val Loss: 0.6873, Val Acc: 59.2054, Test Acc: 57.1828
2022-09-07 11:36:54,337:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 11:36:55,322:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 62.3701 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h36m52s_on_Sep_07_2022/MODELS_
2022-09-07 11:36:55,322:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.99s, LR: 0.00050, Train Loss: 0.6794, Train Acc: 62.7822,
                            Val Loss: 0.6791, Val Acc: 61.4632, Test Acc: 62.3701
2022-09-07 11:36:55,323:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 11:36:56,249:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 0.6685, Train Acc: 62.5969,
                            Val Loss: 0.6727, Val Acc: 61.2209, Test Acc: 62.2819
2022-09-07 11:36:56,249:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 11:36:57,153:main_SBMs_node_classification.py:190 -   train_val_pipeline(): Saving best model with test accuracy: 62.4682 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h36m52s_on_Sep_07_2022/MODELS_
2022-09-07 11:36:57,153:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.6612, Train Acc: 62.6681,
                            Val Loss: 0.6685, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:36:57,153:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 5/1000
2022-09-07 11:36:58,031:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 0.6549, Train Acc: 62.9957,
                            Val Loss: 0.6653, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:36:58,031:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 6/1000
2022-09-07 11:36:58,895:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.86s, LR: 0.00050, Train Loss: 0.6497, Train Acc: 63.9786,
                            Val Loss: 0.6620, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:36:58,896:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 7/1000
2022-09-07 11:36:59,788:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.6456, Train Acc: 64.4771,
                            Val Loss: 0.6589, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:36:59,788:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 8/1000
2022-09-07 11:37:00,672:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 0.6413, Train Acc: 64.4984,
                            Val Loss: 0.6565, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:37:00,672:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 9/1000
2022-09-07 11:37:01,538:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 0.6374, Train Acc: 65.0468,
                            Val Loss: 0.6549, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:37:01,538:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 10/1000
2022-09-07 11:37:02,407:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 0.6331, Train Acc: 64.8973,
                            Val Loss: 0.6539, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:37:02,407:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 11/1000
2022-09-07 11:37:03,284:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 0.6285, Train Acc: 65.5027,
                            Val Loss: 0.6534, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:37:03,284:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 12/1000
2022-09-07 11:37:04,222:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.6240, Train Acc: 65.3531,
                            Val Loss: 0.6531, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:37:04,223:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 13/1000
2022-09-07 11:37:05,105:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 0.6186, Train Acc: 66.3573,
                            Val Loss: 0.6528, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:37:05,105:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 14/1000
2022-09-07 11:37:05,988:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 0.6127, Train Acc: 66.9627,
                            Val Loss: 0.6528, Val Acc: 61.4018, Test Acc: 62.4682
2022-09-07 11:37:05,988:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 15/1000
2022-09-07 11:37:06,858:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 0.6070, Train Acc: 66.5852,
                            Val Loss: 0.6526, Val Acc: 61.4503, Test Acc: 62.4682
2022-09-07 11:37:06,858:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 16/1000
2022-09-07 11:37:07,732:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 0.6000, Train Acc: 67.6892,
                            Val Loss: 0.6523, Val Acc: 61.4987, Test Acc: 62.4682
2022-09-07 11:37:07,732:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 17/1000
2022-09-07 11:37:08,604:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 0.5933, Train Acc: 67.7603,
                            Val Loss: 0.6521, Val Acc: 61.5472, Test Acc: 62.4682
2022-09-07 11:37:08,604:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 18/1000
2022-09-07 11:37:09,540:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.94s, LR: 0.00050, Train Loss: 0.5931, Train Acc: 67.4114,
                            Val Loss: 0.6519, Val Acc: 61.5472, Test Acc: 62.4682
2022-09-07 11:37:09,541:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 19/1000
2022-09-07 11:37:10,440:main_SBMs_node_classification.py:212 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 0.5869, Train Acc: 67.4114,
                            Val Loss: 0.6517, Val Acc: 61.5472, Test Acc: 62.4682
2022-09-07 11:37:10,440:main_SBMs_node_classification.py:170 -   train_val_pipeline(): Epoch 20/1000
2022-09-07 11:37:44,706:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 11:37:50,518:main_SBMs_node_classification.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 2, 'in_dim': 3, 'n_classes': 2}
2022-09-07 11:37:50,518:main_SBMs_node_classification.py:353 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 11:37:50,518:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:37:50,519:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:37:50,519:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:37:50,519:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:37:50,524:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 11:37:50,525:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522989
2022-09-07 11:37:50,525:main_SBMs_node_classification.py:47 -   train_val_pipeline(): [!] Starting with seed 41...
2022-09-07 11:37:50,525:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:37:50,525:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:37:50,525:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:37:50,525:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:37:51,007:main_SBMs_node_classification.py:90 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:37:51,405:main_SBMs_node_classification.py:98 -   train_val_pipeline(): Time PE:0.8734526634216309
2022-09-07 11:37:51,408:main_SBMs_node_classification.py:134 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:37:51,408:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:37:51,408:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:37:51,408:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:37:51,409:main_SBMs_node_classification.py:171 -   train_val_pipeline(): Epoch 1/1
2022-09-07 11:37:52,378:main_SBMs_node_classification.py:191 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h37m50s_on_Sep_07_2022/MODELS_
2022-09-07 11:37:52,378:main_SBMs_node_classification.py:213 -   train_val_pipeline(): 	Time: 0.97s, LR: 0.00050, Train Loss: 0.7111, Train Acc: 50.0000,
                            Val Loss: 0.7083, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:253 -   train_val_pipeline(): Test Accuracy: 50.0000
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:254 -   train_val_pipeline(): Best Test Accuracy: 50.0000
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:255 -   train_val_pipeline(): Train Accuracy: 50.0000
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:256 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 50.0000
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:257 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:258 -   train_val_pipeline(): TOTAL TIME TAKEN: 2.2745s
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:259 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.9686s
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:261 -   train_val_pipeline(): {'seed': 41, 'epochs': 1, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:262 -   train_val_pipeline(): train history: [50.0]
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:263 -   train_val_pipeline(): test history: [50.0]
2022-09-07 11:37:52,806:main_SBMs_node_classification.py:264 -   train_val_pipeline(): val history: [50.0]
2022-09-07 11:38:11,625:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 11:38:17,019:main_SBMs_node_classification.py:354 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 2, 'in_dim': 3, 'n_classes': 2}
2022-09-07 11:38:17,020:main_SBMs_node_classification.py:355 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 11:38:17,020:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:38:17,021:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:38:17,021:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:38:17,021:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:38:17,026:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 11:38:17,027:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522989
2022-09-07 11:38:17,027:main_SBMs_node_classification.py:49 -   train_val_pipeline(): [!] Starting with seed 41...
2022-09-07 11:38:17,027:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:38:17,028:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:38:17,028:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:38:17,028:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:38:17,565:main_SBMs_node_classification.py:92 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:38:17,823:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.7901592254638672
2022-09-07 11:38:17,826:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:38:17,826:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:38:17,826:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:38:17,826:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:38:17,828:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1
2022-09-07 11:39:46,027:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 11:39:51,409:main_SBMs_node_classification.py:354 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 2, 'in_dim': 3, 'n_classes': 2}
2022-09-07 11:39:51,409:main_SBMs_node_classification.py:355 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 11:39:51,409:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:39:51,410:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:39:51,410:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:39:51,410:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:39:51,415:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 11:39:51,416:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522989
2022-09-07 11:39:51,416:main_SBMs_node_classification.py:49 -   train_val_pipeline(): [!] Starting with seed 41...
2022-09-07 11:39:51,416:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:39:51,417:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:39:51,417:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:39:51,417:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:39:51,949:main_SBMs_node_classification.py:92 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:39:52,230:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.8079140186309814
2022-09-07 11:39:52,233:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:39:52,233:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:39:52,233:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:39:52,233:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:39:52,234:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1
2022-09-07 11:39:53,147:main_SBMs_node_classification.py:193 -   train_val_pipeline(): Saving best model with test accuracy: 51.0913 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h39m51s_on_Sep_07_2022/MODELS_
2022-09-07 11:39:53,147:main_SBMs_node_classification.py:215 -   train_val_pipeline(): 	Time: 0.91s, LR: 0.00050, Train Loss: 0.6945, Train Acc: 50.7619,
                            Val Loss: 0.6902, Val Acc: 50.7429, Test Acc: 51.0913
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:255 -   train_val_pipeline(): Test Accuracy: 51.0913
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:256 -   train_val_pipeline(): Best Test Accuracy: 51.0913
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:257 -   train_val_pipeline(): Train Accuracy: 52.5908
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:258 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 50.7619
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:259 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:260 -   train_val_pipeline(): TOTAL TIME TAKEN: 2.1360s
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:261 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.9132s
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:263 -   train_val_pipeline(): {'seed': 41, 'epochs': 1, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 2}
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:264 -   train_val_pipeline(): train history: [50.761881023595876]
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:265 -   train_val_pipeline(): test history: [51.09128799430721]
2022-09-07 11:39:53,558:main_SBMs_node_classification.py:266 -   train_val_pipeline(): val history: [50.74289405684754]
2022-09-07 11:40:52,537:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 11:40:57,932:main_SBMs_node_classification.py:354 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 26, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 2, 'in_dim': 3, 'n_classes': 2}
2022-09-07 11:40:57,932:main_SBMs_node_classification.py:355 -                 main(): {'seed': 41, 'epochs': 1, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41, 95, 22, 35], 'job_num': 2}
2022-09-07 11:40:57,932:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:40:57,933:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:40:57,933:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:40:57,933:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:40:57,938:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 11:40:57,939:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 522989
2022-09-07 11:40:57,939:main_SBMs_node_classification.py:49 -   train_val_pipeline(): [!] Starting with seed 41...
2022-09-07 11:40:57,939:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:40:57,939:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:40:57,940:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:40:57,940:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:40:58,435:main_SBMs_node_classification.py:92 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:40:58,696:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.7511107921600342
2022-09-07 11:40:58,698:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:40:58,698:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:40:58,698:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:40:58,698:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:40:58,699:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1
2022-09-07 11:40:59,620:main_SBMs_node_classification.py:193 -   train_val_pipeline(): Saving best model with test accuracy: 49.6798 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h40m57s_on_Sep_07_2022/MODELS_
2022-09-07 11:40:59,620:main_SBMs_node_classification.py:215 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 0.6956, Train Acc: 47.8564,
                            Val Loss: 0.6843, Val Acc: 50.0226, Test Acc: 49.6798
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:255 -   train_val_pipeline(): Test Accuracy: 49.6798
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:256 -   train_val_pipeline(): Best Test Accuracy: 49.6798
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:257 -   train_val_pipeline(): Train Accuracy: 49.9501
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:258 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 47.8564
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:259 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:260 -   train_val_pipeline(): TOTAL TIME TAKEN: 2.0932s
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:261 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.9207s
2022-09-07 11:41:00,038:main_SBMs_node_classification.py:49 -   train_val_pipeline(): [!] Starting with seed 95...
2022-09-07 11:41:00,038:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:41:00,038:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:41:00,038:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:41:00,038:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:41:00,044:main_SBMs_node_classification.py:92 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:41:00,395:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.3506772518157959
2022-09-07 11:41:00,395:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:41:00,395:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:41:00,395:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:41:00,396:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:41:00,399:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1
2022-09-07 11:41:01,376:main_SBMs_node_classification.py:193 -   train_val_pipeline(): Saving best model with test accuracy: 45.4849 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h40m57s_on_Sep_07_2022/MODELS_
2022-09-07 11:41:01,376:main_SBMs_node_classification.py:215 -   train_val_pipeline(): 	Time: 0.98s, LR: 0.00050, Train Loss: 0.6988, Train Acc: 50.3492,
                            Val Loss: 0.6995, Val Acc: 47.1738, Test Acc: 45.4849
2022-09-07 11:41:01,838:main_SBMs_node_classification.py:255 -   train_val_pipeline(): Test Accuracy: 45.4849
2022-09-07 11:41:01,838:main_SBMs_node_classification.py:256 -   train_val_pipeline(): Best Test Accuracy: 45.4849
2022-09-07 11:41:01,838:main_SBMs_node_classification.py:257 -   train_val_pipeline(): Train Accuracy: 46.0424
2022-09-07 11:41:01,838:main_SBMs_node_classification.py:258 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 50.3492
2022-09-07 11:41:01,838:main_SBMs_node_classification.py:259 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 11:41:01,839:main_SBMs_node_classification.py:260 -   train_val_pipeline(): TOTAL TIME TAKEN: 1.7943s
2022-09-07 11:41:01,839:main_SBMs_node_classification.py:261 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.9771s
2022-09-07 11:41:01,839:main_SBMs_node_classification.py:49 -   train_val_pipeline(): [!] Starting with seed 22...
2022-09-07 11:41:01,839:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:41:01,839:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:41:01,839:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:41:01,839:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:41:01,845:main_SBMs_node_classification.py:92 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:41:02,308:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.46341490745544434
2022-09-07 11:41:02,309:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:41:02,309:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:41:02,309:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:41:02,309:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:41:02,311:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1
2022-09-07 11:41:03,203:main_SBMs_node_classification.py:193 -   train_val_pipeline(): Saving best model with test accuracy: 57.5142 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h40m57s_on_Sep_07_2022/MODELS_
2022-09-07 11:41:03,203:main_SBMs_node_classification.py:215 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 0.7174, Train Acc: 50.0000,
                            Val Loss: 0.6902, Val Acc: 56.9154, Test Acc: 57.5142
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:255 -   train_val_pipeline(): Test Accuracy: 57.5142
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:256 -   train_val_pipeline(): Best Test Accuracy: 57.5142
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:257 -   train_val_pipeline(): Train Accuracy: 54.8804
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:258 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 50.0000
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:259 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:260 -   train_val_pipeline(): TOTAL TIME TAKEN: 1.7570s
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:261 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.8928s
2022-09-07 11:41:03,602:main_SBMs_node_classification.py:49 -   train_val_pipeline(): [!] Starting with seed 35...
2022-09-07 11:41:03,602:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 11:41:03,602:pe_layer.py:129 -             __init__(): Using 2 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 11:41:03,603:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 11:41:03,603:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 11:41:03,608:main_SBMs_node_classification.py:92 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (2).
2022-09-07 11:41:03,884:main_SBMs_node_classification.py:100 -   train_val_pipeline(): Time PE:0.27617907524108887
2022-09-07 11:41:03,884:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Training Graphs: 10
2022-09-07 11:41:03,885:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Validation Graphs: 10
2022-09-07 11:41:03,885:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Test Graphs: 10
2022-09-07 11:41:03,885:main_SBMs_node_classification.py:139 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 11:41:03,886:main_SBMs_node_classification.py:173 -   train_val_pipeline(): Epoch 1/1
2022-09-07 11:41:04,741:main_SBMs_node_classification.py:193 -   train_val_pipeline(): Saving best model with test accuracy: 50.0000 to out/SBMs_node_classification_b26-bnorm-alt-studycheckpoints/GraphTransformer_SBM_PATTERN_GPU0_2_2_11h40m57s_on_Sep_07_2022/MODELS_
2022-09-07 11:41:04,741:main_SBMs_node_classification.py:215 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 0.7349, Train Acc: 50.0000,
                            Val Loss: 0.7195, Val Acc: 50.0000, Test Acc: 50.0000
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:255 -   train_val_pipeline(): Test Accuracy: 50.0000
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:256 -   train_val_pipeline(): Best Test Accuracy: 50.0000
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:257 -   train_val_pipeline(): Train Accuracy: 49.9501
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:258 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 50.0000
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:259 -   train_val_pipeline(): Convergence Time (Epochs): 0.0000
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:260 -   train_val_pipeline(): TOTAL TIME TAKEN: 1.5346s
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:261 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.8545s
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:263 -   train_val_pipeline(): {'seed': 41, 'epochs': 1, 'batch_size': 26, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41, 95, 22, 35], 'job_num': 2}
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:264 -   train_val_pipeline(): train history: [47.85643070787637, 50.34923008751523, 50.0, 50.0]
2022-09-07 11:41:05,142:main_SBMs_node_classification.py:265 -   train_val_pipeline(): test history: [49.67978042086002, 45.48490393412626, 57.514231981295104, 50.0]
2022-09-07 11:41:05,143:main_SBMs_node_classification.py:266 -   train_val_pipeline(): val history: [50.02260981912144, 47.17377260981912, 56.91537467700258, 50.0]
2022-09-07 14:47:56,423:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 14:48:01,607:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 4, 'in_dim': 7, 'n_classes': 6}
2022-09-07 14:48:01,607:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41, 95, 22, 35], 'job_num': 4}
2022-09-07 14:48:01,608:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 14:48:01,632:pe_layer.py:129 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 14:48:01,632:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 14:48:01,632:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 14:48:01,639:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 14:48:01,641:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523567
2022-09-07 14:48:01,645:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41, 95, 22, 35]...
2022-09-07 14:48:01,645:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 14:48:01,646:pe_layer.py:129 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 14:48:01,646:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 14:48:01,646:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 14:48:01,655:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (4).
2022-09-07 17:15:23,434:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 17:15:28,758:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 256, 'in_dim': 7, 'n_classes': 6}
2022-09-07 17:15:28,758:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41, 95, 22, 35], 'job_num': 256}
2022-09-07 17:15:28,759:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 17:15:28,766:pe_layer.py:129 -             __init__(): Using 256 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 17:15:28,766:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 17:15:28,766:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 17:15:28,777:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 17:15:28,778:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 609499
2022-09-07 17:15:28,779:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41, 95, 22, 35]...
2022-09-07 17:15:28,779:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 17:15:28,782:pe_layer.py:129 -             __init__(): Using 256 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 17:15:28,782:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 17:15:28,782:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 17:15:28,788:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (256).
2022-09-07 19:09:06,699:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:09:11,762:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:09:11,762:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-07 19:09:18,035:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:09:23,040:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:09:23,040:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-07 19:09:23,040:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:09:23,041:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:09:23,042:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:09:23,042:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:09:23,045:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:09:23,046:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 316935
2022-09-07 19:09:23,046:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:09:23,046:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:09:23,047:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:09:23,047:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:09:23,047:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:09:23,050:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 19:09:54,407:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:09:59,266:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:09:59,266:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-07 19:09:59,266:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:09:59,267:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:09:59,267:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:09:59,267:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:09:59,271:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:09:59,271:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 316935
2022-09-07 19:09:59,271:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:09:59,272:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:09:59,272:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:09:59,272:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:09:59,272:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:09:59,276:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 19:10:13,706:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:10:18,561:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:10:18,561:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-07 19:10:18,561:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:10:18,562:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:10:18,562:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:10:18,562:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:10:18,566:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:10:18,566:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 315905
2022-09-07 19:10:18,567:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:10:18,567:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:10:18,567:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:10:18,567:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:10:18,567:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:10:18,571:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:10:32,939:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:14.372220754623413
2022-09-07 19:10:32,956:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 19:10:32,956:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 19:10:32,957:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 19:10:32,957:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 19:10:32,959:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 19:10:44,709:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:10:49,528:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:10:49,528:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-07 19:10:49,528:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:10:49,529:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:10:49,529:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:10:49,529:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:10:49,535:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:10:49,536:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523265
2022-09-07 19:10:49,536:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:10:49,536:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:10:49,537:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:10:49,537:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:10:49,537:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:10:49,542:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:11:03,607:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:14.071043968200684
2022-09-07 19:11:03,625:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 19:11:03,625:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 19:11:03,625:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 19:11:03,625:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 19:11:03,627:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 19:11:37,176:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:11:42,077:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:11:42,077:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-07 19:11:42,077:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:11:42,078:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:11:42,078:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:11:42,078:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:11:42,083:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:11:42,084:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523265
2022-09-07 19:11:42,084:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:11:42,084:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:11:42,085:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:11:42,085:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:11:42,085:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:11:42,090:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:11:56,276:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:14.19155502319336
2022-09-07 19:11:56,293:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 19:11:56,293:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 19:11:56,293:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 19:11:56,293:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 19:11:56,295:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 19:12:21,863:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5005 to out/CYCLES_graph_classification_randPE/checkpoints/GraphTransformer_CYCLES_GPU0_1_6_19h11m42s_on_Sep_07_2022/MODELS_
2022-09-07 19:12:21,864:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.57s, LR: 0.00050, Train Loss: 0.7447, Train Acc: 0.5550,
                            Val Loss: 1.1872, Val Acc: 0.5030, Test Acc: 0.5005
2022-09-07 19:12:21,864:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 19:12:49,137:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5024 to out/CYCLES_graph_classification_randPE/checkpoints/GraphTransformer_CYCLES_GPU0_1_6_19h11m42s_on_Sep_07_2022/MODELS_
2022-09-07 19:12:49,138:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 27.27s, LR: 0.00050, Train Loss: 0.7178, Train Acc: 0.5450,
                            Val Loss: 1.2925, Val Acc: 0.5050, Test Acc: 0.5024
2022-09-07 19:12:49,138:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 19:13:14,334:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.20s, LR: 0.00050, Train Loss: 0.7083, Train Acc: 0.5550,
                            Val Loss: 1.1159, Val Acc: 0.4770, Test Acc: 0.4974
2022-09-07 19:13:14,335:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 19:14:06,667:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:14:11,546:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:14:11,546:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-07 19:14:11,546:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:14:11,547:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:14:11,547:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:14:11,547:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:14:11,553:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:14:11,553:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523265
2022-09-07 19:14:11,554:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:14:11,554:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:14:11,554:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:14:11,554:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:14:11,554:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:14:11,560:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:14:25,537:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:13.983496189117432
2022-09-07 19:14:25,556:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 19:14:25,556:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 19:14:25,556:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 19:14:25,556:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 19:14:25,558:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 19:14:50,944:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_randPE/checkpoints/GraphTransformer_CYCLES_GPU0_1_6_19h14m11s_on_Sep_07_2022/MODELS_
2022-09-07 19:14:50,945:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.39s, LR: 0.00050, Train Loss: nan, Train Acc: 0.5000,
                            Val Loss: nan, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:14:50,945:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 19:15:17,838:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.89s, LR: 0.00050, Train Loss: nan, Train Acc: 0.5000,
                            Val Loss: nan, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:15:17,838:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 19:15:33,229:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:15:38,095:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:15:38,095:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-07 19:15:38,095:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:15:38,096:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:15:38,096:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:15:38,096:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:15:38,101:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:15:38,102:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523265
2022-09-07 19:15:38,102:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:15:38,103:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:15:38,104:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:15:38,104:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:15:38,104:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:15:38,110:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:16:37,557:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:16:42,576:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 4, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:16:42,576:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-07 19:16:42,576:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:16:42,577:pe_layer.py:129 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:16:42,577:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:16:42,577:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:16:42,583:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:16:42,584:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523083
2022-09-07 19:16:42,584:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:16:42,584:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:16:42,585:pe_layer.py:129 -             __init__(): Using 4 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:16:42,585:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-07 19:16:42,585:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:16:42,590:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (4).
2022-09-07 19:17:49,630:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:17:54,614:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:17:54,614:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-07 19:17:54,614:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:17:54,615:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:17:54,615:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 19:17:54,615:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:17:54,621:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:17:54,622:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523265
2022-09-07 19:17:54,622:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:17:54,622:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:17:54,623:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:17:54,623:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 19:17:54,623:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:17:54,629:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:19:04,672:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:70.05014896392822
2022-09-07 19:19:04,691:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 19:19:04,691:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 19:19:04,691:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 19:19:04,691:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 19:19:04,693:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 19:19:30,802:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5071 to out/CYCLES_graph_classification_randPE/checkpoints/GraphTransformer_CYCLES_GPU0_1_6_19h17m54s_on_Sep_07_2022/MODELS_
2022-09-07 19:19:30,803:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.11s, LR: 0.00050, Train Loss: 1.1086, Train Acc: 0.4650,
                            Val Loss: 0.8999, Val Acc: 0.4920, Test Acc: 0.5071
2022-09-07 19:19:30,803:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 19:19:56,371:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.57s, LR: 0.00050, Train Loss: 0.8963, Train Acc: 0.4550,
                            Val Loss: 0.9245, Val Acc: 0.4880, Test Acc: 0.5029
2022-09-07 19:19:56,371:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 19:20:28,144:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 31.77s, LR: 0.00050, Train Loss: 0.7938, Train Acc: 0.5600,
                            Val Loss: 0.8398, Val Acc: 0.5120, Test Acc: 0.5022
2022-09-07 19:20:28,144:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 19:20:53,400:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.26s, LR: 0.00050, Train Loss: 0.8169, Train Acc: 0.4950,
                            Val Loss: 0.7536, Val Acc: 0.5120, Test Acc: 0.5054
2022-09-07 19:20:53,400:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-07 19:23:04,817:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5077 to out/CYCLES_graph_classification_randPE/checkpoints/GraphTransformer_CYCLES_GPU0_1_6_19h17m54s_on_Sep_07_2022/MODELS_
2022-09-07 19:23:04,817:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 131.42s, LR: 0.00050, Train Loss: 0.7410, Train Acc: 0.5350,
                            Val Loss: 0.7378, Val Acc: 0.5070, Test Acc: 0.5077
2022-09-07 19:23:04,817:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-07 19:23:30,153:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.34s, LR: 0.00050, Train Loss: 0.7483, Train Acc: 0.5600,
                            Val Loss: 0.9399, Val Acc: 0.4950, Test Acc: 0.4996
2022-09-07 19:23:30,154:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-07 19:23:55,361:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5585 to out/CYCLES_graph_classification_randPE/checkpoints/GraphTransformer_CYCLES_GPU0_1_6_19h17m54s_on_Sep_07_2022/MODELS_
2022-09-07 19:23:55,362:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.21s, LR: 0.00050, Train Loss: 0.7281, Train Acc: 0.4900,
                            Val Loss: 0.6962, Val Acc: 0.5630, Test Acc: 0.5585
2022-09-07 19:23:55,362:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-07 19:24:20,726:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.36s, LR: 0.00050, Train Loss: 0.7121, Train Acc: 0.5100,
                            Val Loss: 0.7036, Val Acc: 0.5090, Test Acc: 0.5100
2022-09-07 19:24:20,726:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-07 19:24:46,169:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.44s, LR: 0.00050, Train Loss: 0.7572, Train Acc: 0.5350,
                            Val Loss: 0.7209, Val Acc: 0.5460, Test Acc: 0.5292
2022-09-07 19:24:46,170:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 10/1000
2022-09-07 19:26:02,511:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:26:07,512:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:26:07,512:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-07 19:26:07,512:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:26:07,513:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:26:07,513:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 19:26:07,513:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:26:07,518:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:26:07,519:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523265
2022-09-07 19:26:07,519:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:26:07,519:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:26:07,521:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:26:07,521:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 19:26:07,521:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:26:07,527:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:27:18,719:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 19:27:23,658:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.5, 'dropout': 0.5, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'rand_pos_enc': True, 'pos_enc_dim': 6, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'RWK', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 19:27:23,658:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-07 19:27:23,658:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:27:23,659:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:27:23,659:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 19:27:23,659:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:27:23,664:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 19:27:23,665:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 523265
2022-09-07 19:27:23,665:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 19:27:23,665:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 19:27:23,666:pe_layer.py:129 -             __init__(): Using 6 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 19:27:23,666:pe_layer.py:134 -             __init__(): Using matrix: RWK
2022-09-07 19:27:23,666:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-07 19:27:23,672:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (6).
2022-09-07 19:28:34,193:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:70.52728509902954
2022-09-07 19:28:34,212:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 19:28:34,212:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 19:28:34,212:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 19:28:34,212:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 19:28:34,215:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 19:28:59,386:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_randPE/checkpoints/GraphTransformer_CYCLES_GPU0_1_6_19h27m23s_on_Sep_07_2022/MODELS_
2022-09-07 19:28:59,387:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.17s, LR: 0.00050, Train Loss: 0.8332, Train Acc: 0.4850,
                            Val Loss: 0.7360, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:28:59,387:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 19:29:24,177:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.79s, LR: 0.00050, Train Loss: 0.7640, Train Acc: 0.5200,
                            Val Loss: 0.7866, Val Acc: 0.5000, Test Acc: 0.4999
2022-09-07 19:29:24,177:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 19:31:07,966:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 103.79s, LR: 0.00050, Train Loss: 0.7585, Train Acc: 0.5300,
                            Val Loss: 0.6958, Val Acc: 0.5010, Test Acc: 0.4948
2022-09-07 19:31:07,967:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 19:31:32,784:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.82s, LR: 0.00050, Train Loss: 0.7391, Train Acc: 0.4900,
                            Val Loss: 0.9058, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:31:32,784:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-07 19:31:57,395:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.61s, LR: 0.00050, Train Loss: 0.6966, Train Acc: 0.5600,
                            Val Loss: 1.1438, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:31:57,395:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-07 19:32:22,027:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.63s, LR: 0.00050, Train Loss: 0.7427, Train Acc: 0.5450,
                            Val Loss: 1.3736, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:32:22,027:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-07 19:32:46,577:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.55s, LR: 0.00050, Train Loss: 0.7148, Train Acc: 0.5450,
                            Val Loss: 1.2765, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:32:46,577:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-07 19:33:11,138:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.56s, LR: 0.00050, Train Loss: 0.6961, Train Acc: 0.5400,
                            Val Loss: 1.2469, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-07 19:33:11,138:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-07 23:53:13,681:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 23:53:18,518:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-07 23:53:18,518:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-07 23:53:18,520:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 23:53:18,523:pe_layer.py:132 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 23:53:18,523:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-07 23:53:18,523:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-07 23:53:18,528:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-07 23:53:18,529:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-07 23:53:18,529:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-07 23:53:18,529:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-07 23:53:18,530:pe_layer.py:132 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-07 23:53:18,530:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-07 23:53:18,530:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-07 23:53:18,535:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-07 23:53:29,075:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:10.545762062072754
2022-09-07 23:53:29,094:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-07 23:53:29,094:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-07 23:53:29,094:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-07 23:53:29,094:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-07 23:53:29,097:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-07 23:53:52,248:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5105 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m18s_on_Sep_07_2022/MODELS_
2022-09-07 23:53:52,250:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.15s, LR: 0.00050, Train Loss: 0.8141, Train Acc: 0.5550,
                            Val Loss: 1.5047, Val Acc: 0.5180, Test Acc: 0.5105
2022-09-07 23:53:52,250:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-07 23:54:15,615:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5139 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m18s_on_Sep_07_2022/MODELS_
2022-09-07 23:54:15,616:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.37s, LR: 0.00050, Train Loss: 0.6696, Train Acc: 0.6100,
                            Val Loss: 0.9795, Val Acc: 0.5100, Test Acc: 0.5139
2022-09-07 23:54:15,616:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-07 23:54:38,143:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6095 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m18s_on_Sep_07_2022/MODELS_
2022-09-07 23:54:38,143:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00050, Train Loss: 0.6363, Train Acc: 0.6400,
                            Val Loss: 0.8873, Val Acc: 0.6190, Test Acc: 0.6095
2022-09-07 23:54:38,143:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-07 23:55:00,642:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6621 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m18s_on_Sep_07_2022/MODELS_
2022-09-07 23:55:00,642:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.50s, LR: 0.00050, Train Loss: 0.5680, Train Acc: 0.6900,
                            Val Loss: 0.7352, Val Acc: 0.6610, Test Acc: 0.6621
2022-09-07 23:55:00,643:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-07 23:55:23,006:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.36s, LR: 0.00050, Train Loss: 0.5795, Train Acc: 0.7200,
                            Val Loss: 0.8399, Val Acc: 0.6160, Test Acc: 0.6241
2022-09-07 23:55:23,006:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-07 23:55:42,889:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-07 23:55:47,054:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.05s, LR: 0.00050, Train Loss: 0.5885, Train Acc: 0.6750,
                            Val Loss: 0.9253, Val Acc: 0.5850, Test Acc: 0.6117
2022-09-07 23:55:47,054:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-07 23:56:12,481:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.43s, LR: 0.00050, Train Loss: 0.6397, Train Acc: 0.6800,
                            Val Loss: 0.6914, Val Acc: 0.6190, Test Acc: 0.6392
2022-09-07 23:56:12,481:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-07 23:56:39,211:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.73s, LR: 0.00050, Train Loss: 0.5750, Train Acc: 0.7000,
                            Val Loss: 0.7708, Val Acc: 0.6390, Test Acc: 0.6558
2022-09-07 23:56:39,212:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-07 23:57:05,708:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6668 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_23h53m18s_on_Sep_07_2022/MODELS_
2022-09-07 23:57:05,708:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.50s, LR: 0.00050, Train Loss: 0.6105, Train Acc: 0.7200,
                            Val Loss: 0.9255, Val Acc: 0.6440, Test Acc: 0.6668
2022-09-07 23:57:05,708:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 10/1000
2022-09-07 23:57:32,258:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.55s, LR: 0.00050, Train Loss: 0.5594, Train Acc: 0.7550,
                            Val Loss: 0.9464, Val Acc: 0.6300, Test Acc: 0.6316
2022-09-07 23:57:32,259:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 11/1000
2022-09-07 23:57:59,020:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.76s, LR: 0.00050, Train Loss: 0.5689, Train Acc: 0.6950,
                            Val Loss: 0.9246, Val Acc: 0.6280, Test Acc: 0.6286
2022-09-07 23:57:59,020:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 12/1000
2022-09-07 23:58:25,191:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.17s, LR: 0.00050, Train Loss: 0.5480, Train Acc: 0.7450,
                            Val Loss: 0.8528, Val Acc: 0.6450, Test Acc: 0.6399
2022-09-07 23:58:25,192:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 13/1000
2022-09-07 23:58:51,827:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.64s, LR: 0.00050, Train Loss: 0.5655, Train Acc: 0.6900,
                            Val Loss: 0.8564, Val Acc: 0.5500, Test Acc: 0.5614
2022-09-07 23:58:51,828:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 14/1000
2022-09-07 23:59:18,503:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.68s, LR: 0.00050, Train Loss: 0.5702, Train Acc: 0.6900,
                            Val Loss: 1.2539, Val Acc: 0.6110, Test Acc: 0.5881
2022-09-07 23:59:18,504:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 15/1000
2022-09-07 23:59:44,699:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.20s, LR: 0.00050, Train Loss: 0.5502, Train Acc: 0.7250,
                            Val Loss: 1.1001, Val Acc: 0.6300, Test Acc: 0.6220
2022-09-07 23:59:44,699:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 16/1000
2022-09-08 00:00:13,603:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 28.90s, LR: 0.00050, Train Loss: 0.5689, Train Acc: 0.6950,
                            Val Loss: 0.7103, Val Acc: 0.5980, Test Acc: 0.6313
2022-09-08 00:00:13,604:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 17/1000
2022-09-08 00:00:40,118:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.51s, LR: 0.00050, Train Loss: 0.5212, Train Acc: 0.7650,
                            Val Loss: 0.9677, Val Acc: 0.5360, Test Acc: 0.5385
2022-09-08 00:00:40,118:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 18/1000
2022-09-08 00:01:05,954:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 00:01:11,283:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 00:01:11,283:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 00:01:11,283:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:01:11,284:pe_layer.py:132 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:01:11,284:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-08 00:01:11,284:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-08 00:01:11,290:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 00:01:11,291:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-08 00:01:11,291:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 00:01:11,291:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:01:11,292:pe_layer.py:132 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:01:11,292:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-08 00:01:11,292:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-08 00:01:11,298:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-08 00:01:23,862:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:12.571229934692383
2022-09-08 00:01:23,880:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-08 00:01:23,881:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-08 00:01:23,881:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-08 00:01:23,881:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 00:01:23,884:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 00:01:49,227:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h01m11s_on_Sep_08_2022/MODELS_
2022-09-08 00:01:49,228:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.34s, LR: 0.00050, Train Loss: 0.7339, Train Acc: 0.5750,
                            Val Loss: 1.9156, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:01:49,228:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 00:02:25,392:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 00:02:30,517:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 00:02:30,517:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 00:02:30,518:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:02:30,519:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:02:30,519:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-08 00:02:30,519:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-08 00:02:30,524:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 00:02:30,525:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-08 00:02:30,525:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 00:02:30,525:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:02:30,526:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:02:30,526:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-08 00:02:30,526:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-08 00:02:30,532:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-08 00:02:43,008:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 00:02:48,047:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 00:02:48,048:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 00:02:48,048:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:02:48,049:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:02:48,049:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-08 00:02:48,049:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-08 00:02:48,054:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 00:02:48,055:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-08 00:02:48,056:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 00:02:48,056:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:02:48,056:pe_layer.py:132 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:02:48,056:pe_layer.py:137 -             __init__(): Using matrix: A
2022-09-08 00:02:48,056:pe_layer.py:138 -             __init__(): Matrix power: 1
2022-09-08 00:02:48,062:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-08 00:03:17,179:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:29.123391151428223
2022-09-08 00:03:17,197:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-08 00:03:17,197:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-08 00:03:17,197:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-08 00:03:17,197:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 00:03:17,200:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 00:03:43,653:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5554 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_00h02m48s_on_Sep_08_2022/MODELS_
2022-09-08 00:03:43,654:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.45s, LR: 0.00050, Train Loss: 1.0041, Train Acc: 0.5300,
                            Val Loss: 2.5553, Val Acc: 0.5530, Test Acc: 0.5554
2022-09-08 00:03:43,655:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 00:04:11,855:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 28.20s, LR: 0.00050, Train Loss: 0.6526, Train Acc: 0.6450,
                            Val Loss: 0.9899, Val Acc: 0.5380, Test Acc: 0.5439
2022-09-08 00:04:11,856:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-08 00:04:39,816:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6230 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_00h02m48s_on_Sep_08_2022/MODELS_
2022-09-08 00:04:39,817:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 27.96s, LR: 0.00050, Train Loss: 0.6589, Train Acc: 0.6500,
                            Val Loss: 1.1261, Val Acc: 0.6240, Test Acc: 0.6230
2022-09-08 00:04:39,817:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-08 00:05:06,750:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6291 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_64_00h02m48s_on_Sep_08_2022/MODELS_
2022-09-08 00:05:06,751:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.93s, LR: 0.00050, Train Loss: 0.6199, Train Acc: 0.6850,
                            Val Loss: 1.0376, Val Acc: 0.6240, Test Acc: 0.6291
2022-09-08 00:05:06,751:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-08 00:05:33,229:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.48s, LR: 0.00050, Train Loss: 0.5557, Train Acc: 0.7450,
                            Val Loss: 0.9887, Val Acc: 0.5910, Test Acc: 0.5985
2022-09-08 00:05:33,229:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-08 00:06:00,607:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 27.38s, LR: 0.00050, Train Loss: 0.5628, Train Acc: 0.7100,
                            Val Loss: 0.9709, Val Acc: 0.5880, Test Acc: 0.6009
2022-09-08 00:06:00,609:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-08 00:06:27,556:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.95s, LR: 0.00050, Train Loss: 0.5450, Train Acc: 0.7500,
                            Val Loss: 1.2134, Val Acc: 0.5970, Test Acc: 0.6125
2022-09-08 00:06:27,556:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-08 00:06:55,948:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 28.39s, LR: 0.00050, Train Loss: 0.4907, Train Acc: 0.7350,
                            Val Loss: 1.1557, Val Acc: 0.6240, Test Acc: 0.6221
2022-09-08 00:06:55,948:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-08 00:23:56,534:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 00:24:01,713:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 00:24:01,713:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 00:24:01,713:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:24:01,714:pe_layer.py:131 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:24:01,715:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-08 00:24:01,715:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-08 00:24:01,720:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 00:24:01,721:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-08 00:24:01,721:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 00:24:01,721:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:24:01,722:pe_layer.py:131 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:24:01,722:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-08 00:24:01,722:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-08 00:24:01,728:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-08 00:24:15,512:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:13.790877103805542
2022-09-08 00:24:15,531:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-08 00:24:15,532:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-08 00:24:15,532:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-08 00:24:15,532:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 00:24:15,535:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 00:24:44,416:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5110 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h24m01s_on_Sep_08_2022/MODELS_
2022-09-08 00:24:44,417:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 28.88s, LR: 0.00050, Train Loss: 0.8786, Train Acc: 0.5050,
                            Val Loss: 0.8540, Val Acc: 0.5150, Test Acc: 0.5110
2022-09-08 00:24:44,418:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 00:25:13,352:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5186 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h24m01s_on_Sep_08_2022/MODELS_
2022-09-08 00:25:13,352:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 28.93s, LR: 0.00050, Train Loss: 0.5944, Train Acc: 0.7000,
                            Val Loss: 0.8825, Val Acc: 0.5160, Test Acc: 0.5186
2022-09-08 00:25:13,352:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-08 00:25:40,904:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 27.55s, LR: 0.00050, Train Loss: 0.5630, Train Acc: 0.7250,
                            Val Loss: 1.5822, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:25:40,904:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-08 00:26:09,129:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 28.22s, LR: 0.00050, Train Loss: 0.4464, Train Acc: 0.8200,
                            Val Loss: 1.8002, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:26:09,130:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-08 00:26:35,782:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.65s, LR: 0.00050, Train Loss: 0.4089, Train Acc: 0.8050,
                            Val Loss: 1.1127, Val Acc: 0.5090, Test Acc: 0.5065
2022-09-08 00:26:35,783:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-08 00:27:01,783:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.00s, LR: 0.00050, Train Loss: 0.2988, Train Acc: 0.8700,
                            Val Loss: 1.5334, Val Acc: 0.5000, Test Acc: 0.5002
2022-09-08 00:27:01,783:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-08 00:27:28,855:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6864 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h24m01s_on_Sep_08_2022/MODELS_
2022-09-08 00:27:28,856:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 27.07s, LR: 0.00050, Train Loss: 0.3313, Train Acc: 0.8600,
                            Val Loss: 0.9407, Val Acc: 0.6880, Test Acc: 0.6864
2022-09-08 00:27:28,856:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-08 00:27:54,580:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.72s, LR: 0.00050, Train Loss: 0.3021, Train Acc: 0.8800,
                            Val Loss: 0.6775, Val Acc: 0.6910, Test Acc: 0.6838
2022-09-08 00:27:54,580:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-08 00:28:19,591:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.8209 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h24m01s_on_Sep_08_2022/MODELS_
2022-09-08 00:28:19,591:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.01s, LR: 0.00050, Train Loss: 0.2666, Train Acc: 0.9200,
                            Val Loss: 0.4058, Val Acc: 0.8410, Test Acc: 0.8209
2022-09-08 00:28:19,591:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 10/1000
2022-09-08 00:28:45,143:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.55s, LR: 0.00050, Train Loss: 0.2354, Train Acc: 0.9000,
                            Val Loss: 0.8270, Val Acc: 0.6100, Test Acc: 0.5915
2022-09-08 00:28:45,143:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 11/1000
2022-09-08 00:29:11,043:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.8814 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h24m01s_on_Sep_08_2022/MODELS_
2022-09-08 00:29:11,044:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.90s, LR: 0.00050, Train Loss: 0.1931, Train Acc: 0.9500,
                            Val Loss: 0.3256, Val Acc: 0.8920, Test Acc: 0.8814
2022-09-08 00:29:11,044:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 12/1000
2022-09-08 00:29:36,497:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.45s, LR: 0.00050, Train Loss: 0.1241, Train Acc: 0.9600,
                            Val Loss: 0.2902, Val Acc: 0.9000, Test Acc: 0.8793
2022-09-08 00:29:36,497:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 13/1000
2022-09-08 00:30:01,931:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9239 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h24m01s_on_Sep_08_2022/MODELS_
2022-09-08 00:30:01,932:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.43s, LR: 0.00050, Train Loss: 0.1291, Train Acc: 0.9600,
                            Val Loss: 0.2556, Val Acc: 0.9180, Test Acc: 0.9239
2022-09-08 00:30:01,932:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 14/1000
2022-09-08 00:30:28,305:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9447 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h24m01s_on_Sep_08_2022/MODELS_
2022-09-08 00:30:28,306:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.37s, LR: 0.00050, Train Loss: 0.1143, Train Acc: 0.9600,
                            Val Loss: 0.2536, Val Acc: 0.9330, Test Acc: 0.9447
2022-09-08 00:30:28,306:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 15/1000
2022-09-08 00:31:51,740:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 00:31:56,724:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': True, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 00:31:56,724:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 00:31:56,724:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:31:56,725:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:31:56,725:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 00:31:56,725:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 00:31:56,731:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 00:31:56,732:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-08 00:31:56,732:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 00:31:56,732:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:31:56,733:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:31:56,733:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 00:31:56,733:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 00:31:56,738:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-08 00:32:08,453:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:11.721461057662964
2022-09-08 00:32:08,472:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-08 00:32:08,472:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-08 00:32:08,472:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-08 00:32:08,472:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 00:32:08,475:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 00:32:36,620:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h31m56s_on_Sep_08_2022/MODELS_
2022-09-08 00:32:36,622:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 28.15s, LR: 0.00050, Train Loss: 0.8346, Train Acc: 0.5600,
                            Val Loss: 0.8841, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:32:36,622:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 00:33:06,287:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 29.66s, LR: 0.00050, Train Loss: 0.6549, Train Acc: 0.6250,
                            Val Loss: 0.7783, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:33:06,287:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-08 00:33:36,092:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 29.80s, LR: 0.00050, Train Loss: 0.6100, Train Acc: 0.7000,
                            Val Loss: 0.7376, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:33:36,093:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-08 00:34:01,057:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.96s, LR: 0.00050, Train Loss: 0.5953, Train Acc: 0.7250,
                            Val Loss: 0.7263, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:34:01,058:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-08 00:34:25,838:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.78s, LR: 0.00050, Train Loss: 0.6201, Train Acc: 0.6800,
                            Val Loss: 0.6956, Val Acc: 0.4790, Test Acc: 0.4867
2022-09-08 00:34:25,838:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-08 00:34:49,800:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5167 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h31m56s_on_Sep_08_2022/MODELS_
2022-09-08 00:34:49,800:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.96s, LR: 0.00050, Train Loss: 0.5539, Train Acc: 0.7300,
                            Val Loss: 0.7086, Val Acc: 0.5180, Test Acc: 0.5167
2022-09-08 00:34:49,800:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-08 00:35:14,448:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.65s, LR: 0.00050, Train Loss: 0.5561, Train Acc: 0.7350,
                            Val Loss: 0.7090, Val Acc: 0.5060, Test Acc: 0.5021
2022-09-08 00:35:14,448:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-08 00:35:38,832:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5408 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h31m56s_on_Sep_08_2022/MODELS_
2022-09-08 00:35:38,832:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.38s, LR: 0.00050, Train Loss: 0.5224, Train Acc: 0.7200,
                            Val Loss: 0.7179, Val Acc: 0.5330, Test Acc: 0.5408
2022-09-08 00:35:38,832:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-08 00:36:03,697:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5536 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h31m56s_on_Sep_08_2022/MODELS_
2022-09-08 00:36:03,698:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.87s, LR: 0.00050, Train Loss: 0.5256, Train Acc: 0.7350,
                            Val Loss: 0.7368, Val Acc: 0.5510, Test Acc: 0.5536
2022-09-08 00:36:03,698:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 10/1000
2022-09-08 00:36:29,523:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 00:36:34,099:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': True, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 00:36:34,099:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 00:36:34,099:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:36:34,100:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:36:34,100:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 00:36:34,100:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 00:36:34,105:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 00:36:34,106:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-08 00:36:34,106:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 00:36:34,106:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:36:34,106:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:36:34,107:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 00:36:34,107:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 00:36:34,111:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-08 00:36:44,200:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:10.093618154525757
2022-09-08 00:36:44,216:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-08 00:36:44,217:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-08 00:36:44,217:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-08 00:36:44,217:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 00:36:44,219:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 00:37:07,798:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h36m34s_on_Sep_08_2022/MODELS_
2022-09-08 00:37:07,800:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.58s, LR: 0.00050, Train Loss: 0.7603, Train Acc: 0.6050,
                            Val Loss: 0.9734, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:37:07,800:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 00:37:31,111:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.31s, LR: 0.00050, Train Loss: 0.6687, Train Acc: 0.6200,
                            Val Loss: 0.9270, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:37:31,111:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-08 00:37:54,630:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.52s, LR: 0.00050, Train Loss: 0.5941, Train Acc: 0.7000,
                            Val Loss: 0.9220, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:37:54,631:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-08 00:38:19,486:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.85s, LR: 0.00050, Train Loss: 0.5474, Train Acc: 0.7100,
                            Val Loss: 0.8708, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:38:19,486:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-08 00:38:43,058:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.57s, LR: 0.00050, Train Loss: 0.6339, Train Acc: 0.6650,
                            Val Loss: 0.7087, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-08 00:38:43,059:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-08 00:39:07,216:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5474 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h36m34s_on_Sep_08_2022/MODELS_
2022-09-08 00:39:07,216:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.16s, LR: 0.00050, Train Loss: 0.5179, Train Acc: 0.7500,
                            Val Loss: 0.6841, Val Acc: 0.5450, Test Acc: 0.5474
2022-09-08 00:39:07,217:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-08 00:39:31,356:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00050, Train Loss: 0.5266, Train Acc: 0.7550,
                            Val Loss: 0.7580, Val Acc: 0.4980, Test Acc: 0.5037
2022-09-08 00:39:31,356:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-08 00:39:55,438:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.08s, LR: 0.00050, Train Loss: 0.5049, Train Acc: 0.7700,
                            Val Loss: 0.7784, Val Acc: 0.5070, Test Acc: 0.5092
2022-09-08 00:39:55,439:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-08 00:40:19,360:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 00:40:24,032:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': True, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 00:40:24,032:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 00:40:24,033:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:40:24,034:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:40:24,034:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 00:40:24,034:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 00:40:24,038:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 00:40:24,039:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-08 00:40:24,039:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 00:40:24,039:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 00:40:24,040:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 00:40:24,040:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 00:40:24,040:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 00:40:24,045:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-08 00:40:33,944:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:9.904235124588013
2022-09-08 00:40:33,958:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-08 00:40:33,958:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-08 00:40:33,958:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-08 00:40:33,958:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 00:40:33,960:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 00:40:57,771:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5017 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:40:57,772:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.81s, LR: 0.00050, Train Loss: 0.7350, Train Acc: 0.6100,
                            Val Loss: 1.1362, Val Acc: 0.5010, Test Acc: 0.5017
2022-09-08 00:40:57,772:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 00:41:21,382:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5706 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:41:21,383:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.61s, LR: 0.00050, Train Loss: 0.5882, Train Acc: 0.7250,
                            Val Loss: 0.8551, Val Acc: 0.5790, Test Acc: 0.5706
2022-09-08 00:41:21,383:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-08 00:41:44,596:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.21s, LR: 0.00050, Train Loss: 0.5611, Train Acc: 0.7100,
                            Val Loss: 0.7704, Val Acc: 0.5120, Test Acc: 0.5144
2022-09-08 00:41:44,596:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-08 00:42:07,813:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5844 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:42:07,814:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.22s, LR: 0.00050, Train Loss: 0.4873, Train Acc: 0.7600,
                            Val Loss: 0.6994, Val Acc: 0.5670, Test Acc: 0.5844
2022-09-08 00:42:07,814:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-08 00:42:31,008:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5999 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:42:31,008:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.19s, LR: 0.00050, Train Loss: 0.4282, Train Acc: 0.8100,
                            Val Loss: 0.7432, Val Acc: 0.5850, Test Acc: 0.5999
2022-09-08 00:42:31,008:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-08 00:56:10,003:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.7141 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:56:10,004:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 819.00s, LR: 0.00050, Train Loss: 0.3706, Train Acc: 0.8450,
                            Val Loss: 0.6291, Val Acc: 0.7050, Test Acc: 0.7141
2022-09-08 00:56:10,005:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-08 00:56:34,070:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.07s, LR: 0.00050, Train Loss: 0.3420, Train Acc: 0.8600,
                            Val Loss: 0.9484, Val Acc: 0.6750, Test Acc: 0.6671
2022-09-08 00:56:34,070:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-08 00:56:57,780:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.71s, LR: 0.00050, Train Loss: 0.3597, Train Acc: 0.8400,
                            Val Loss: 0.6933, Val Acc: 0.6900, Test Acc: 0.7023
2022-09-08 00:56:57,781:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-08 00:57:21,040:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.7722 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:57:21,040:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.26s, LR: 0.00050, Train Loss: 0.3665, Train Acc: 0.8300,
                            Val Loss: 0.5586, Val Acc: 0.7540, Test Acc: 0.7722
2022-09-08 00:57:21,040:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 10/1000
2022-09-08 00:57:44,815:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.7834 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:57:44,816:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.78s, LR: 0.00050, Train Loss: 0.3195, Train Acc: 0.8800,
                            Val Loss: 0.6379, Val Acc: 0.7740, Test Acc: 0.7834
2022-09-08 00:57:44,816:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 11/1000
2022-09-08 00:58:08,773:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.96s, LR: 0.00050, Train Loss: 0.3084, Train Acc: 0.8750,
                            Val Loss: 0.5290, Val Acc: 0.7570, Test Acc: 0.7615
2022-09-08 00:58:08,773:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 12/1000
2022-09-08 00:58:33,071:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.8440 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:58:33,072:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.30s, LR: 0.00050, Train Loss: 0.2793, Train Acc: 0.8950,
                            Val Loss: 0.4226, Val Acc: 0.8220, Test Acc: 0.8440
2022-09-08 00:58:33,072:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 13/1000
2022-09-08 00:58:56,891:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.82s, LR: 0.00050, Train Loss: 0.2225, Train Acc: 0.9350,
                            Val Loss: 0.5141, Val Acc: 0.8060, Test Acc: 0.8054
2022-09-08 00:58:56,891:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 14/1000
2022-09-08 00:59:20,545:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.65s, LR: 0.00050, Train Loss: 0.1994, Train Acc: 0.9350,
                            Val Loss: 0.8253, Val Acc: 0.6870, Test Acc: 0.7112
2022-09-08 00:59:20,545:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 15/1000
2022-09-08 00:59:45,780:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.8943 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 00:59:45,780:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.24s, LR: 0.00050, Train Loss: 0.1688, Train Acc: 0.9550,
                            Val Loss: 0.3297, Val Acc: 0.8830, Test Acc: 0.8943
2022-09-08 00:59:45,780:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 16/1000
2022-09-08 01:00:10,333:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.55s, LR: 0.00050, Train Loss: 0.1531, Train Acc: 0.9600,
                            Val Loss: 0.3865, Val Acc: 0.8730, Test Acc: 0.8660
2022-09-08 01:00:10,334:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 17/1000
2022-09-08 01:00:34,375:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.04s, LR: 0.00050, Train Loss: 0.1513, Train Acc: 0.9350,
                            Val Loss: 0.3378, Val Acc: 0.8820, Test Acc: 0.8861
2022-09-08 01:00:34,376:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 18/1000
2022-09-08 01:00:58,331:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.95s, LR: 0.00050, Train Loss: 0.1397, Train Acc: 0.9500,
                            Val Loss: 0.5570, Val Acc: 0.7770, Test Acc: 0.7786
2022-09-08 01:00:58,331:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 19/1000
2022-09-08 01:01:22,689:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.36s, LR: 0.00050, Train Loss: 0.1616, Train Acc: 0.9300,
                            Val Loss: 0.4508, Val Acc: 0.8240, Test Acc: 0.8539
2022-09-08 01:01:22,689:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 20/1000
2022-09-08 01:01:46,668:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.98s, LR: 0.00050, Train Loss: 0.2730, Train Acc: 0.8850,
                            Val Loss: 0.3403, Val Acc: 0.8800, Test Acc: 0.8839
2022-09-08 01:01:46,669:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 21/1000
2022-09-08 01:02:11,233:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.56s, LR: 0.00050, Train Loss: 0.1979, Train Acc: 0.9250,
                            Val Loss: 0.4285, Val Acc: 0.8230, Test Acc: 0.8122
2022-09-08 01:02:11,233:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 22/1000
2022-09-08 01:02:35,329:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00050, Train Loss: 0.1725, Train Acc: 0.9500,
                            Val Loss: 0.3882, Val Acc: 0.8740, Test Acc: 0.8835
2022-09-08 01:02:35,330:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 23/1000
2022-09-08 01:02:59,022:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.69s, LR: 0.00050, Train Loss: 0.1524, Train Acc: 0.9500,
                            Val Loss: 0.3754, Val Acc: 0.8890, Test Acc: 0.8784
2022-09-08 01:02:59,023:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 24/1000
2022-09-08 01:03:23,258:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.8951 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:03:23,258:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.23s, LR: 0.00050, Train Loss: 0.1153, Train Acc: 0.9600,
                            Val Loss: 0.3140, Val Acc: 0.9040, Test Acc: 0.8951
2022-09-08 01:03:23,258:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 25/1000
2022-09-08 01:03:47,214:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.8976 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:03:47,214:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.96s, LR: 0.00050, Train Loss: 0.1255, Train Acc: 0.9700,
                            Val Loss: 0.2973, Val Acc: 0.9050, Test Acc: 0.8976
2022-09-08 01:03:47,214:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 26/1000
2022-09-08 01:04:11,671:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.46s, LR: 0.00050, Train Loss: 0.0892, Train Acc: 0.9800,
                            Val Loss: 0.3797, Val Acc: 0.8700, Test Acc: 0.8661
2022-09-08 01:04:11,672:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 27/1000
2022-09-08 01:04:35,295:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9036 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:04:35,295:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.62s, LR: 0.00050, Train Loss: 0.0992, Train Acc: 0.9650,
                            Val Loss: 0.2950, Val Acc: 0.9050, Test Acc: 0.9036
2022-09-08 01:04:35,295:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 28/1000
2022-09-08 01:04:59,334:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.04s, LR: 0.00050, Train Loss: 0.0774, Train Acc: 0.9650,
                            Val Loss: 0.3881, Val Acc: 0.8800, Test Acc: 0.8882
2022-09-08 01:04:59,335:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 29/1000
2022-09-08 01:05:24,961:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.63s, LR: 0.00050, Train Loss: 0.0445, Train Acc: 0.9900,
                            Val Loss: 0.4548, Val Acc: 0.8600, Test Acc: 0.8675
2022-09-08 01:05:24,961:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 30/1000
2022-09-08 01:05:48,720:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.76s, LR: 0.00050, Train Loss: 0.0989, Train Acc: 0.9600,
                            Val Loss: 0.5159, Val Acc: 0.8410, Test Acc: 0.8566
2022-09-08 01:05:48,721:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 31/1000
2022-09-08 01:06:12,169:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.45s, LR: 0.00050, Train Loss: 0.0978, Train Acc: 0.9650,
                            Val Loss: 0.3810, Val Acc: 0.8890, Test Acc: 0.8930
2022-09-08 01:06:12,169:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 32/1000
2022-09-08 01:06:35,628:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9060 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:06:35,628:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.46s, LR: 0.00050, Train Loss: 0.0341, Train Acc: 0.9950,
                            Val Loss: 0.4011, Val Acc: 0.9060, Test Acc: 0.9060
2022-09-08 01:06:35,628:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 33/1000
2022-09-08 01:06:59,275:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.65s, LR: 0.00050, Train Loss: 0.0370, Train Acc: 1.0000,
                            Val Loss: 0.3636, Val Acc: 0.9120, Test Acc: 0.8987
2022-09-08 01:06:59,275:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 34/1000
2022-09-08 01:07:23,520:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9122 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:07:23,520:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.24s, LR: 0.00050, Train Loss: 0.0244, Train Acc: 1.0000,
                            Val Loss: 0.3078, Val Acc: 0.9180, Test Acc: 0.9122
2022-09-08 01:07:23,521:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 35/1000
2022-09-08 01:07:47,439:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9207 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:07:47,439:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.92s, LR: 0.00050, Train Loss: 0.0544, Train Acc: 0.9850,
                            Val Loss: 0.3108, Val Acc: 0.9140, Test Acc: 0.9207
2022-09-08 01:07:47,439:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 36/1000
2022-09-08 01:08:10,919:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.48s, LR: 0.00050, Train Loss: 0.0680, Train Acc: 0.9800,
                            Val Loss: 0.4006, Val Acc: 0.8860, Test Acc: 0.8639
2022-09-08 01:08:10,919:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 37/1000
2022-09-08 01:08:34,409:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.49s, LR: 0.00050, Train Loss: 0.0507, Train Acc: 0.9800,
                            Val Loss: 0.8114, Val Acc: 0.8000, Test Acc: 0.7994
2022-09-08 01:08:34,409:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 38/1000
2022-09-08 01:08:57,865:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.46s, LR: 0.00050, Train Loss: 0.0332, Train Acc: 0.9900,
                            Val Loss: 0.5100, Val Acc: 0.8870, Test Acc: 0.8834
2022-09-08 01:08:57,866:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 39/1000
2022-09-08 01:09:21,372:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.51s, LR: 0.00025, Train Loss: 0.0162, Train Acc: 0.9950,
                            Val Loss: 0.3774, Val Acc: 0.9210, Test Acc: 0.9155
2022-09-08 01:09:21,372:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 40/1000
2022-09-08 01:09:44,828:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9233 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:09:44,828:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.46s, LR: 0.00025, Train Loss: 0.0159, Train Acc: 1.0000,
                            Val Loss: 0.3431, Val Acc: 0.9280, Test Acc: 0.9233
2022-09-08 01:09:44,828:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 41/1000
2022-09-08 01:10:08,293:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.47s, LR: 0.00025, Train Loss: 0.0109, Train Acc: 1.0000,
                            Val Loss: 0.3370, Val Acc: 0.9250, Test Acc: 0.9204
2022-09-08 01:10:08,294:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 42/1000
2022-09-08 01:10:31,777:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.48s, LR: 0.00025, Train Loss: 0.0408, Train Acc: 0.9900,
                            Val Loss: 0.3181, Val Acc: 0.9170, Test Acc: 0.9183
2022-09-08 01:10:31,778:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 43/1000
2022-09-08 01:10:55,756:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.98s, LR: 0.00025, Train Loss: 0.0181, Train Acc: 0.9900,
                            Val Loss: 0.3635, Val Acc: 0.9000, Test Acc: 0.8971
2022-09-08 01:10:55,757:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 44/1000
2022-09-08 01:11:19,379:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.62s, LR: 0.00025, Train Loss: 0.0163, Train Acc: 0.9950,
                            Val Loss: 0.3548, Val Acc: 0.8910, Test Acc: 0.8795
2022-09-08 01:11:19,380:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 45/1000
2022-09-08 01:11:42,995:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.61s, LR: 0.00025, Train Loss: 0.0111, Train Acc: 1.0000,
                            Val Loss: 0.3732, Val Acc: 0.8910, Test Acc: 0.8759
2022-09-08 01:11:42,996:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 46/1000
2022-09-08 01:12:07,577:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.58s, LR: 0.00025, Train Loss: 0.0108, Train Acc: 0.9950,
                            Val Loss: 0.3620, Val Acc: 0.9000, Test Acc: 0.8875
2022-09-08 01:12:07,577:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 47/1000
2022-09-08 01:12:31,678:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00025, Train Loss: 0.0229, Train Acc: 0.9900,
                            Val Loss: 0.3364, Val Acc: 0.9090, Test Acc: 0.8971
2022-09-08 01:12:31,678:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 48/1000
2022-09-08 01:12:55,653:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.97s, LR: 0.00025, Train Loss: 0.0045, Train Acc: 1.0000,
                            Val Loss: 0.3588, Val Acc: 0.9140, Test Acc: 0.9092
2022-09-08 01:12:55,653:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 49/1000
2022-09-08 01:13:20,203:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.55s, LR: 0.00025, Train Loss: 0.0078, Train Acc: 1.0000,
                            Val Loss: 0.3476, Val Acc: 0.9310, Test Acc: 0.9216
2022-09-08 01:13:20,204:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 50/1000
2022-09-08 01:13:44,515:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.9237 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_00h40m24s_on_Sep_08_2022/MODELS_
2022-09-08 01:13:44,515:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.31s, LR: 0.00013, Train Loss: 0.0035, Train Acc: 1.0000,
                            Val Loss: 0.3263, Val Acc: 0.9310, Test Acc: 0.9237
2022-09-08 01:13:44,515:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 51/1000
2022-09-08 01:14:10,011:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.50s, LR: 0.00013, Train Loss: 0.0081, Train Acc: 1.0000,
                            Val Loss: 0.3195, Val Acc: 0.9290, Test Acc: 0.9223
2022-09-08 01:14:10,011:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 52/1000
2022-09-08 01:14:34,560:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.55s, LR: 0.00013, Train Loss: 0.0019, Train Acc: 1.0000,
                            Val Loss: 0.3187, Val Acc: 0.9270, Test Acc: 0.9191
2022-09-08 01:14:34,560:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 53/1000
2022-09-08 01:14:58,752:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.19s, LR: 0.00013, Train Loss: 0.0042, Train Acc: 1.0000,
                            Val Loss: 0.3189, Val Acc: 0.9220, Test Acc: 0.9123
2022-09-08 01:14:58,753:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 54/1000
2022-09-08 01:15:22,876:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.12s, LR: 0.00013, Train Loss: 0.0031, Train Acc: 1.0000,
                            Val Loss: 0.3193, Val Acc: 0.9200, Test Acc: 0.9124
2022-09-08 01:15:22,876:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 55/1000
2022-09-08 01:15:46,745:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.87s, LR: 0.00013, Train Loss: 0.0027, Train Acc: 1.0000,
                            Val Loss: 0.3179, Val Acc: 0.9190, Test Acc: 0.9126
2022-09-08 01:15:46,746:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 56/1000
2022-09-08 01:16:10,664:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.92s, LR: 0.00013, Train Loss: 0.0018, Train Acc: 1.0000,
                            Val Loss: 0.3182, Val Acc: 0.9190, Test Acc: 0.9131
2022-09-08 01:16:10,664:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 57/1000
2022-09-08 01:16:34,259:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.59s, LR: 0.00013, Train Loss: 0.0020, Train Acc: 1.0000,
                            Val Loss: 0.3184, Val Acc: 0.9200, Test Acc: 0.9146
2022-09-08 01:16:34,259:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 58/1000
2022-09-08 01:16:58,399:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00013, Train Loss: 0.0020, Train Acc: 1.0000,
                            Val Loss: 0.3194, Val Acc: 0.9240, Test Acc: 0.9158
2022-09-08 01:16:58,400:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 59/1000
2022-09-08 01:17:21,814:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.41s, LR: 0.00013, Train Loss: 0.0025, Train Acc: 1.0000,
                            Val Loss: 0.3211, Val Acc: 0.9260, Test Acc: 0.9173
2022-09-08 01:17:21,815:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 60/1000
2022-09-08 01:17:45,213:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.40s, LR: 0.00013, Train Loss: 0.0014, Train Acc: 1.0000,
                            Val Loss: 0.3234, Val Acc: 0.9260, Test Acc: 0.9193
2022-09-08 01:17:45,214:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 61/1000
2022-09-08 01:18:09,020:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.81s, LR: 0.00006, Train Loss: 0.0025, Train Acc: 1.0000,
                            Val Loss: 0.3234, Val Acc: 0.9290, Test Acc: 0.9206
2022-09-08 01:18:09,021:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 62/1000
2022-09-08 01:18:33,480:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.46s, LR: 0.00006, Train Loss: 0.0016, Train Acc: 1.0000,
                            Val Loss: 0.3242, Val Acc: 0.9280, Test Acc: 0.9212
2022-09-08 01:18:33,481:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 63/1000
2022-09-08 01:18:57,228:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.75s, LR: 0.00006, Train Loss: 0.0024, Train Acc: 1.0000,
                            Val Loss: 0.3237, Val Acc: 0.9280, Test Acc: 0.9201
2022-09-08 01:18:57,228:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 64/1000
2022-09-08 01:19:21,297:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.07s, LR: 0.00006, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3240, Val Acc: 0.9260, Test Acc: 0.9197
2022-09-08 01:19:21,297:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 65/1000
2022-09-08 01:19:45,587:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.29s, LR: 0.00006, Train Loss: 0.0030, Train Acc: 1.0000,
                            Val Loss: 0.3251, Val Acc: 0.9280, Test Acc: 0.9204
2022-09-08 01:19:45,588:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 66/1000
2022-09-08 01:20:09,737:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.15s, LR: 0.00006, Train Loss: 0.0014, Train Acc: 1.0000,
                            Val Loss: 0.3248, Val Acc: 0.9290, Test Acc: 0.9215
2022-09-08 01:20:09,738:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 67/1000
2022-09-08 01:20:33,755:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.02s, LR: 0.00006, Train Loss: 0.0014, Train Acc: 1.0000,
                            Val Loss: 0.3236, Val Acc: 0.9300, Test Acc: 0.9206
2022-09-08 01:20:33,755:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 68/1000
2022-09-08 01:20:57,884:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.13s, LR: 0.00006, Train Loss: 0.0019, Train Acc: 1.0000,
                            Val Loss: 0.3227, Val Acc: 0.9270, Test Acc: 0.9193
2022-09-08 01:20:57,885:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 69/1000
2022-09-08 01:21:21,970:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.08s, LR: 0.00006, Train Loss: 0.0013, Train Acc: 1.0000,
                            Val Loss: 0.3225, Val Acc: 0.9260, Test Acc: 0.9192
2022-09-08 01:21:21,971:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 70/1000
2022-09-08 01:21:45,629:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.66s, LR: 0.00006, Train Loss: 0.0044, Train Acc: 1.0000,
                            Val Loss: 0.3228, Val Acc: 0.9260, Test Acc: 0.9192
2022-09-08 01:21:45,630:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 71/1000
2022-09-08 01:22:09,927:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.30s, LR: 0.00006, Train Loss: 0.0018, Train Acc: 1.0000,
                            Val Loss: 0.3227, Val Acc: 0.9260, Test Acc: 0.9179
2022-09-08 01:22:09,927:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 72/1000
2022-09-08 01:22:33,961:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.03s, LR: 0.00003, Train Loss: 0.0014, Train Acc: 1.0000,
                            Val Loss: 0.3226, Val Acc: 0.9250, Test Acc: 0.9176
2022-09-08 01:22:33,962:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 73/1000
2022-09-08 01:22:57,986:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.02s, LR: 0.00003, Train Loss: 0.0028, Train Acc: 1.0000,
                            Val Loss: 0.3232, Val Acc: 0.9240, Test Acc: 0.9171
2022-09-08 01:22:57,986:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 74/1000
2022-09-08 01:23:22,242:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.26s, LR: 0.00003, Train Loss: 0.0023, Train Acc: 1.0000,
                            Val Loss: 0.3244, Val Acc: 0.9260, Test Acc: 0.9175
2022-09-08 01:23:22,243:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 75/1000
2022-09-08 01:23:46,384:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.14s, LR: 0.00003, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3238, Val Acc: 0.9240, Test Acc: 0.9179
2022-09-08 01:23:46,384:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 76/1000
2022-09-08 01:24:10,560:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00003, Train Loss: 0.0024, Train Acc: 1.0000,
                            Val Loss: 0.3246, Val Acc: 0.9240, Test Acc: 0.9174
2022-09-08 01:24:10,561:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 77/1000
2022-09-08 01:24:34,723:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.16s, LR: 0.00003, Train Loss: 0.0031, Train Acc: 1.0000,
                            Val Loss: 0.3249, Val Acc: 0.9190, Test Acc: 0.9159
2022-09-08 01:24:34,723:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 78/1000
2022-09-08 01:24:59,116:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.39s, LR: 0.00003, Train Loss: 0.0016, Train Acc: 1.0000,
                            Val Loss: 0.3247, Val Acc: 0.9260, Test Acc: 0.9180
2022-09-08 01:24:59,117:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 79/1000
2022-09-08 01:25:22,963:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.85s, LR: 0.00003, Train Loss: 0.0022, Train Acc: 1.0000,
                            Val Loss: 0.3250, Val Acc: 0.9270, Test Acc: 0.9187
2022-09-08 01:25:22,963:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 80/1000
2022-09-08 01:25:46,530:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.57s, LR: 0.00003, Train Loss: 0.0012, Train Acc: 1.0000,
                            Val Loss: 0.3251, Val Acc: 0.9290, Test Acc: 0.9193
2022-09-08 01:25:46,531:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 81/1000
2022-09-08 01:26:11,393:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.86s, LR: 0.00003, Train Loss: 0.0019, Train Acc: 1.0000,
                            Val Loss: 0.3249, Val Acc: 0.9280, Test Acc: 0.9188
2022-09-08 01:26:11,393:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 82/1000
2022-09-08 01:26:35,576:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.18s, LR: 0.00003, Train Loss: 0.0019, Train Acc: 1.0000,
                            Val Loss: 0.3250, Val Acc: 0.9300, Test Acc: 0.9196
2022-09-08 01:26:35,577:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 83/1000
2022-09-08 01:27:00,993:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.42s, LR: 0.00002, Train Loss: 0.0016, Train Acc: 1.0000,
                            Val Loss: 0.3256, Val Acc: 0.9270, Test Acc: 0.9196
2022-09-08 01:27:00,994:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 84/1000
2022-09-08 01:27:25,267:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.27s, LR: 0.00002, Train Loss: 0.0025, Train Acc: 1.0000,
                            Val Loss: 0.3257, Val Acc: 0.9280, Test Acc: 0.9201
2022-09-08 01:27:25,267:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 85/1000
2022-09-08 01:27:49,065:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.80s, LR: 0.00002, Train Loss: 0.0023, Train Acc: 1.0000,
                            Val Loss: 0.3270, Val Acc: 0.9260, Test Acc: 0.9200
2022-09-08 01:27:49,065:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 86/1000
2022-09-08 01:28:12,819:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.75s, LR: 0.00002, Train Loss: 0.0018, Train Acc: 1.0000,
                            Val Loss: 0.3254, Val Acc: 0.9260, Test Acc: 0.9187
2022-09-08 01:28:12,819:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 87/1000
2022-09-08 01:28:36,385:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.57s, LR: 0.00002, Train Loss: 0.0019, Train Acc: 1.0000,
                            Val Loss: 0.3265, Val Acc: 0.9280, Test Acc: 0.9202
2022-09-08 01:28:36,386:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 88/1000
2022-09-08 01:29:00,224:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.84s, LR: 0.00002, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3279, Val Acc: 0.9270, Test Acc: 0.9198
2022-09-08 01:29:00,225:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 89/1000
2022-09-08 01:29:24,055:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.83s, LR: 0.00002, Train Loss: 0.0013, Train Acc: 1.0000,
                            Val Loss: 0.3275, Val Acc: 0.9270, Test Acc: 0.9190
2022-09-08 01:29:24,055:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 90/1000
2022-09-08 01:29:49,041:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.99s, LR: 0.00002, Train Loss: 0.0014, Train Acc: 1.0000,
                            Val Loss: 0.3273, Val Acc: 0.9270, Test Acc: 0.9204
2022-09-08 01:29:49,042:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 91/1000
2022-09-08 01:30:13,359:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.32s, LR: 0.00002, Train Loss: 0.0016, Train Acc: 1.0000,
                            Val Loss: 0.3282, Val Acc: 0.9280, Test Acc: 0.9208
2022-09-08 01:30:13,359:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 92/1000
2022-09-08 01:30:37,304:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.94s, LR: 0.00002, Train Loss: 0.0013, Train Acc: 1.0000,
                            Val Loss: 0.3282, Val Acc: 0.9270, Test Acc: 0.9205
2022-09-08 01:30:37,304:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 93/1000
2022-09-08 01:31:01,226:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.92s, LR: 0.00002, Train Loss: 0.0016, Train Acc: 1.0000,
                            Val Loss: 0.3276, Val Acc: 0.9260, Test Acc: 0.9211
2022-09-08 01:31:01,227:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 94/1000
2022-09-08 01:31:24,994:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.77s, LR: 0.00001, Train Loss: 0.0020, Train Acc: 1.0000,
                            Val Loss: 0.3273, Val Acc: 0.9260, Test Acc: 0.9205
2022-09-08 01:31:24,995:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 95/1000
2022-09-08 01:31:49,287:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.29s, LR: 0.00001, Train Loss: 0.0033, Train Acc: 1.0000,
                            Val Loss: 0.3270, Val Acc: 0.9260, Test Acc: 0.9201
2022-09-08 01:31:49,288:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 96/1000
2022-09-08 01:32:13,826:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.54s, LR: 0.00001, Train Loss: 0.0012, Train Acc: 1.0000,
                            Val Loss: 0.3278, Val Acc: 0.9270, Test Acc: 0.9203
2022-09-08 01:32:13,827:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 97/1000
2022-09-08 01:32:37,929:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00001, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3268, Val Acc: 0.9270, Test Acc: 0.9198
2022-09-08 01:32:37,929:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 98/1000
2022-09-08 01:33:02,553:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.62s, LR: 0.00001, Train Loss: 0.0013, Train Acc: 1.0000,
                            Val Loss: 0.3271, Val Acc: 0.9280, Test Acc: 0.9206
2022-09-08 01:33:02,553:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 99/1000
2022-09-08 01:33:26,528:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.97s, LR: 0.00001, Train Loss: 0.0016, Train Acc: 1.0000,
                            Val Loss: 0.3268, Val Acc: 0.9270, Test Acc: 0.9194
2022-09-08 01:33:26,529:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 100/1000
2022-09-08 01:33:51,404:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.87s, LR: 0.00001, Train Loss: 0.0027, Train Acc: 1.0000,
                            Val Loss: 0.3274, Val Acc: 0.9280, Test Acc: 0.9200
2022-09-08 01:33:51,404:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 101/1000
2022-09-08 01:34:16,346:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.94s, LR: 0.00001, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3278, Val Acc: 0.9270, Test Acc: 0.9197
2022-09-08 01:34:16,347:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 102/1000
2022-09-08 01:34:40,798:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.45s, LR: 0.00001, Train Loss: 0.0023, Train Acc: 1.0000,
                            Val Loss: 0.3283, Val Acc: 0.9260, Test Acc: 0.9192
2022-09-08 01:34:40,798:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 103/1000
2022-09-08 01:35:05,603:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.80s, LR: 0.00001, Train Loss: 0.0020, Train Acc: 1.0000,
                            Val Loss: 0.3291, Val Acc: 0.9290, Test Acc: 0.9199
2022-09-08 01:35:05,603:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 104/1000
2022-09-08 01:35:29,715:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.11s, LR: 0.00001, Train Loss: 0.0020, Train Acc: 1.0000,
                            Val Loss: 0.3283, Val Acc: 0.9270, Test Acc: 0.9186
2022-09-08 01:35:29,716:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 105/1000
2022-09-08 01:35:54,315:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.60s, LR: 0.00000, Train Loss: 0.0077, Train Acc: 1.0000,
                            Val Loss: 0.3288, Val Acc: 0.9280, Test Acc: 0.9191
2022-09-08 01:35:54,316:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 106/1000
2022-09-08 01:36:18,416:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00000, Train Loss: 0.0021, Train Acc: 1.0000,
                            Val Loss: 0.3289, Val Acc: 0.9280, Test Acc: 0.9194
2022-09-08 01:36:18,416:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 107/1000
2022-09-08 01:36:42,384:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.97s, LR: 0.00000, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3285, Val Acc: 0.9260, Test Acc: 0.9180
2022-09-08 01:36:42,384:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 108/1000
2022-09-08 01:37:06,847:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.46s, LR: 0.00000, Train Loss: 0.0022, Train Acc: 1.0000,
                            Val Loss: 0.3304, Val Acc: 0.9260, Test Acc: 0.9182
2022-09-08 01:37:06,848:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 109/1000
2022-09-08 01:37:30,910:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.06s, LR: 0.00000, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3287, Val Acc: 0.9260, Test Acc: 0.9178
2022-09-08 01:37:30,911:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 110/1000
2022-09-08 01:37:54,818:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.91s, LR: 0.00000, Train Loss: 0.0025, Train Acc: 1.0000,
                            Val Loss: 0.3289, Val Acc: 0.9260, Test Acc: 0.9191
2022-09-08 01:37:54,818:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 111/1000
2022-09-08 01:38:18,596:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.78s, LR: 0.00000, Train Loss: 0.0015, Train Acc: 1.0000,
                            Val Loss: 0.3282, Val Acc: 0.9270, Test Acc: 0.9184
2022-09-08 01:38:18,596:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 112/1000
2022-09-08 01:38:42,624:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.03s, LR: 0.00000, Train Loss: 0.0017, Train Acc: 1.0000,
                            Val Loss: 0.3282, Val Acc: 0.9280, Test Acc: 0.9203
2022-09-08 01:38:42,624:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 113/1000
2022-09-08 01:39:07,810:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.18s, LR: 0.00000, Train Loss: 0.0028, Train Acc: 1.0000,
                            Val Loss: 0.3286, Val Acc: 0.9260, Test Acc: 0.9195
2022-09-08 01:39:07,811:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 114/1000
2022-09-08 01:39:33,095:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.28s, LR: 0.00000, Train Loss: 0.0029, Train Acc: 1.0000,
                            Val Loss: 0.3280, Val Acc: 0.9260, Test Acc: 0.9195
2022-09-08 01:39:33,095:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 115/1000
2022-09-08 01:39:57,494:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.40s, LR: 0.00000, Train Loss: 0.0014, Train Acc: 1.0000,
                            Val Loss: 0.3284, Val Acc: 0.9260, Test Acc: 0.9199
2022-09-08 01:39:57,495:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 116/1000
2022-09-08 01:40:21,914:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.42s, LR: 0.00000, Train Loss: 0.0057, Train Acc: 1.0000,
                            Val Loss: 0.3293, Val Acc: 0.9270, Test Acc: 0.9195
2022-09-08 01:40:21,916:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 117/1000
2022-09-08 01:40:45,542:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.63s, LR: 0.00000, Train Loss: 0.0012, Train Acc: 1.0000,
                            Val Loss: 0.3287, Val Acc: 0.9260, Test Acc: 0.9199
2022-09-08 01:40:45,542:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 118/1000
2022-09-08 01:41:09,733:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.19s, LR: 0.00000, Train Loss: 0.0037, Train Acc: 1.0000,
                            Val Loss: 0.3300, Val Acc: 0.9280, Test Acc: 0.9203
2022-09-08 01:41:09,734:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 119/1000
2022-09-08 01:41:34,059:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.32s, LR: 0.00000, Train Loss: 0.0020, Train Acc: 1.0000,
                            Val Loss: 0.3298, Val Acc: 0.9290, Test Acc: 0.9199
2022-09-08 01:41:34,060:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 120/1000
2022-09-08 01:41:58,443:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.38s, LR: 0.00000, Train Loss: 0.0010, Train Acc: 1.0000,
                            Val Loss: 0.3285, Val Acc: 0.9280, Test Acc: 0.9195
2022-09-08 01:41:58,444:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 121/1000
2022-09-08 01:42:22,637:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.19s, LR: 0.00000, Train Loss: 0.0012, Train Acc: 1.0000,
                            Val Loss: 0.3277, Val Acc: 0.9260, Test Acc: 0.9196
2022-09-08 01:42:22,638:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 122/1000
2022-09-08 01:42:46,447:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.81s, LR: 0.00000, Train Loss: 0.0015, Train Acc: 1.0000,
                            Val Loss: 0.3283, Val Acc: 0.9250, Test Acc: 0.9190
2022-09-08 01:42:46,447:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 123/1000
2022-09-08 01:43:08,744:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.30s, LR: 0.00000, Train Loss: 0.0014, Train Acc: 1.0000,
                            Val Loss: 0.3284, Val Acc: 0.9250, Test Acc: 0.9193
2022-09-08 01:43:08,744:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 124/1000
2022-09-08 01:43:30,351:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.61s, LR: 0.00000, Train Loss: 0.0012, Train Acc: 1.0000,
                            Val Loss: 0.3281, Val Acc: 0.9250, Test Acc: 0.9194
2022-09-08 01:43:30,352:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 125/1000
2022-09-08 01:43:52,864:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.51s, LR: 0.00000, Train Loss: 0.0015, Train Acc: 1.0000,
                            Val Loss: 0.3284, Val Acc: 0.9290, Test Acc: 0.9195
2022-09-08 01:43:52,865:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 126/1000
2022-09-08 01:44:15,759:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.89s, LR: 0.00000, Train Loss: 0.0020, Train Acc: 1.0000,
                            Val Loss: 0.3292, Val Acc: 0.9280, Test Acc: 0.9196
2022-09-08 01:44:15,760:main_CYCLES_graph_classification.py:213 -   train_val_pipeline(): 
!! LR EQUAL TO MIN LR SET.
2022-09-08 01:44:35,281:main_CYCLES_graph_classification.py:232 -   train_val_pipeline(): Test Accuracy: 0.9196
2022-09-08 01:44:35,281:main_CYCLES_graph_classification.py:233 -   train_val_pipeline(): Best Test Accuracy: 0.9237
2022-09-08 01:44:35,281:main_CYCLES_graph_classification.py:234 -   train_val_pipeline(): Train Accuracy: 1.0000
2022-09-08 01:44:35,281:main_CYCLES_graph_classification.py:235 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 1.0000
2022-09-08 01:44:35,281:main_CYCLES_graph_classification.py:236 -   train_val_pipeline(): Convergence Time (Epochs): 125.0000
2022-09-08 01:44:35,281:main_CYCLES_graph_classification.py:237 -   train_val_pipeline(): TOTAL TIME TAKEN: 3851.2415s
2022-09-08 01:44:35,281:main_CYCLES_graph_classification.py:238 -   train_val_pipeline(): AVG TIME PER EPOCH: 30.3315s
2022-09-08 01:44:35,282:main_CYCLES_graph_classification.py:242 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 01:44:35,282:main_CYCLES_graph_classification.py:243 -   train_val_pipeline(): train history: [1.0]
2022-09-08 01:44:35,282:main_CYCLES_graph_classification.py:244 -   train_val_pipeline(): test history: [0.9196]
2022-09-08 01:44:35,282:main_CYCLES_graph_classification.py:245 -   train_val_pipeline(): val history: [0.928]
2022-09-08 01:48:06,190:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 01:48:11,061:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': True, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-08 01:48:11,061:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 1}
2022-09-08 01:48:11,061:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 01:48:11,062:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 01:48:11,062:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 01:48:11,062:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 01:48:11,068:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 01:48:11,069:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-08 01:48:11,069:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 01:48:11,069:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 01:48:11,070:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 01:48:11,070:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 01:48:11,070:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 01:48:11,076:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-08 01:48:21,680:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:10.610944032669067
2022-09-08 01:48:21,711:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-08 01:48:21,712:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-08 01:48:21,712:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-08 01:48:21,712:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 01:48:21,714:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 01:48:47,012:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5128 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_01h48m11s_on_Sep_08_2022/MODELS_
2022-09-08 01:48:47,015:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.30s, LR: 0.00050, Train Loss: 0.8536, Train Acc: 0.5150,
                            Val Loss: 0.8315, Val Acc: 0.5200, Test Acc: 0.5128
2022-09-08 01:48:47,015:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 01:49:12,194:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5292 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_01h48m11s_on_Sep_08_2022/MODELS_
2022-09-08 01:49:12,196:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.18s, LR: 0.00050, Train Loss: 0.7037, Train Acc: 0.6100,
                            Val Loss: 0.7994, Val Acc: 0.5170, Test Acc: 0.5292
2022-09-08 01:49:12,196:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-08 01:49:36,361:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5500 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_01h48m11s_on_Sep_08_2022/MODELS_
2022-09-08 01:49:36,362:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.17s, LR: 0.00050, Train Loss: 0.6108, Train Acc: 0.6600,
                            Val Loss: 0.7931, Val Acc: 0.5380, Test Acc: 0.5500
2022-09-08 01:49:36,362:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-08 01:50:01,067:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6466 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_01h48m11s_on_Sep_08_2022/MODELS_
2022-09-08 01:50:01,067:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.71s, LR: 0.00050, Train Loss: 0.5819, Train Acc: 0.7000,
                            Val Loss: 0.6522, Val Acc: 0.6330, Test Acc: 0.6466
2022-09-08 01:50:01,067:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-08 01:50:27,387:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6629 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_01h48m11s_on_Sep_08_2022/MODELS_
2022-09-08 01:50:27,388:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 26.32s, LR: 0.00050, Train Loss: 0.5662, Train Acc: 0.6950,
                            Val Loss: 0.6345, Val Acc: 0.6610, Test Acc: 0.6629
2022-09-08 01:50:27,388:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-08 01:50:52,042:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6982 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_01h48m11s_on_Sep_08_2022/MODELS_
2022-09-08 01:50:52,042:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.65s, LR: 0.00050, Train Loss: 0.5243, Train Acc: 0.7450,
                            Val Loss: 0.5867, Val Acc: 0.6760, Test Acc: 0.6982
2022-09-08 01:50:52,042:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-08 01:51:16,554:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.51s, LR: 0.00050, Train Loss: 0.4726, Train Acc: 0.7550,
                            Val Loss: 0.7712, Val Acc: 0.6080, Test Acc: 0.6237
2022-09-08 01:51:16,556:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-08 01:51:41,122:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.57s, LR: 0.00050, Train Loss: 0.4753, Train Acc: 0.8000,
                            Val Loss: 0.6615, Val Acc: 0.6490, Test Acc: 0.6636
2022-09-08 01:51:41,122:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 9/1000
2022-09-08 01:52:06,222:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.10s, LR: 0.00050, Train Loss: 0.5232, Train Acc: 0.7300,
                            Val Loss: 0.9090, Val Acc: 0.5810, Test Acc: 0.5841
2022-09-08 01:52:06,223:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 10/1000
2022-09-08 01:52:31,132:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.91s, LR: 0.00050, Train Loss: 0.4860, Train Acc: 0.7650,
                            Val Loss: 0.7696, Val Acc: 0.6150, Test Acc: 0.6472
2022-09-08 01:52:31,133:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 11/1000
2022-09-08 01:52:56,544:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.41s, LR: 0.00050, Train Loss: 0.4837, Train Acc: 0.7400,
                            Val Loss: 0.6836, Val Acc: 0.6850, Test Acc: 0.6929
2022-09-08 01:52:56,545:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 12/1000
2022-09-08 01:53:21,720:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.7115 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_1_16_01h48m11s_on_Sep_08_2022/MODELS_
2022-09-08 01:53:21,720:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 25.18s, LR: 0.00050, Train Loss: 0.4238, Train Acc: 0.8000,
                            Val Loss: 0.6035, Val Acc: 0.7120, Test Acc: 0.7115
2022-09-08 01:53:21,720:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 13/1000
2022-09-08 01:53:46,151:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.43s, LR: 0.00050, Train Loss: 0.4110, Train Acc: 0.8100,
                            Val Loss: 1.0081, Val Acc: 0.6370, Test Acc: 0.6485
2022-09-08 01:53:46,151:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 14/1000
2022-09-08 01:54:10,256:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00050, Train Loss: 0.4808, Train Acc: 0.7750,
                            Val Loss: 0.8582, Val Acc: 0.6270, Test Acc: 0.6371
2022-09-08 01:54:10,257:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 15/1000
2022-09-08 01:55:39,190:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-08 01:55:45,427:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'pos_enc': False, 'adj_enc': False, 'dataset': 'SBM_PATTERN', 'matrix_type': 'A', 'pow_of_mat': 1, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'edge_feat': False, 'rw_pos_enc': False, 'pos_enc_dim': 16, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': True, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 3, 'n_classes': 2}
2022-09-08 01:55:45,427:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-08 01:55:45,427:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 01:55:45,434:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 01:55:45,434:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 01:55:45,434:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 01:55:45,440:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-08 01:55:45,441:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524375
2022-09-08 01:55:45,442:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-08 01:55:45,442:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-08 01:55:45,442:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-08 01:55:45,442:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-08 01:55:45,442:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-08 01:55:45,448:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-08 02:10:52,729:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:907.2790749073029
2022-09-08 02:10:52,739:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10000
2022-09-08 02:10:52,739:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 2000
2022-09-08 02:10:52,739:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 2000
2022-09-08 02:10:52,739:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 2
2022-09-08 02:10:52,743:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-08 02:19:03,563:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 84.4827 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_01h55m45s_on_Sep_08_2022/MODELS_
2022-09-08 02:19:03,564:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 490.82s, LR: 0.00050, Train Loss: 0.3911, Train Acc: 81.8588,
                            Val Loss: 0.3517, Val Acc: 84.3499, Test Acc: 84.4827
2022-09-08 02:19:03,564:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 2/1000
2022-09-08 02:27:03,165:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 479.60s, LR: 0.00050, Train Loss: 0.3450, Train Acc: 84.6836,
                            Val Loss: 0.3878, Val Acc: 82.5408, Test Acc: 82.6728
2022-09-08 02:27:03,167:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 3/1000
2022-09-08 02:35:18,656:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 84.7296 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_01h55m45s_on_Sep_08_2022/MODELS_
2022-09-08 02:35:18,657:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 495.49s, LR: 0.00050, Train Loss: 0.3388, Train Acc: 85.0317,
                            Val Loss: 0.3469, Val Acc: 84.4671, Test Acc: 84.7296
2022-09-08 02:35:18,657:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 4/1000
2022-09-08 02:43:13,132:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 474.48s, LR: 0.00050, Train Loss: 0.3355, Train Acc: 85.1703,
                            Val Loss: 0.3575, Val Acc: 84.1790, Test Acc: 84.3050
2022-09-08 02:43:13,135:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 5/1000
2022-09-08 02:51:12,322:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 479.19s, LR: 0.00050, Train Loss: 0.3344, Train Acc: 85.2301,
                            Val Loss: 0.3528, Val Acc: 84.5357, Test Acc: 84.6507
2022-09-08 02:51:12,323:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 6/1000
2022-09-08 02:59:07,544:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.3294 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_01h55m45s_on_Sep_08_2022/MODELS_
2022-09-08 02:59:07,544:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 475.22s, LR: 0.00050, Train Loss: 0.3340, Train Acc: 85.2383,
                            Val Loss: 0.3346, Val Acc: 85.2070, Test Acc: 85.3294
2022-09-08 02:59:07,545:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 7/1000
2022-09-08 03:07:03,550:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 476.01s, LR: 0.00050, Train Loss: 0.3328, Train Acc: 85.3236,
                            Val Loss: 0.3467, Val Acc: 84.7485, Test Acc: 84.9077
2022-09-08 03:07:03,551:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 8/1000
2022-09-08 03:15:09,094:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 485.54s, LR: 0.00050, Train Loss: 0.3320, Train Acc: 85.3399,
                            Val Loss: 0.3392, Val Acc: 85.0713, Test Acc: 85.2223
2022-09-08 03:15:09,095:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 9/1000
2022-09-08 03:23:16,609:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 487.51s, LR: 0.00050, Train Loss: 0.3320, Train Acc: 85.3238,
                            Val Loss: 0.3386, Val Acc: 85.0189, Test Acc: 85.1979
2022-09-08 03:23:16,610:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 10/1000
2022-09-08 03:31:25,432:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 488.82s, LR: 0.00050, Train Loss: 0.3310, Train Acc: 85.3810,
                            Val Loss: 0.3518, Val Acc: 84.3650, Test Acc: 84.5589
2022-09-08 03:31:25,434:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 11/1000
2022-09-08 03:39:38,144:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 492.71s, LR: 0.00050, Train Loss: 0.3313, Train Acc: 85.3694,
                            Val Loss: 0.3402, Val Acc: 85.1619, Test Acc: 85.2705
2022-09-08 03:39:38,145:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 12/1000
2022-09-08 03:47:49,850:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 491.70s, LR: 0.00050, Train Loss: 0.3308, Train Acc: 85.4116,
                            Val Loss: 0.3392, Val Acc: 84.9289, Test Acc: 85.0122
2022-09-08 03:47:49,852:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 13/1000
2022-09-08 03:55:50,717:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.5368 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_01h55m45s_on_Sep_08_2022/MODELS_
2022-09-08 03:55:50,718:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 480.87s, LR: 0.00050, Train Loss: 0.3302, Train Acc: 85.4256,
                            Val Loss: 0.3303, Val Acc: 85.4346, Test Acc: 85.5368
2022-09-08 03:55:50,718:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 14/1000
2022-09-08 04:03:53,596:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 482.88s, LR: 0.00050, Train Loss: 0.3294, Train Acc: 85.4791,
                            Val Loss: 0.3355, Val Acc: 85.2365, Test Acc: 85.4130
2022-09-08 04:03:53,599:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 15/1000
2022-09-08 04:11:50,387:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 476.79s, LR: 0.00050, Train Loss: 0.3291, Train Acc: 85.4783,
                            Val Loss: 0.3388, Val Acc: 85.2618, Test Acc: 85.5237
2022-09-08 04:11:50,389:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 16/1000
2022-09-08 04:19:49,950:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 479.56s, LR: 0.00050, Train Loss: 0.3288, Train Acc: 85.4682,
                            Val Loss: 0.3325, Val Acc: 85.2685, Test Acc: 85.4570
2022-09-08 04:19:49,952:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 17/1000
2022-09-08 04:27:45,087:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 475.14s, LR: 0.00050, Train Loss: 0.3284, Train Acc: 85.5245,
                            Val Loss: 0.3472, Val Acc: 84.7358, Test Acc: 84.9779
2022-09-08 04:27:45,089:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 18/1000
2022-09-08 04:35:46,156:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 481.07s, LR: 0.00050, Train Loss: 0.3280, Train Acc: 85.5335,
                            Val Loss: 0.3389, Val Acc: 84.9251, Test Acc: 85.1003
2022-09-08 04:35:46,158:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 19/1000
2022-09-08 04:43:46,615:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 85.6738 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_PATTERN_GPU0_1_16_01h55m45s_on_Sep_08_2022/MODELS_
2022-09-08 04:43:46,616:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 480.46s, LR: 0.00050, Train Loss: 0.3275, Train Acc: 85.5417,
                            Val Loss: 0.3313, Val Acc: 85.4333, Test Acc: 85.6738
2022-09-08 04:43:46,616:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 20/1000
2022-09-08 04:51:44,964:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 478.35s, LR: 0.00050, Train Loss: 0.3270, Train Acc: 85.5702,
                            Val Loss: 0.3350, Val Acc: 85.1075, Test Acc: 85.4272
2022-09-08 04:51:44,967:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 21/1000
2022-09-08 04:59:36,521:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 471.55s, LR: 0.00050, Train Loss: 0.3268, Train Acc: 85.5664,
                            Val Loss: 0.3340, Val Acc: 85.3844, Test Acc: 85.5023
2022-09-08 04:59:36,523:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 22/1000
2022-09-08 05:07:30,670:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 474.15s, LR: 0.00050, Train Loss: 0.3263, Train Acc: 85.6253,
                            Val Loss: 0.3341, Val Acc: 85.3380, Test Acc: 85.4053
2022-09-08 05:07:30,672:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 23/1000
2022-09-08 05:15:22,285:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 471.61s, LR: 0.00050, Train Loss: 0.3260, Train Acc: 85.6180,
                            Val Loss: 0.3373, Val Acc: 85.3434, Test Acc: 85.6047
2022-09-08 05:15:22,285:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 24/1000
2022-09-08 05:23:18,718:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 476.43s, LR: 0.00050, Train Loss: 0.3255, Train Acc: 85.6374,
                            Val Loss: 0.3393, Val Acc: 84.9450, Test Acc: 85.2042
2022-09-08 05:23:18,720:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 25/1000
2022-09-08 07:23:15,270:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 7196.55s, LR: 0.00025, Train Loss: 0.3218, Train Acc: 85.7775,
                            Val Loss: 0.3360, Val Acc: 85.1825, Test Acc: 85.4087
2022-09-08 07:23:15,272:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 26/1000
2022-09-08 07:31:07,710:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 472.44s, LR: 0.00025, Train Loss: 0.3209, Train Acc: 85.8490,
                            Val Loss: 0.3307, Val Acc: 85.5097, Test Acc: 85.6225
2022-09-08 07:31:07,711:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 27/1000
2022-09-08 07:39:00,023:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 472.31s, LR: 0.00025, Train Loss: 0.3200, Train Acc: 85.9035,
                            Val Loss: 0.3331, Val Acc: 85.4395, Test Acc: 85.5814
2022-09-08 07:39:00,026:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 28/1000
2022-09-08 07:46:53,596:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 473.57s, LR: 0.00025, Train Loss: 0.3197, Train Acc: 85.9193,
                            Val Loss: 0.3379, Val Acc: 85.3190, Test Acc: 85.5087
2022-09-08 07:46:53,598:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 29/1000
2022-09-08 07:55:21,443:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 507.85s, LR: 0.00025, Train Loss: 0.3191, Train Acc: 85.9357,
                            Val Loss: 0.3366, Val Acc: 85.4592, Test Acc: 85.6011
2022-09-08 07:55:21,446:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 30/1000
2022-09-08 08:04:47,884:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 566.44s, LR: 0.00025, Train Loss: 0.3186, Train Acc: 85.9815,
                            Val Loss: 0.3329, Val Acc: 85.4188, Test Acc: 85.5551
2022-09-08 08:04:47,885:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 31/1000
2022-09-08 08:14:23,544:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 575.66s, LR: 0.00025, Train Loss: 0.3175, Train Acc: 86.0107,
                            Val Loss: 0.3343, Val Acc: 85.3268, Test Acc: 85.5760
2022-09-08 08:14:23,546:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 32/1000
2022-09-08 09:14:46,939:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 3623.39s, LR: 0.00025, Train Loss: 0.3170, Train Acc: 86.0557,
                            Val Loss: 0.3338, Val Acc: 85.3455, Test Acc: 85.5149
2022-09-08 09:14:46,941:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 33/1000
2022-09-08 09:22:46,080:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 479.14s, LR: 0.00025, Train Loss: 0.3158, Train Acc: 86.0941,
                            Val Loss: 0.3332, Val Acc: 85.2960, Test Acc: 85.4468
2022-09-08 09:22:46,082:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 34/1000
2022-09-08 09:30:52,532:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 486.45s, LR: 0.00025, Train Loss: 0.3151, Train Acc: 86.1267,
                            Val Loss: 0.3368, Val Acc: 85.2225, Test Acc: 85.4362
2022-09-08 09:30:52,534:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 35/1000
2022-09-08 09:38:50,479:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 477.94s, LR: 0.00025, Train Loss: 0.3143, Train Acc: 86.1793,
                            Val Loss: 0.3342, Val Acc: 85.3855, Test Acc: 85.4743
2022-09-08 09:38:50,481:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 36/1000
2022-09-08 10:06:07,375:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 1636.89s, LR: 0.00013, Train Loss: 0.3103, Train Acc: 86.3717,
                            Val Loss: 0.3346, Val Acc: 85.4925, Test Acc: 85.5086
2022-09-08 10:06:07,377:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 37/1000
2022-09-08 11:09:49,958:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 3822.58s, LR: 0.00013, Train Loss: 0.3087, Train Acc: 86.3951,
                            Val Loss: 0.3370, Val Acc: 85.4035, Test Acc: 85.5083
2022-09-08 11:09:49,961:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 38/1000
2022-09-08 11:23:50,524:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 840.56s, LR: 0.00013, Train Loss: 0.3078, Train Acc: 86.4405,
                            Val Loss: 0.3387, Val Acc: 85.3464, Test Acc: 85.4364
2022-09-08 11:23:50,526:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 39/1000
2022-09-08 11:32:07,361:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 496.83s, LR: 0.00013, Train Loss: 0.3075, Train Acc: 86.4754,
                            Val Loss: 0.3380, Val Acc: 85.2444, Test Acc: 85.4115
2022-09-08 11:32:07,362:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 40/1000
2022-09-10 12:31:33,030:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:31:33,114:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:31:33,114:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:31:33,114:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:31:33,124:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:31:33,124:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:31:33,124:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:31:33,128:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:31:33,129:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317023
2022-09-10 12:31:33,245:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:31:33,246:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:31:33,246:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:31:33,246:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:31:33,246:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:31:33,251:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:31:33,251:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:31:33,251:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:31:33,251:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:31:33,253:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:32:13,044:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:32:13,104:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:32:13,104:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:32:13,104:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:32:13,105:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:32:13,105:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:32:13,105:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:32:13,108:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:32:13,108:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317023
2022-09-10 12:32:13,219:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:32:13,219:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:32:13,220:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:32:13,220:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:32:13,220:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:32:13,223:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:32:13,223:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:32:13,223:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:32:13,223:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:32:13,224:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:32:34,345:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:32:34,409:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:32:34,409:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:32:34,409:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:32:34,410:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:32:34,410:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:32:34,410:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:32:34,413:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:32:34,414:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317023
2022-09-10 12:32:34,533:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:32:34,533:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:32:34,534:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:32:34,534:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:32:34,534:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:32:34,538:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:32:34,538:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:32:34,538:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:32:34,538:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:32:34,539:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:32:38,757:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 4.22s, LR: 0.00050, Train Loss: 2.2936, Train Acc: 0.1444,
                            Val Loss: 5.5383, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:32:38,762:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:32:42,917:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 4.15s, LR: 0.00050, Train Loss: 2.0313, Train Acc: 0.2111,
                            Val Loss: 6.9981, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:32:42,921:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:32:46,905:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 3.98s, LR: 0.00050, Train Loss: 1.9010, Train Acc: 0.2889,
                            Val Loss: 92.1915, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:32:46,910:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:32:50,113:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:32:50,113:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:32:50,114:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0044hrs
2022-09-10 12:32:50,114:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 4.1194s
2022-09-10 12:32:50,118:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:32:50,118:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:32:50,118:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:32:50,118:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:32:56,472:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:32:56,537:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'num_initials': 2, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:32:56,537:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:32:56,538:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:32:56,538:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:32:56,538:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:32:56,538:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:32:56,541:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:32:56,542:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317023
2022-09-10 12:32:56,652:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:32:56,653:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:32:56,654:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:32:56,654:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:32:56,654:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:32:56,657:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:32:56,657:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:32:56,657:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:32:56,657:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:32:56,658:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:33:00,807:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 4.15s, LR: 0.00050, Train Loss: 2.2500, Train Acc: 0.2111,
                            Val Loss: 2.8104, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:00,812:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:33:04,927:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 4.12s, LR: 0.00050, Train Loss: 1.8564, Train Acc: 0.3000,
                            Val Loss: 8.1757, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:04,932:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:33:08,924:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 3.99s, LR: 0.00050, Train Loss: 1.9453, Train Acc: 0.1889,
                            Val Loss: 54.6100, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:08,928:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:33:13,015:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 4.09s, LR: 0.00050, Train Loss: 2.0003, Train Acc: 0.2778,
                            Val Loss: 870.4585, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:13,020:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:33:17,010:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 3.99s, LR: 0.00050, Train Loss: 1.7224, Train Acc: 0.3333,
                            Val Loss: 15049.6382, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:17,014:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:33:20,939:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 3.92s, LR: 0.00050, Train Loss: 1.6737, Train Acc: 0.3667,
                            Val Loss: 27233.6807, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:20,944:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:33:23,823:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:33:23,823:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:33:23,824:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0076hrs
2022-09-10 12:33:23,825:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 4.0437s
2022-09-10 12:33:23,826:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:33:23,827:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:33:23,827:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:33:23,827:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:33:28,664:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:33:28,725:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'num_initials': 2, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:33:28,725:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:33:28,726:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:33:28,726:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:33:28,726:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:33:28,726:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:33:28,729:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:33:28,730:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317491
2022-09-10 12:33:28,843:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:33:28,844:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:33:28,844:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:33:28,844:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:33:28,844:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:33:28,848:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:33:28,848:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:33:28,848:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:33:28,848:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:33:28,849:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:33:36,534:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 7.69s, LR: 0.00050, Train Loss: 2.1877, Train Acc: 0.2111,
                            Val Loss: 5.4337, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:36,539:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:33:44,183:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 7.64s, LR: 0.00050, Train Loss: 1.9295, Train Acc: 0.2333,
                            Val Loss: 14.3423, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:44,187:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:33:46,470:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:33:46,470:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:33:46,470:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0049hrs
2022-09-10 12:33:46,470:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 7.6651s
2022-09-10 12:33:46,473:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:33:46,473:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:33:46,473:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:33:46,473:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:33:51,142:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:33:51,206:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:33:51,206:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:33:51,206:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:33:51,207:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:33:51,207:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:33:51,207:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:33:51,210:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:33:51,210:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317491
2022-09-10 12:33:51,321:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:33:51,321:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:33:51,322:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:33:51,322:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:33:51,322:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:33:51,326:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:33:51,326:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:33:51,326:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:33:51,326:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:33:51,327:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:33:58,886:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 7.56s, LR: 0.00050, Train Loss: 2.1936, Train Acc: 0.1444,
                            Val Loss: 3.2723, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:33:58,890:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:34:06,554:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 7.66s, LR: 0.00050, Train Loss: 2.2283, Train Acc: 0.1556,
                            Val Loss: 35.1329, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:06,558:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:34:09,890:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:34:09,890:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:34:09,890:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0052hrs
2022-09-10 12:34:09,890:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 7.6116s
2022-09-10 12:34:09,891:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:34:09,891:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:34:09,891:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:34:09,891:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:34:18,860:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:34:18,920:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:34:18,920:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:34:18,921:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:34:18,922:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:34:18,922:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:34:18,922:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:34:18,925:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:34:18,925:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317491
2022-09-10 12:34:19,036:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:34:19,037:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:34:19,038:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:34:19,038:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:34:19,038:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:34:19,131:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:34:19,131:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:34:19,131:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:34:19,131:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:34:19,132:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:34:20,027:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 2.5102, Train Acc: 0.1222,
                            Val Loss: 3.9078, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:20,031:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:34:21,014:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.98s, LR: 0.00050, Train Loss: 2.1914, Train Acc: 0.2111,
                            Val Loss: 5.8541, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:21,019:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:34:21,977:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 2.1075, Train Acc: 0.2556,
                            Val Loss: 141.9960, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:21,982:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:34:22,872:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 1.9647, Train Acc: 0.2889,
                            Val Loss: 1951.9043, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:22,877:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:34:23,802:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.93s, LR: 0.00050, Train Loss: 1.8458, Train Acc: 0.3444,
                            Val Loss: 23448.7585, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:23,806:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:34:24,651:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 1.5868, Train Acc: 0.4889,
                            Val Loss: 205771.3255, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:24,657:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:34:25,491:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.83s, LR: 0.00050, Train Loss: 1.3113, Train Acc: 0.5667,
                            Val Loss: 214580.6042, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:25,496:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 7
2022-09-10 12:34:26,369:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 1.2271, Train Acc: 0.6222,
                            Val Loss: 319965.7188, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:26,374:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 8
2022-09-10 12:34:27,208:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.83s, LR: 0.00050, Train Loss: 1.0824, Train Acc: 0.7222,
                            Val Loss: 132346.6406, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:27,212:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 9
2022-09-10 12:34:28,070:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.86s, LR: 0.00050, Train Loss: 0.9247, Train Acc: 0.7222,
                            Val Loss: 327474.6094, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:28,074:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 10
2022-09-10 12:34:35,896:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:34:35,960:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 5, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:34:35,960:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:34:35,960:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:34:35,961:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:34:35,961:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:34:35,961:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:34:35,964:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:34:35,964:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 316183
2022-09-10 12:34:36,081:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:34:36,082:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:34:36,083:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:34:36,083:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:34:36,083:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:34:36,160:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:34:36,160:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:34:36,160:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:34:36,160:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:34:36,161:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:34:37,065:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 2.5107, Train Acc: 0.2000,
                            Val Loss: 3.9273, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:37,070:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:34:37,954:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.88s, LR: 0.00050, Train Loss: 1.9030, Train Acc: 0.3000,
                            Val Loss: 47.9143, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:37,959:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:34:39,017:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 1.06s, LR: 0.00050, Train Loss: 1.8399, Train Acc: 0.3444,
                            Val Loss: 271.3689, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:39,021:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:34:39,925:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 1.6080, Train Acc: 0.4111,
                            Val Loss: 5577.8822, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:39,929:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:34:40,833:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.90s, LR: 0.00050, Train Loss: 1.6413, Train Acc: 0.4667,
                            Val Loss: 37485.1826, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:40,838:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:34:41,726:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 1.4511, Train Acc: 0.5222,
                            Val Loss: 191593.7852, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:41,731:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:34:42,582:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.85s, LR: 0.00050, Train Loss: 1.3594, Train Acc: 0.6000,
                            Val Loss: 386285.6250, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:42,586:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 7
2022-09-10 12:34:43,447:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.86s, LR: 0.00050, Train Loss: 1.4833, Train Acc: 0.4333,
                            Val Loss: 503571.9271, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:43,451:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 8
2022-09-10 12:34:44,292:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.84s, LR: 0.00050, Train Loss: 1.4211, Train Acc: 0.5222,
                            Val Loss: 520417.4323, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:34:44,296:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 9
2022-09-10 12:34:44,494:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:34:44,494:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:34:44,494:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0024hrs
2022-09-10 12:34:44,494:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.8998s
2022-09-10 12:34:44,496:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:34:44,496:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:34:44,496:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:34:44,496:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:35:33,652:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:35:33,713:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 5, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:35:33,713:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:35:33,714:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:35:33,714:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:35:33,714:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:35:33,714:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:35:33,717:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:35:33,718:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 316183
2022-09-10 12:35:33,834:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:35:33,835:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:35:33,836:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:35:33,836:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:35:33,836:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:35:33,911:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:35:33,911:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:35:33,911:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:35:33,911:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:35:33,913:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:35:34,890:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.98s, LR: 0.00050, Train Loss: 2.3019, Train Acc: 0.1222,
                            Val Loss: 2.3229, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:34,894:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:35:35,812:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.92s, LR: 0.00050, Train Loss: 2.2289, Train Acc: 0.2111,
                            Val Loss: 2.9988, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:35,816:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:35:36,779:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.96s, LR: 0.00050, Train Loss: 2.1500, Train Acc: 0.2000,
                            Val Loss: 79.9145, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:36,783:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:35:37,675:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 2.0345, Train Acc: 0.3000,
                            Val Loss: 2602.4307, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:37,680:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:35:38,566:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.89s, LR: 0.00050, Train Loss: 1.9769, Train Acc: 0.2778,
                            Val Loss: 6136.8628, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:38,570:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:35:39,443:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.87s, LR: 0.00050, Train Loss: 1.8445, Train Acc: 0.3556,
                            Val Loss: 60082.0449, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:39,447:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:35:54,605:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:35:54,670:main_CSL_graph_classification.py:328 -                 main(): {'L': 4, 'n_heads': 8, 'hidden_dim': 32, 'out_dim': 32, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:35:54,670:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:35:54,670:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:35:54,671:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:35:54,671:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:35:54,671:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:35:54,673:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:35:54,673:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 34939
2022-09-10 12:35:54,796:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:35:54,796:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:35:54,798:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:35:54,798:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:35:54,798:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:35:54,881:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:35:54,881:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:35:54,881:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:35:54,881:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:35:54,882:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:35:55,395:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 2.5345, Train Acc: 0.0556,
                            Val Loss: 3.1812, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:55,398:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:35:55,903:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.3066, Train Acc: 0.1111,
                            Val Loss: 9.2463, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:55,906:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:35:56,412:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 2.2609, Train Acc: 0.2000,
                            Val Loss: 35.6109, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:56,415:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:35:56,992:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.58s, LR: 0.00050, Train Loss: 2.2175, Train Acc: 0.2333,
                            Val Loss: 2445.7756, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:56,995:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:35:57,517:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.52s, LR: 0.00050, Train Loss: 2.1243, Train Acc: 0.2222,
                            Val Loss: 681.9959, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:57,520:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:35:58,010:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 2.0712, Train Acc: 0.2000,
                            Val Loss: 26220.4059, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:58,013:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:35:58,500:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 2.0487, Train Acc: 0.2111,
                            Val Loss: 249208.9375, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:58,503:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 7
2022-09-10 12:35:58,994:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 2.0056, Train Acc: 0.2111,
                            Val Loss: 99892.1003, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:58,997:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 8
2022-09-10 12:35:59,482:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 1.9564, Train Acc: 0.2667,
                            Val Loss: 88121.1576, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:59,485:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 9
2022-09-10 12:35:59,945:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00050, Train Loss: 1.8996, Train Acc: 0.2778,
                            Val Loss: 180402.1836, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:35:59,948:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 10
2022-09-10 12:35:59,985:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:35:59,985:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:35:59,986:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0015hrs
2022-09-10 12:35:59,986:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.5039s
2022-09-10 12:35:59,987:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:35:59,987:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:35:59,987:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:35:59,987:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:36:08,647:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:36:08,710:main_CSL_graph_classification.py:328 -                 main(): {'L': 4, 'n_heads': 8, 'hidden_dim': 32, 'out_dim': 32, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:36:08,710:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:36:08,710:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:36:08,711:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:36:08,711:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:36:08,711:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:36:08,713:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:36:08,713:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 34939
2022-09-10 12:36:08,826:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:36:08,827:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:36:08,828:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:36:08,828:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:36:08,828:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:36:08,904:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:36:08,904:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:36:08,904:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:36:08,904:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:36:08,905:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:36:09,401:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.5345, Train Acc: 0.0556,
                            Val Loss: 3.1812, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:09,404:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:36:09,900:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.3066, Train Acc: 0.1111,
                            Val Loss: 9.2463, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:09,904:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:36:10,400:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.2609, Train Acc: 0.2000,
                            Val Loss: 35.6109, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:10,404:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:36:10,975:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.57s, LR: 0.00050, Train Loss: 2.2175, Train Acc: 0.2333,
                            Val Loss: 2445.7756, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:10,978:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:36:11,475:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.1243, Train Acc: 0.2222,
                            Val Loss: 681.9959, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:11,478:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:36:11,980:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.0712, Train Acc: 0.2000,
                            Val Loss: 26220.4059, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:11,983:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:36:12,491:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 2.0487, Train Acc: 0.2111,
                            Val Loss: 249208.9375, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:12,494:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 7
2022-09-10 12:36:12,959:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00050, Train Loss: 2.0056, Train Acc: 0.2111,
                            Val Loss: 99892.1003, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:12,962:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 8
2022-09-10 12:36:13,438:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 1.9564, Train Acc: 0.2667,
                            Val Loss: 88121.1576, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:13,441:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 9
2022-09-10 12:36:13,943:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 1.8996, Train Acc: 0.2778,
                            Val Loss: 180402.1836, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:13,946:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 10
2022-09-10 12:36:14,440:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 1.8444, Train Acc: 0.3556,
                            Val Loss: 112014.2656, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:14,443:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 11
2022-09-10 12:36:14,953:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 1.8884, Train Acc: 0.3222,
                            Val Loss: 206311.5000, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:14,956:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 12
2022-09-10 12:36:15,443:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00025, Train Loss: 1.8567, Train Acc: 0.3111,
                            Val Loss: 169792.5000, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:15,446:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 13
2022-09-10 12:36:15,918:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00025, Train Loss: 1.7643, Train Acc: 0.3444,
                            Val Loss: 98263.0469, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:15,922:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 14
2022-09-10 12:36:16,375:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.45s, LR: 0.00025, Train Loss: 1.7165, Train Acc: 0.3556,
                            Val Loss: 17413.9508, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:16,378:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 15
2022-09-10 12:36:16,855:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00025, Train Loss: 1.7693, Train Acc: 0.4000,
                            Val Loss: 59360.7077, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:16,858:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 16
2022-09-10 12:36:17,337:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00025, Train Loss: 1.7540, Train Acc: 0.3889,
                            Val Loss: 18756.7371, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:17,340:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 17
2022-09-10 12:36:17,800:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00025, Train Loss: 1.7901, Train Acc: 0.3333,
                            Val Loss: 203192.3737, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:17,803:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 18
2022-09-10 12:36:18,258:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.45s, LR: 0.00025, Train Loss: 1.7195, Train Acc: 0.3667,
                            Val Loss: 177362.7617, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:18,261:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 19
2022-09-10 12:36:18,720:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00025, Train Loss: 1.6962, Train Acc: 0.3889,
                            Val Loss: 40523.9984, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:18,723:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 20
2022-09-10 12:36:19,215:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00025, Train Loss: 1.7185, Train Acc: 0.3333,
                            Val Loss: 94146.6719, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:19,218:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 21
2022-09-10 12:36:19,693:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00025, Train Loss: 1.6524, Train Acc: 0.3333,
                            Val Loss: 94554.6823, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:19,696:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 22
2022-09-10 12:36:20,156:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00025, Train Loss: 1.6489, Train Acc: 0.3556,
                            Val Loss: 26862.1488, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:20,159:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 23
2022-09-10 12:36:20,620:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00013, Train Loss: 1.6934, Train Acc: 0.3778,
                            Val Loss: 141783.4948, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:20,623:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 24
2022-09-10 12:36:21,077:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.45s, LR: 0.00013, Train Loss: 1.6191, Train Acc: 0.3889,
                            Val Loss: 81176.1992, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:21,080:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 25
2022-09-10 12:36:21,542:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00013, Train Loss: 1.6855, Train Acc: 0.3444,
                            Val Loss: 25509.8102, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:21,545:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 26
2022-09-10 12:36:22,003:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00013, Train Loss: 1.6294, Train Acc: 0.3889,
                            Val Loss: 24926.2967, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:22,007:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 27
2022-09-10 12:36:42,303:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:36:42,368:main_CSL_graph_classification.py:328 -                 main(): {'L': 4, 'n_heads': 8, 'hidden_dim': 32, 'out_dim': 32, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'num_initials': 20, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:36:42,368:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:36:42,368:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:36:42,369:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:36:42,369:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:36:42,370:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:36:42,371:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:36:42,371:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 35671
2022-09-10 12:36:42,496:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:36:42,497:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:36:42,500:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:36:42,500:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:36:42,500:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:36:42,613:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:36:42,613:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:36:42,614:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:36:42,614:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:36:42,615:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:36:43,113:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.4425, Train Acc: 0.0778,
                            Val Loss: 2.5368, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:43,116:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:36:43,596:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 2.2986, Train Acc: 0.0556,
                            Val Loss: 6.5426, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:43,599:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:36:44,103:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.1459, Train Acc: 0.1556,
                            Val Loss: 43.8891, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:44,106:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:36:44,653:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.55s, LR: 0.00050, Train Loss: 2.1290, Train Acc: 0.1778,
                            Val Loss: 567.4426, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:44,656:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:36:45,153:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 2.0770, Train Acc: 0.2444,
                            Val Loss: 9303.4266, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:45,156:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:36:45,640:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 1.9730, Train Acc: 0.2333,
                            Val Loss: 38606.7165, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:45,643:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:36:46,194:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.55s, LR: 0.00050, Train Loss: 2.0031, Train Acc: 0.2556,
                            Val Loss: 167381.0612, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:46,197:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 7
2022-09-10 12:36:46,675:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 2.0031, Train Acc: 0.3000,
                            Val Loss: 66480.7891, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:46,679:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 8
2022-09-10 12:36:47,174:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 1.9432, Train Acc: 0.2333,
                            Val Loss: 77790.1953, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:47,178:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 9
2022-09-10 12:36:47,658:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 1.8642, Train Acc: 0.3333,
                            Val Loss: 55308.3535, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:36:47,661:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 10
2022-09-10 12:37:04,266:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:37:04,329:main_CSL_graph_classification.py:328 -                 main(): {'L': 4, 'n_heads': 8, 'hidden_dim': 32, 'out_dim': 32, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'n_gape': 3, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:37:04,329:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:37:04,329:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:37:04,330:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:37:04,330:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:37:04,330:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:37:04,332:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:37:04,333:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 36514
2022-09-10 12:37:04,451:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:37:04,452:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:37:04,453:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:37:04,453:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:37:04,453:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:37:04,455:main_CSL_graph_classification.py:86 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-10 12:37:04,699:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:37:04,699:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:37:04,699:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:37:04,699:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:37:04,700:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:37:05,254:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.55s, LR: 0.00050, Train Loss: 2.2775, Train Acc: 0.2000,
                            Val Loss: 2.0104, Val Acc: 0.3000, Test Acc: 0.3000
2022-09-10 12:37:05,257:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:37:05,760:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 1.8542, Train Acc: 0.3889,
                            Val Loss: 1.6863, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-10 12:37:05,764:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:37:06,262:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 1.6779, Train Acc: 0.4556,
                            Val Loss: 1.5036, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-10 12:37:06,265:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:37:06,776:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 1.4418, Train Acc: 0.5556,
                            Val Loss: 1.3068, Val Acc: 0.6000, Test Acc: 0.6000
2022-09-10 12:37:06,780:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:37:07,290:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 1.2961, Train Acc: 0.5444,
                            Val Loss: 1.1809, Val Acc: 0.6000, Test Acc: 0.6000
2022-09-10 12:37:07,294:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:37:07,856:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.56s, LR: 0.00050, Train Loss: 1.2201, Train Acc: 0.5778,
                            Val Loss: 1.1437, Val Acc: 0.6000, Test Acc: 0.6000
2022-09-10 12:37:07,860:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:37:08,358:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 1.1679, Train Acc: 0.5889,
                            Val Loss: 1.0477, Val Acc: 0.6000, Test Acc: 0.6000
2022-09-10 12:37:08,361:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 7
2022-09-10 12:37:08,830:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 1.1005, Train Acc: 0.6111,
                            Val Loss: 1.0096, Val Acc: 0.6000, Test Acc: 0.6000
2022-09-10 12:37:08,833:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 8
2022-09-10 12:37:09,329:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 1.0094, Train Acc: 0.6889,
                            Val Loss: 0.9576, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:09,333:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 9
2022-09-10 12:37:09,823:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.9897, Train Acc: 0.6889,
                            Val Loss: 0.9333, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:09,826:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 10
2022-09-10 12:37:10,295:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.9464, Train Acc: 0.6222,
                            Val Loss: 0.8584, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:10,298:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 11
2022-09-10 12:37:10,836:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.54s, LR: 0.00050, Train Loss: 0.8917, Train Acc: 0.7000,
                            Val Loss: 0.8055, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:10,840:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 12
2022-09-10 12:37:11,328:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.8704, Train Acc: 0.6889,
                            Val Loss: 0.7187, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:11,332:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 13
2022-09-10 12:37:11,818:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.7980, Train Acc: 0.7000,
                            Val Loss: 0.6933, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:11,821:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 14
2022-09-10 12:37:12,330:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 0.7892, Train Acc: 0.7000,
                            Val Loss: 0.6967, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:12,333:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 15
2022-09-10 12:37:12,803:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.7576, Train Acc: 0.7000,
                            Val Loss: 0.6924, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:12,806:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 16
2022-09-10 12:37:13,296:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.7344, Train Acc: 0.7000,
                            Val Loss: 0.6841, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:13,300:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 17
2022-09-10 12:37:13,790:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.6716, Train Acc: 0.7333,
                            Val Loss: 0.6577, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:13,793:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 18
2022-09-10 12:37:14,266:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.7112, Train Acc: 0.7222,
                            Val Loss: 0.6236, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:14,269:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 19
2022-09-10 12:37:14,774:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 0.7185, Train Acc: 0.7333,
                            Val Loss: 0.6446, Val Acc: 0.7000, Test Acc: 0.7000
2022-09-10 12:37:14,778:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 20
2022-09-10 12:37:15,261:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.7123, Train Acc: 0.7667,
                            Val Loss: 0.6326, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:15,264:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 21
2022-09-10 12:37:15,769:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 0.6687, Train Acc: 0.7778,
                            Val Loss: 0.6104, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:15,773:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 22
2022-09-10 12:37:16,277:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.50s, LR: 0.00050, Train Loss: 0.6669, Train Acc: 0.7667,
                            Val Loss: 0.6103, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:16,280:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 23
2022-09-10 12:37:16,773:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.6679, Train Acc: 0.7556,
                            Val Loss: 0.6075, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:16,776:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 24
2022-09-10 12:37:17,262:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.6198, Train Acc: 0.8000,
                            Val Loss: 0.6125, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:17,265:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 25
2022-09-10 12:37:17,730:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.5883, Train Acc: 0.8000,
                            Val Loss: 0.5472, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:17,734:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 26
2022-09-10 12:37:18,196:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00050, Train Loss: 0.5558, Train Acc: 0.8000,
                            Val Loss: 0.5386, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:18,199:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 27
2022-09-10 12:37:18,680:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.5331, Train Acc: 0.8000,
                            Val Loss: 0.4681, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:18,683:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 28
2022-09-10 12:37:19,195:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 0.5614, Train Acc: 0.8000,
                            Val Loss: 0.4637, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:19,198:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 29
2022-09-10 12:37:19,679:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.5376, Train Acc: 0.8000,
                            Val Loss: 0.4362, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:19,682:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 30
2022-09-10 12:37:20,147:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00050, Train Loss: 0.5175, Train Acc: 0.8000,
                            Val Loss: 0.4358, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:20,150:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 31
2022-09-10 12:37:20,628:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.4669, Train Acc: 0.8000,
                            Val Loss: 0.4087, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:20,631:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 32
2022-09-10 12:37:21,125:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.4272, Train Acc: 0.8000,
                            Val Loss: 0.3965, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:21,128:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 33
2022-09-10 12:37:21,610:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.4246, Train Acc: 0.8000,
                            Val Loss: 0.3750, Val Acc: 0.8000, Test Acc: 0.8000
2022-09-10 12:37:21,613:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 34
2022-09-10 12:37:22,090:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.4095, Train Acc: 0.8111,
                            Val Loss: 0.3436, Val Acc: 0.9000, Test Acc: 0.9000
2022-09-10 12:37:22,094:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 35
2022-09-10 12:37:22,559:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.3705, Train Acc: 0.8222,
                            Val Loss: 0.3424, Val Acc: 0.9000, Test Acc: 0.9000
2022-09-10 12:37:22,563:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 36
2022-09-10 12:37:23,046:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.4338, Train Acc: 0.8111,
                            Val Loss: 0.2911, Val Acc: 0.9000, Test Acc: 0.9000
2022-09-10 12:37:23,050:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 37
2022-09-10 12:37:23,572:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.52s, LR: 0.00050, Train Loss: 0.3070, Train Acc: 0.8778,
                            Val Loss: 0.3227, Val Acc: 0.9000, Test Acc: 0.9000
2022-09-10 12:37:23,575:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 38
2022-09-10 12:37:24,058:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.48s, LR: 0.00050, Train Loss: 0.3164, Train Acc: 0.8778,
                            Val Loss: 0.2168, Val Acc: 0.9000, Test Acc: 0.9000
2022-09-10 12:37:24,061:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 39
2022-09-10 12:37:24,526:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.2465, Train Acc: 0.9333,
                            Val Loss: 0.1755, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:24,529:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 40
2022-09-10 12:37:24,996:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.2947, Train Acc: 0.9444,
                            Val Loss: 0.1363, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:24,999:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 41
2022-09-10 12:37:25,492:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.3738, Train Acc: 0.9111,
                            Val Loss: 0.1206, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:25,495:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 42
2022-09-10 12:37:25,981:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.2065, Train Acc: 0.9333,
                            Val Loss: 0.0674, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:25,984:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 43
2022-09-10 12:37:26,477:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.49s, LR: 0.00050, Train Loss: 0.3628, Train Acc: 0.9111,
                            Val Loss: 0.1083, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:26,480:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 44
2022-09-10 12:37:26,991:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.51s, LR: 0.00050, Train Loss: 0.3505, Train Acc: 0.9111,
                            Val Loss: 0.1150, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:26,994:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 45
2022-09-10 12:37:27,462:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.47s, LR: 0.00050, Train Loss: 0.1737, Train Acc: 0.9556,
                            Val Loss: 0.0468, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:27,465:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 46
2022-09-10 12:37:27,930:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 0.46s, LR: 0.00050, Train Loss: 0.2084, Train Acc: 0.8889,
                            Val Loss: 0.0465, Val Acc: 1.0000, Test Acc: 1.0000
2022-09-10 12:37:27,933:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 47
2022-09-10 12:37:28,006:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:37:28,006:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:37:28,006:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0066hrs
2022-09-10 12:37:28,007:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 0.4915s
2022-09-10 12:37:28,010:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:37:28,010:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:37:28,010:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:37:28,010:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:39:49,195:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:39:49,261:main_CSL_graph_classification.py:328 -                 main(): {'L': 6, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 20, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 5, 'rw_pos_enc': False, 'num_initials': 10, 'power_method': True, 'power_iters': 5, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CSL', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'num_node_type': 41, 'num_edge_type': 164, 'n_classes': 10}
2022-09-10 12:39:49,261:main_CSL_graph_classification.py:329 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 5, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 18, 'seed_array': [41]}
2022-09-10 12:39:49,261:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:39:49,262:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:39:49,262:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:39:49,262:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:39:49,262:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:39:49,265:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:39:49,266:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 317491
2022-09-10 12:39:49,381:main_CSL_graph_classification.py:77 -   train_val_pipeline(): RUN NUMBER: 0
2022-09-10 12:39:49,381:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:39:49,382:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:39:49,382:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:39:49,382:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:39:49,382:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:39:49,386:main_CSL_graph_classification.py:102 -   train_val_pipeline(): Training Graphs: 90
2022-09-10 12:39:49,386:main_CSL_graph_classification.py:103 -   train_val_pipeline(): Validation Graphs: 30
2022-09-10 12:39:49,386:main_CSL_graph_classification.py:104 -   train_val_pipeline(): Test Graphs: 30
2022-09-10 12:39:49,386:main_CSL_graph_classification.py:105 -   train_val_pipeline(): Number of Classes: 10
2022-09-10 12:39:49,388:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 0
2022-09-10 12:39:51,795:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 2.41s, LR: 0.00050, Train Loss: 3.4935, Train Acc: 0.1111,
                            Val Loss: 8.3784, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:39:51,799:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 1
2022-09-10 12:39:54,154:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 2.35s, LR: 0.00050, Train Loss: 3.5710, Train Acc: 0.0444,
                            Val Loss: 61.1366, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:39:54,159:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 2
2022-09-10 12:39:56,403:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 2.24s, LR: 0.00050, Train Loss: 3.1789, Train Acc: 0.0667,
                            Val Loss: 346.4213, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:39:56,408:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 3
2022-09-10 12:39:58,694:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 2.29s, LR: 0.00050, Train Loss: 2.6846, Train Acc: 0.0667,
                            Val Loss: 15551.6286, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:39:58,698:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 4
2022-09-10 12:40:00,964:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 2.27s, LR: 0.00050, Train Loss: 2.7554, Train Acc: 0.1000,
                            Val Loss: 40359.8704, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:40:00,968:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 5
2022-09-10 12:40:03,269:main_CSL_graph_classification.py:181 -   train_val_pipeline(): 	Time: 2.30s, LR: 0.00050, Train Loss: 2.6770, Train Acc: 0.0556,
                            Val Loss: 20260.4180, Val Acc: 0.1000, Test Acc: 0.1000
2022-09-10 12:40:03,273:main_CSL_graph_classification.py:143 -   train_val_pipeline(): Epoch 6
2022-09-10 12:40:03,986:main_CSL_graph_classification.py:228 -   train_val_pipeline(): ------------------------------------------------------------------------------------------
2022-09-10 12:40:03,986:main_CSL_graph_classification.py:229 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:40:03,986:main_CSL_graph_classification.py:232 -   train_val_pipeline(): TOTAL TIME TAKEN: 0.0041hrs
2022-09-10 12:40:03,986:main_CSL_graph_classification.py:233 -   train_val_pipeline(): AVG TIME PER EPOCH: 2.3101s
2022-09-10 12:40:03,990:main_CSL_graph_classification.py:236 -   train_val_pipeline(): 


FINAL RESULTS

TEST ACCURACY averaged: nan with s.d. nan
2022-09-10 12:40:03,990:main_CSL_graph_classification.py:237 -   train_val_pipeline(): 
All splits Test Accuracies: []

2022-09-10 12:40:03,990:main_CSL_graph_classification.py:238 -   train_val_pipeline(): 


FINAL RESULTS

TRAIN ACCURACY averaged: nan with s.d. nan
2022-09-10 12:40:03,990:main_CSL_graph_classification.py:239 -   train_val_pipeline(): 
All splits Train Accuracies: []

2022-09-10 12:40:54,832:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:40:59,340:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:40:59,340:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:41:05,124:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:41:09,596:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:41:09,596:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:41:09,596:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:41:09,597:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:41:09,597:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:41:09,597:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:41:09,602:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:41:09,602:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:41:09,602:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:41:09,603:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:41:09,603:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:41:09,603:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:41:09,603:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:41:09,624:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:41:09,624:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:41:09,625:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:41:09,625:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:41:09,627:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:42:13,123:main_CYCLES_graph_classification.py:223 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 12:42:13,123:main_CYCLES_graph_classification.py:224 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:42:15,274:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:42:19,662:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:42:19,663:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:42:19,663:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:42:19,664:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:42:19,664:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:42:19,664:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:42:19,668:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:42:19,669:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:42:19,669:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:42:19,669:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:42:19,670:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:42:19,670:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:42:19,670:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:42:19,690:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:42:19,690:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:42:19,691:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:42:19,691:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:42:19,695:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:42:50,424:main_CYCLES_graph_classification.py:223 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 12:42:50,425:main_CYCLES_graph_classification.py:224 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:44:24,996:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:44:29,518:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 5, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:44:29,518:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:44:29,518:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:44:29,519:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:44:29,519:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:44:29,519:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:44:29,519:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:44:29,524:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:44:29,525:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:44:29,525:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:44:29,525:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:44:29,526:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:44:29,526:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:44:29,526:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:44:29,526:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:44:29,544:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:44:29,544:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:44:29,544:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:44:29,544:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:44:29,547:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:45:10,068:main_CYCLES_graph_classification.py:223 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 12:45:10,068:main_CYCLES_graph_classification.py:224 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:45:12,097:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:45:16,420:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 5, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:45:16,420:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:45:16,420:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:45:16,421:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:45:16,421:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:45:16,421:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:45:16,421:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:45:16,426:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:45:16,427:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:45:16,427:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:45:16,427:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:45:16,427:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:45:16,427:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:45:16,427:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:45:16,427:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:45:16,448:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:45:16,448:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:45:16,448:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:45:16,448:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:45:16,450:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:45:37,400:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:45:41,672:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 5, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:45:41,672:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:45:41,672:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:45:41,673:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:45:41,673:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:45:41,673:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:45:41,673:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:45:41,678:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:45:41,678:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:45:41,679:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:45:41,679:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:45:41,679:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:45:41,679:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:45:41,679:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:45:41,679:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:45:41,698:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:45:41,698:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:45:41,698:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:45:41,698:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:45:41,700:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:45:54,904:main_CYCLES_graph_classification.py:223 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 12:45:54,904:main_CYCLES_graph_classification.py:224 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:46:02,820:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:46:07,194:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 5, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:46:07,194:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:46:07,194:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:46:07,195:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:46:07,195:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:46:07,195:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:46:07,195:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:46:07,199:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:46:07,200:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:46:07,200:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:46:07,200:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:46:07,201:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:46:07,201:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:46:07,201:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:46:07,201:pe_layer.py:137 -             __init__(): Using power method with 5 iterations
2022-09-10 12:46:07,220:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:46:07,220:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:46:07,220:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:46:07,220:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:46:07,222:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:47:36,908:main_CYCLES_graph_classification.py:223 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 12:47:36,908:main_CYCLES_graph_classification.py:224 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:47:43,712:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:47:48,120:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': True, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 1, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:47:48,120:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:47:48,120:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:47:48,121:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:47:48,121:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:47:48,121:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:47:48,121:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:47:48,126:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:47:48,126:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:47:48,126:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:47:48,127:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 12:47:48,127:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:47:48,127:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:47:48,127:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:47:48,127:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:47:48,147:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:47:48,147:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:47:48,148:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:47:48,148:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:47:48,150:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:48:06,912:main_CYCLES_graph_classification.py:223 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 12:48:06,913:main_CYCLES_graph_classification.py:224 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 12:49:16,043:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:49:20,444:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 1, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:49:20,444:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:49:20,445:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:49:20,445:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:49:20,445:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:49:20,445:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:49:20,445:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:49:20,451:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:49:20,451:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:49:20,452:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:49:20,452:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:49:20,452:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:49:20,452:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:49:20,452:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:49:20,452:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:49:20,457:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 12:49:30,112:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:9.659936904907227
2022-09-10 12:49:30,125:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:49:30,126:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:49:30,126:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:49:30,126:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:49:30,128:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:51:23,679:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:51:28,109:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 1, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:51:28,109:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:51:28,109:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:51:28,110:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:51:28,110:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:51:28,110:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:51:28,110:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:51:28,115:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:51:28,116:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:51:28,116:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:51:28,116:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:51:28,117:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:51:28,117:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:51:28,117:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:51:28,117:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:51:28,122:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 12:51:37,892:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:9.77617883682251
2022-09-10 12:51:37,907:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:51:37,908:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:51:37,908:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:51:37,908:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:51:37,909:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:52:06,718:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:52:11,019:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 1, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:52:11,019:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:52:11,019:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:52:11,020:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:52:11,020:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:52:11,020:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:52:11,020:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:52:11,025:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:52:11,026:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:52:11,026:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:52:11,026:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:52:11,026:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:52:11,026:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:52:11,026:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:52:11,026:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:52:11,031:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 12:52:20,570:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:9.544279098510742
2022-09-10 12:52:20,584:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:52:20,584:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:52:20,584:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:52:20,584:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:52:20,586:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:52:44,558:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:52:48,879:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 1, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:52:48,879:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:52:48,879:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:52:48,880:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:52:48,880:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:52:48,880:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:52:48,880:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:52:48,885:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:52:48,886:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:52:48,886:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:52:48,886:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:52:48,887:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:52:48,887:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:52:48,887:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:52:48,887:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:52:48,892:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 12:52:58,362:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:9.476140975952148
2022-09-10 12:52:58,376:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:52:58,376:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:52:58,377:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:52:58,377:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:52:58,378:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:53:13,692:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:53:17,987:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 1, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:53:17,987:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 12:53:17,987:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:53:17,988:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:53:17,989:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:53:17,989:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:53:17,989:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:53:17,993:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:53:17,994:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:53:17,994:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:53:17,994:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:53:17,995:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:53:17,995:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:53:17,995:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:53:17,995:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:53:18,000:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 12:53:27,477:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:9.482335090637207
2022-09-10 12:53:27,491:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:53:27,492:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:53:27,492:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:53:27,492:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:53:27,494:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:55:32,589:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 12:55:36,889:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': True, 'power_iters': 1, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 12:55:36,889:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-10 12:55:36,889:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:55:36,890:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:55:36,890:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:55:36,890:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:55:36,890:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:55:36,895:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 12:55:36,896:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 12:55:36,896:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 12:55:36,896:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 12:55:36,897:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 12:55:36,897:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 12:55:36,897:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 12:55:36,897:pe_layer.py:137 -             __init__(): Using power method with 1 iterations
2022-09-10 12:55:36,902:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 12:55:46,442:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:9.545792818069458
2022-09-10 12:55:46,457:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 12:55:46,457:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 12:55:46,457:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 12:55:46,457:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 12:55:46,459:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 12:57:40,632:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_12h55m36s_on_Sep_10_2022/MODELS_
2022-09-10 12:57:40,634:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 114.17s, LR: 0.00050, Train Loss: 0.7039, Train Acc: 0.5250,
                            Val Loss: 2.3216, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-10 12:57:40,634:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 12:59:36,041:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 115.41s, LR: 0.00050, Train Loss: 0.6988, Train Acc: 0.5400,
                            Val Loss: 1.9276, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-10 12:59:36,041:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 13:01:33,454:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5004 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_12h55m36s_on_Sep_10_2022/MODELS_
2022-09-10 13:01:33,454:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 117.41s, LR: 0.00050, Train Loss: 0.6903, Train Acc: 0.5450,
                            Val Loss: 1.2956, Val Acc: 0.5000, Test Acc: 0.5004
2022-09-10 13:01:33,454:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 13:01:51,115:main_CYCLES_graph_classification.py:223 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 13:01:51,115:main_CYCLES_graph_classification.py:224 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 13:02:50,685:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 13:02:55,191:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 13:02:55,191:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41]}
2022-09-10 13:02:55,192:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:02:55,193:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:02:55,193:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:02:55,193:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:02:55,198:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 13:02:55,199:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 13:02:55,199:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 13:02:55,199:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:02:55,200:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:02:55,200:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:02:55,200:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:02:55,205:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 13:07:21,707:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:266.50852513313293
2022-09-10 13:07:21,721:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 13:07:21,722:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 13:07:21,722:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 13:07:21,722:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 13:07:21,724:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 13:07:50,012:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 13:07:54,498:main_CYCLES_graph_classification.py:349 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 13:07:54,498:main_CYCLES_graph_classification.py:350 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-10 13:07:54,499:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:07:54,499:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:07:54,499:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:07:54,499:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:07:54,504:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 13:07:54,505:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 13:07:54,505:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 13:07:54,506:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:07:54,506:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:07:54,506:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:07:54,506:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:07:54,511:main_CYCLES_graph_classification.py:72 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 13:10:29,929:main_CYCLES_graph_classification.py:80 -   train_val_pipeline(): Time PE:155.42361187934875
2022-09-10 13:10:29,944:main_CYCLES_graph_classification.py:126 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 13:10:29,944:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 13:10:29,944:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 13:10:29,944:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 13:10:29,946:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 13:10:51,841:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5181 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h07m54s_on_Sep_10_2022/MODELS_
2022-09-10 13:10:51,842:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.90s, LR: 0.00050, Train Loss: 0.8355, Train Acc: 0.5250,
                            Val Loss: 1.0779, Val Acc: 0.5110, Test Acc: 0.5181
2022-09-10 13:10:51,843:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 13:11:13,923:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5429 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h07m54s_on_Sep_10_2022/MODELS_
2022-09-10 13:11:13,923:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.08s, LR: 0.00050, Train Loss: 0.6814, Train Acc: 0.6200,
                            Val Loss: 1.3091, Val Acc: 0.5280, Test Acc: 0.5429
2022-09-10 13:11:13,923:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 13:11:35,285:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.36s, LR: 0.00050, Train Loss: 0.5577, Train Acc: 0.7250,
                            Val Loss: 1.0876, Val Acc: 0.5090, Test Acc: 0.5132
2022-09-10 13:11:35,285:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 13:11:56,356:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.5794 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h07m54s_on_Sep_10_2022/MODELS_
2022-09-10 13:11:56,356:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.07s, LR: 0.00050, Train Loss: 0.5546, Train Acc: 0.7250,
                            Val Loss: 0.7631, Val Acc: 0.5530, Test Acc: 0.5794
2022-09-10 13:11:56,356:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 13:12:17,745:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6883 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h07m54s_on_Sep_10_2022/MODELS_
2022-09-10 13:12:17,745:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 21.39s, LR: 0.00050, Train Loss: 0.5782, Train Acc: 0.6900,
                            Val Loss: 0.6237, Val Acc: 0.6770, Test Acc: 0.6883
2022-09-10 13:12:17,745:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 13:12:40,702:main_CYCLES_graph_classification.py:170 -   train_val_pipeline(): Saving best model with test accuracy: 0.6914 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h07m54s_on_Sep_10_2022/MODELS_
2022-09-10 13:12:40,703:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 22.96s, LR: 0.00050, Train Loss: 0.5014, Train Acc: 0.7450,
                            Val Loss: 0.6343, Val Acc: 0.7090, Test Acc: 0.6914
2022-09-10 13:12:40,703:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 13:13:04,455:main_CYCLES_graph_classification.py:192 -   train_val_pipeline(): 	Time: 23.75s, LR: 0.00050, Train Loss: 0.5356, Train Acc: 0.7300,
                            Val Loss: 1.5102, Val Acc: 0.5250, Test Acc: 0.5237
2022-09-10 13:13:04,455:main_CYCLES_graph_classification.py:154 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 13:14:00,980:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 13:14:07,176:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 13:14:11,742:main_CYCLES_graph_classification.py:350 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 13:14:11,742:main_CYCLES_graph_classification.py:351 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-10 13:14:11,742:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:14:11,743:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:14:11,743:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:14:11,743:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:14:11,748:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 13:14:11,749:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 13:14:11,749:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 13:14:11,749:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:14:11,750:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:14:11,750:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:14:11,750:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:16:29,038:main_CYCLES_graph_classification.py:73 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 13:16:38,562:main_CYCLES_graph_classification.py:81 -   train_val_pipeline(): Time PE:146.8130443096161
2022-09-10 13:16:38,577:main_CYCLES_graph_classification.py:127 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 13:16:38,577:main_CYCLES_graph_classification.py:128 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 13:16:38,577:main_CYCLES_graph_classification.py:129 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 13:16:38,577:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 13:16:38,579:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 13:16:59,869:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.5008 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:16:59,870:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.29s, LR: 0.00050, Train Loss: 0.7780, Train Acc: 0.5050,
                            Val Loss: 0.7901, Val Acc: 0.5010, Test Acc: 0.5008
2022-09-10 13:16:59,870:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 13:17:22,666:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.5227 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:17:22,666:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 22.80s, LR: 0.00050, Train Loss: 0.6312, Train Acc: 0.6700,
                            Val Loss: 0.8412, Val Acc: 0.5250, Test Acc: 0.5227
2022-09-10 13:17:22,666:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 13:17:43,958:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.7138 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:17:43,958:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.29s, LR: 0.00050, Train Loss: 0.5128, Train Acc: 0.7450,
                            Val Loss: 0.5817, Val Acc: 0.7110, Test Acc: 0.7138
2022-09-10 13:17:43,959:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 13:18:05,302:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.7366 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:18:05,302:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.34s, LR: 0.00050, Train Loss: 0.4077, Train Acc: 0.8200,
                            Val Loss: 0.5432, Val Acc: 0.7540, Test Acc: 0.7366
2022-09-10 13:18:05,302:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 13:18:26,649:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.35s, LR: 0.00050, Train Loss: 0.3115, Train Acc: 0.8750,
                            Val Loss: 0.7540, Val Acc: 0.6830, Test Acc: 0.7045
2022-09-10 13:18:26,649:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 13:18:48,043:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.8247 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:18:48,043:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.39s, LR: 0.00050, Train Loss: 0.2446, Train Acc: 0.9200,
                            Val Loss: 0.4809, Val Acc: 0.8080, Test Acc: 0.8247
2022-09-10 13:18:48,043:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 13:19:09,121:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.9237 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:19:09,122:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.08s, LR: 0.00050, Train Loss: 0.2150, Train Acc: 0.9200,
                            Val Loss: 0.2733, Val Acc: 0.9090, Test Acc: 0.9237
2022-09-10 13:19:09,122:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 13:19:31,107:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.9400 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:19:31,107:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.99s, LR: 0.00050, Train Loss: 0.1919, Train Acc: 0.9400,
                            Val Loss: 0.2156, Val Acc: 0.9360, Test Acc: 0.9400
2022-09-10 13:19:31,107:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 13:19:54,212:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 23.10s, LR: 0.00050, Train Loss: 0.1810, Train Acc: 0.9300,
                            Val Loss: 0.2656, Val Acc: 0.9000, Test Acc: 0.9223
2022-09-10 13:19:54,213:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 13:20:17,855:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 23.64s, LR: 0.00050, Train Loss: 0.1471, Train Acc: 0.9350,
                            Val Loss: 0.2537, Val Acc: 0.9260, Test Acc: 0.9380
2022-09-10 13:20:17,856:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 13:20:40,496:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.9449 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:20:40,497:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 22.64s, LR: 0.00050, Train Loss: 0.1867, Train Acc: 0.9550,
                            Val Loss: 0.2142, Val Acc: 0.9430, Test Acc: 0.9449
2022-09-10 13:20:40,497:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 13:21:03,449:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 22.95s, LR: 0.00050, Train Loss: 0.1778, Train Acc: 0.9500,
                            Val Loss: 0.3161, Val Acc: 0.9110, Test Acc: 0.9230
2022-09-10 13:21:03,450:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 13:21:27,554:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.9548 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:21:27,555:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 24.10s, LR: 0.00050, Train Loss: 0.1539, Train Acc: 0.9600,
                            Val Loss: 0.2085, Val Acc: 0.9470, Test Acc: 0.9548
2022-09-10 13:21:27,555:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 13:21:49,117:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.9576 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:21:49,117:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.56s, LR: 0.00050, Train Loss: 0.1368, Train Acc: 0.9550,
                            Val Loss: 0.2018, Val Acc: 0.9520, Test Acc: 0.9576
2022-09-10 13:21:49,117:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 13:22:10,105:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 20.99s, LR: 0.00050, Train Loss: 0.1277, Train Acc: 0.9550,
                            Val Loss: 0.2215, Val Acc: 0.9450, Test Acc: 0.9449
2022-09-10 13:22:10,106:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 13:22:31,598:main_CYCLES_graph_classification.py:171 -   train_val_pipeline(): Saving best model with test accuracy: 0.9614 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h14m11s_on_Sep_10_2022/MODELS_
2022-09-10 13:22:31,598:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.49s, LR: 0.00050, Train Loss: 0.1318, Train Acc: 0.9500,
                            Val Loss: 0.2088, Val Acc: 0.9560, Test Acc: 0.9614
2022-09-10 13:22:31,598:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 13:22:53,293:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.69s, LR: 0.00050, Train Loss: 0.1172, Train Acc: 0.9400,
                            Val Loss: 0.5226, Val Acc: 0.8650, Test Acc: 0.8669
2022-09-10 13:22:53,294:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 13:23:14,407:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.11s, LR: 0.00050, Train Loss: 0.0908, Train Acc: 0.9700,
                            Val Loss: 0.2766, Val Acc: 0.9240, Test Acc: 0.9312
2022-09-10 13:23:14,407:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 13:23:35,430:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.02s, LR: 0.00050, Train Loss: 0.1339, Train Acc: 0.9450,
                            Val Loss: 0.2985, Val Acc: 0.9220, Test Acc: 0.9336
2022-09-10 13:23:35,430:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 13:23:56,548:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 21.12s, LR: 0.00050, Train Loss: 0.1469, Train Acc: 0.9400,
                            Val Loss: 0.3396, Val Acc: 0.8890, Test Acc: 0.8941
2022-09-10 13:23:56,548:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 13:24:18,924:main_CYCLES_graph_classification.py:193 -   train_val_pipeline(): 	Time: 22.38s, LR: 0.00050, Train Loss: 0.1719, Train Acc: 0.9400,
                            Val Loss: 0.4044, Val Acc: 0.8860, Test Acc: 0.9075
2022-09-10 13:24:18,925:main_CYCLES_graph_classification.py:155 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 13:24:25,983:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 13:24:30,394:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 16, 'wl_pos_enc': False, 'full_graph': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 13:24:30,394:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'job_num': 1, 'seed_array': [41]}
2022-09-10 13:24:30,395:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:24:30,395:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:24:30,395:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:24:30,396:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:24:30,401:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 13:24:30,401:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 524295
2022-09-10 13:24:30,402:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 13:24:30,402:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 13:24:30,402:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 13:24:30,402:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 13:24:30,402:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 13:24:30,408:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 13:24:40,061:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:9.659610033035278
2022-09-10 13:24:40,077:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 13:24:40,077:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 13:24:40,077:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 13:24:40,077:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 13:24:40,079:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 13:25:01,922:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6047 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h24m30s_on_Sep_10_2022/MODELS_
2022-09-10 13:25:01,924:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.85s, LR: 0.00050, Train Loss: 0.9541, Train Acc: 0.5300,
                            Val Loss: 0.6841, Val Acc: 0.5910, Test Acc: 0.6047
2022-09-10 13:25:01,924:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 13:25:23,965:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.04s, LR: 0.00050, Train Loss: 0.6229, Train Acc: 0.6750,
                            Val Loss: 0.7257, Val Acc: 0.5730, Test Acc: 0.5759
2022-09-10 13:25:23,965:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 13:25:44,972:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.01s, LR: 0.00050, Train Loss: 0.6374, Train Acc: 0.6800,
                            Val Loss: 0.6959, Val Acc: 0.5830, Test Acc: 0.5950
2022-09-10 13:25:44,972:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 13:26:06,798:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6190 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h24m30s_on_Sep_10_2022/MODELS_
2022-09-10 13:26:06,799:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.83s, LR: 0.00050, Train Loss: 0.5486, Train Acc: 0.7550,
                            Val Loss: 0.7086, Val Acc: 0.6180, Test Acc: 0.6190
2022-09-10 13:26:06,799:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 13:26:27,708:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6277 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h24m30s_on_Sep_10_2022/MODELS_
2022-09-10 13:26:27,708:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.91s, LR: 0.00050, Train Loss: 0.5333, Train Acc: 0.7500,
                            Val Loss: 0.6964, Val Acc: 0.6300, Test Acc: 0.6277
2022-09-10 13:26:27,708:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 13:26:49,340:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7461 to out/CYCLES_graph_classification/checkpoints/GraphTransformer_CYCLES_GPU0_1_16_13h24m30s_on_Sep_10_2022/MODELS_
2022-09-10 13:26:49,341:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.63s, LR: 0.00050, Train Loss: 0.4842, Train Acc: 0.7950,
                            Val Loss: 0.5489, Val Acc: 0.7440, Test Acc: 0.7461
2022-09-10 13:26:49,341:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 13:27:10,513:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.17s, LR: 0.00050, Train Loss: 0.4592, Train Acc: 0.8300,
                            Val Loss: 0.6065, Val Acc: 0.6970, Test Acc: 0.7105
2022-09-10 13:27:10,513:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 13:27:32,081:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.57s, LR: 0.00050, Train Loss: 0.4452, Train Acc: 0.7950,
                            Val Loss: 0.5851, Val Acc: 0.6970, Test Acc: 0.6990
2022-09-10 13:27:32,081:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 13:27:53,692:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.61s, LR: 0.00050, Train Loss: 0.4192, Train Acc: 0.8000,
                            Val Loss: 0.5560, Val Acc: 0.7420, Test Acc: 0.7394
2022-09-10 13:27:53,692:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 13:28:15,188:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.50s, LR: 0.00050, Train Loss: 0.3915, Train Acc: 0.8100,
                            Val Loss: 0.9468, Val Acc: 0.6130, Test Acc: 0.6076
2022-09-10 13:28:15,189:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 13:28:36,680:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.49s, LR: 0.00050, Train Loss: 0.4600, Train Acc: 0.8100,
                            Val Loss: 1.1280, Val Acc: 0.6460, Test Acc: 0.6407
2022-09-10 13:28:36,680:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 17:08:55,633:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:08:59,034:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:08:59,034:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'job_num': 8}
2022-09-10 17:08:59,038:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:08:59,047:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:08:59,047:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:08:59,047:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:08:59,056:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:08:59,058:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:09:06,137:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:09:09,343:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:09:09,343:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'job_num': 8, 'save_name': 'gatedgcn'}
2022-09-10 17:09:09,343:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:09:09,344:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:09:09,344:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:09:09,344:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:09:09,351:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:09:09,352:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:09:09,353:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:09:09,353:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:09:09,353:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:09:09,353:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:09:09,353:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:09:09,363:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:09:12,659:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.306696891784668
2022-09-10 17:09:21,025:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:09:24,285:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:09:24,285:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'job_num': 8, 'save_name': 'gatedgcn'}
2022-09-10 17:09:24,286:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:09:24,287:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:09:24,287:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:09:24,287:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:09:24,294:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:09:24,296:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:09:24,296:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:09:24,296:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:09:24,297:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:09:24,297:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:09:24,297:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:09:24,304:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:09:27,540:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.2442028522491455
2022-09-10 17:09:27,555:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:09:27,555:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:09:27,555:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:09:27,560:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:09:49,566:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.284608244895935
2022-09-10 17:09:49,567:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.01s, LR: 0.00100, Train Loss: 1.3076, Train MAE: 1.3076,
                            Val Loss: 1.1948, Val Acc: 1.1948, Test MAE: 1.2846
2022-09-10 17:09:49,577:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:10:11,542:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.1497296392917633
2022-09-10 17:10:11,542:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.97s, LR: 0.00100, Train Loss: 1.1073, Train MAE: 1.1073,
                            Val Loss: 1.0962, Val Acc: 1.0962, Test MAE: 1.1497
2022-09-10 17:10:11,552:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 17:10:17,029:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:10:17,029:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:10:20,841:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:10:24,151:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:10:24,151:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'job_num': 8, 'save_name': 'gatedgcn'}
2022-09-10 17:10:24,152:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:10:24,153:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:10:24,153:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:10:24,153:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:10:24,160:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:10:24,162:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:10:24,162:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:10:24,162:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:10:24,162:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:10:24,162:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:10:24,162:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:10:24,170:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:10:27,502:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.3397927284240723
2022-09-10 17:10:27,516:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:10:27,516:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:10:27,516:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:10:27,518:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:10:49,361:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5674041509628296
2022-09-10 17:10:49,363:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.84s, LR: 0.00100, Train Loss: 1.2194, Train MAE: 1.2194,
                            Val Loss: 1.4634, Val Acc: 1.4634, Test MAE: 1.5674
2022-09-10 17:10:49,372:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:11:11,518:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.551559567451477
2022-09-10 17:11:11,519:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.15s, LR: 0.00100, Train Loss: 0.9793, Train MAE: 0.9793,
                            Val Loss: 1.4397, Val Acc: 1.4397, Test MAE: 1.5516
2022-09-10 17:11:11,529:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 17:11:33,588:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.06s, LR: 0.00100, Train Loss: 0.8976, Train MAE: 0.8976,
                            Val Loss: 1.4501, Val Acc: 1.4501, Test MAE: 1.5576
2022-09-10 17:11:33,598:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 17:11:55,566:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5508970767259598
2022-09-10 17:11:55,567:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.97s, LR: 0.00100, Train Loss: 0.8496, Train MAE: 0.8496,
                            Val Loss: 1.4391, Val Acc: 1.4391, Test MAE: 1.5509
2022-09-10 17:11:55,576:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 17:12:17,307:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.73s, LR: 0.00100, Train Loss: 0.8218, Train MAE: 0.8218,
                            Val Loss: 1.4443, Val Acc: 1.4443, Test MAE: 1.5540
2022-09-10 17:12:17,317:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 17:12:27,312:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:12:27,312:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:13:12,644:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:13:15,820:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': True, 'pos_enc_dim': 16, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:13:15,820:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:13:15,821:pe_layer.py:65 -             __init__(): pos_enc
2022-09-10 17:13:15,821:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:13:15,821:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:13:15,821:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:13:15,829:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:13:15,830:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 512226
2022-09-10 17:13:15,831:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:13:15,831:pe_layer.py:65 -             __init__(): pos_enc
2022-09-10 17:13:15,831:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:13:15,831:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:13:15,831:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:13:15,839:main_molecules_graph_regression.py:57 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-10 17:13:23,173:main_molecules_graph_regression.py:59 -   train_val_pipeline(): Time PE: 7.342639207839966
2022-09-10 17:13:23,173:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 17:13:26,735:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:10.903908014297485
2022-09-10 17:13:26,748:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:13:26,748:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:13:26,748:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:13:26,751:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:13:48,279:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.6814246624708176
2022-09-10 17:13:48,281:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.53s, LR: 0.00100, Train Loss: 1.4769, Train MAE: 1.4769,
                            Val Loss: 1.6118, Val Acc: 1.6118, Test MAE: 1.6814
2022-09-10 17:13:48,293:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:13:50,650:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:13:50,651:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:13:58,049:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:14:04,081:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:14:07,356:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 16, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:14:07,356:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:14:07,357:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:14:07,358:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:14:07,358:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:14:07,358:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:14:07,365:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:14:07,366:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510900
2022-09-10 17:14:07,366:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:14:07,366:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:14:07,367:pe_layer.py:129 -             __init__(): Using 16 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:14:07,367:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:14:07,367:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:14:07,373:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (16).
2022-09-10 17:14:11,201:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.8345069885253906
2022-09-10 17:14:11,214:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:14:11,214:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:14:11,214:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:14:11,216:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:14:33,450:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.563013181090355
2022-09-10 17:14:33,452:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.24s, LR: 0.00100, Train Loss: 1.2310, Train MAE: 1.2310,
                            Val Loss: 1.4562, Val Acc: 1.4562, Test MAE: 1.5630
2022-09-10 17:14:33,461:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:14:41,856:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:14:41,856:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:14:56,592:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:14:59,902:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': True, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:14:59,902:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:14:59,902:pe_layer.py:65 -             __init__(): pos_enc
2022-09-10 17:14:59,902:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:14:59,902:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:14:59,902:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:14:59,910:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:14:59,911:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510003
2022-09-10 17:14:59,912:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:14:59,912:pe_layer.py:65 -             __init__(): pos_enc
2022-09-10 17:14:59,912:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:14:59,912:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:14:59,912:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:14:59,919:main_molecules_graph_regression.py:57 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-10 17:15:07,410:main_molecules_graph_regression.py:59 -   train_val_pipeline(): Time PE: 7.498470067977905
2022-09-10 17:15:07,424:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:15:07,424:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:15:07,424:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:15:07,427:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:15:29,481:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.8330449610948563
2022-09-10 17:15:29,482:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.06s, LR: 0.00100, Train Loss: 1.0424, Train MAE: 1.0424,
                            Val Loss: 0.7879, Val Acc: 0.7879, Test MAE: 0.8330
2022-09-10 17:15:29,492:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:15:51,864:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7165969014167786
2022-09-10 17:15:51,864:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.37s, LR: 0.00100, Train Loss: 0.6673, Train MAE: 0.6673,
                            Val Loss: 0.6689, Val Acc: 0.6689, Test MAE: 0.7166
2022-09-10 17:15:51,874:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 17:16:14,352:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.48s, LR: 0.00100, Train Loss: 0.5888, Train MAE: 0.5888,
                            Val Loss: 0.6805, Val Acc: 0.6805, Test MAE: 0.7292
2022-09-10 17:16:14,363:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 17:16:20,187:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:16:20,187:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:16:27,757:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:16:31,008:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:16:31,008:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:16:31,008:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:16:31,009:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:16:31,009:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:16:31,009:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:16:31,017:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:16:31,019:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:16:31,019:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:16:31,019:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:16:31,020:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:16:31,020:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:16:31,020:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:16:31,028:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:16:34,467:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.4480268955230713
2022-09-10 17:16:34,480:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:16:34,480:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:16:34,480:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:16:34,483:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:16:56,933:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.800143301486969
2022-09-10 17:16:56,935:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.45s, LR: 0.00100, Train Loss: 1.0390, Train MAE: 1.0390,
                            Val Loss: 0.7349, Val Acc: 0.7349, Test MAE: 0.8001
2022-09-10 17:16:56,946:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:17:03,672:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:17:03,673:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:17:06,155:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:17:09,512:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:17:09,512:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:17:09,512:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:17:09,513:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:17:09,513:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:17:09,513:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:17:09,520:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:17:09,522:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:17:09,522:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:17:09,522:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:17:09,523:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:17:09,523:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:17:09,523:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:17:09,530:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:17:12,734:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.212275981903076
2022-09-10 17:17:12,748:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:17:12,748:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:17:12,748:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:17:12,750:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:17:34,881:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5577715337276459
2022-09-10 17:17:34,882:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00100, Train Loss: 1.2738, Train MAE: 1.2738,
                            Val Loss: 1.4504, Val Acc: 1.4504, Test MAE: 1.5578
2022-09-10 17:17:34,892:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:17:56,499:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5510423630475998
2022-09-10 17:17:56,500:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.61s, LR: 0.00100, Train Loss: 0.9705, Train MAE: 0.9705,
                            Val Loss: 1.4393, Val Acc: 1.4393, Test MAE: 1.5510
2022-09-10 17:17:56,510:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 17:18:03,627:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:18:03,627:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:19:53,116:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:19:56,397:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:19:56,397:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:19:56,398:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:19:56,399:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:19:56,399:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:19:56,399:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:19:56,406:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:19:56,408:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510084
2022-09-10 17:19:56,408:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:19:56,408:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:19:56,409:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:19:56,409:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:19:56,409:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:19:56,417:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:19:59,652:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.243911027908325
2022-09-10 17:19:59,666:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:19:59,666:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:19:59,666:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:19:59,668:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:20:12,288:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:20:15,448:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:20:15,448:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:20:15,449:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:20:15,449:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:20:15,449:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:20:15,449:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:20:15,457:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:20:15,458:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510084
2022-09-10 17:20:15,459:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:20:15,459:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:20:15,459:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:20:15,460:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:20:15,460:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:20:15,467:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:20:18,691:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.232445240020752
2022-09-10 17:20:18,705:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:20:18,705:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:20:18,705:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:20:18,707:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:20:35,074:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:20:38,202:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:20:38,202:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:20:38,202:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:20:38,203:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:20:38,203:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:20:38,203:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:20:38,211:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:20:38,212:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510084
2022-09-10 17:20:38,213:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:20:38,213:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:20:38,213:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:20:38,213:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:20:38,213:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:20:38,221:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:20:41,468:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.255387306213379
2022-09-10 17:20:41,481:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:20:41,482:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:20:41,482:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:20:41,484:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:22:00,795:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:22:03,992:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:22:03,992:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:22:03,993:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:22:03,993:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:22:03,993:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:22:03,993:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:22:04,001:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:22:04,002:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510084
2022-09-10 17:22:04,003:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:22:04,003:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:22:04,003:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:22:04,003:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:22:04,003:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:22:04,012:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:22:07,453:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.450634002685547
2022-09-10 17:22:07,467:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:22:07,467:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:22:07,467:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:22:07,470:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:22:29,448:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5580641627311707
2022-09-10 17:22:29,449:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.98s, LR: 0.00100, Train Loss: 1.2408, Train MAE: 1.2408,
                            Val Loss: 1.4507, Val Acc: 1.4507, Test MAE: 1.5581
2022-09-10 17:22:29,459:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:22:31,717:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:22:31,718:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:22:40,024:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:22:43,348:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:22:43,348:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:22:43,348:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:22:43,349:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:22:43,349:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:22:43,349:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:22:43,356:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:22:43,358:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510084
2022-09-10 17:22:43,358:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:22:43,359:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:22:43,359:pe_layer.py:131 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:22:43,359:pe_layer.py:136 -             __init__(): Using matrix: A
2022-09-10 17:22:43,359:pe_layer.py:137 -             __init__(): Matrix power: 1
2022-09-10 17:22:43,367:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:22:46,813:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.454232931137085
2022-09-10 17:22:46,829:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:22:46,829:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:22:46,829:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:22:46,831:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:22:51,266:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:22:51,266:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:25:39,403:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:25:42,652:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:25:42,652:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:25:42,653:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:25:42,654:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:25:42,654:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:25:42,654:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:25:42,661:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:25:42,662:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:25:42,662:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:25:42,663:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:25:42,663:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:25:42,663:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:25:42,663:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:25:42,670:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:26:03,997:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:26:07,312:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:26:07,312:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:26:07,313:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:26:07,313:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:26:07,313:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:26:07,313:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:26:07,320:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:26:07,322:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:26:07,322:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:26:07,322:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:26:07,323:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:26:07,323:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:26:07,323:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:26:07,331:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:26:10,577:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.2551350593566895
2022-09-10 17:26:10,592:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:26:10,592:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:26:10,592:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:26:10,595:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:26:32,426:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.8028173819184303
2022-09-10 17:26:32,427:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.83s, LR: 0.00100, Train Loss: 1.0666, Train MAE: 1.0666,
                            Val Loss: 0.7318, Val Acc: 0.7318, Test MAE: 0.8028
2022-09-10 17:26:32,437:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:26:38,818:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:26:38,818:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:26:40,945:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:26:44,134:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:26:44,134:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:26:44,135:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:26:44,136:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:26:44,136:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:26:44,136:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:26:44,143:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:26:44,144:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:26:44,144:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:26:44,145:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:26:44,145:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:26:44,145:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:26:44,145:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:26:44,153:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:26:47,390:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.245936870574951
2022-09-10 17:26:47,405:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:26:47,405:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:26:47,405:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:26:47,408:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:27:09,081:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.8213333114981651
2022-09-10 17:27:09,082:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.67s, LR: 0.00100, Train Loss: 1.0970, Train MAE: 1.0970,
                            Val Loss: 0.7742, Val Acc: 0.7742, Test MAE: 0.8213
2022-09-10 17:27:09,093:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:27:12,610:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:27:12,610:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:27:14,582:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:27:17,762:main_molecules_graph_regression.py:352 -                 main(): {'L': 16, 'hidden_dim': 78, 'out_dim': 78, 'residual': True, 'edge_feat': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'batch_norm': True, 'pos_enc': False, 'pos_enc_dim': 8, 'gpu_id': 0, 'batch_size': 128, 'layer_norm': False, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'pow_of_mat': 1, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'self_loop': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:27:17,762:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.001, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-05, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 12, 'seed_array': [41], 'save_name': 'gatedgcn', 'job_num': 8}
2022-09-10 17:27:17,762:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:27:17,763:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:27:17,763:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:27:17,763:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:27:17,770:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:27:17,772:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GatedGCN, 510076
2022-09-10 17:27:17,772:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:27:17,773:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:27:17,773:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:27:17,773:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:27:17,773:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:27:17,781:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:27:21,086:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.3136050701141357
2022-09-10 17:27:21,100:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:27:21,100:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:27:21,100:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:27:21,102:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:27:42,619:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7778168246150017
2022-09-10 17:27:42,620:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 21.52s, LR: 0.00100, Train Loss: 1.0443, Train MAE: 1.0443,
                            Val Loss: 0.7205, Val Acc: 0.7205, Test MAE: 0.7778
2022-09-10 17:27:42,630:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:27:45,787:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:27:45,787:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:28:29,406:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:28:32,688:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 64, 'learned_pos_enc': True, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:28:32,688:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 64, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:28:32,689:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 17:28:32,689:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:28:32,690:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:28:32,690:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:28:32,695:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:28:32,695:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:28:32,695:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:28:32,696:pe_layer.py:65 -             __init__(): learned_pos_enc
2022-09-10 17:28:32,696:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:28:32,696:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:28:32,696:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:28:32,716:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:28:32,717:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:28:32,717:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:28:32,719:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:28:40,098:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:28:40,098:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:29:06,847:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:29:10,229:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:29:10,230:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:29:10,230:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:29:10,231:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:29:10,231:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:29:10,231:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:29:10,236:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:29:10,237:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:29:10,237:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:29:10,237:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:29:10,237:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:29:10,238:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:29:10,238:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:29:10,242:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:29:13,652:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.414973735809326
2022-09-10 17:29:13,665:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:29:13,665:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:29:13,665:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:29:13,668:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:29:28,764:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7485588267445564
2022-09-10 17:29:28,766:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.10s, LR: 0.00070, Train Loss: 0.8404, Train MAE: 0.8404,
                            Val Loss: 0.7304, Val Acc: 0.7304, Test MAE: 0.7486
2022-09-10 17:29:28,772:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:29:37,062:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:29:37,063:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:29:38,977:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:29:42,219:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:29:42,219:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:29:42,219:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:29:42,220:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:29:42,220:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:29:42,220:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:29:42,225:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:29:42,226:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:29:42,226:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:29:42,226:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:29:42,227:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:29:42,227:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:29:42,227:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:29:42,231:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:29:45,809:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.5824170112609863
2022-09-10 17:29:45,824:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:29:45,824:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:29:45,824:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:29:45,826:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:30:01,123:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7687787860631943
2022-09-10 17:30:01,125:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.30s, LR: 0.00070, Train Loss: 0.8718, Train MAE: 0.8718,
                            Val Loss: 0.7457, Val Acc: 0.7457, Test MAE: 0.7688
2022-09-10 17:30:01,131:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:30:03,838:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:30:03,838:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:30:05,732:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:30:08,953:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:30:08,953:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:30:08,953:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:30:08,954:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:30:08,954:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:30:08,954:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:30:08,959:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:30:08,959:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:30:08,959:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:30:08,960:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:30:08,960:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:30:08,960:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:30:08,960:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:30:08,965:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:30:12,311:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.351339817047119
2022-09-10 17:30:12,325:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:30:12,325:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:30:12,325:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:30:12,327:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:30:27,290:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.8020187467336655
2022-09-10 17:30:27,291:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.96s, LR: 0.00070, Train Loss: 0.9421, Train MAE: 0.9421,
                            Val Loss: 0.7442, Val Acc: 0.7442, Test MAE: 0.8020
2022-09-10 17:30:27,297:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:30:34,570:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:30:34,570:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:30:37,134:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:30:40,282:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:30:40,282:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:30:40,282:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:30:40,283:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:30:40,283:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:30:40,283:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:30:40,288:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:30:40,289:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:30:40,289:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:30:40,289:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:30:40,290:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:30:40,290:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:30:40,290:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:30:40,295:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:30:43,569:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.2796013355255127
2022-09-10 17:30:43,582:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:30:43,582:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:30:43,582:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:30:43,584:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:30:59,088:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7068301737308502
2022-09-10 17:30:59,089:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.50s, LR: 0.00070, Train Loss: 0.8881, Train MAE: 0.8881,
                            Val Loss: 0.6788, Val Acc: 0.6788, Test MAE: 0.7068
2022-09-10 17:30:59,095:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:31:00,570:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:31:00,570:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:31:09,012:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:31:12,429:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:31:12,429:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:31:12,430:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:31:12,431:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:31:12,431:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:31:12,431:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:31:12,436:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:31:12,437:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:31:12,437:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:31:12,437:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:31:12,437:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:31:12,437:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:31:12,438:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:31:12,443:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:31:16,201:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.764004707336426
2022-09-10 17:31:16,215:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:31:16,215:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:31:16,215:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:31:16,217:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:31:31,416:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7772538587450981
2022-09-10 17:31:31,417:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.20s, LR: 0.00070, Train Loss: 0.9066, Train MAE: 0.9066,
                            Val Loss: 0.7629, Val Acc: 0.7629, Test MAE: 0.7773
2022-09-10 17:31:31,423:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:31:36,488:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:31:36,488:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:31:38,364:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:31:41,613:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:31:41,614:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:31:41,614:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:31:41,615:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:31:41,615:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:31:41,615:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:31:41,620:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:31:41,620:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:31:41,621:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:31:41,621:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:31:41,621:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:31:41,621:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:31:41,621:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:31:41,626:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:31:45,048:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.427602767944336
2022-09-10 17:31:45,063:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:31:45,063:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:31:45,063:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:31:45,065:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:32:00,360:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.546168565750122
2022-09-10 17:32:00,361:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.30s, LR: 0.00070, Train Loss: 1.4872, Train MAE: 1.4872,
                            Val Loss: 1.4404, Val Acc: 1.4404, Test MAE: 1.5462
2022-09-10 17:32:00,367:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:32:03,856:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:32:03,856:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:32:14,546:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:32:17,798:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:32:17,798:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:32:17,798:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:32:17,799:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:32:17,800:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:32:17,800:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:32:17,805:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:32:17,806:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:32:17,806:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:32:17,806:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:32:17,807:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:32:17,807:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:32:17,807:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:32:17,812:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:32:21,277:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.470782995223999
2022-09-10 17:32:21,291:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:32:21,291:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:32:21,291:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:32:21,293:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:32:36,153:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5585673302412033
2022-09-10 17:32:36,155:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.86s, LR: 0.00070, Train Loss: 1.5069, Train MAE: 1.5069,
                            Val Loss: 1.4393, Val Acc: 1.4393, Test MAE: 1.5586
2022-09-10 17:32:36,161:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:32:39,204:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:32:39,204:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:32:44,077:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:32:47,309:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:32:47,309:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:32:47,309:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:32:47,310:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:32:47,310:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:32:47,310:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:32:47,315:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:32:47,316:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:32:47,316:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:32:47,316:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:32:47,317:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:32:47,317:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:32:47,317:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:32:47,322:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:32:50,827:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.5109612941741943
2022-09-10 17:32:50,841:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:32:50,841:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:32:50,841:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:32:50,843:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:33:06,095:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.9087798818945885
2022-09-10 17:33:06,096:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.25s, LR: 0.00070, Train Loss: 0.8753, Train MAE: 0.8753,
                            Val Loss: 0.8924, Val Acc: 0.8924, Test MAE: 0.9088
2022-09-10 17:33:06,103:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:33:18,066:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:33:18,066:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:33:19,969:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:33:23,146:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:33:23,147:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:33:23,147:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:33:23,148:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:33:23,148:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:33:23,148:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:33:23,153:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:33:23,154:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:33:23,154:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:33:23,154:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:33:23,155:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:33:23,155:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:33:23,155:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:33:23,160:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:33:26,433:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.278416156768799
2022-09-10 17:33:26,447:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:33:26,447:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:33:26,447:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:33:26,448:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:33:41,621:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.119960941374302
2022-09-10 17:33:41,622:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.17s, LR: 0.00070, Train Loss: 0.9845, Train MAE: 0.9845,
                            Val Loss: 1.0894, Val Acc: 1.0894, Test MAE: 1.1200
2022-09-10 17:33:41,628:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:33:52,123:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:33:52,123:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:34:00,705:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:34:03,952:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:34:03,952:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:34:03,953:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:34:03,954:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:34:03,954:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:34:03,954:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:34:03,959:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:34:03,959:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:34:03,959:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:34:03,960:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:34:03,960:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:34:03,960:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:34:03,960:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:34:03,965:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:34:07,242:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.2822139263153076
2022-09-10 17:34:07,255:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:34:07,255:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:34:07,255:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:34:07,257:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:34:22,084:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7241323739290237
2022-09-10 17:34:22,085:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.83s, LR: 0.00070, Train Loss: 0.9371, Train MAE: 0.9371,
                            Val Loss: 0.6927, Val Acc: 0.6927, Test MAE: 0.7241
2022-09-10 17:34:22,092:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:34:31,302:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:34:31,302:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:34:33,756:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:34:36,906:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:34:36,906:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:34:36,907:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:34:36,907:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:34:36,907:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:34:36,908:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:34:36,913:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:34:36,913:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:34:36,914:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:34:36,914:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:34:36,914:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:34:36,914:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:34:36,914:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:34:36,920:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:34:40,333:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.4196691513061523
2022-09-10 17:34:40,346:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:34:40,346:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:34:40,346:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:34:40,348:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:34:55,703:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.0141690447926521
2022-09-10 17:34:55,704:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.36s, LR: 0.00070, Train Loss: 0.9247, Train MAE: 0.9247,
                            Val Loss: 0.9875, Val Acc: 0.9875, Test MAE: 1.0142
2022-09-10 17:34:55,710:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:35:00,154:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:35:00,154:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:35:02,552:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:35:05,816:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:35:05,816:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:35:05,816:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:35:05,817:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:35:05,817:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:35:05,817:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:35:05,822:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:35:05,823:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:35:05,823:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:35:05,823:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:35:05,823:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:35:05,823:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:35:05,823:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:35:05,828:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:35:09,376:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.552903890609741
2022-09-10 17:35:09,390:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:35:09,390:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:35:09,390:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:35:09,392:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:35:25,941:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7498296201229095
2022-09-10 17:35:25,943:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.55s, LR: 0.00070, Train Loss: 0.8745, Train MAE: 0.8745,
                            Val Loss: 0.7227, Val Acc: 0.7227, Test MAE: 0.7498
2022-09-10 17:35:25,951:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:35:39,096:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:35:39,096:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:35:41,477:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:35:44,879:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:35:44,879:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:35:44,880:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:35:44,881:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:35:44,881:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:35:44,881:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:35:44,886:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:35:44,887:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:35:44,887:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:35:44,887:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:35:44,888:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:35:44,888:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:35:44,888:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:35:44,893:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:35:48,523:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.6356279850006104
2022-09-10 17:35:48,539:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:35:48,539:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:35:48,539:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:35:48,542:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:36:04,358:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.650589644908905
2022-09-10 17:36:04,359:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.82s, LR: 0.00070, Train Loss: 0.8512, Train MAE: 0.8512,
                            Val Loss: 0.6383, Val Acc: 0.6383, Test MAE: 0.6506
2022-09-10 17:36:04,365:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:36:12,613:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:36:12,613:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:36:14,756:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:36:18,138:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:36:18,141:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:36:18,142:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:36:18,143:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:36:18,143:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:36:18,143:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:36:18,149:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:36:18,150:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:36:18,150:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:36:18,150:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:36:18,151:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:36:18,151:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:36:18,151:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:36:18,157:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:36:21,632:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:3.4823899269104004
2022-09-10 17:36:21,647:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:36:21,648:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:36:21,648:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:36:21,650:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:36:37,702:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.0291253849864006
2022-09-10 17:36:37,703:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.05s, LR: 0.00070, Train Loss: 0.9825, Train MAE: 0.9825,
                            Val Loss: 0.9956, Val Acc: 0.9956, Test MAE: 1.0291
2022-09-10 17:36:37,709:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:36:54,007:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6609885096549988
2022-09-10 17:36:54,008:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.30s, LR: 0.00070, Train Loss: 0.6663, Train MAE: 0.6663,
                            Val Loss: 0.6197, Val Acc: 0.6197, Test MAE: 0.6610
2022-09-10 17:36:54,014:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 17:36:59,995:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:36:59,995:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:37:47,211:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:37:50,446:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:37:50,446:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:37:50,447:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:37:50,447:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:37:50,447:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:37:50,447:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:37:50,453:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:37:50,453:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:37:50,454:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:37:50,454:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:37:50,454:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:37:50,454:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:37:50,454:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:37:50,460:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:38:01,240:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:38:04,455:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:38:04,455:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:38:04,456:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:38:04,457:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:38:04,457:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:38:04,457:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:38:04,462:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:38:04,463:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:38:04,463:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:38:04,463:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:38:04,464:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:38:04,464:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:38:04,464:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:38:04,470:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:42:11,278:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:42:14,621:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:42:14,621:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:42:14,621:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:42:14,622:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:42:14,622:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:42:14,622:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:42:14,627:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:42:14,628:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:42:14,628:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:42:14,628:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:42:14,628:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:42:14,628:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:42:14,628:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:42:14,633:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:44:12,992:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:44:16,223:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:44:16,223:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:44:16,223:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:44:16,224:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:44:16,224:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:44:16,224:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:44:16,230:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:44:16,230:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:44:16,231:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:44:16,231:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:44:16,231:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:44:16,231:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:44:16,231:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:44:16,237:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:44:53,237:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:44:56,389:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:44:56,389:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:44:56,390:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:44:56,390:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:44:56,390:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:44:56,390:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:44:56,396:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:44:56,396:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:44:56,397:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:44:56,397:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:44:56,397:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:44:56,397:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:44:56,397:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:44:56,402:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:45:26,786:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:45:30,077:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:45:30,077:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:45:30,077:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:45:30,078:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:45:30,078:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:45:30,078:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:45:30,083:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:45:30,084:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:45:30,084:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:45:30,084:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:45:30,085:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:45:30,085:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:45:30,085:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:45:30,090:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:46:22,968:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:46:26,261:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:46:26,261:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:46:26,261:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:46:26,262:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:46:26,262:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:46:26,262:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:46:26,268:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:46:26,268:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:46:26,268:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:46:26,269:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:46:26,269:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:46:26,269:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:46:26,269:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:46:26,275:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:46:53,902:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:27.633391857147217
2022-09-10 17:46:53,918:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:46:53,918:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:46:53,918:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:46:53,921:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:50:05,993:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:50:09,203:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:50:09,203:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:50:09,204:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:50:09,217:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:50:09,217:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:50:09,217:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:50:09,223:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:50:09,224:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:50:09,224:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:50:09,224:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:50:09,224:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:50:09,224:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:50:09,224:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:50:09,230:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:50:15,672:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:50:18,946:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:50:18,946:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:50:18,946:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:50:18,947:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:50:18,947:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:50:18,947:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:50:18,952:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:50:18,953:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:50:18,953:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:50:18,953:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:50:18,954:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:50:18,954:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:50:18,954:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:50:18,959:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:50:57,837:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:38.88408279418945
2022-09-10 17:50:57,854:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:50:57,854:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:50:57,854:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:50:57,856:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:51:12,979:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5547848790884018
2022-09-10 17:51:12,980:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.12s, LR: 0.00070, Train Loss: 1.4916, Train MAE: 1.4916,
                            Val Loss: 1.4427, Val Acc: 1.4427, Test MAE: 1.5548
2022-09-10 17:51:12,987:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:51:20,560:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:51:20,560:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:51:40,865:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:51:44,124:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:51:44,125:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:51:44,125:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:51:44,126:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:51:44,126:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:51:44,126:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:51:44,131:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:51:44,132:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:51:44,132:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:51:44,132:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:51:44,133:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:51:44,133:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:51:44,133:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:51:44,138:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:52:07,144:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:23.012024879455566
2022-09-10 17:52:07,160:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:52:07,160:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:52:07,160:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:52:07,162:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:52:22,092:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7724011763930321
2022-09-10 17:52:22,093:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.93s, LR: 0.00070, Train Loss: 1.0150, Train MAE: 1.0150,
                            Val Loss: 0.7505, Val Acc: 0.7505, Test MAE: 0.7724
2022-09-10 17:52:22,099:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:52:27,691:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:52:27,691:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:52:29,887:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:52:33,115:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:52:33,116:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:52:33,116:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:52:33,117:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:52:33,117:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:52:33,117:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:52:33,122:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:52:33,123:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:52:33,123:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:52:33,123:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:52:33,123:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:52:33,123:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:52:33,123:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:52:33,128:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:53:00,422:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:27.29925012588501
2022-09-10 17:53:00,437:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:53:00,437:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:53:00,437:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:53:00,439:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:53:15,642:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5517375767230988
2022-09-10 17:53:15,643:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.20s, LR: 0.00070, Train Loss: 1.4889, Train MAE: 1.4889,
                            Val Loss: 1.4421, Val Acc: 1.4421, Test MAE: 1.5517
2022-09-10 17:53:15,650:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:53:19,173:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:53:19,173:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:53:21,627:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:53:24,913:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:53:24,913:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:53:24,914:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:53:24,915:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:53:24,915:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:53:24,915:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:53:24,920:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:53:24,920:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:53:24,920:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:53:24,921:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:53:24,921:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:53:24,921:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:53:24,921:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:53:24,926:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:54:02,255:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:37.3348069190979
2022-09-10 17:54:02,278:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:54:02,278:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:54:02,278:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:54:02,280:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:54:17,117:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.5521874129772186
2022-09-10 17:54:17,118:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.84s, LR: 0.00070, Train Loss: 1.4944, Train MAE: 1.4944,
                            Val Loss: 1.4424, Val Acc: 1.4424, Test MAE: 1.5522
2022-09-10 17:54:17,124:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:54:22,537:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:54:22,537:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:54:26,689:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:54:29,863:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:54:29,863:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:54:29,863:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:54:29,864:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:54:29,864:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:54:29,864:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:54:29,869:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:54:29,870:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:54:29,870:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:54:29,870:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:54:29,871:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:54:29,871:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:54:29,871:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:54:29,876:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:54:46,089:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:16.21875834465027
2022-09-10 17:54:46,106:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:54:46,106:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:54:46,106:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:54:46,108:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:55:00,712:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7480789721012115
2022-09-10 17:55:00,713:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.61s, LR: 0.00070, Train Loss: 0.8560, Train MAE: 0.8560,
                            Val Loss: 0.7359, Val Acc: 0.7359, Test MAE: 0.7481
2022-09-10 17:55:00,719:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:55:04,399:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:55:04,399:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:55:11,293:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:55:14,460:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:55:14,460:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:55:14,460:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:55:14,462:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:55:14,462:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:55:14,462:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:55:14,467:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:55:14,468:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:55:14,468:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:55:14,468:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:55:14,468:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:55:14,468:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:55:14,468:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:55:14,474:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:55:32,443:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:17.975497007369995
2022-09-10 17:55:32,460:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:55:32,461:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:55:32,461:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:55:32,463:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:55:47,617:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.8844448402523994
2022-09-10 17:55:47,618:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.15s, LR: 0.00070, Train Loss: 0.9530, Train MAE: 0.9530,
                            Val Loss: 0.8625, Val Acc: 0.8625, Test MAE: 0.8844
2022-09-10 17:55:47,625:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:55:53,418:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:55:53,418:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:55:55,602:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:55:58,851:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:55:58,851:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:55:58,851:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:55:58,852:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:55:58,852:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:55:58,852:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:55:58,857:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:55:58,858:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 17:55:58,858:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:55:58,858:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:55:58,859:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:55:58,859:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:55:58,859:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:55:58,865:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:56:29,767:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:30.9088032245636
2022-09-10 17:56:29,783:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:56:29,783:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:56:29,783:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:56:29,786:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:56:44,237:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.556051954627037
2022-09-10 17:56:44,238:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.45s, LR: 0.00070, Train Loss: 1.4975, Train MAE: 1.4975,
                            Val Loss: 1.4371, Val Acc: 1.4371, Test MAE: 1.5561
2022-09-10 17:56:44,246:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:56:48,046:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:56:48,047:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:57:00,721:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:57:03,961:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'n_gape': 3, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:57:03,961:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:57:03,962:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:57:03,963:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:57:03,963:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:57:03,963:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:57:03,968:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:57:03,969:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525661
2022-09-10 17:57:03,969:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:57:03,969:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:57:03,970:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:57:03,970:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:57:03,970:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:57:03,975:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:57:03,976:main_molecules_graph_regression.py:67 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-10 17:57:13,471:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:57:13,471:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:57:13,471:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:57:13,474:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:57:18,025:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 17:57:18,025:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 17:57:30,947:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 17:57:34,224:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'n_gape': 3, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 17:57:34,224:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 17:57:34,224:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:57:34,225:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:57:34,225:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:57:34,225:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:57:34,230:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 17:57:34,231:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525661
2022-09-10 17:57:34,231:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 17:57:34,231:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 17:57:34,232:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 17:57:34,232:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 17:57:34,232:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 17:57:34,237:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 17:57:34,237:main_molecules_graph_regression.py:67 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-10 17:57:43,817:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 17:57:43,817:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 17:57:43,817:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 17:57:43,819:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 17:57:58,939:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7783317565917969
2022-09-10 17:57:58,940:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.12s, LR: 0.00070, Train Loss: 0.9343, Train MAE: 0.9343,
                            Val Loss: 0.7069, Val Acc: 0.7069, Test MAE: 0.7783
2022-09-10 17:57:58,946:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 17:58:14,383:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6411221697926521
2022-09-10 17:58:14,383:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.44s, LR: 0.00070, Train Loss: 0.6147, Train MAE: 0.6147,
                            Val Loss: 0.5996, Val Acc: 0.5996, Test MAE: 0.6411
2022-09-10 17:58:14,389:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 17:58:29,646:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6097567565739155
2022-09-10 17:58:29,647:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.26s, LR: 0.00070, Train Loss: 0.5759, Train MAE: 0.5759,
                            Val Loss: 0.5596, Val Acc: 0.5596, Test MAE: 0.6098
2022-09-10 17:58:29,653:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 17:58:44,985:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.33s, LR: 0.00070, Train Loss: 0.5555, Train MAE: 0.5555,
                            Val Loss: 0.7318, Val Acc: 0.7318, Test MAE: 0.7772
2022-09-10 17:58:44,992:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 17:59:00,144:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.15s, LR: 0.00070, Train Loss: 0.5318, Train MAE: 0.5318,
                            Val Loss: 0.5990, Val Acc: 0.5990, Test MAE: 0.6465
2022-09-10 17:59:00,150:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 17:59:15,286:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5788893140852451
2022-09-10 17:59:15,286:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.14s, LR: 0.00070, Train Loss: 0.5040, Train MAE: 0.5040,
                            Val Loss: 0.5488, Val Acc: 0.5488, Test MAE: 0.5789
2022-09-10 17:59:15,292:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 17:59:30,349:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.06s, LR: 0.00070, Train Loss: 0.5187, Train MAE: 0.5187,
                            Val Loss: 0.6116, Val Acc: 0.6116, Test MAE: 0.6491
2022-09-10 17:59:30,356:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 17:59:45,707:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.35s, LR: 0.00070, Train Loss: 0.4678, Train MAE: 0.4678,
                            Val Loss: 0.5618, Val Acc: 0.5618, Test MAE: 0.5910
2022-09-10 17:59:45,713:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 18:00:01,271:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.56s, LR: 0.00070, Train Loss: 0.4746, Train MAE: 0.4746,
                            Val Loss: 0.6089, Val Acc: 0.6089, Test MAE: 0.6276
2022-09-10 18:00:01,277:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 18:00:18,260:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:00:21,489:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': True, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'n_gape': 3, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:00:21,489:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:00:21,489:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:00:21,490:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:00:21,490:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:00:21,490:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:00:21,495:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:00:21,496:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525661
2022-09-10 18:00:21,496:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:00:21,496:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:00:21,497:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:00:21,497:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:00:21,497:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:00:21,502:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 18:00:21,502:main_molecules_graph_regression.py:67 -   train_val_pipeline(): [!] Using 3 random automata.
2022-09-10 18:00:32,241:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:00:32,241:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:00:32,241:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:00:32,244:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:00:48,424:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.79389638453722
2022-09-10 18:00:48,425:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.18s, LR: 0.00070, Train Loss: 0.8574, Train MAE: 0.8574,
                            Val Loss: 0.7754, Val Acc: 0.7754, Test MAE: 0.7939
2022-09-10 18:00:48,431:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:01:04,256:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6676396131515503
2022-09-10 18:01:04,258:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.83s, LR: 0.00070, Train Loss: 0.6446, Train MAE: 0.6446,
                            Val Loss: 0.6274, Val Acc: 0.6274, Test MAE: 0.6676
2022-09-10 18:01:04,264:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:01:19,723:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.46s, LR: 0.00070, Train Loss: 0.6289, Train MAE: 0.6289,
                            Val Loss: 0.6508, Val Acc: 0.6508, Test MAE: 0.6910
2022-09-10 18:01:19,729:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:01:35,627:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.90s, LR: 0.00070, Train Loss: 0.6138, Train MAE: 0.6138,
                            Val Loss: 0.6757, Val Acc: 0.6757, Test MAE: 0.7155
2022-09-10 18:01:35,634:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:01:51,986:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6392079368233681
2022-09-10 18:01:51,987:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.35s, LR: 0.00070, Train Loss: 0.5882, Train MAE: 0.5882,
                            Val Loss: 0.5892, Val Acc: 0.5892, Test MAE: 0.6392
2022-09-10 18:01:51,993:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 18:02:07,211:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6084773913025856
2022-09-10 18:02:07,211:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.22s, LR: 0.00070, Train Loss: 0.5722, Train MAE: 0.5722,
                            Val Loss: 0.5690, Val Acc: 0.5690, Test MAE: 0.6085
2022-09-10 18:02:07,218:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 18:02:23,240:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.02s, LR: 0.00070, Train Loss: 0.5868, Train MAE: 0.5868,
                            Val Loss: 0.6486, Val Acc: 0.6486, Test MAE: 0.6851
2022-09-10 18:02:23,247:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 18:02:26,810:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:02:26,810:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:02:49,434:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:02:52,707:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:02:52,707:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:02:52,707:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:02:52,708:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:02:52,708:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:02:52,708:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:02:52,714:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:02:52,714:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 18:02:52,715:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:02:52,715:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:02:52,715:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:02:52,715:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:02:52,716:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:02:52,721:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 18:03:05,457:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:12.742675065994263
2022-09-10 18:03:05,474:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:03:05,474:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:03:05,474:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:03:05,477:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:03:20,530:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7398144379258156
2022-09-10 18:03:20,531:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.05s, LR: 0.00070, Train Loss: 0.8698, Train MAE: 0.8698,
                            Val Loss: 0.7108, Val Acc: 0.7108, Test MAE: 0.7398
2022-09-10 18:03:20,536:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:03:35,074:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.54s, LR: 0.00070, Train Loss: 0.6378, Train MAE: 0.6378,
                            Val Loss: 0.6904, Val Acc: 0.6904, Test MAE: 0.7441
2022-09-10 18:03:35,080:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:03:49,433:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7220808044075966
2022-09-10 18:03:49,434:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.35s, LR: 0.00070, Train Loss: 0.6060, Train MAE: 0.6060,
                            Val Loss: 0.6823, Val Acc: 0.6823, Test MAE: 0.7221
2022-09-10 18:03:49,440:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:04:04,061:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7076291367411613
2022-09-10 18:04:04,061:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.62s, LR: 0.00070, Train Loss: 0.5888, Train MAE: 0.5888,
                            Val Loss: 0.6616, Val Acc: 0.6616, Test MAE: 0.7076
2022-09-10 18:04:04,067:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:04:18,753:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.616034921258688
2022-09-10 18:04:18,754:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.69s, LR: 0.00070, Train Loss: 0.5635, Train MAE: 0.5635,
                            Val Loss: 0.5820, Val Acc: 0.5820, Test MAE: 0.6160
2022-09-10 18:04:18,759:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 18:04:33,270:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5891240760684013
2022-09-10 18:04:33,271:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.51s, LR: 0.00070, Train Loss: 0.5406, Train MAE: 0.5406,
                            Val Loss: 0.5471, Val Acc: 0.5471, Test MAE: 0.5891
2022-09-10 18:04:33,277:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 18:04:47,815:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5383161641657352
2022-09-10 18:04:47,815:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.54s, LR: 0.00070, Train Loss: 0.5542, Train MAE: 0.5542,
                            Val Loss: 0.5071, Val Acc: 0.5071, Test MAE: 0.5383
2022-09-10 18:04:47,821:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 18:05:02,437:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.62s, LR: 0.00070, Train Loss: 0.4998, Train MAE: 0.4998,
                            Val Loss: 0.5445, Val Acc: 0.5445, Test MAE: 0.5715
2022-09-10 18:05:02,443:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 18:05:16,724:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.28s, LR: 0.00070, Train Loss: 0.5009, Train MAE: 0.5009,
                            Val Loss: 0.5147, Val Acc: 0.5147, Test MAE: 0.5502
2022-09-10 18:05:16,730:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 18:05:30,985:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.25s, LR: 0.00070, Train Loss: 0.4808, Train MAE: 0.4808,
                            Val Loss: 0.9301, Val Acc: 0.9301, Test MAE: 0.9570
2022-09-10 18:05:30,991:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 18:05:45,186:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.20s, LR: 0.00070, Train Loss: 0.4711, Train MAE: 0.4711,
                            Val Loss: 0.5302, Val Acc: 0.5302, Test MAE: 0.5528
2022-09-10 18:05:45,192:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 18:05:59,485:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5353042483329773
2022-09-10 18:05:59,485:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.29s, LR: 0.00070, Train Loss: 0.4693, Train MAE: 0.4693,
                            Val Loss: 0.5098, Val Acc: 0.5098, Test MAE: 0.5353
2022-09-10 18:05:59,491:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 18:06:13,726:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.23s, LR: 0.00070, Train Loss: 0.4549, Train MAE: 0.4549,
                            Val Loss: 0.5295, Val Acc: 0.5295, Test MAE: 0.5388
2022-09-10 18:06:13,733:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 18:06:27,952:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.22s, LR: 0.00070, Train Loss: 0.4550, Train MAE: 0.4550,
                            Val Loss: 0.5473, Val Acc: 0.5473, Test MAE: 0.5635
2022-09-10 18:06:27,958:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 18:06:42,111:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.15s, LR: 0.00070, Train Loss: 0.4563, Train MAE: 0.4563,
                            Val Loss: 0.6128, Val Acc: 0.6128, Test MAE: 0.6570
2022-09-10 18:06:42,117:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 18:06:56,300:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.18s, LR: 0.00070, Train Loss: 0.4446, Train MAE: 0.4446,
                            Val Loss: 0.5623, Val Acc: 0.5623, Test MAE: 0.5615
2022-09-10 18:06:56,306:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 18:07:10,559:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.516027208417654
2022-09-10 18:07:10,559:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.25s, LR: 0.00070, Train Loss: 0.4543, Train MAE: 0.4543,
                            Val Loss: 0.4947, Val Acc: 0.4947, Test MAE: 0.5160
2022-09-10 18:07:10,565:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 18:07:24,801:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.24s, LR: 0.00070, Train Loss: 0.4536, Train MAE: 0.4536,
                            Val Loss: 0.5735, Val Acc: 0.5735, Test MAE: 0.6176
2022-09-10 18:07:24,807:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 18:07:39,401:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.504317618906498
2022-09-10 18:07:39,401:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.59s, LR: 0.00070, Train Loss: 0.4454, Train MAE: 0.4454,
                            Val Loss: 0.4957, Val Acc: 0.4957, Test MAE: 0.5043
2022-09-10 18:07:39,407:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 18:07:54,350:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.94s, LR: 0.00070, Train Loss: 0.4332, Train MAE: 0.4332,
                            Val Loss: 0.5781, Val Acc: 0.5781, Test MAE: 0.6140
2022-09-10 18:07:54,356:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 18:07:55,878:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:07:55,878:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:08:05,792:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:08:08,973:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 8, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:08:08,973:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:08:08,973:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:08:08,974:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:08:08,974:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:08:08,974:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:08:08,979:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:08:08,980:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525514
2022-09-10 18:08:08,980:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:08:08,980:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:08:08,980:pe_layer.py:129 -             __init__(): Using 8 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:08:08,980:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:08:08,980:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:08:08,985:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (8).
2022-09-10 18:08:21,285:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:12.304757833480835
2022-09-10 18:08:21,300:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:08:21,301:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:08:21,301:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:08:21,303:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:08:35,784:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7112036794424057
2022-09-10 18:08:35,785:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.48s, LR: 0.00070, Train Loss: 0.8888, Train MAE: 0.8888,
                            Val Loss: 0.6820, Val Acc: 0.6820, Test MAE: 0.7112
2022-09-10 18:08:35,791:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:08:49,999:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6970350965857506
2022-09-10 18:08:49,999:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.21s, LR: 0.00070, Train Loss: 0.6459, Train MAE: 0.6459,
                            Val Loss: 0.6506, Val Acc: 0.6506, Test MAE: 0.6970
2022-09-10 18:08:50,006:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:09:04,084:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6498869732022285
2022-09-10 18:09:04,085:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.08s, LR: 0.00070, Train Loss: 0.6171, Train MAE: 0.6171,
                            Val Loss: 0.5988, Val Acc: 0.5988, Test MAE: 0.6499
2022-09-10 18:09:04,091:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:09:18,532:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.44s, LR: 0.00070, Train Loss: 0.5997, Train MAE: 0.5997,
                            Val Loss: 0.6297, Val Acc: 0.6297, Test MAE: 0.6581
2022-09-10 18:09:18,538:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:09:32,798:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.26s, LR: 0.00070, Train Loss: 0.5753, Train MAE: 0.5753,
                            Val Loss: 0.6460, Val Acc: 0.6460, Test MAE: 0.6908
2022-09-10 18:09:32,805:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 18:09:34,664:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:09:34,664:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:09:43,557:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:09:46,707:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:09:46,707:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:09:46,708:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:09:46,712:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:09:46,712:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:09:46,712:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:09:46,717:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:09:46,717:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 534082
2022-09-10 18:09:46,717:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:09:46,717:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:09:46,718:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:09:46,718:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:09:46,718:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:09:46,724:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:10:33,888:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:47.1710250377655
2022-09-10 18:10:33,909:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:10:33,909:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:10:33,909:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:10:33,912:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:10:48,612:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.8161567971110344
2022-09-10 18:10:48,613:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.70s, LR: 0.00070, Train Loss: 0.8518, Train MAE: 0.8518,
                            Val Loss: 0.7954, Val Acc: 0.7954, Test MAE: 0.8162
2022-09-10 18:10:48,619:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:11:03,237:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.631119929254055
2022-09-10 18:11:03,238:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.62s, LR: 0.00070, Train Loss: 0.6173, Train MAE: 0.6173,
                            Val Loss: 0.5968, Val Acc: 0.5968, Test MAE: 0.6311
2022-09-10 18:11:03,244:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:11:17,516:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.630511000752449
2022-09-10 18:11:17,517:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.27s, LR: 0.00070, Train Loss: 0.5944, Train MAE: 0.5944,
                            Val Loss: 0.5864, Val Acc: 0.5864, Test MAE: 0.6305
2022-09-10 18:11:17,523:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:11:31,604:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5945997498929501
2022-09-10 18:11:31,604:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.08s, LR: 0.00070, Train Loss: 0.5770, Train MAE: 0.5770,
                            Val Loss: 0.5502, Val Acc: 0.5502, Test MAE: 0.5946
2022-09-10 18:11:31,610:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:11:45,584:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.582357607781887
2022-09-10 18:11:45,584:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 13.97s, LR: 0.00070, Train Loss: 0.5601, Train MAE: 0.5601,
                            Val Loss: 0.5434, Val Acc: 0.5434, Test MAE: 0.5824
2022-09-10 18:11:45,591:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 18:11:59,792:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5804828219115734
2022-09-10 18:11:59,792:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.20s, LR: 0.00070, Train Loss: 0.5356, Train MAE: 0.5356,
                            Val Loss: 0.5535, Val Acc: 0.5535, Test MAE: 0.5805
2022-09-10 18:11:59,799:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 18:12:13,984:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5797690376639366
2022-09-10 18:12:13,985:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.19s, LR: 0.00070, Train Loss: 0.5462, Train MAE: 0.5462,
                            Val Loss: 0.5455, Val Acc: 0.5455, Test MAE: 0.5798
2022-09-10 18:12:13,991:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 18:12:28,184:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5361103489995003
2022-09-10 18:12:28,184:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.19s, LR: 0.00070, Train Loss: 0.5008, Train MAE: 0.5008,
                            Val Loss: 0.5123, Val Acc: 0.5123, Test MAE: 0.5361
2022-09-10 18:12:28,190:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 18:12:42,472:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.28s, LR: 0.00070, Train Loss: 0.5045, Train MAE: 0.5045,
                            Val Loss: 0.5535, Val Acc: 0.5535, Test MAE: 0.5624
2022-09-10 18:12:42,478:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 18:12:56,661:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.18s, LR: 0.00070, Train Loss: 0.4899, Train MAE: 0.4899,
                            Val Loss: 0.5735, Val Acc: 0.5735, Test MAE: 0.5996
2022-09-10 18:12:56,667:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 18:13:10,928:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.26s, LR: 0.00070, Train Loss: 0.4717, Train MAE: 0.4717,
                            Val Loss: 0.5312, Val Acc: 0.5312, Test MAE: 0.5463
2022-09-10 18:13:10,935:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 18:13:25,112:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.18s, LR: 0.00070, Train Loss: 0.4761, Train MAE: 0.4761,
                            Val Loss: 0.6311, Val Acc: 0.6311, Test MAE: 0.6332
2022-09-10 18:13:25,118:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 18:13:27,387:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:13:27,388:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:13:36,850:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:13:40,120:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:13:40,121:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:13:40,121:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:13:40,122:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:13:40,122:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:13:40,122:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:13:40,127:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:13:40,128:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 534082
2022-09-10 18:13:40,128:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:13:40,128:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:13:40,129:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:13:40,129:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:13:40,129:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:13:40,134:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:14:21,606:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:41.477346897125244
2022-09-10 18:14:21,625:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:14:21,625:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:14:21,625:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:14:21,627:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:14:36,045:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 4.62159389257431
2022-09-10 18:14:36,046:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.42s, LR: 0.00070, Train Loss: 1.2928, Train MAE: 1.2928,
                            Val Loss: 4.6645, Val Acc: 4.6645, Test MAE: 4.6216
2022-09-10 18:14:36,052:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:14:40,355:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:14:40,355:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:15:04,972:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:15:08,376:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:15:08,376:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:15:08,376:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:15:08,378:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:15:08,378:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:15:08,378:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:15:08,388:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:15:08,389:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 534082
2022-09-10 18:15:08,390:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:15:08,390:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:15:08,392:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:15:08,392:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:15:08,392:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:15:08,399:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:15:50,232:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:41.842379093170166
2022-09-10 18:15:50,254:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:15:50,254:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:15:50,255:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:15:50,257:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:16:05,346:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.355385109782219
2022-09-10 18:16:05,348:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.09s, LR: 0.00070, Train Loss: 1.1280, Train MAE: 1.1280,
                            Val Loss: 1.3110, Val Acc: 1.3110, Test MAE: 1.3554
2022-09-10 18:16:05,354:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:16:08,913:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:16:08,913:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:16:22,307:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:16:25,654:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:16:25,654:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:16:25,654:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:16:25,655:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:16:25,655:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:16:25,655:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:16:25,661:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:16:25,661:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 534082
2022-09-10 18:16:25,662:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:16:25,662:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:16:25,662:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:16:25,662:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:16:25,662:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:16:25,667:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:17:05,495:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:39.833154916763306
2022-09-10 18:17:05,517:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:17:05,517:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:17:05,517:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:17:05,520:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:17:19,225:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 1.1026705205440521
2022-09-10 18:17:19,227:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 13.71s, LR: 0.00070, Train Loss: 1.1033, Train MAE: 1.1033,
                            Val Loss: 1.0709, Val Acc: 1.0709, Test MAE: 1.1027
2022-09-10 18:17:19,234:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:17:33,733:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.756951093673706
2022-09-10 18:17:33,733:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.50s, LR: 0.00070, Train Loss: 0.7422, Train MAE: 0.7422,
                            Val Loss: 0.6870, Val Acc: 0.6870, Test MAE: 0.7570
2022-09-10 18:17:33,739:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:17:46,904:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 13.16s, LR: 0.00070, Train Loss: 0.6929, Train MAE: 0.6929,
                            Val Loss: 0.8059, Val Acc: 0.8059, Test MAE: 0.8223
2022-09-10 18:17:46,910:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:18:00,071:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.7301363870501518
2022-09-10 18:18:00,071:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 13.16s, LR: 0.00070, Train Loss: 0.6663, Train MAE: 0.6663,
                            Val Loss: 0.6879, Val Acc: 0.6879, Test MAE: 0.7301
2022-09-10 18:18:00,077:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:18:03,044:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:18:03,044:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:18:19,524:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:18:22,800:main_molecules_graph_regression.py:352 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'edge_feat': False, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 128, 'learned_pos_enc': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'ZINC', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc': False, 'random_orientation': False, 'num_atom_type': 28, 'num_bond_type': 4}
2022-09-10 18:18:22,800:main_molecules_graph_regression.py:353 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 128, 'init_lr': 0.0007, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 15, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'save_name': 'b128-bnorm-alt-noedge-500k', 'job_num': 1}
2022-09-10 18:18:22,800:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:18:22,801:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:18:22,801:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:18:22,801:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:18:22,806:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:18:22,807:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 534082
2022-09-10 18:18:22,807:main_molecules_graph_regression.py:40 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:18:22,807:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:18:22,808:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:18:22,808:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:18:22,808:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:18:22,813:main_molecules_graph_regression.py:65 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:18:41,559:main_molecules_graph_regression.py:71 -   train_val_pipeline(): Time PE:18.751509189605713
2022-09-10 18:18:41,573:main_molecules_graph_regression.py:119 -   train_val_pipeline(): Training Graphs: 10000
2022-09-10 18:18:41,573:main_molecules_graph_regression.py:120 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:18:41,573:main_molecules_graph_regression.py:121 -   train_val_pipeline(): Test Graphs: 1000
2022-09-10 18:18:41,575:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:18:56,430:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.8134202137589455
2022-09-10 18:18:56,431:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.86s, LR: 0.00070, Train Loss: 0.9453, Train MAE: 0.9453,
                            Val Loss: 0.7500, Val Acc: 0.7500, Test MAE: 0.8134
2022-09-10 18:18:56,437:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:19:11,975:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.6426535323262215
2022-09-10 18:19:11,976:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.54s, LR: 0.00070, Train Loss: 0.5902, Train MAE: 0.5902,
                            Val Loss: 0.5944, Val Acc: 0.5944, Test MAE: 0.6427
2022-09-10 18:19:11,982:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:19:27,654:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.67s, LR: 0.00070, Train Loss: 0.5595, Train MAE: 0.5595,
                            Val Loss: 0.6623, Val Acc: 0.6623, Test MAE: 0.7108
2022-09-10 18:19:27,660:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:19:43,381:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.640370711684227
2022-09-10 18:19:43,381:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.72s, LR: 0.00070, Train Loss: 0.5375, Train MAE: 0.5375,
                            Val Loss: 0.6065, Val Acc: 0.6065, Test MAE: 0.6404
2022-09-10 18:19:43,387:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:19:58,522:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5845606774091721
2022-09-10 18:19:58,522:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.14s, LR: 0.00070, Train Loss: 0.5030, Train MAE: 0.5030,
                            Val Loss: 0.5504, Val Acc: 0.5504, Test MAE: 0.5846
2022-09-10 18:19:58,529:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 18:20:13,857:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.542625155299902
2022-09-10 18:20:13,857:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.33s, LR: 0.00070, Train Loss: 0.4842, Train MAE: 0.4842,
                            Val Loss: 0.5131, Val Acc: 0.5131, Test MAE: 0.5426
2022-09-10 18:20:13,863:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 18:20:29,028:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.16s, LR: 0.00070, Train Loss: 0.5057, Train MAE: 0.5057,
                            Val Loss: 0.6632, Val Acc: 0.6632, Test MAE: 0.6988
2022-09-10 18:20:29,034:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 18:20:44,471:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5304035320878029
2022-09-10 18:20:44,472:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.44s, LR: 0.00070, Train Loss: 0.4524, Train MAE: 0.4524,
                            Val Loss: 0.5017, Val Acc: 0.5017, Test MAE: 0.5304
2022-09-10 18:20:44,478:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 18:21:00,108:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.5229439102113247
2022-09-10 18:21:00,108:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.63s, LR: 0.00070, Train Loss: 0.4623, Train MAE: 0.4623,
                            Val Loss: 0.5078, Val Acc: 0.5078, Test MAE: 0.5229
2022-09-10 18:21:00,114:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 18:21:15,735:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.62s, LR: 0.00070, Train Loss: 0.4412, Train MAE: 0.4412,
                            Val Loss: 0.5193, Val Acc: 0.5193, Test MAE: 0.5375
2022-09-10 18:21:15,742:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 18:21:30,724:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.4918801486492157
2022-09-10 18:21:30,724:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.98s, LR: 0.00070, Train Loss: 0.4395, Train MAE: 0.4395,
                            Val Loss: 0.4693, Val Acc: 0.4693, Test MAE: 0.4919
2022-09-10 18:21:30,730:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 18:21:45,696:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.97s, LR: 0.00070, Train Loss: 0.4356, Train MAE: 0.4356,
                            Val Loss: 0.5314, Val Acc: 0.5314, Test MAE: 0.5626
2022-09-10 18:21:45,702:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 18:22:00,674:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.97s, LR: 0.00070, Train Loss: 0.4267, Train MAE: 0.4267,
                            Val Loss: 0.5541, Val Acc: 0.5541, Test MAE: 0.5799
2022-09-10 18:22:00,680:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 18:22:15,663:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.4611487351357937
2022-09-10 18:22:15,663:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.98s, LR: 0.00070, Train Loss: 0.4214, Train MAE: 0.4214,
                            Val Loss: 0.4493, Val Acc: 0.4493, Test MAE: 0.4611
2022-09-10 18:22:15,669:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 18:22:30,647:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.98s, LR: 0.00070, Train Loss: 0.4286, Train MAE: 0.4286,
                            Val Loss: 0.5477, Val Acc: 0.5477, Test MAE: 0.5605
2022-09-10 18:22:30,653:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 18:22:46,515:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.86s, LR: 0.00070, Train Loss: 0.4134, Train MAE: 0.4134,
                            Val Loss: 0.5100, Val Acc: 0.5100, Test MAE: 0.5110
2022-09-10 18:22:46,521:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 18:23:01,882:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.4594322070479393
2022-09-10 18:23:01,882:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.36s, LR: 0.00070, Train Loss: 0.4279, Train MAE: 0.4279,
                            Val Loss: 0.4423, Val Acc: 0.4423, Test MAE: 0.4594
2022-09-10 18:23:01,888:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 18:23:16,816:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.4486624598503113
2022-09-10 18:23:16,816:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.93s, LR: 0.00070, Train Loss: 0.4277, Train MAE: 0.4277,
                            Val Loss: 0.4450, Val Acc: 0.4450, Test MAE: 0.4487
2022-09-10 18:23:16,822:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 18:23:31,622:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.80s, LR: 0.00070, Train Loss: 0.4176, Train MAE: 0.4176,
                            Val Loss: 0.4703, Val Acc: 0.4703, Test MAE: 0.4770
2022-09-10 18:23:31,628:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 18:23:46,569:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.94s, LR: 0.00070, Train Loss: 0.4015, Train MAE: 0.4015,
                            Val Loss: 0.4967, Val Acc: 0.4967, Test MAE: 0.5082
2022-09-10 18:23:46,575:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 18:24:01,556:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.98s, LR: 0.00070, Train Loss: 0.3996, Train MAE: 0.3996,
                            Val Loss: 0.4852, Val Acc: 0.4852, Test MAE: 0.4677
2022-09-10 18:24:01,563:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 18:24:16,381:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.82s, LR: 0.00070, Train Loss: 0.3867, Train MAE: 0.3867,
                            Val Loss: 0.5209, Val Acc: 0.5209, Test MAE: 0.5219
2022-09-10 18:24:16,388:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 18:24:31,612:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.4351522922515869
2022-09-10 18:24:31,613:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.22s, LR: 0.00070, Train Loss: 0.3905, Train MAE: 0.3905,
                            Val Loss: 0.4403, Val Acc: 0.4403, Test MAE: 0.4352
2022-09-10 18:24:31,619:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 18:24:47,153:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.53s, LR: 0.00070, Train Loss: 0.3740, Train MAE: 0.3740,
                            Val Loss: 0.6400, Val Acc: 0.6400, Test MAE: 0.6329
2022-09-10 18:24:47,160:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 18:25:02,297:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.14s, LR: 0.00070, Train Loss: 0.3782, Train MAE: 0.3782,
                            Val Loss: 0.5036, Val Acc: 0.5036, Test MAE: 0.4969
2022-09-10 18:25:02,303:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 18:25:18,704:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.40s, LR: 0.00070, Train Loss: 0.3651, Train MAE: 0.3651,
                            Val Loss: 0.5489, Val Acc: 0.5489, Test MAE: 0.5381
2022-09-10 18:25:18,710:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 18:25:34,550:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.84s, LR: 0.00070, Train Loss: 0.3643, Train MAE: 0.3643,
                            Val Loss: 0.5381, Val Acc: 0.5381, Test MAE: 0.5263
2022-09-10 18:25:34,556:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 18:25:51,272:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 16.72s, LR: 0.00070, Train Loss: 0.3537, Train MAE: 0.3537,
                            Val Loss: 0.5476, Val Acc: 0.5476, Test MAE: 0.5412
2022-09-10 18:25:51,278:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 18:26:06,607:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.4052579179406166
2022-09-10 18:26:06,608:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.33s, LR: 0.00070, Train Loss: 0.3473, Train MAE: 0.3473,
                            Val Loss: 0.4230, Val Acc: 0.4230, Test MAE: 0.4053
2022-09-10 18:26:06,614:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 18:26:22,119:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.51s, LR: 0.00070, Train Loss: 0.3366, Train MAE: 0.3366,
                            Val Loss: 0.4615, Val Acc: 0.4615, Test MAE: 0.4340
2022-09-10 18:26:22,125:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 18:26:36,948:main_molecules_graph_regression.py:178 -   train_val_pipeline(): Best model with MAE 0.3569001480937004
2022-09-10 18:26:36,948:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.82s, LR: 0.00070, Train Loss: 0.3516, Train MAE: 0.3516,
                            Val Loss: 0.3876, Val Acc: 0.3876, Test MAE: 0.3569
2022-09-10 18:26:36,955:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 18:26:51,811:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.86s, LR: 0.00070, Train Loss: 0.3342, Train MAE: 0.3342,
                            Val Loss: 0.3748, Val Acc: 0.3748, Test MAE: 0.3618
2022-09-10 18:26:51,818:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 18:27:06,693:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.87s, LR: 0.00070, Train Loss: 0.3142, Train MAE: 0.3142,
                            Val Loss: 0.4045, Val Acc: 0.4045, Test MAE: 0.3943
2022-09-10 18:27:06,700:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 18:27:21,594:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.89s, LR: 0.00070, Train Loss: 0.3326, Train MAE: 0.3326,
                            Val Loss: 0.4515, Val Acc: 0.4515, Test MAE: 0.4459
2022-09-10 18:27:21,600:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 18:27:36,392:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.79s, LR: 0.00070, Train Loss: 0.3450, Train MAE: 0.3450,
                            Val Loss: 0.4206, Val Acc: 0.4206, Test MAE: 0.4136
2022-09-10 18:27:36,398:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 36/1000
2022-09-10 18:27:51,249:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.85s, LR: 0.00070, Train Loss: 0.3265, Train MAE: 0.3265,
                            Val Loss: 0.4526, Val Acc: 0.4526, Test MAE: 0.4420
2022-09-10 18:27:51,255:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 37/1000
2022-09-10 18:28:06,249:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.99s, LR: 0.00070, Train Loss: 0.3171, Train MAE: 0.3171,
                            Val Loss: 0.4667, Val Acc: 0.4667, Test MAE: 0.4462
2022-09-10 18:28:06,256:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 38/1000
2022-09-10 18:28:21,200:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 14.94s, LR: 0.00070, Train Loss: 0.3275, Train MAE: 0.3275,
                            Val Loss: 0.4533, Val Acc: 0.4533, Test MAE: 0.4353
2022-09-10 18:28:21,207:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 39/1000
2022-09-10 18:28:36,349:main_molecules_graph_regression.py:201 -   train_val_pipeline(): 	Time: 15.14s, LR: 0.00070, Train Loss: 0.3182, Train MAE: 0.3182,
                            Val Loss: 0.4979, Val Acc: 0.4979, Test MAE: 0.4819
2022-09-10 18:28:36,356:main_molecules_graph_regression.py:159 -   train_val_pipeline(): Epoch 40/1000
2022-09-10 18:28:38,101:main_molecules_graph_regression.py:233 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 18:28:38,101:main_molecules_graph_regression.py:234 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 18:29:11,154:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:29:21,504:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:29:25,823:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': True, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': False, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 18:29:25,823:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 18:29:25,823:pe_layer.py:65 -             __init__(): pos_enc
2022-09-10 18:29:25,824:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:29:25,824:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:29:25,824:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:29:25,828:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:29:25,829:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 527862
2022-09-10 18:29:25,829:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:29:25,829:pe_layer.py:65 -             __init__(): pos_enc
2022-09-10 18:29:25,829:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:29:25,829:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:29:25,829:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:29:25,834:main_CYCLES_graph_classification.py:64 -   train_val_pipeline(): [!] Adding Laplacian graph positional encoding.
2022-09-10 18:29:47,236:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:29:51,771:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 18:29:51,771:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 18:29:51,771:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:29:51,772:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:29:51,772:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:29:51,772:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:29:51,777:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:29:51,777:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-10 18:29:51,778:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:29:51,778:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:29:51,778:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:29:51,778:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:29:51,778:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:29:51,783:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:31:12,195:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:80.41698694229126
2022-09-10 18:31:12,221:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 18:31:12,221:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:31:12,221:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 18:31:12,221:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 18:31:12,224:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:31:33,659:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.4977 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h29m51s_on_Sep_10_2022/MODELS_
2022-09-10 18:31:33,660:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.44s, LR: 0.00050, Train Loss: 0.5951, Train Acc: 0.7200,
                            Val Loss: 4.6757, Val Acc: 0.4940, Test Acc: 0.4977
2022-09-10 18:31:33,660:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:31:55,062:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5001 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h29m51s_on_Sep_10_2022/MODELS_
2022-09-10 18:31:55,062:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.40s, LR: 0.00050, Train Loss: 0.3755, Train Acc: 0.8850,
                            Val Loss: 3.5773, Val Acc: 0.5000, Test Acc: 0.5001
2022-09-10 18:31:55,062:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:32:17,363:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6866 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h29m51s_on_Sep_10_2022/MODELS_
2022-09-10 18:32:17,363:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.30s, LR: 0.00050, Train Loss: 0.3269, Train Acc: 0.8650,
                            Val Loss: 0.7594, Val Acc: 0.6910, Test Acc: 0.6866
2022-09-10 18:32:17,363:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:32:28,926:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:32:33,464:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 18:32:33,464:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 18:32:33,464:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:32:33,465:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:32:33,465:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:32:33,465:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:32:33,471:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:32:33,471:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-10 18:32:33,471:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:32:33,472:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:32:33,472:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:32:33,472:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:32:33,472:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:32:33,478:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:34:10,362:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:96.89067697525024
2022-09-10 18:34:10,388:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 18:34:10,388:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:34:10,389:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 18:34:10,389:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 18:34:10,392:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:34:30,700:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.4977 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:34:30,701:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.31s, LR: 0.00050, Train Loss: 0.6703, Train Acc: 0.7800,
                            Val Loss: 5.3093, Val Acc: 0.4940, Test Acc: 0.4977
2022-09-10 18:34:30,701:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:34:50,857:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7601 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:34:50,857:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.16s, LR: 0.00050, Train Loss: 0.3963, Train Acc: 0.9150,
                            Val Loss: 0.5583, Val Acc: 0.7620, Test Acc: 0.7601
2022-09-10 18:34:50,857:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:35:11,264:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8676 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:35:11,264:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.41s, LR: 0.00050, Train Loss: 0.3475, Train Acc: 0.8800,
                            Val Loss: 0.7567, Val Acc: 0.8640, Test Acc: 0.8676
2022-09-10 18:35:11,264:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:35:31,444:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8884 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:35:31,445:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.18s, LR: 0.00050, Train Loss: 0.3270, Train Acc: 0.9100,
                            Val Loss: 0.3538, Val Acc: 0.8800, Test Acc: 0.8884
2022-09-10 18:35:31,445:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:35:51,672:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.23s, LR: 0.00050, Train Loss: 0.2918, Train Acc: 0.8800,
                            Val Loss: 0.7722, Val Acc: 0.6440, Test Acc: 0.6553
2022-09-10 18:35:51,672:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 18:36:11,867:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.19s, LR: 0.00050, Train Loss: 0.2626, Train Acc: 0.9100,
                            Val Loss: 0.4999, Val Acc: 0.8080, Test Acc: 0.8185
2022-09-10 18:36:11,867:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 18:36:32,115:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.25s, LR: 0.00050, Train Loss: 0.2157, Train Acc: 0.9350,
                            Val Loss: 0.5289, Val Acc: 0.8450, Test Acc: 0.8415
2022-09-10 18:36:32,115:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 18:36:52,551:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9007 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:36:52,552:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.44s, LR: 0.00050, Train Loss: 0.2060, Train Acc: 0.9250,
                            Val Loss: 0.3520, Val Acc: 0.8830, Test Acc: 0.9007
2022-09-10 18:36:52,552:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 18:37:12,565:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9008 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:37:12,566:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.01s, LR: 0.00050, Train Loss: 0.2432, Train Acc: 0.9250,
                            Val Loss: 0.3275, Val Acc: 0.8990, Test Acc: 0.9008
2022-09-10 18:37:12,566:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 18:37:32,721:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.16s, LR: 0.00050, Train Loss: 0.2253, Train Acc: 0.9300,
                            Val Loss: 1.0383, Val Acc: 0.7060, Test Acc: 0.7192
2022-09-10 18:37:32,721:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 18:37:53,174:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9348 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:37:53,174:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.45s, LR: 0.00050, Train Loss: 0.2284, Train Acc: 0.9300,
                            Val Loss: 0.2451, Val Acc: 0.9190, Test Acc: 0.9348
2022-09-10 18:37:53,174:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 18:38:13,271:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9413 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:38:13,271:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.10s, LR: 0.00050, Train Loss: 0.2206, Train Acc: 0.9350,
                            Val Loss: 0.2134, Val Acc: 0.9340, Test Acc: 0.9413
2022-09-10 18:38:13,271:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 18:38:33,332:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.06s, LR: 0.00050, Train Loss: 0.1855, Train Acc: 0.9500,
                            Val Loss: 0.6227, Val Acc: 0.8780, Test Acc: 0.8841
2022-09-10 18:38:33,333:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 18:38:53,374:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.04s, LR: 0.00050, Train Loss: 0.2006, Train Acc: 0.9400,
                            Val Loss: 0.4688, Val Acc: 0.8900, Test Acc: 0.8940
2022-09-10 18:38:53,375:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 18:39:13,419:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.04s, LR: 0.00050, Train Loss: 0.1848, Train Acc: 0.9450,
                            Val Loss: 0.4175, Val Acc: 0.8080, Test Acc: 0.8147
2022-09-10 18:39:13,419:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 18:39:33,489:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.07s, LR: 0.00050, Train Loss: 0.1947, Train Acc: 0.9550,
                            Val Loss: 0.2719, Val Acc: 0.9100, Test Acc: 0.9220
2022-09-10 18:39:33,490:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 18:39:53,960:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9421 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:39:53,961:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.47s, LR: 0.00050, Train Loss: 0.1596, Train Acc: 0.9250,
                            Val Loss: 0.2217, Val Acc: 0.9380, Test Acc: 0.9421
2022-09-10 18:39:53,961:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 18:40:14,028:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.07s, LR: 0.00050, Train Loss: 0.1509, Train Acc: 0.9450,
                            Val Loss: 0.2335, Val Acc: 0.9240, Test Acc: 0.9350
2022-09-10 18:40:14,028:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 18:40:34,060:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.03s, LR: 0.00050, Train Loss: 0.1727, Train Acc: 0.9350,
                            Val Loss: 0.2317, Val Acc: 0.9260, Test Acc: 0.9351
2022-09-10 18:40:34,061:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 18:40:54,111:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9454 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:40:54,112:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.05s, LR: 0.00050, Train Loss: 0.1747, Train Acc: 0.9350,
                            Val Loss: 0.1945, Val Acc: 0.9400, Test Acc: 0.9454
2022-09-10 18:40:54,112:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 18:41:14,209:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.10s, LR: 0.00050, Train Loss: 0.1422, Train Acc: 0.9450,
                            Val Loss: 0.2367, Val Acc: 0.9320, Test Acc: 0.9410
2022-09-10 18:41:14,209:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 18:41:34,448:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.24s, LR: 0.00050, Train Loss: 0.1993, Train Acc: 0.9250,
                            Val Loss: 0.3236, Val Acc: 0.9030, Test Acc: 0.9172
2022-09-10 18:41:34,448:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 18:41:54,495:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.05s, LR: 0.00050, Train Loss: 0.1842, Train Acc: 0.9400,
                            Val Loss: 0.4549, Val Acc: 0.8630, Test Acc: 0.8636
2022-09-10 18:41:54,495:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 18:42:14,748:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.25s, LR: 0.00050, Train Loss: 0.2142, Train Acc: 0.9550,
                            Val Loss: 2.1637, Val Acc: 0.6240, Test Acc: 0.6354
2022-09-10 18:42:14,749:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 18:42:35,027:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.28s, LR: 0.00050, Train Loss: 0.1659, Train Acc: 0.9450,
                            Val Loss: 0.9807, Val Acc: 0.7610, Test Acc: 0.7562
2022-09-10 18:42:35,027:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 18:42:55,319:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9497 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h32m33s_on_Sep_10_2022/MODELS_
2022-09-10 18:42:55,319:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.29s, LR: 0.00050, Train Loss: 0.1621, Train Acc: 0.9400,
                            Val Loss: 0.1938, Val Acc: 0.9470, Test Acc: 0.9497
2022-09-10 18:42:55,319:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 18:43:15,573:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.25s, LR: 0.00050, Train Loss: 0.1382, Train Acc: 0.9400,
                            Val Loss: 0.2362, Val Acc: 0.9370, Test Acc: 0.9414
2022-09-10 18:43:15,573:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 18:43:35,602:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.03s, LR: 0.00050, Train Loss: 0.1336, Train Acc: 0.9550,
                            Val Loss: 0.1803, Val Acc: 0.9460, Test Acc: 0.9490
2022-09-10 18:43:35,603:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 18:43:55,923:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.32s, LR: 0.00050, Train Loss: 0.0989, Train Acc: 0.9650,
                            Val Loss: 0.1967, Val Acc: 0.9380, Test Acc: 0.9475
2022-09-10 18:43:55,923:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 18:44:16,221:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.30s, LR: 0.00050, Train Loss: 0.1024, Train Acc: 0.9450,
                            Val Loss: 0.2151, Val Acc: 0.9440, Test Acc: 0.9492
2022-09-10 18:44:16,221:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 18:44:36,251:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.03s, LR: 0.00050, Train Loss: 0.1164, Train Acc: 0.9350,
                            Val Loss: 0.2181, Val Acc: 0.9360, Test Acc: 0.9409
2022-09-10 18:44:36,251:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 18:44:56,358:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.11s, LR: 0.00050, Train Loss: 0.1149, Train Acc: 0.9600,
                            Val Loss: 0.2107, Val Acc: 0.9280, Test Acc: 0.9363
2022-09-10 18:44:56,358:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 18:45:16,407:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.05s, LR: 0.00050, Train Loss: 0.1126, Train Acc: 0.9550,
                            Val Loss: 0.2323, Val Acc: 0.9240, Test Acc: 0.9349
2022-09-10 18:45:16,408:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 18:45:36,912:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.50s, LR: 0.00050, Train Loss: 0.0904, Train Acc: 0.9600,
                            Val Loss: 0.2333, Val Acc: 0.9320, Test Acc: 0.9340
2022-09-10 18:45:36,913:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 18:45:54,501:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:45:58,819:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 18:45:58,819:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 18:45:58,819:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:45:58,820:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:45:58,820:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:45:58,820:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:45:58,825:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:45:58,826:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-10 18:45:58,826:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:45:58,826:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:45:58,827:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:45:58,827:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:45:58,827:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:45:58,832:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:46:32,953:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:34.12696290016174
2022-09-10 18:46:32,968:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 18:46:32,968:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:46:32,968:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 18:46:32,968:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 18:46:32,970:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:46:54,016:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.4977 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:46:54,017:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.05s, LR: 0.00050, Train Loss: 0.5868, Train Acc: 0.7950,
                            Val Loss: 5.1537, Val Acc: 0.4940, Test Acc: 0.4977
2022-09-10 18:46:54,017:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:47:14,718:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5580 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:47:14,718:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.70s, LR: 0.00050, Train Loss: 0.3671, Train Acc: 0.8800,
                            Val Loss: 2.1340, Val Acc: 0.5640, Test Acc: 0.5580
2022-09-10 18:47:14,718:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:47:35,719:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8674 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:47:35,720:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.00s, LR: 0.00050, Train Loss: 0.3301, Train Acc: 0.8950,
                            Val Loss: 0.6998, Val Acc: 0.8600, Test Acc: 0.8674
2022-09-10 18:47:35,720:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 18:47:56,496:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9040 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:47:56,496:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00050, Train Loss: 0.3071, Train Acc: 0.9000,
                            Val Loss: 0.3241, Val Acc: 0.8950, Test Acc: 0.9040
2022-09-10 18:47:56,496:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 18:48:17,359:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.86s, LR: 0.00050, Train Loss: 0.2793, Train Acc: 0.9000,
                            Val Loss: 0.5107, Val Acc: 0.7730, Test Acc: 0.7809
2022-09-10 18:48:17,359:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 18:48:38,122:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9163 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:48:38,122:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.76s, LR: 0.00050, Train Loss: 0.2204, Train Acc: 0.9450,
                            Val Loss: 0.2618, Val Acc: 0.9070, Test Acc: 0.9163
2022-09-10 18:48:38,123:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 18:48:58,991:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.87s, LR: 0.00050, Train Loss: 0.2006, Train Acc: 0.9500,
                            Val Loss: 0.3610, Val Acc: 0.9000, Test Acc: 0.9085
2022-09-10 18:48:58,991:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 18:49:19,776:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00050, Train Loss: 0.1674, Train Acc: 0.9500,
                            Val Loss: 0.5024, Val Acc: 0.7960, Test Acc: 0.8054
2022-09-10 18:49:19,776:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 18:49:40,557:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00050, Train Loss: 0.2269, Train Acc: 0.9450,
                            Val Loss: 0.8251, Val Acc: 0.5840, Test Acc: 0.5894
2022-09-10 18:49:40,557:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 18:50:01,337:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00050, Train Loss: 0.2722, Train Acc: 0.9200,
                            Val Loss: 1.0793, Val Acc: 0.6980, Test Acc: 0.7128
2022-09-10 18:50:01,337:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 18:50:22,713:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.37s, LR: 0.00050, Train Loss: 0.2997, Train Acc: 0.8900,
                            Val Loss: 1.2961, Val Acc: 0.6760, Test Acc: 0.6714
2022-09-10 18:50:22,713:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 18:50:44,080:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.37s, LR: 0.00050, Train Loss: 0.2397, Train Acc: 0.9150,
                            Val Loss: 0.4280, Val Acc: 0.8310, Test Acc: 0.8446
2022-09-10 18:50:44,081:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 18:51:05,371:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.29s, LR: 0.00050, Train Loss: 0.2116, Train Acc: 0.9400,
                            Val Loss: 1.1340, Val Acc: 0.5030, Test Acc: 0.5011
2022-09-10 18:51:05,371:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 18:51:27,267:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.89s, LR: 0.00050, Train Loss: 0.1805, Train Acc: 0.9450,
                            Val Loss: 0.3697, Val Acc: 0.8690, Test Acc: 0.8779
2022-09-10 18:51:27,267:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 18:51:50,116:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.85s, LR: 0.00050, Train Loss: 0.1686, Train Acc: 0.9450,
                            Val Loss: 0.2680, Val Acc: 0.9080, Test Acc: 0.9114
2022-09-10 18:51:50,116:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 18:52:13,254:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9396 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:52:13,254:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.14s, LR: 0.00050, Train Loss: 0.1509, Train Acc: 0.9500,
                            Val Loss: 0.2123, Val Acc: 0.9340, Test Acc: 0.9396
2022-09-10 18:52:13,254:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 18:52:34,754:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9409 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:52:34,754:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.50s, LR: 0.00050, Train Loss: 0.1782, Train Acc: 0.9450,
                            Val Loss: 0.1995, Val Acc: 0.9360, Test Acc: 0.9409
2022-09-10 18:52:34,754:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 18:52:57,245:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.49s, LR: 0.00050, Train Loss: 0.1859, Train Acc: 0.9250,
                            Val Loss: 0.3020, Val Acc: 0.9390, Test Acc: 0.9395
2022-09-10 18:52:57,245:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 18:53:19,230:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.98s, LR: 0.00050, Train Loss: 0.1865, Train Acc: 0.9250,
                            Val Loss: 0.2471, Val Acc: 0.9350, Test Acc: 0.9398
2022-09-10 18:53:19,230:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 18:53:41,136:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.91s, LR: 0.00050, Train Loss: 0.2148, Train Acc: 0.9250,
                            Val Loss: 0.3191, Val Acc: 0.9220, Test Acc: 0.9325
2022-09-10 18:53:41,137:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 18:54:01,943:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9470 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h45m58s_on_Sep_10_2022/MODELS_
2022-09-10 18:54:01,944:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.81s, LR: 0.00050, Train Loss: 0.1293, Train Acc: 0.9600,
                            Val Loss: 0.3171, Val Acc: 0.9450, Test Acc: 0.9470
2022-09-10 18:54:01,944:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 18:54:22,971:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.03s, LR: 0.00050, Train Loss: 0.1738, Train Acc: 0.9600,
                            Val Loss: 0.1813, Val Acc: 0.9430, Test Acc: 0.9457
2022-09-10 18:54:22,972:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 18:54:44,130:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.16s, LR: 0.00050, Train Loss: 0.1577, Train Acc: 0.9550,
                            Val Loss: 0.2797, Val Acc: 0.9250, Test Acc: 0.9384
2022-09-10 18:54:44,130:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 18:55:05,082:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.95s, LR: 0.00050, Train Loss: 0.1387, Train Acc: 0.9600,
                            Val Loss: 0.2115, Val Acc: 0.9320, Test Acc: 0.9355
2022-09-10 18:55:05,083:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 18:55:25,789:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.71s, LR: 0.00050, Train Loss: 0.1078, Train Acc: 0.9500,
                            Val Loss: 0.2579, Val Acc: 0.9230, Test Acc: 0.9256
2022-09-10 18:55:25,789:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 18:55:46,698:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.91s, LR: 0.00050, Train Loss: 0.1121, Train Acc: 0.9600,
                            Val Loss: 0.4255, Val Acc: 0.8230, Test Acc: 0.8246
2022-09-10 18:55:46,699:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 18:56:07,387:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.69s, LR: 0.00050, Train Loss: 0.1493, Train Acc: 0.9450,
                            Val Loss: 0.8066, Val Acc: 0.8450, Test Acc: 0.8531
2022-09-10 18:56:07,388:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 18:56:28,170:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00050, Train Loss: 0.1080, Train Acc: 0.9550,
                            Val Loss: 0.5067, Val Acc: 0.9110, Test Acc: 0.9186
2022-09-10 18:56:28,170:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 18:56:48,879:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.71s, LR: 0.00050, Train Loss: 0.1338, Train Acc: 0.9650,
                            Val Loss: 0.2348, Val Acc: 0.9340, Test Acc: 0.9414
2022-09-10 18:56:48,880:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 18:57:09,570:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.69s, LR: 0.00050, Train Loss: 0.1330, Train Acc: 0.9450,
                            Val Loss: 0.2334, Val Acc: 0.9380, Test Acc: 0.9346
2022-09-10 18:57:09,570:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 18:57:30,269:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.70s, LR: 0.00050, Train Loss: 0.1595, Train Acc: 0.9500,
                            Val Loss: 0.2362, Val Acc: 0.9290, Test Acc: 0.9385
2022-09-10 18:57:30,270:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 18:57:51,358:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.09s, LR: 0.00050, Train Loss: 0.1209, Train Acc: 0.9350,
                            Val Loss: 0.2689, Val Acc: 0.9310, Test Acc: 0.9291
2022-09-10 18:57:51,359:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 18:58:14,166:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 18:58:18,495:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 18:58:18,495:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 18:58:18,495:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:58:18,496:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:58:18,496:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:58:18,496:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:58:18,501:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 18:58:18,502:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-10 18:58:18,502:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 18:58:18,502:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 18:58:18,502:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 18:58:18,502:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 18:58:18,502:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 18:58:18,507:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 18:58:52,252:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:33.749828815460205
2022-09-10 18:58:52,268:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 18:58:52,268:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 18:58:52,268:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 18:58:52,268:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 18:58:52,271:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 18:59:13,679:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5168 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 18:59:13,681:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.41s, LR: 0.00050, Train Loss: 0.8766, Train Acc: 0.5750,
                            Val Loss: 0.9556, Val Acc: 0.5130, Test Acc: 0.5168
2022-09-10 18:59:13,681:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 18:59:34,843:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7648 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 18:59:34,843:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.16s, LR: 0.00050, Train Loss: 0.4512, Train Acc: 0.8050,
                            Val Loss: 0.5223, Val Acc: 0.7640, Test Acc: 0.7648
2022-09-10 18:59:34,843:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 18:59:55,515:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8289 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 18:59:55,515:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.67s, LR: 0.00050, Train Loss: 0.3878, Train Acc: 0.8650,
                            Val Loss: 0.4926, Val Acc: 0.8130, Test Acc: 0.8289
2022-09-10 18:59:55,515:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:00:16,276:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8571 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 19:00:16,277:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.76s, LR: 0.00050, Train Loss: 0.3119, Train Acc: 0.8800,
                            Val Loss: 0.4335, Val Acc: 0.8580, Test Acc: 0.8571
2022-09-10 19:00:16,277:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:00:37,345:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8949 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 19:00:37,345:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.07s, LR: 0.00050, Train Loss: 0.3313, Train Acc: 0.8650,
                            Val Loss: 0.3228, Val Acc: 0.8870, Test Acc: 0.8949
2022-09-10 19:00:37,346:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:00:58,027:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.68s, LR: 0.00050, Train Loss: 0.2397, Train Acc: 0.9150,
                            Val Loss: 0.5966, Val Acc: 0.7900, Test Acc: 0.7910
2022-09-10 19:00:58,027:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:01:18,698:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9147 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 19:01:18,698:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.67s, LR: 0.00050, Train Loss: 0.2450, Train Acc: 0.9050,
                            Val Loss: 0.2899, Val Acc: 0.8990, Test Acc: 0.9147
2022-09-10 19:01:18,698:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:01:39,382:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.68s, LR: 0.00050, Train Loss: 0.1743, Train Acc: 0.9350,
                            Val Loss: 0.3899, Val Acc: 0.8610, Test Acc: 0.8737
2022-09-10 19:01:39,383:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:02:00,302:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9284 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 19:02:00,302:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.92s, LR: 0.00050, Train Loss: 0.2082, Train Acc: 0.9300,
                            Val Loss: 0.2375, Val Acc: 0.9270, Test Acc: 0.9284
2022-09-10 19:02:00,302:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:02:21,380:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.08s, LR: 0.00050, Train Loss: 0.1920, Train Acc: 0.9200,
                            Val Loss: 0.2892, Val Acc: 0.9030, Test Acc: 0.9072
2022-09-10 19:02:21,380:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:02:42,248:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.87s, LR: 0.00050, Train Loss: 0.1679, Train Acc: 0.9550,
                            Val Loss: 0.7019, Val Acc: 0.6600, Test Acc: 0.6485
2022-09-10 19:02:42,249:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:03:03,765:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.52s, LR: 0.00050, Train Loss: 0.1666, Train Acc: 0.9400,
                            Val Loss: 0.2910, Val Acc: 0.9010, Test Acc: 0.9035
2022-09-10 19:03:03,765:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:03:24,799:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9378 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 19:03:24,799:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.03s, LR: 0.00050, Train Loss: 0.1563, Train Acc: 0.9500,
                            Val Loss: 0.2517, Val Acc: 0.9230, Test Acc: 0.9378
2022-09-10 19:03:24,799:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:03:46,541:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.74s, LR: 0.00050, Train Loss: 0.1415, Train Acc: 0.9450,
                            Val Loss: 0.2978, Val Acc: 0.9060, Test Acc: 0.9143
2022-09-10 19:03:46,542:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:04:07,597:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9411 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_18h58m18s_on_Sep_10_2022/MODELS_
2022-09-10 19:04:07,597:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.05s, LR: 0.00050, Train Loss: 0.1060, Train Acc: 0.9650,
                            Val Loss: 0.2249, Val Acc: 0.9310, Test Acc: 0.9411
2022-09-10 19:04:07,597:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:04:30,577:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.98s, LR: 0.00050, Train Loss: 0.1003, Train Acc: 0.9600,
                            Val Loss: 0.5065, Val Acc: 0.8870, Test Acc: 0.8906
2022-09-10 19:04:30,578:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:04:51,698:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.12s, LR: 0.00050, Train Loss: 0.1114, Train Acc: 0.9450,
                            Val Loss: 0.2895, Val Acc: 0.9150, Test Acc: 0.9227
2022-09-10 19:04:51,699:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:05:12,729:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.03s, LR: 0.00050, Train Loss: 0.0934, Train Acc: 0.9550,
                            Val Loss: 0.2760, Val Acc: 0.9090, Test Acc: 0.9102
2022-09-10 19:05:12,729:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:05:33,674:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.94s, LR: 0.00050, Train Loss: 0.1329, Train Acc: 0.9550,
                            Val Loss: 0.3573, Val Acc: 0.8400, Test Acc: 0.8476
2022-09-10 19:05:33,675:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:05:54,913:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.24s, LR: 0.00050, Train Loss: 0.1619, Train Acc: 0.9350,
                            Val Loss: 0.2756, Val Acc: 0.9010, Test Acc: 0.8991
2022-09-10 19:05:54,913:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:06:16,563:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.65s, LR: 0.00050, Train Loss: 0.1637, Train Acc: 0.9400,
                            Val Loss: 1.1962, Val Acc: 0.6050, Test Acc: 0.5930
2022-09-10 19:06:16,563:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:06:37,378:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.81s, LR: 0.00050, Train Loss: 0.1657, Train Acc: 0.9200,
                            Val Loss: 0.3237, Val Acc: 0.9360, Test Acc: 0.9382
2022-09-10 19:06:37,379:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 19:06:58,656:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.28s, LR: 0.00050, Train Loss: 0.1334, Train Acc: 0.9550,
                            Val Loss: 0.2782, Val Acc: 0.8890, Test Acc: 0.8795
2022-09-10 19:06:58,656:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 19:07:20,011:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.35s, LR: 0.00050, Train Loss: 0.1245, Train Acc: 0.9500,
                            Val Loss: 0.3534, Val Acc: 0.9040, Test Acc: 0.9137
2022-09-10 19:07:20,011:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 19:07:41,824:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.81s, LR: 0.00050, Train Loss: 0.0948, Train Acc: 0.9700,
                            Val Loss: 0.3455, Val Acc: 0.8820, Test Acc: 0.8959
2022-09-10 19:07:41,825:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 19:08:04,628:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.80s, LR: 0.00050, Train Loss: 0.0969, Train Acc: 0.9700,
                            Val Loss: 0.2585, Val Acc: 0.9390, Test Acc: 0.9410
2022-09-10 19:08:04,629:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 19:08:26,701:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.07s, LR: 0.00025, Train Loss: 0.0681, Train Acc: 0.9700,
                            Val Loss: 0.2189, Val Acc: 0.9320, Test Acc: 0.9357
2022-09-10 19:08:26,701:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 19:08:48,924:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.22s, LR: 0.00025, Train Loss: 0.0616, Train Acc: 0.9750,
                            Val Loss: 0.2222, Val Acc: 0.9250, Test Acc: 0.9287
2022-09-10 19:08:48,924:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 19:09:10,378:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.45s, LR: 0.00025, Train Loss: 0.0554, Train Acc: 0.9850,
                            Val Loss: 0.2259, Val Acc: 0.9320, Test Acc: 0.9377
2022-09-10 19:09:10,379:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 19:09:31,827:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.45s, LR: 0.00025, Train Loss: 0.0725, Train Acc: 0.9650,
                            Val Loss: 0.2295, Val Acc: 0.9300, Test Acc: 0.9390
2022-09-10 19:09:31,828:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 19:09:52,770:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.94s, LR: 0.00025, Train Loss: 0.0617, Train Acc: 0.9750,
                            Val Loss: 0.2222, Val Acc: 0.9340, Test Acc: 0.9345
2022-09-10 19:09:52,770:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 19:10:13,793:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.02s, LR: 0.00025, Train Loss: 0.0482, Train Acc: 0.9900,
                            Val Loss: 0.2267, Val Acc: 0.9190, Test Acc: 0.9182
2022-09-10 19:10:13,794:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 19:10:36,045:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.25s, LR: 0.00025, Train Loss: 0.0442, Train Acc: 0.9900,
                            Val Loss: 0.2543, Val Acc: 0.9290, Test Acc: 0.9322
2022-09-10 19:10:36,045:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 19:10:58,288:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.24s, LR: 0.00025, Train Loss: 0.0336, Train Acc: 0.9850,
                            Val Loss: 0.2311, Val Acc: 0.9320, Test Acc: 0.9347
2022-09-10 19:10:58,289:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 19:11:20,575:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.29s, LR: 0.00025, Train Loss: 0.0500, Train Acc: 0.9800,
                            Val Loss: 0.2302, Val Acc: 0.9200, Test Acc: 0.9249
2022-09-10 19:11:20,576:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 36/1000
2022-09-10 19:11:41,534:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.96s, LR: 0.00025, Train Loss: 0.0546, Train Acc: 0.9750,
                            Val Loss: 0.2453, Val Acc: 0.9210, Test Acc: 0.9285
2022-09-10 19:11:41,534:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 37/1000
2022-09-10 19:12:02,184:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.65s, LR: 0.00025, Train Loss: 0.0414, Train Acc: 0.9900,
                            Val Loss: 0.2526, Val Acc: 0.9300, Test Acc: 0.9358
2022-09-10 19:12:02,184:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 38/1000
2022-09-10 19:12:23,723:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.54s, LR: 0.00025, Train Loss: 0.0244, Train Acc: 0.9950,
                            Val Loss: 0.2498, Val Acc: 0.9330, Test Acc: 0.9360
2022-09-10 19:12:23,724:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 39/1000
2022-09-10 19:12:32,497:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:12:41,804:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:12:46,095:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 19:12:46,096:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 19:12:46,096:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:12:46,097:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:12:46,097:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:12:46,097:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:12:46,102:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:12:46,102:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526359
2022-09-10 19:12:46,103:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:12:46,103:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:12:46,103:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:12:46,103:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:12:46,103:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:12:46,109:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-10 19:13:04,114:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:18.01130509376526
2022-09-10 19:13:04,130:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 19:13:04,130:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 19:13:04,130:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 19:13:04,130:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 19:13:04,133:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:13:26,643:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5032 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h12m46s_on_Sep_10_2022/MODELS_
2022-09-10 19:13:26,644:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.51s, LR: 0.00050, Train Loss: 0.6615, Train Acc: 0.6950,
                            Val Loss: 1.2894, Val Acc: 0.5010, Test Acc: 0.5032
2022-09-10 19:13:26,644:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 19:13:49,079:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7798 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h12m46s_on_Sep_10_2022/MODELS_
2022-09-10 19:13:49,079:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.44s, LR: 0.00050, Train Loss: 0.4421, Train Acc: 0.8750,
                            Val Loss: 0.4821, Val Acc: 0.7790, Test Acc: 0.7798
2022-09-10 19:13:49,079:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 19:14:11,327:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.25s, LR: 0.00050, Train Loss: 0.3662, Train Acc: 0.8850,
                            Val Loss: 0.5984, Val Acc: 0.7540, Test Acc: 0.7463
2022-09-10 19:14:11,327:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:14:34,271:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8721 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h12m46s_on_Sep_10_2022/MODELS_
2022-09-10 19:14:34,272:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.94s, LR: 0.00050, Train Loss: 0.3042, Train Acc: 0.9150,
                            Val Loss: 0.4395, Val Acc: 0.8690, Test Acc: 0.8721
2022-09-10 19:14:34,272:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:14:57,464:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8849 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h12m46s_on_Sep_10_2022/MODELS_
2022-09-10 19:14:57,465:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.19s, LR: 0.00050, Train Loss: 0.2729, Train Acc: 0.9200,
                            Val Loss: 0.3760, Val Acc: 0.8770, Test Acc: 0.8849
2022-09-10 19:14:57,465:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:15:19,995:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00050, Train Loss: 0.2406, Train Acc: 0.9350,
                            Val Loss: 0.4117, Val Acc: 0.8330, Test Acc: 0.8371
2022-09-10 19:15:19,995:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:15:43,005:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9367 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h12m46s_on_Sep_10_2022/MODELS_
2022-09-10 19:15:43,006:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.01s, LR: 0.00050, Train Loss: 0.2110, Train Acc: 0.9200,
                            Val Loss: 0.2567, Val Acc: 0.9280, Test Acc: 0.9367
2022-09-10 19:15:43,006:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:16:06,283:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.28s, LR: 0.00050, Train Loss: 0.1671, Train Acc: 0.9450,
                            Val Loss: 0.2332, Val Acc: 0.9300, Test Acc: 0.9348
2022-09-10 19:16:06,284:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:16:30,296:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 24.01s, LR: 0.00050, Train Loss: 0.2015, Train Acc: 0.9450,
                            Val Loss: 0.2656, Val Acc: 0.9120, Test Acc: 0.9232
2022-09-10 19:16:30,296:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:16:53,173:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.88s, LR: 0.00050, Train Loss: 0.1935, Train Acc: 0.9300,
                            Val Loss: 0.4203, Val Acc: 0.8430, Test Acc: 0.8518
2022-09-10 19:16:53,173:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:17:16,121:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.95s, LR: 0.00050, Train Loss: 0.2010, Train Acc: 0.9300,
                            Val Loss: 0.2936, Val Acc: 0.9220, Test Acc: 0.9307
2022-09-10 19:17:16,122:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:17:38,785:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.66s, LR: 0.00050, Train Loss: 0.1870, Train Acc: 0.9350,
                            Val Loss: 0.3132, Val Acc: 0.8950, Test Acc: 0.8916
2022-09-10 19:17:38,785:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:18:00,954:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9451 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h12m46s_on_Sep_10_2022/MODELS_
2022-09-10 19:18:00,954:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.17s, LR: 0.00050, Train Loss: 0.1862, Train Acc: 0.9400,
                            Val Loss: 0.3002, Val Acc: 0.9330, Test Acc: 0.9451
2022-09-10 19:18:00,954:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:18:22,851:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.90s, LR: 0.00050, Train Loss: 0.1570, Train Acc: 0.9450,
                            Val Loss: 0.2533, Val Acc: 0.9050, Test Acc: 0.9075
2022-09-10 19:18:22,851:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:18:45,093:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.24s, LR: 0.00050, Train Loss: 0.1704, Train Acc: 0.9450,
                            Val Loss: 0.2562, Val Acc: 0.9230, Test Acc: 0.9223
2022-09-10 19:18:45,093:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:19:07,619:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00050, Train Loss: 0.1381, Train Acc: 0.9550,
                            Val Loss: 0.7585, Val Acc: 0.8120, Test Acc: 0.8153
2022-09-10 19:19:07,619:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:19:30,622:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.00s, LR: 0.00050, Train Loss: 0.1543, Train Acc: 0.9450,
                            Val Loss: 0.2704, Val Acc: 0.9010, Test Acc: 0.9034
2022-09-10 19:19:30,622:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:19:53,318:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.70s, LR: 0.00050, Train Loss: 0.1323, Train Acc: 0.9450,
                            Val Loss: 0.2498, Val Acc: 0.9200, Test Acc: 0.9231
2022-09-10 19:19:53,318:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:20:15,565:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.25s, LR: 0.00050, Train Loss: 0.1231, Train Acc: 0.9400,
                            Val Loss: 0.2686, Val Acc: 0.9290, Test Acc: 0.9433
2022-09-10 19:20:15,566:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:20:37,857:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.29s, LR: 0.00025, Train Loss: 0.1907, Train Acc: 0.9350,
                            Val Loss: 0.2504, Val Acc: 0.9320, Test Acc: 0.9427
2022-09-10 19:20:37,857:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:21:00,858:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.00s, LR: 0.00025, Train Loss: 0.0874, Train Acc: 0.9650,
                            Val Loss: 0.2671, Val Acc: 0.9280, Test Acc: 0.9255
2022-09-10 19:21:00,858:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:22:19,860:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:22:24,627:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 20, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 7, 'n_classes': 6}
2022-09-10 19:22:24,628:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 20}
2022-09-10 19:22:24,628:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:22:24,629:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:22:24,629:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:22:24,629:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:22:24,635:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:22:24,635:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525247
2022-09-10 19:22:24,636:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:22:24,636:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:22:24,636:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:22:24,636:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:22:24,636:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:22:24,920:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-10 19:22:34,948:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:10.305535078048706
2022-09-10 19:22:34,951:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10
2022-09-10 19:22:34,951:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 10
2022-09-10 19:22:34,951:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 10
2022-09-10 19:22:34,951:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 6
2022-09-10 19:22:34,954:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:22:35,702:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:35,702:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.75s, LR: 0.00050, Train Loss: 1.8059, Train Acc: 16.8301,
                            Val Loss: 1.8099, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-10 19:22:35,702:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 19:22:36,358:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7822, Train Acc: 18.0335,
                            Val Loss: 1.8059, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-10 19:22:36,358:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 19:22:37,047:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 18.5792 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:37,047:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.7660, Train Acc: 18.7588,
                            Val Loss: 1.8020, Val Acc: 18.7962, Test Acc: 18.5792
2022-09-10 19:22:37,047:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:22:37,786:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 20.6213 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:37,786:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.74s, LR: 0.00050, Train Loss: 1.7542, Train Acc: 19.8348,
                            Val Loss: 1.7980, Val Acc: 20.6264, Test Acc: 20.6213
2022-09-10 19:22:37,786:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:22:38,510:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.7434, Train Acc: 20.7209,
                            Val Loss: 1.7935, Val Acc: 20.3794, Test Acc: 19.3362
2022-09-10 19:22:38,510:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:22:39,205:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.7338, Train Acc: 21.4570,
                            Val Loss: 1.7887, Val Acc: 20.3844, Test Acc: 20.6135
2022-09-10 19:22:39,205:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:22:39,905:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 21.7011 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:39,905:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.7249, Train Acc: 21.6053,
                            Val Loss: 1.7839, Val Acc: 21.0776, Test Acc: 21.7011
2022-09-10 19:22:39,905:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:22:40,575:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7162, Train Acc: 22.0257,
                            Val Loss: 1.7793, Val Acc: 21.3735, Test Acc: 21.6547
2022-09-10 19:22:40,575:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:22:41,219:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 22.0914 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:41,220:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7078, Train Acc: 23.0921,
                            Val Loss: 1.7744, Val Acc: 21.4738, Test Acc: 22.0914
2022-09-10 19:22:41,220:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:22:41,914:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 22.6367 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:41,914:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.6992, Train Acc: 24.6560,
                            Val Loss: 1.7693, Val Acc: 22.5424, Test Acc: 22.6367
2022-09-10 19:22:41,914:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:22:42,584:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.6903, Train Acc: 25.8288,
                            Val Loss: 1.7642, Val Acc: 22.9201, Test Acc: 22.6304
2022-09-10 19:22:42,584:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:22:43,240:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 22.7302 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:43,240:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6807, Train Acc: 27.3777,
                            Val Loss: 1.7591, Val Acc: 22.8215, Test Acc: 22.7302
2022-09-10 19:22:43,240:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:22:43,929:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 22.8717 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:43,929:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.6704, Train Acc: 29.2725,
                            Val Loss: 1.7531, Val Acc: 22.8220, Test Acc: 22.8717
2022-09-10 19:22:43,930:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:22:44,576:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 23.6917 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:44,576:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6597, Train Acc: 30.5523,
                            Val Loss: 1.7462, Val Acc: 23.3180, Test Acc: 23.6917
2022-09-10 19:22:44,576:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:22:45,231:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 24.1342 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:45,231:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6487, Train Acc: 32.6347,
                            Val Loss: 1.7387, Val Acc: 24.1875, Test Acc: 24.1342
2022-09-10 19:22:45,231:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:22:45,947:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 24.9417 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:45,947:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.6374, Train Acc: 34.7312,
                            Val Loss: 1.7286, Val Acc: 24.7007, Test Acc: 24.9417
2022-09-10 19:22:45,947:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:22:46,609:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 26.2022 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:46,609:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6258, Train Acc: 36.4525,
                            Val Loss: 1.7176, Val Acc: 26.2297, Test Acc: 26.2022
2022-09-10 19:22:46,609:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:22:47,298:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 27.2482 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:47,298:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.6140, Train Acc: 38.8098,
                            Val Loss: 1.7070, Val Acc: 26.3961, Test Acc: 27.2482
2022-09-10 19:22:47,298:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:22:47,948:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 30.1776 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:47,948:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6019, Train Acc: 40.1584,
                            Val Loss: 1.6942, Val Acc: 28.2122, Test Acc: 30.1776
2022-09-10 19:22:47,948:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:22:48,623:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 35.4881 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:48,623:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.5889, Train Acc: 40.8905,
                            Val Loss: 1.6832, Val Acc: 30.5518, Test Acc: 35.4881
2022-09-10 19:22:48,623:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:22:49,290:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 36.6326 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:49,290:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.5757, Train Acc: 41.4918,
                            Val Loss: 1.6805, Val Acc: 33.0906, Test Acc: 36.6326
2022-09-10 19:22:49,290:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:22:49,951:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 37.4868 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:49,951:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.5623, Train Acc: 42.3580,
                            Val Loss: 1.6777, Val Acc: 34.0703, Test Acc: 37.4868
2022-09-10 19:22:49,951:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 19:22:50,635:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 37.5061 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:50,635:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.5485, Train Acc: 44.1101,
                            Val Loss: 1.6852, Val Acc: 35.3342, Test Acc: 37.5061
2022-09-10 19:22:50,635:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 19:22:51,276:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 37.7937 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h22m24s_on_Sep_10_2022/MODELS_
2022-09-10 19:22:51,276:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.5342, Train Acc: 45.0218,
                            Val Loss: 1.7207, Val Acc: 34.0454, Test Acc: 37.7937
2022-09-10 19:22:51,276:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 19:22:51,921:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.5192, Train Acc: 45.6954,
                            Val Loss: 1.7650, Val Acc: 33.5093, Test Acc: 35.9555
2022-09-10 19:22:51,921:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 19:22:52,611:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.5033, Train Acc: 46.3229,
                            Val Loss: 1.8420, Val Acc: 29.9663, Test Acc: 32.9567
2022-09-10 19:22:52,611:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 19:22:53,279:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.4866, Train Acc: 47.8191,
                            Val Loss: 1.9581, Val Acc: 25.6924, Test Acc: 29.6068
2022-09-10 19:22:53,279:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 19:22:53,940:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.4693, Train Acc: 49.8984,
                            Val Loss: 2.0350, Val Acc: 24.9413, Test Acc: 27.6360
2022-09-10 19:22:53,940:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 19:22:54,589:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.4512, Train Acc: 51.0628,
                            Val Loss: 2.2428, Val Acc: 21.9019, Test Acc: 25.0636
2022-09-10 19:22:54,589:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 19:22:55,235:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.4349, Train Acc: 52.3003,
                            Val Loss: 2.2001, Val Acc: 22.5641, Test Acc: 26.2310
2022-09-10 19:22:55,235:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 19:22:55,895:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.4209, Train Acc: 52.1127,
                            Val Loss: 2.2966, Val Acc: 22.3152, Test Acc: 26.8811
2022-09-10 19:22:55,895:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 19:22:56,539:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.3946, Train Acc: 54.6319,
                            Val Loss: 2.4035, Val Acc: 21.9207, Test Acc: 25.9792
2022-09-10 19:22:56,539:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 19:22:57,170:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.3762, Train Acc: 55.3060,
                            Val Loss: 2.3792, Val Acc: 22.4411, Test Acc: 26.5877
2022-09-10 19:22:57,170:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 19:22:57,806:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.3611, Train Acc: 54.8725,
                            Val Loss: 2.3266, Val Acc: 23.7140, Test Acc: 27.9207
2022-09-10 19:22:57,807:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 19:22:58,469:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.3415, Train Acc: 57.3985,
                            Val Loss: 2.3086, Val Acc: 24.5406, Test Acc: 29.5515
2022-09-10 19:22:58,470:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 36/1000
2022-09-10 19:22:59,133:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.3339, Train Acc: 56.4706,
                            Val Loss: 2.2466, Val Acc: 25.0443, Test Acc: 30.0948
2022-09-10 19:22:59,133:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 37/1000
2022-09-10 19:22:59,766:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00025, Train Loss: 1.3221, Train Acc: 57.6842,
                            Val Loss: 2.1769, Val Acc: 26.5031, Test Acc: 30.2911
2022-09-10 19:22:59,766:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 38/1000
2022-09-10 19:23:00,409:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.3054, Train Acc: 59.0302,
                            Val Loss: 2.1704, Val Acc: 27.1007, Test Acc: 30.5627
2022-09-10 19:23:00,409:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 39/1000
2022-09-10 19:23:01,051:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.2975, Train Acc: 58.6415,
                            Val Loss: 2.2038, Val Acc: 26.6518, Test Acc: 30.5748
2022-09-10 19:23:01,051:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 40/1000
2022-09-10 19:23:01,740:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00025, Train Loss: 1.2797, Train Acc: 60.4749,
                            Val Loss: 2.2062, Val Acc: 26.4768, Test Acc: 30.2986
2022-09-10 19:23:01,740:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 41/1000
2022-09-10 19:23:02,396:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.2702, Train Acc: 60.7486,
                            Val Loss: 2.1383, Val Acc: 27.8064, Test Acc: 31.6429
2022-09-10 19:23:02,396:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 42/1000
2022-09-10 19:23:03,018:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.2521, Train Acc: 60.8382,
                            Val Loss: 2.0978, Val Acc: 28.4191, Test Acc: 32.3175
2022-09-10 19:23:03,018:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 43/1000
2022-09-10 19:23:03,654:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.2419, Train Acc: 60.2179,
                            Val Loss: 2.1320, Val Acc: 27.5444, Test Acc: 32.3607
2022-09-10 19:23:03,654:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 44/1000
2022-09-10 19:23:04,278:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00025, Train Loss: 1.2236, Train Acc: 61.5927,
                            Val Loss: 2.1908, Val Acc: 26.5966, Test Acc: 31.3082
2022-09-10 19:23:04,278:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 45/1000
2022-09-10 19:23:04,905:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00013, Train Loss: 1.2141, Train Acc: 62.1600,
                            Val Loss: 2.1371, Val Acc: 27.7418, Test Acc: 32.4798
2022-09-10 19:23:04,905:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 46/1000
2022-09-10 19:23:05,528:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.2017, Train Acc: 62.6042,
                            Val Loss: 2.0765, Val Acc: 29.8153, Test Acc: 33.2759
2022-09-10 19:23:05,528:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 47/1000
2022-09-10 19:23:06,151:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00013, Train Loss: 1.1956, Train Acc: 62.3711,
                            Val Loss: 2.0374, Val Acc: 31.0433, Test Acc: 33.9771
2022-09-10 19:23:06,151:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 48/1000
2022-09-10 19:23:06,789:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.1891, Train Acc: 62.5964,
                            Val Loss: 2.0228, Val Acc: 30.9320, Test Acc: 34.1455
2022-09-10 19:23:06,789:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 49/1000
2022-09-10 19:23:07,496:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00013, Train Loss: 1.1782, Train Acc: 63.0550,
                            Val Loss: 2.0220, Val Acc: 30.4979, Test Acc: 34.3837
2022-09-10 19:23:07,496:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 50/1000
2022-09-10 19:23:08,140:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.1731, Train Acc: 63.3444,
                            Val Loss: 2.0103, Val Acc: 30.7276, Test Acc: 34.6061
2022-09-10 19:23:08,140:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 51/1000
2022-09-10 19:23:08,805:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00013, Train Loss: 1.1628, Train Acc: 63.2025,
                            Val Loss: 1.9879, Val Acc: 31.8003, Test Acc: 34.8060
2022-09-10 19:23:08,806:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 52/1000
2022-09-10 19:23:09,520:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00013, Train Loss: 1.1560, Train Acc: 63.2391,
                            Val Loss: 1.9641, Val Acc: 32.2102, Test Acc: 35.4036
2022-09-10 19:23:09,520:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 53/1000
2022-09-10 19:23:10,207:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00013, Train Loss: 1.1471, Train Acc: 63.2352,
                            Val Loss: 1.9547, Val Acc: 31.9429, Test Acc: 34.8551
2022-09-10 19:23:10,207:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 54/1000
2022-09-10 19:23:12,489:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:23:16,740:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 20, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 7, 'n_classes': 6}
2022-09-10 19:23:16,740:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 20}
2022-09-10 19:23:16,740:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:23:16,741:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:23:16,741:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:23:16,741:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:23:16,745:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:23:16,746:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525247
2022-09-10 19:23:16,746:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:23:16,746:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:23:16,747:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:23:16,747:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:23:16,747:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:23:16,987:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-10 19:23:25,229:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:8.476737022399902
2022-09-10 19:23:25,232:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10
2022-09-10 19:23:25,232:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 10
2022-09-10 19:23:25,232:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 10
2022-09-10 19:23:25,232:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 6
2022-09-10 19:23:25,233:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:23:25,980:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 16.9596 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:25,980:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.75s, LR: 0.00050, Train Loss: 1.8062, Train Acc: 16.6833,
                            Val Loss: 1.8257, Val Acc: 16.7732, Test Acc: 16.9596
2022-09-10 19:23:25,980:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 19:23:26,675:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.7806, Train Acc: 19.8151,
                            Val Loss: 1.8192, Val Acc: 16.5412, Test Acc: 16.6681
2022-09-10 19:23:26,675:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 19:23:27,347:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 17.5663 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:27,347:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7649, Train Acc: 21.0835,
                            Val Loss: 1.8125, Val Acc: 17.0547, Test Acc: 17.5663
2022-09-10 19:23:27,347:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:23:28,028:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 18.6349 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:28,028:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.7535, Train Acc: 22.2421,
                            Val Loss: 1.8047, Val Acc: 18.3500, Test Acc: 18.6349
2022-09-10 19:23:28,028:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:23:28,694:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 19.3270 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:28,694:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7441, Train Acc: 23.2700,
                            Val Loss: 1.7967, Val Acc: 19.2173, Test Acc: 19.3270
2022-09-10 19:23:28,694:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:23:29,434:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 20.3647 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:29,434:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.74s, LR: 0.00050, Train Loss: 1.7357, Train Acc: 26.0238,
                            Val Loss: 1.7896, Val Acc: 20.0846, Test Acc: 20.3647
2022-09-10 19:23:29,434:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:23:30,093:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.7282, Train Acc: 28.4720,
                            Val Loss: 1.7830, Val Acc: 20.0846, Test Acc: 20.3647
2022-09-10 19:23:30,093:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:23:30,714:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.62s, LR: 0.00050, Train Loss: 1.7215, Train Acc: 29.8195,
                            Val Loss: 1.7768, Val Acc: 20.0846, Test Acc: 20.3647
2022-09-10 19:23:30,714:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:23:31,351:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7152, Train Acc: 30.5526,
                            Val Loss: 1.7710, Val Acc: 20.0846, Test Acc: 20.3647
2022-09-10 19:23:31,355:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:23:32,039:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.7089, Train Acc: 32.4458,
                            Val Loss: 1.7657, Val Acc: 20.0846, Test Acc: 20.3647
2022-09-10 19:23:32,039:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:23:32,667:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.63s, LR: 0.00050, Train Loss: 1.7024, Train Acc: 33.6878,
                            Val Loss: 1.7608, Val Acc: 20.0846, Test Acc: 20.3647
2022-09-10 19:23:32,667:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:23:33,314:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 20.5802 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:33,314:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6955, Train Acc: 34.2469,
                            Val Loss: 1.7564, Val Acc: 20.0846, Test Acc: 20.5802
2022-09-10 19:23:33,314:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:23:33,972:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 20.6241 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:33,972:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6879, Train Acc: 35.2963,
                            Val Loss: 1.7528, Val Acc: 20.1368, Test Acc: 20.6241
2022-09-10 19:23:33,972:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:23:34,609:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 21.1565 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:34,609:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6797, Train Acc: 36.1973,
                            Val Loss: 1.7507, Val Acc: 19.9686, Test Acc: 21.1565
2022-09-10 19:23:34,609:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:23:35,270:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 22.3355 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:35,270:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6708, Train Acc: 37.0820,
                            Val Loss: 1.7510, Val Acc: 20.7807, Test Acc: 22.3355
2022-09-10 19:23:35,270:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:23:35,952:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 23.4608 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:35,952:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.6610, Train Acc: 37.1175,
                            Val Loss: 1.7540, Val Acc: 21.6393, Test Acc: 23.4608
2022-09-10 19:23:35,952:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:23:36,627:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 24.2747 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:36,627:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.6505, Train Acc: 38.1520,
                            Val Loss: 1.7593, Val Acc: 23.6059, Test Acc: 24.2747
2022-09-10 19:23:36,627:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:23:37,268:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 24.9850 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:37,269:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.6391, Train Acc: 38.4886,
                            Val Loss: 1.7694, Val Acc: 25.1548, Test Acc: 24.9850
2022-09-10 19:23:37,269:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:23:37,948:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 25.3041 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:37,948:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.6270, Train Acc: 39.4617,
                            Val Loss: 1.7864, Val Acc: 26.5645, Test Acc: 25.3041
2022-09-10 19:23:37,948:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:23:38,604:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 25.5954 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:38,605:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6145, Train Acc: 40.1772,
                            Val Loss: 1.8030, Val Acc: 26.4310, Test Acc: 25.5954
2022-09-10 19:23:38,605:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:23:39,251:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 25.7098 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:39,251:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.6021, Train Acc: 40.5918,
                            Val Loss: 1.8218, Val Acc: 26.3071, Test Acc: 25.7098
2022-09-10 19:23:39,251:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:23:39,930:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 26.0445 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:39,930:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.5896, Train Acc: 40.9566,
                            Val Loss: 1.8432, Val Acc: 26.6874, Test Acc: 26.0445
2022-09-10 19:23:39,930:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 19:23:40,587:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 27.9432 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:40,587:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.5767, Train Acc: 41.3966,
                            Val Loss: 1.8510, Val Acc: 26.9138, Test Acc: 27.9432
2022-09-10 19:23:40,587:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 19:23:41,268:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 29.2239 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:41,268:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.5635, Train Acc: 42.4049,
                            Val Loss: 1.8236, Val Acc: 27.7167, Test Acc: 29.2239
2022-09-10 19:23:41,268:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 19:23:41,914:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 29.4017 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:41,914:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.5496, Train Acc: 43.7495,
                            Val Loss: 1.8032, Val Acc: 28.0504, Test Acc: 29.4017
2022-09-10 19:23:41,914:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 19:23:42,593:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 29.9850 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:42,593:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.5350, Train Acc: 44.2906,
                            Val Loss: 1.7884, Val Acc: 27.7635, Test Acc: 29.9850
2022-09-10 19:23:42,593:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 19:23:43,231:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 30.5386 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:43,231:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.5272, Train Acc: 44.4310,
                            Val Loss: 1.7667, Val Acc: 28.0192, Test Acc: 30.5386
2022-09-10 19:23:43,231:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 19:23:43,913:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 31.4038 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:43,914:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.5188, Train Acc: 45.1132,
                            Val Loss: 1.7446, Val Acc: 28.1552, Test Acc: 31.4038
2022-09-10 19:23:43,914:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 19:23:44,571:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 32.1017 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:44,571:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.5102, Train Acc: 45.7987,
                            Val Loss: 1.7376, Val Acc: 28.7474, Test Acc: 32.1017
2022-09-10 19:23:44,571:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 19:23:45,216:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 32.5804 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:45,216:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.5011, Train Acc: 46.0279,
                            Val Loss: 1.7294, Val Acc: 29.2596, Test Acc: 32.5804
2022-09-10 19:23:45,216:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 19:23:45,899:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 32.8225 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:45,899:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.4918, Train Acc: 46.6879,
                            Val Loss: 1.7127, Val Acc: 29.9089, Test Acc: 32.8225
2022-09-10 19:23:45,899:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 19:23:46,570:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 34.1646 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:46,570:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.4823, Train Acc: 47.2932,
                            Val Loss: 1.7003, Val Acc: 30.8769, Test Acc: 34.1646
2022-09-10 19:23:46,570:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 19:23:47,292:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00025, Train Loss: 1.4724, Train Acc: 48.0334,
                            Val Loss: 1.6971, Val Acc: 31.5174, Test Acc: 33.8161
2022-09-10 19:23:47,292:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 19:23:47,953:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 34.7069 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:47,953:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00025, Train Loss: 1.4622, Train Acc: 48.3705,
                            Val Loss: 1.6834, Val Acc: 32.7249, Test Acc: 34.7069
2022-09-10 19:23:47,954:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 19:23:48,628:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.4516, Train Acc: 48.9997,
                            Val Loss: 1.6743, Val Acc: 32.9512, Test Acc: 34.1803
2022-09-10 19:23:48,628:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 36/1000
2022-09-10 19:23:49,270:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 34.9087 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:49,270:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00025, Train Loss: 1.4407, Train Acc: 49.5773,
                            Val Loss: 1.6720, Val Acc: 33.7060, Test Acc: 34.9087
2022-09-10 19:23:49,270:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 37/1000
2022-09-10 19:23:49,962:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 35.5547 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_20_19h23m16s_on_Sep_10_2022/MODELS_
2022-09-10 19:23:49,962:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00025, Train Loss: 1.4294, Train Acc: 50.4294,
                            Val Loss: 1.6677, Val Acc: 34.6267, Test Acc: 35.5547
2022-09-10 19:23:49,962:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 38/1000
2022-09-10 19:23:50,628:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.4179, Train Acc: 51.1886,
                            Val Loss: 1.6651, Val Acc: 34.0632, Test Acc: 35.0662
2022-09-10 19:23:50,628:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 39/1000
2022-09-10 19:23:51,313:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00025, Train Loss: 1.4060, Train Acc: 51.9407,
                            Val Loss: 1.6665, Val Acc: 33.9482, Test Acc: 34.6705
2022-09-10 19:23:51,313:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 40/1000
2022-09-10 19:23:51,967:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.3940, Train Acc: 52.5450,
                            Val Loss: 1.6679, Val Acc: 33.6080, Test Acc: 33.9135
2022-09-10 19:23:51,967:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 41/1000
2022-09-10 19:23:52,638:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.3823, Train Acc: 52.8599,
                            Val Loss: 1.6710, Val Acc: 34.5166, Test Acc: 33.8286
2022-09-10 19:23:52,638:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 42/1000
2022-09-10 19:23:53,338:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00025, Train Loss: 1.3715, Train Acc: 53.6975,
                            Val Loss: 1.6867, Val Acc: 33.8653, Test Acc: 33.1713
2022-09-10 19:23:53,338:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 43/1000
2022-09-10 19:23:54,009:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.3594, Train Acc: 53.4865,
                            Val Loss: 1.6856, Val Acc: 33.7714, Test Acc: 32.6177
2022-09-10 19:23:54,009:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 44/1000
2022-09-10 19:23:54,657:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.3450, Train Acc: 54.7581,
                            Val Loss: 1.6880, Val Acc: 34.3570, Test Acc: 32.0144
2022-09-10 19:23:54,658:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 45/1000
2022-09-10 19:23:55,306:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.3343, Train Acc: 55.5926,
                            Val Loss: 1.7170, Val Acc: 33.1793, Test Acc: 31.9850
2022-09-10 19:23:55,306:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 46/1000
2022-09-10 19:23:55,976:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.3216, Train Acc: 56.4352,
                            Val Loss: 1.7210, Val Acc: 33.1872, Test Acc: 31.9131
2022-09-10 19:23:55,976:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 47/1000
2022-09-10 19:23:56,623:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.3058, Train Acc: 57.0238,
                            Val Loss: 1.7296, Val Acc: 33.3970, Test Acc: 31.7643
2022-09-10 19:23:56,623:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 48/1000
2022-09-10 19:23:57,295:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.2934, Train Acc: 57.2983,
                            Val Loss: 1.7627, Val Acc: 32.0696, Test Acc: 30.3339
2022-09-10 19:23:57,295:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 49/1000
2022-09-10 19:23:57,943:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00025, Train Loss: 1.2808, Train Acc: 57.7591,
                            Val Loss: 1.7557, Val Acc: 33.0195, Test Acc: 29.8307
2022-09-10 19:23:57,943:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 50/1000
2022-09-10 19:23:58,611:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00013, Train Loss: 1.2647, Train Acc: 58.7450,
                            Val Loss: 1.7607, Val Acc: 33.1715, Test Acc: 29.9048
2022-09-10 19:23:58,611:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 51/1000
2022-09-10 19:23:59,250:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00013, Train Loss: 1.2562, Train Acc: 58.8228,
                            Val Loss: 1.7699, Val Acc: 32.8843, Test Acc: 29.8731
2022-09-10 19:23:59,250:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 52/1000
2022-09-10 19:23:59,934:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00013, Train Loss: 1.2488, Train Acc: 59.6581,
                            Val Loss: 1.7705, Val Acc: 33.2132, Test Acc: 29.5170
2022-09-10 19:23:59,947:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 53/1000
2022-09-10 19:24:00,600:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00013, Train Loss: 1.2406, Train Acc: 60.3379,
                            Val Loss: 1.7649, Val Acc: 33.4346, Test Acc: 29.9606
2022-09-10 19:24:00,601:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 54/1000
2022-09-10 19:24:02,893:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:24:07,342:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 20, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 7, 'n_classes': 6}
2022-09-10 19:24:07,342:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 20}
2022-09-10 19:24:07,342:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:24:07,343:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:24:07,343:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:24:07,343:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:24:07,348:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:24:07,349:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 525247
2022-09-10 19:24:07,349:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:24:07,349:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:24:07,350:pe_layer.py:129 -             __init__(): Using 20 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:24:07,350:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:24:07,350:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:24:07,590:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (20).
2022-09-10 19:24:15,438:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:8.08287000656128
2022-09-10 19:24:15,441:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10
2022-09-10 19:24:15,441:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 10
2022-09-10 19:24:15,441:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 10
2022-09-10 19:24:15,441:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 6
2022-09-10 19:24:15,443:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:24:15,806:main_SBMs_node_classification.py:245 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 19:24:15,806:main_SBMs_node_classification.py:246 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 19:24:21,745:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:24:26,160:main_SBMs_node_classification.py:353 -                 main(): {'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'mean', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 32, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'SBM_CLUSTER', 'matrix_type': 'A', 'spectral_attn': False, 'cat_gape': False, 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'pos_enc_dim': 128, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 7, 'n_classes': 6}
2022-09-10 19:24:26,160:main_SBMs_node_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 32, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 20}
2022-09-10 19:24:26,160:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:24:26,164:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:24:26,164:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:24:26,164:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:24:26,170:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:24:26,171:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 549979
2022-09-10 19:24:26,171:main_SBMs_node_classification.py:48 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:24:26,171:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:24:26,173:pe_layer.py:129 -             __init__(): Using 128 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:24:26,173:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:24:26,173:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:24:26,457:main_SBMs_node_classification.py:91 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (128).
2022-09-10 19:24:36,509:main_SBMs_node_classification.py:99 -   train_val_pipeline(): Time PE:10.329168319702148
2022-09-10 19:24:36,511:main_SBMs_node_classification.py:135 -   train_val_pipeline(): Training Graphs: 10
2022-09-10 19:24:36,511:main_SBMs_node_classification.py:136 -   train_val_pipeline(): Validation Graphs: 10
2022-09-10 19:24:36,511:main_SBMs_node_classification.py:137 -   train_val_pipeline(): Test Graphs: 10
2022-09-10 19:24:36,511:main_SBMs_node_classification.py:138 -   train_val_pipeline(): Number of Classes: 6
2022-09-10 19:24:36,513:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:24:37,266:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 16.6667 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:37,267:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.75s, LR: 0.00050, Train Loss: 1.7997, Train Acc: 17.8878,
                            Val Loss: 1.8433, Val Acc: 16.6667, Test Acc: 16.6667
2022-09-10 19:24:37,267:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 19:24:37,906:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 16.8103 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:37,906:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.64s, LR: 0.00050, Train Loss: 1.7731, Train Acc: 22.5543,
                            Val Loss: 1.8288, Val Acc: 16.8175, Test Acc: 16.8103
2022-09-10 19:24:37,906:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 19:24:38,655:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 17.3851 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:38,655:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.75s, LR: 0.00050, Train Loss: 1.7545, Train Acc: 25.0634,
                            Val Loss: 1.8154, Val Acc: 17.4208, Test Acc: 17.3851
2022-09-10 19:24:38,655:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:24:39,371:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 19.0312 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:39,371:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.7404, Train Acc: 25.6973,
                            Val Loss: 1.8026, Val Acc: 19.0933, Test Acc: 19.0312
2022-09-10 19:24:39,371:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:24:40,038:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 19.9927 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:40,038:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7290, Train Acc: 26.5429,
                            Val Loss: 1.7909, Val Acc: 20.1982, Test Acc: 19.9927
2022-09-10 19:24:40,039:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:24:40,748:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 20.1637 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:40,748:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00050, Train Loss: 1.7191, Train Acc: 27.7982,
                            Val Loss: 1.7798, Val Acc: 20.2883, Test Acc: 20.1637
2022-09-10 19:24:40,748:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:24:41,455:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00050, Train Loss: 1.7098, Train Acc: 28.5813,
                            Val Loss: 1.7698, Val Acc: 20.2883, Test Acc: 20.1637
2022-09-10 19:24:41,455:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:24:42,121:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.7008, Train Acc: 29.1620,
                            Val Loss: 1.7619, Val Acc: 20.2883, Test Acc: 20.1637
2022-09-10 19:24:42,121:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:24:42,813:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.6921, Train Acc: 30.8924,
                            Val Loss: 1.7561, Val Acc: 20.2883, Test Acc: 20.1637
2022-09-10 19:24:42,814:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:24:43,517:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 20.2635 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:43,517:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.6831, Train Acc: 32.1204,
                            Val Loss: 1.7514, Val Acc: 20.3875, Test Acc: 20.2635
2022-09-10 19:24:43,517:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:24:44,206:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 20.7585 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:44,206:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.6737, Train Acc: 34.0507,
                            Val Loss: 1.7477, Val Acc: 20.4929, Test Acc: 20.7585
2022-09-10 19:24:44,206:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:24:44,879:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 23.4595 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:44,879:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.6634, Train Acc: 34.8140,
                            Val Loss: 1.7455, Val Acc: 21.8887, Test Acc: 23.4595
2022-09-10 19:24:44,879:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:24:45,588:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 27.5807 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:45,588:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00050, Train Loss: 1.6521, Train Acc: 35.8707,
                            Val Loss: 1.7442, Val Acc: 25.3822, Test Acc: 27.5807
2022-09-10 19:24:45,588:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:24:46,250:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 28.8881 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:46,250:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.6401, Train Acc: 36.2334,
                            Val Loss: 1.7429, Val Acc: 26.8812, Test Acc: 28.8881
2022-09-10 19:24:46,250:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:24:46,945:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 29.0175 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:46,945:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.6275, Train Acc: 37.2387,
                            Val Loss: 1.7406, Val Acc: 27.9761, Test Acc: 29.0175
2022-09-10 19:24:46,946:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:24:47,617:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 29.8631 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:47,617:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.6145, Train Acc: 37.5070,
                            Val Loss: 1.7385, Val Acc: 27.3793, Test Acc: 29.8631
2022-09-10 19:24:47,617:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:24:48,292:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.6014, Train Acc: 38.1290,
                            Val Loss: 1.7395, Val Acc: 25.4696, Test Acc: 27.8125
2022-09-10 19:24:48,292:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:24:49,013:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00050, Train Loss: 1.5885, Train Acc: 38.3582,
                            Val Loss: 1.7424, Val Acc: 25.3825, Test Acc: 27.7133
2022-09-10 19:24:49,013:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:24:49,699:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.5754, Train Acc: 38.4581,
                            Val Loss: 1.7426, Val Acc: 26.1808, Test Acc: 28.6998
2022-09-10 19:24:49,700:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:24:50,352:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.65s, LR: 0.00050, Train Loss: 1.5618, Train Acc: 38.9998,
                            Val Loss: 1.7381, Val Acc: 27.1506, Test Acc: 29.4484
2022-09-10 19:24:50,352:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:24:51,039:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.5483, Train Acc: 39.3464,
                            Val Loss: 1.7339, Val Acc: 28.2037, Test Acc: 29.3251
2022-09-10 19:24:51,039:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:24:51,723:main_SBMs_node_classification.py:192 -   train_val_pipeline(): Saving best model with test accuracy: 30.8066 to out/SBMs_node_classification_b32-bnorm-altcheckpoints/GraphTransformer_SBM_CLUSTER_GPU0_20_128_19h24m26s_on_Sep_10_2022/MODELS_
2022-09-10 19:24:51,723:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.5344, Train Acc: 40.5864,
                            Val Loss: 1.7338, Val Acc: 26.3537, Test Acc: 30.8066
2022-09-10 19:24:51,723:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 19:24:52,403:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.5198, Train Acc: 41.8555,
                            Val Loss: 1.7399, Val Acc: 26.5429, Test Acc: 30.6227
2022-09-10 19:24:52,403:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 19:24:53,073:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.5046, Train Acc: 42.5464,
                            Val Loss: 1.7551, Val Acc: 25.1884, Test Acc: 29.0129
2022-09-10 19:24:53,073:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 19:24:53,734:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.66s, LR: 0.00050, Train Loss: 1.4889, Train Acc: 43.4118,
                            Val Loss: 1.7767, Val Acc: 24.5176, Test Acc: 30.2969
2022-09-10 19:24:53,735:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 19:24:54,448:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00050, Train Loss: 1.4726, Train Acc: 44.4281,
                            Val Loss: 1.7955, Val Acc: 25.6247, Test Acc: 30.1618
2022-09-10 19:24:54,448:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 19:24:55,125:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00050, Train Loss: 1.4557, Train Acc: 45.5609,
                            Val Loss: 1.8154, Val Acc: 26.1416, Test Acc: 30.3701
2022-09-10 19:24:55,125:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 19:24:55,835:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00050, Train Loss: 1.4381, Train Acc: 46.5868,
                            Val Loss: 1.8734, Val Acc: 25.7298, Test Acc: 30.2550
2022-09-10 19:24:55,835:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 19:24:56,507:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00050, Train Loss: 1.4197, Train Acc: 47.5696,
                            Val Loss: 1.9185, Val Acc: 24.5126, Test Acc: 28.4122
2022-09-10 19:24:56,507:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 19:24:57,205:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.4006, Train Acc: 48.6676,
                            Val Loss: 1.9929, Val Acc: 23.1781, Test Acc: 27.1375
2022-09-10 19:24:57,205:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 19:24:57,905:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00050, Train Loss: 1.3812, Train Acc: 49.5451,
                            Val Loss: 2.1077, Val Acc: 21.3348, Test Acc: 23.9466
2022-09-10 19:24:57,905:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 19:24:58,595:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.69s, LR: 0.00050, Train Loss: 1.3620, Train Acc: 50.5747,
                            Val Loss: 2.1822, Val Acc: 21.3823, Test Acc: 24.2651
2022-09-10 19:24:58,595:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 19:24:59,316:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.72s, LR: 0.00025, Train Loss: 1.3421, Train Acc: 51.3987,
                            Val Loss: 2.1807, Val Acc: 20.9617, Test Acc: 24.0732
2022-09-10 19:24:59,316:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 19:24:59,999:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.68s, LR: 0.00025, Train Loss: 1.3272, Train Acc: 52.7100,
                            Val Loss: 2.1731, Val Acc: 21.5497, Test Acc: 24.6348
2022-09-10 19:24:59,999:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 19:25:00,709:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.71s, LR: 0.00025, Train Loss: 1.3176, Train Acc: 53.3310,
                            Val Loss: 2.1232, Val Acc: 21.8670, Test Acc: 25.3549
2022-09-10 19:25:00,709:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 36/1000
2022-09-10 19:25:01,382:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.3037, Train Acc: 54.1838,
                            Val Loss: 2.1114, Val Acc: 22.6156, Test Acc: 25.4907
2022-09-10 19:25:01,382:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 37/1000
2022-09-10 19:25:02,084:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.70s, LR: 0.00025, Train Loss: 1.2908, Train Acc: 55.0765,
                            Val Loss: 2.1822, Val Acc: 22.0778, Test Acc: 24.6215
2022-09-10 19:25:02,084:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 38/1000
2022-09-10 19:25:02,756:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.67s, LR: 0.00025, Train Loss: 1.2777, Train Acc: 56.2157,
                            Val Loss: 2.2123, Val Acc: 23.9326, Test Acc: 25.4097
2022-09-10 19:25:02,756:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 39/1000
2022-09-10 19:25:03,544:main_SBMs_node_classification.py:214 -   train_val_pipeline(): 	Time: 0.79s, LR: 0.00025, Train Loss: 1.2630, Train Acc: 56.7377,
                            Val Loss: 2.1335, Val Acc: 24.8464, Test Acc: 26.5588
2022-09-10 19:25:03,544:main_SBMs_node_classification.py:172 -   train_val_pipeline(): Epoch 40/1000
2022-09-10 19:25:03,758:main_SBMs_node_classification.py:245 -   train_val_pipeline(): -----------------------------------------------------------------------------------------
2022-09-10 19:25:03,758:main_SBMs_node_classification.py:246 -   train_val_pipeline(): Exiting from training early because of KeyboardInterrupt
2022-09-10 19:25:25,177:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:25:29,674:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 32, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 19:25:29,675:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 19:25:29,675:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:25:29,676:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:25:29,676:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:25:29,676:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:25:29,681:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:25:29,681:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 526359
2022-09-10 19:25:29,681:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:25:29,681:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:25:29,682:pe_layer.py:129 -             __init__(): Using 32 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:25:29,682:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:25:29,682:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:25:29,686:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (32).
2022-09-10 19:25:49,278:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:19.59681987762451
2022-09-10 19:25:49,294:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 19:25:49,294:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 19:25:49,294:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 19:25:49,294:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 19:25:49,297:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:26:12,320:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5069 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:26:12,321:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.02s, LR: 0.00050, Train Loss: 0.8118, Train Acc: 0.5850,
                            Val Loss: 1.2173, Val Acc: 0.5010, Test Acc: 0.5069
2022-09-10 19:26:12,321:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 19:26:34,499:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5433 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:26:34,499:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.18s, LR: 0.00050, Train Loss: 0.6595, Train Acc: 0.6750,
                            Val Loss: 0.7457, Val Acc: 0.5820, Test Acc: 0.5433
2022-09-10 19:26:34,499:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 19:26:56,540:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5558 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:26:56,541:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.04s, LR: 0.00050, Train Loss: 0.5579, Train Acc: 0.7250,
                            Val Loss: 0.7535, Val Acc: 0.5600, Test Acc: 0.5558
2022-09-10 19:26:56,541:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:27:18,923:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5899 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:27:18,923:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.38s, LR: 0.00050, Train Loss: 0.5320, Train Acc: 0.7600,
                            Val Loss: 0.7362, Val Acc: 0.5910, Test Acc: 0.5899
2022-09-10 19:27:18,923:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:27:39,842:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6128 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:27:39,842:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.92s, LR: 0.00050, Train Loss: 0.5387, Train Acc: 0.7200,
                            Val Loss: 0.7368, Val Acc: 0.6050, Test Acc: 0.6128
2022-09-10 19:27:39,842:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:28:02,160:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6432 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:28:02,160:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.32s, LR: 0.00050, Train Loss: 0.4541, Train Acc: 0.7850,
                            Val Loss: 0.7124, Val Acc: 0.6450, Test Acc: 0.6432
2022-09-10 19:28:02,160:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:28:24,934:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.77s, LR: 0.00050, Train Loss: 0.4763, Train Acc: 0.7800,
                            Val Loss: 0.8052, Val Acc: 0.6060, Test Acc: 0.6142
2022-09-10 19:28:24,934:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:28:47,743:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7680 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:28:47,743:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.81s, LR: 0.00050, Train Loss: 0.4472, Train Acc: 0.8250,
                            Val Loss: 0.5209, Val Acc: 0.7770, Test Acc: 0.7680
2022-09-10 19:28:47,743:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:29:11,062:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.32s, LR: 0.00050, Train Loss: 0.3838, Train Acc: 0.8300,
                            Val Loss: 0.6689, Val Acc: 0.6960, Test Acc: 0.6938
2022-09-10 19:29:11,062:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:29:32,516:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7835 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:29:32,516:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.45s, LR: 0.00050, Train Loss: 0.3730, Train Acc: 0.8300,
                            Val Loss: 0.4971, Val Acc: 0.7750, Test Acc: 0.7835
2022-09-10 19:29:32,516:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:29:54,710:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.19s, LR: 0.00050, Train Loss: 0.3493, Train Acc: 0.8650,
                            Val Loss: 0.9186, Val Acc: 0.6530, Test Acc: 0.6479
2022-09-10 19:29:54,710:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:30:18,527:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7979 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:30:18,528:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.82s, LR: 0.00050, Train Loss: 0.2707, Train Acc: 0.9000,
                            Val Loss: 0.4687, Val Acc: 0.7900, Test Acc: 0.7979
2022-09-10 19:30:18,528:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:30:41,169:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.64s, LR: 0.00050, Train Loss: 0.2330, Train Acc: 0.9150,
                            Val Loss: 0.5480, Val Acc: 0.7730, Test Acc: 0.7739
2022-09-10 19:30:41,169:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:31:03,572:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8657 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:31:03,573:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.40s, LR: 0.00050, Train Loss: 0.1992, Train Acc: 0.9300,
                            Val Loss: 0.3736, Val Acc: 0.8560, Test Acc: 0.8657
2022-09-10 19:31:03,573:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:31:26,275:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.70s, LR: 0.00050, Train Loss: 0.1908, Train Acc: 0.9300,
                            Val Loss: 0.3822, Val Acc: 0.8440, Test Acc: 0.8428
2022-09-10 19:31:26,276:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:31:49,432:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.16s, LR: 0.00050, Train Loss: 0.1609, Train Acc: 0.9450,
                            Val Loss: 0.4134, Val Acc: 0.8340, Test Acc: 0.8426
2022-09-10 19:31:49,432:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:32:11,948:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9188 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:32:11,948:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.52s, LR: 0.00050, Train Loss: 0.1569, Train Acc: 0.9200,
                            Val Loss: 0.2801, Val Acc: 0.9250, Test Acc: 0.9188
2022-09-10 19:32:11,948:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:32:34,472:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.52s, LR: 0.00050, Train Loss: 0.1461, Train Acc: 0.9500,
                            Val Loss: 0.2996, Val Acc: 0.9070, Test Acc: 0.9140
2022-09-10 19:32:34,473:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:32:56,145:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.67s, LR: 0.00050, Train Loss: 0.1486, Train Acc: 0.9500,
                            Val Loss: 0.2822, Val Acc: 0.9100, Test Acc: 0.9146
2022-09-10 19:32:56,146:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:33:17,334:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9334 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:33:17,335:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.19s, LR: 0.00050, Train Loss: 0.1404, Train Acc: 0.9550,
                            Val Loss: 0.2717, Val Acc: 0.9330, Test Acc: 0.9334
2022-09-10 19:33:17,335:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:33:38,926:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.59s, LR: 0.00050, Train Loss: 0.0997, Train Acc: 0.9750,
                            Val Loss: 0.2983, Val Acc: 0.9100, Test Acc: 0.9087
2022-09-10 19:33:38,927:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:34:00,585:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.66s, LR: 0.00050, Train Loss: 0.1014, Train Acc: 0.9700,
                            Val Loss: 0.4268, Val Acc: 0.8110, Test Acc: 0.8170
2022-09-10 19:34:00,585:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 19:34:22,342:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.76s, LR: 0.00050, Train Loss: 0.1201, Train Acc: 0.9500,
                            Val Loss: 0.3808, Val Acc: 0.8630, Test Acc: 0.8579
2022-09-10 19:34:22,342:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 19:34:44,338:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9423 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:34:44,338:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.00s, LR: 0.00050, Train Loss: 0.0959, Train Acc: 0.9700,
                            Val Loss: 0.2495, Val Acc: 0.9420, Test Acc: 0.9423
2022-09-10 19:34:44,338:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 19:35:05,833:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.49s, LR: 0.00050, Train Loss: 0.0909, Train Acc: 0.9750,
                            Val Loss: 0.2662, Val Acc: 0.9040, Test Acc: 0.9097
2022-09-10 19:35:05,833:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 19:35:27,262:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.43s, LR: 0.00050, Train Loss: 0.0708, Train Acc: 0.9750,
                            Val Loss: 0.2788, Val Acc: 0.9020, Test Acc: 0.9215
2022-09-10 19:35:27,262:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 19:35:48,389:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.13s, LR: 0.00050, Train Loss: 0.0879, Train Acc: 0.9600,
                            Val Loss: 0.2485, Val Acc: 0.9220, Test Acc: 0.9275
2022-09-10 19:35:48,390:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 19:36:09,500:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.11s, LR: 0.00050, Train Loss: 0.0654, Train Acc: 0.9800,
                            Val Loss: 0.3414, Val Acc: 0.9070, Test Acc: 0.9065
2022-09-10 19:36:09,501:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 19:36:31,154:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.65s, LR: 0.00050, Train Loss: 0.0531, Train Acc: 0.9750,
                            Val Loss: 0.3538, Val Acc: 0.9000, Test Acc: 0.9034
2022-09-10 19:36:31,154:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 19:36:52,851:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.70s, LR: 0.00050, Train Loss: 0.0852, Train Acc: 0.9750,
                            Val Loss: 0.2910, Val Acc: 0.9260, Test Acc: 0.9271
2022-09-10 19:36:52,852:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 19:37:14,404:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9440 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_32_19h25m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:37:14,404:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.55s, LR: 0.00050, Train Loss: 0.0682, Train Acc: 0.9750,
                            Val Loss: 0.2936, Val Acc: 0.9360, Test Acc: 0.9440
2022-09-10 19:37:14,404:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 19:37:37,258:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.85s, LR: 0.00050, Train Loss: 0.0709, Train Acc: 0.9750,
                            Val Loss: 0.3642, Val Acc: 0.8760, Test Acc: 0.8820
2022-09-10 19:37:37,259:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 19:38:01,042:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.78s, LR: 0.00050, Train Loss: 0.0553, Train Acc: 0.9750,
                            Val Loss: 0.3031, Val Acc: 0.9480, Test Acc: 0.9386
2022-09-10 19:38:01,043:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 19:38:22,706:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.66s, LR: 0.00050, Train Loss: 0.0363, Train Acc: 0.9900,
                            Val Loss: 0.3481, Val Acc: 0.8930, Test Acc: 0.8889
2022-09-10 19:38:22,707:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 19:38:44,477:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.77s, LR: 0.00050, Train Loss: 0.1222, Train Acc: 0.9550,
                            Val Loss: 0.3132, Val Acc: 0.9280, Test Acc: 0.9289
2022-09-10 19:38:44,478:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 36/1000
2022-09-10 19:39:07,940:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.46s, LR: 0.00050, Train Loss: 0.0714, Train Acc: 0.9750,
                            Val Loss: 0.4220, Val Acc: 0.8710, Test Acc: 0.8877
2022-09-10 19:39:07,941:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 37/1000
2022-09-10 19:39:30,425:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.48s, LR: 0.00050, Train Loss: 0.0346, Train Acc: 0.9950,
                            Val Loss: 0.3495, Val Acc: 0.9140, Test Acc: 0.9175
2022-09-10 19:39:30,425:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 38/1000
2022-09-10 19:39:53,451:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.03s, LR: 0.00050, Train Loss: 0.0337, Train Acc: 0.9900,
                            Val Loss: 0.3156, Val Acc: 0.9170, Test Acc: 0.9227
2022-09-10 19:39:53,452:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 39/1000
2022-09-10 19:40:16,893:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.44s, LR: 0.00025, Train Loss: 0.0403, Train Acc: 0.9850,
                            Val Loss: 0.2789, Val Acc: 0.9240, Test Acc: 0.9155
2022-09-10 19:40:16,894:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 40/1000
2022-09-10 19:40:24,588:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:40:29,285:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 19:40:29,285:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 19:40:29,285:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:40:29,286:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:40:29,286:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:40:29,286:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:40:29,291:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:40:29,292:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-10 19:40:29,292:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:40:29,293:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:40:29,293:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:40:29,293:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:40:29,293:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:40:29,298:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 19:41:05,340:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:36.047035694122314
2022-09-10 19:41:05,363:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 19:41:05,364:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 19:41:05,364:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 19:41:05,364:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 19:41:05,368:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:41:28,142:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6071 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h40m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:41:28,144:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.78s, LR: 0.00050, Train Loss: 0.6768, Train Acc: 0.7050,
                            Val Loss: 0.7317, Val Acc: 0.6070, Test Acc: 0.6071
2022-09-10 19:41:28,144:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 19:41:50,598:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.45s, LR: 0.00050, Train Loss: 0.4504, Train Acc: 0.8450,
                            Val Loss: 0.7394, Val Acc: 0.5940, Test Acc: 0.5900
2022-09-10 19:41:50,598:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 19:42:13,239:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7102 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h40m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:42:13,239:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.64s, LR: 0.00050, Train Loss: 0.4461, Train Acc: 0.8450,
                            Val Loss: 0.6576, Val Acc: 0.7010, Test Acc: 0.7102
2022-09-10 19:42:13,239:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:42:34,401:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8473 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h40m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:42:34,401:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.16s, LR: 0.00050, Train Loss: 0.3093, Train Acc: 0.9050,
                            Val Loss: 0.5560, Val Acc: 0.8470, Test Acc: 0.8473
2022-09-10 19:42:34,401:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:42:56,067:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8827 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h40m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:42:56,068:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.67s, LR: 0.00050, Train Loss: 0.3129, Train Acc: 0.8800,
                            Val Loss: 0.4492, Val Acc: 0.8810, Test Acc: 0.8827
2022-09-10 19:42:56,068:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:43:16,583:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8927 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h40m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:43:16,584:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.52s, LR: 0.00050, Train Loss: 0.2475, Train Acc: 0.9100,
                            Val Loss: 0.3603, Val Acc: 0.8920, Test Acc: 0.8927
2022-09-10 19:43:16,584:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:43:37,236:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.65s, LR: 0.00050, Train Loss: 0.2280, Train Acc: 0.9150,
                            Val Loss: 0.4454, Val Acc: 0.8390, Test Acc: 0.8500
2022-09-10 19:43:37,237:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:43:57,831:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.59s, LR: 0.00050, Train Loss: 0.1947, Train Acc: 0.9350,
                            Val Loss: 0.5747, Val Acc: 0.7340, Test Acc: 0.7485
2022-09-10 19:43:57,832:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:44:18,619:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.79s, LR: 0.00050, Train Loss: 0.2640, Train Acc: 0.9100,
                            Val Loss: 1.0631, Val Acc: 0.7450, Test Acc: 0.7463
2022-09-10 19:44:18,620:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:44:39,126:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.51s, LR: 0.00050, Train Loss: 0.2742, Train Acc: 0.8850,
                            Val Loss: 0.6264, Val Acc: 0.7660, Test Acc: 0.7747
2022-09-10 19:44:39,126:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:44:59,640:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.51s, LR: 0.00050, Train Loss: 0.2340, Train Acc: 0.9150,
                            Val Loss: 0.9197, Val Acc: 0.6390, Test Acc: 0.6479
2022-09-10 19:44:59,640:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:45:20,712:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.07s, LR: 0.00050, Train Loss: 0.2422, Train Acc: 0.9050,
                            Val Loss: 0.4849, Val Acc: 0.8200, Test Acc: 0.8266
2022-09-10 19:45:20,713:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:45:41,490:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00050, Train Loss: 0.1956, Train Acc: 0.9100,
                            Val Loss: 0.5140, Val Acc: 0.8630, Test Acc: 0.8692
2022-09-10 19:45:41,490:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:46:02,279:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.79s, LR: 0.00050, Train Loss: 0.1940, Train Acc: 0.9450,
                            Val Loss: 0.3740, Val Acc: 0.8700, Test Acc: 0.8725
2022-09-10 19:46:02,279:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:46:23,912:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8951 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h40m29s_on_Sep_10_2022/MODELS_
2022-09-10 19:46:23,912:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.63s, LR: 0.00050, Train Loss: 0.1818, Train Acc: 0.9300,
                            Val Loss: 0.3217, Val Acc: 0.8900, Test Acc: 0.8951
2022-09-10 19:46:23,912:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:46:47,895:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.98s, LR: 0.00050, Train Loss: 0.2204, Train Acc: 0.9350,
                            Val Loss: 2.6764, Val Acc: 0.5260, Test Acc: 0.5315
2022-09-10 19:46:47,895:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:47:10,021:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00050, Train Loss: 0.1856, Train Acc: 0.9350,
                            Val Loss: 1.1659, Val Acc: 0.7280, Test Acc: 0.7184
2022-09-10 19:47:10,022:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:47:32,119:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.10s, LR: 0.00050, Train Loss: 0.1491, Train Acc: 0.9400,
                            Val Loss: 0.5406, Val Acc: 0.8350, Test Acc: 0.8509
2022-09-10 19:47:32,120:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:47:55,940:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.82s, LR: 0.00050, Train Loss: 0.2298, Train Acc: 0.8950,
                            Val Loss: 0.3934, Val Acc: 0.8440, Test Acc: 0.8527
2022-09-10 19:47:55,941:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:48:18,328:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.39s, LR: 0.00050, Train Loss: 0.2193, Train Acc: 0.9200,
                            Val Loss: 0.3328, Val Acc: 0.8600, Test Acc: 0.8681
2022-09-10 19:48:18,329:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:48:40,254:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.93s, LR: 0.00050, Train Loss: 0.1346, Train Acc: 0.9450,
                            Val Loss: 0.5525, Val Acc: 0.7310, Test Acc: 0.7325
2022-09-10 19:48:40,254:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:49:02,096:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.84s, LR: 0.00050, Train Loss: 0.1900, Train Acc: 0.9350,
                            Val Loss: 0.3674, Val Acc: 0.8390, Test Acc: 0.8453
2022-09-10 19:49:02,097:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 19:49:36,390:main_utils.py:42 -            gpu_setup(): cuda not available
2022-09-10 19:49:40,979:main_CYCLES_graph_classification.py:353 -                 main(): {'num_train_data': 200, 'L': 10, 'n_heads': 8, 'hidden_dim': 80, 'out_dim': 80, 'residual': True, 'readout': 'sum', 'in_feat_dropout': 0.0, 'dropout': 0.0, 'layer_norm': False, 'batch_norm': True, 'self_loop': False, 'pos_enc': False, 'learned_pos_enc': False, 'pos_enc_dim': 64, 'wl_pos_enc': False, 'full_graph': False, 'gpu_id': 0, 'batch_size': 25, 'edge_feat': False, 'rand_pos_enc': True, 'rw_pos_enc': False, 'power_method': False, 'diag': False, 'pow_of_mat': 1, 'adj_enc': False, 'dataset': 'CYCLES', 'matrix_type': 'A', 'log_file': './DEBUG.log', 'device': device(type='cpu'), 'spectral_attn': False, 'cat_gape': False, 'gape_softmax_after': False, 'gape_softmax_before': False, 'gape_individual': False, 'random_orientation': False, 'in_dim': 1, 'in_dim_edge': 1, 'n_classes': 2}
2022-09-10 19:49:40,979:main_CYCLES_graph_classification.py:354 -                 main(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 19:49:40,979:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:49:40,980:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:49:40,980:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:49:40,980:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:49:40,985:main_utils.py:53 -     view_model_param(): MODEL DETAILS:

2022-09-10 19:49:40,986:main_utils.py:58 -     view_model_param(): MODEL/Total parameters: GraphTransformer, 532023
2022-09-10 19:49:40,986:main_CYCLES_graph_classification.py:43 -   train_val_pipeline(): [!] Starting seed: 41 in [41]...
2022-09-10 19:49:40,986:pe_layer.py:65 -             __init__(): rand_pos_enc
2022-09-10 19:49:40,987:pe_layer.py:129 -             __init__(): Using 64 dimension positional encoding (# states if an automata enc, otherwise smallest k eigvecs)
2022-09-10 19:49:40,987:pe_layer.py:134 -             __init__(): Using matrix: A
2022-09-10 19:49:40,987:pe_layer.py:135 -             __init__(): Matrix power: 1
2022-09-10 19:49:40,992:main_CYCLES_graph_classification.py:76 -   train_val_pipeline(): [!] Adding random automaton graph positional encoding (64).
2022-09-10 19:50:14,639:main_CYCLES_graph_classification.py:84 -   train_val_pipeline(): Time PE:33.65328311920166
2022-09-10 19:50:14,661:main_CYCLES_graph_classification.py:130 -   train_val_pipeline(): Training Graphs: 200
2022-09-10 19:50:14,661:main_CYCLES_graph_classification.py:131 -   train_val_pipeline(): Validation Graphs: 1000
2022-09-10 19:50:14,661:main_CYCLES_graph_classification.py:132 -   train_val_pipeline(): Test Graphs: 10000
2022-09-10 19:50:14,661:main_CYCLES_graph_classification.py:133 -   train_val_pipeline(): Number of Classes: 2
2022-09-10 19:50:14,665:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 1/1000
2022-09-10 19:50:36,794:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5000 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:50:36,795:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00050, Train Loss: 0.7427, Train Acc: 0.5800,
                            Val Loss: 1.1528, Val Acc: 0.5000, Test Acc: 0.5000
2022-09-10 19:50:36,795:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 2/1000
2022-09-10 19:50:59,215:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.5153 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:50:59,215:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.42s, LR: 0.00050, Train Loss: 0.6484, Train Acc: 0.6550,
                            Val Loss: 0.9553, Val Acc: 0.5200, Test Acc: 0.5153
2022-09-10 19:50:59,215:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 3/1000
2022-09-10 19:51:20,812:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6253 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:51:20,813:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.60s, LR: 0.00050, Train Loss: 0.5813, Train Acc: 0.6950,
                            Val Loss: 0.6519, Val Acc: 0.6260, Test Acc: 0.6253
2022-09-10 19:51:20,813:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 4/1000
2022-09-10 19:51:42,866:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.05s, LR: 0.00050, Train Loss: 0.5551, Train Acc: 0.7300,
                            Val Loss: 1.2019, Val Acc: 0.5470, Test Acc: 0.5444
2022-09-10 19:51:42,867:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 5/1000
2022-09-10 19:52:04,907:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.04s, LR: 0.00050, Train Loss: 0.5303, Train Acc: 0.7350,
                            Val Loss: 1.0170, Val Acc: 0.5930, Test Acc: 0.5908
2022-09-10 19:52:04,908:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 6/1000
2022-09-10 19:52:26,816:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.91s, LR: 0.00050, Train Loss: 0.4685, Train Acc: 0.8200,
                            Val Loss: 1.1903, Val Acc: 0.5150, Test Acc: 0.5173
2022-09-10 19:52:26,816:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 7/1000
2022-09-10 19:52:48,464:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.6963 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:52:48,464:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.65s, LR: 0.00050, Train Loss: 0.4166, Train Acc: 0.8350,
                            Val Loss: 0.6834, Val Acc: 0.7070, Test Acc: 0.6963
2022-09-10 19:52:48,464:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 8/1000
2022-09-10 19:53:10,330:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.7849 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:53:10,331:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.87s, LR: 0.00050, Train Loss: 0.3909, Train Acc: 0.8400,
                            Val Loss: 0.4944, Val Acc: 0.7670, Test Acc: 0.7849
2022-09-10 19:53:10,331:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 9/1000
2022-09-10 19:53:31,973:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.64s, LR: 0.00050, Train Loss: 0.3610, Train Acc: 0.8550,
                            Val Loss: 1.3003, Val Acc: 0.5890, Test Acc: 0.5941
2022-09-10 19:53:31,974:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 10/1000
2022-09-10 19:53:53,656:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.68s, LR: 0.00050, Train Loss: 0.3380, Train Acc: 0.8750,
                            Val Loss: 0.5951, Val Acc: 0.7610, Test Acc: 0.7603
2022-09-10 19:53:53,657:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 11/1000
2022-09-10 19:54:15,749:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.09s, LR: 0.00050, Train Loss: 0.2957, Train Acc: 0.8900,
                            Val Loss: 0.7559, Val Acc: 0.6540, Test Acc: 0.6704
2022-09-10 19:54:15,750:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 12/1000
2022-09-10 19:54:37,800:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.8452 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:54:37,800:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.05s, LR: 0.00050, Train Loss: 0.2316, Train Acc: 0.9350,
                            Val Loss: 0.3903, Val Acc: 0.8300, Test Acc: 0.8452
2022-09-10 19:54:37,800:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 13/1000
2022-09-10 19:54:59,498:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9192 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:54:59,498:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.70s, LR: 0.00050, Train Loss: 0.2022, Train Acc: 0.9450,
                            Val Loss: 0.3151, Val Acc: 0.8940, Test Acc: 0.9192
2022-09-10 19:54:59,498:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 14/1000
2022-09-10 19:55:21,158:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.66s, LR: 0.00050, Train Loss: 0.1705, Train Acc: 0.9500,
                            Val Loss: 0.4052, Val Acc: 0.8620, Test Acc: 0.8845
2022-09-10 19:55:21,158:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 15/1000
2022-09-10 19:55:42,809:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9231 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:55:42,809:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.65s, LR: 0.00050, Train Loss: 0.1772, Train Acc: 0.9350,
                            Val Loss: 0.2527, Val Acc: 0.9210, Test Acc: 0.9231
2022-09-10 19:55:42,810:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 16/1000
2022-09-10 19:56:05,239:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9343 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:56:05,239:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.43s, LR: 0.00050, Train Loss: 0.1553, Train Acc: 0.9500,
                            Val Loss: 0.2478, Val Acc: 0.9360, Test Acc: 0.9343
2022-09-10 19:56:05,239:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 17/1000
2022-09-10 19:56:27,087:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9411 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 19:56:27,087:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.85s, LR: 0.00050, Train Loss: 0.1640, Train Acc: 0.9300,
                            Val Loss: 0.2303, Val Acc: 0.9400, Test Acc: 0.9411
2022-09-10 19:56:27,087:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 18/1000
2022-09-10 19:56:48,834:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.75s, LR: 0.00050, Train Loss: 0.1462, Train Acc: 0.9400,
                            Val Loss: 0.2576, Val Acc: 0.9320, Test Acc: 0.9332
2022-09-10 19:56:48,834:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 19/1000
2022-09-10 19:57:10,684:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.85s, LR: 0.00050, Train Loss: 0.1590, Train Acc: 0.9400,
                            Val Loss: 0.3037, Val Acc: 0.8850, Test Acc: 0.8819
2022-09-10 19:57:10,684:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 20/1000
2022-09-10 19:57:33,037:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.35s, LR: 0.00050, Train Loss: 0.1788, Train Acc: 0.9350,
                            Val Loss: 0.3401, Val Acc: 0.8960, Test Acc: 0.8901
2022-09-10 19:57:33,037:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 21/1000
2022-09-10 19:57:54,816:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.78s, LR: 0.00050, Train Loss: 0.1303, Train Acc: 0.9450,
                            Val Loss: 2.0010, Val Acc: 0.5720, Test Acc: 0.5765
2022-09-10 19:57:54,816:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 22/1000
2022-09-10 19:58:16,869:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.05s, LR: 0.00050, Train Loss: 0.1132, Train Acc: 0.9650,
                            Val Loss: 0.3203, Val Acc: 0.8620, Test Acc: 0.8751
2022-09-10 19:58:16,869:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 23/1000
2022-09-10 19:58:38,082:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.21s, LR: 0.00050, Train Loss: 0.1184, Train Acc: 0.9500,
                            Val Loss: 0.3738, Val Acc: 0.8860, Test Acc: 0.9031
2022-09-10 19:58:38,082:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 24/1000
2022-09-10 19:59:00,055:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.97s, LR: 0.00050, Train Loss: 0.1303, Train Acc: 0.9350,
                            Val Loss: 0.3167, Val Acc: 0.9360, Test Acc: 0.9360
2022-09-10 19:59:00,056:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 25/1000
2022-09-10 19:59:22,112:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.06s, LR: 0.00050, Train Loss: 0.1106, Train Acc: 0.9550,
                            Val Loss: 0.2995, Val Acc: 0.9340, Test Acc: 0.9317
2022-09-10 19:59:22,113:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 26/1000
2022-09-10 19:59:43,775:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.66s, LR: 0.00050, Train Loss: 0.1114, Train Acc: 0.9550,
                            Val Loss: 0.3190, Val Acc: 0.9210, Test Acc: 0.9205
2022-09-10 19:59:43,776:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 27/1000
2022-09-10 20:00:05,786:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.01s, LR: 0.00050, Train Loss: 0.1158, Train Acc: 0.9550,
                            Val Loss: 0.3011, Val Acc: 0.9270, Test Acc: 0.9315
2022-09-10 20:00:05,787:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 28/1000
2022-09-10 20:00:27,565:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.78s, LR: 0.00050, Train Loss: 0.1025, Train Acc: 0.9550,
                            Val Loss: 0.2910, Val Acc: 0.9230, Test Acc: 0.9335
2022-09-10 20:00:27,566:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 29/1000
2022-09-10 20:00:49,330:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9554 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 20:00:49,330:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.76s, LR: 0.00025, Train Loss: 0.0955, Train Acc: 0.9650,
                            Val Loss: 0.2083, Val Acc: 0.9490, Test Acc: 0.9554
2022-09-10 20:00:49,331:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 30/1000
2022-09-10 20:01:11,067:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.74s, LR: 0.00025, Train Loss: 0.0850, Train Acc: 0.9650,
                            Val Loss: 0.2269, Val Acc: 0.9310, Test Acc: 0.9253
2022-09-10 20:01:11,067:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 31/1000
2022-09-10 20:01:33,005:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.94s, LR: 0.00025, Train Loss: 0.0929, Train Acc: 0.9700,
                            Val Loss: 0.2387, Val Acc: 0.9380, Test Acc: 0.9298
2022-09-10 20:01:33,006:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 32/1000
2022-09-10 20:01:54,854:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.85s, LR: 0.00025, Train Loss: 0.0580, Train Acc: 0.9800,
                            Val Loss: 0.2377, Val Acc: 0.9490, Test Acc: 0.9417
2022-09-10 20:01:54,855:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 33/1000
2022-09-10 20:02:16,691:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.84s, LR: 0.00025, Train Loss: 0.0545, Train Acc: 0.9750,
                            Val Loss: 0.2317, Val Acc: 0.9480, Test Acc: 0.9446
2022-09-10 20:02:16,692:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 34/1000
2022-09-10 20:02:38,412:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9562 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 20:02:38,412:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.72s, LR: 0.00025, Train Loss: 0.0445, Train Acc: 0.9850,
                            Val Loss: 0.2794, Val Acc: 0.9530, Test Acc: 0.9562
2022-09-10 20:02:38,413:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 35/1000
2022-09-10 20:03:00,059:main_CYCLES_graph_classification.py:174 -   train_val_pipeline(): Saving best model with test accuracy: 0.9575 to out/CYCLES_graph_classification_b25-bnorm-altcheckpoints/GraphTransformer_CYCLES_GPU0_64_64_19h49m40s_on_Sep_10_2022/MODELS_
2022-09-10 20:03:00,059:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.65s, LR: 0.00025, Train Loss: 0.1147, Train Acc: 0.9650,
                            Val Loss: 0.2726, Val Acc: 0.9550, Test Acc: 0.9575
2022-09-10 20:03:00,059:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 36/1000
2022-09-10 20:03:21,832:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.77s, LR: 0.00025, Train Loss: 0.0722, Train Acc: 0.9850,
                            Val Loss: 0.2467, Val Acc: 0.9530, Test Acc: 0.9535
2022-09-10 20:03:21,833:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 37/1000
2022-09-10 20:03:43,482:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.65s, LR: 0.00025, Train Loss: 0.0503, Train Acc: 0.9750,
                            Val Loss: 0.3130, Val Acc: 0.9540, Test Acc: 0.9570
2022-09-10 20:03:43,482:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 38/1000
2022-09-10 20:04:05,199:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.72s, LR: 0.00025, Train Loss: 0.0675, Train Acc: 0.9750,
                            Val Loss: 0.7925, Val Acc: 0.8510, Test Acc: 0.8445
2022-09-10 20:04:05,200:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 39/1000
2022-09-10 20:04:26,914:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.71s, LR: 0.00025, Train Loss: 0.0359, Train Acc: 0.9950,
                            Val Loss: 0.3074, Val Acc: 0.9320, Test Acc: 0.9273
2022-09-10 20:04:26,914:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 40/1000
2022-09-10 20:04:48,302:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.39s, LR: 0.00025, Train Loss: 0.0570, Train Acc: 0.9750,
                            Val Loss: 0.3308, Val Acc: 0.9070, Test Acc: 0.8869
2022-09-10 20:04:48,303:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 41/1000
2022-09-10 20:05:09,088:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.78s, LR: 0.00013, Train Loss: 0.0558, Train Acc: 0.9750,
                            Val Loss: 0.2936, Val Acc: 0.9110, Test Acc: 0.9015
2022-09-10 20:05:09,088:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 42/1000
2022-09-10 20:05:30,024:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 20.94s, LR: 0.00013, Train Loss: 0.0495, Train Acc: 0.9900,
                            Val Loss: 0.2438, Val Acc: 0.9310, Test Acc: 0.9286
2022-09-10 20:05:30,025:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 43/1000
2022-09-10 20:05:52,153:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00013, Train Loss: 0.0341, Train Acc: 0.9950,
                            Val Loss: 0.2539, Val Acc: 0.9450, Test Acc: 0.9494
2022-09-10 20:05:52,154:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 44/1000
2022-09-10 20:06:14,038:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.88s, LR: 0.00013, Train Loss: 0.0312, Train Acc: 0.9950,
                            Val Loss: 0.2502, Val Acc: 0.9450, Test Acc: 0.9413
2022-09-10 20:06:14,039:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 45/1000
2022-09-10 20:06:36,489:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.45s, LR: 0.00013, Train Loss: 0.0333, Train Acc: 0.9950,
                            Val Loss: 0.2661, Val Acc: 0.9310, Test Acc: 0.9252
2022-09-10 20:06:36,489:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 46/1000
2022-09-10 20:06:58,313:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.82s, LR: 0.00013, Train Loss: 0.0260, Train Acc: 1.0000,
                            Val Loss: 0.3086, Val Acc: 0.9080, Test Acc: 0.9032
2022-09-10 20:06:58,314:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 47/1000
2022-09-10 20:07:19,999:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.69s, LR: 0.00013, Train Loss: 0.0224, Train Acc: 1.0000,
                            Val Loss: 0.2915, Val Acc: 0.9170, Test Acc: 0.9137
2022-09-10 20:07:20,000:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 48/1000
2022-09-10 20:07:41,728:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.73s, LR: 0.00013, Train Loss: 0.0248, Train Acc: 0.9950,
                            Val Loss: 0.2520, Val Acc: 0.9450, Test Acc: 0.9338
2022-09-10 20:07:41,728:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 49/1000
2022-09-10 20:08:03,465:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.74s, LR: 0.00013, Train Loss: 0.0291, Train Acc: 0.9900,
                            Val Loss: 0.2473, Val Acc: 0.9400, Test Acc: 0.9354
2022-09-10 20:08:03,466:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 50/1000
2022-09-10 20:08:25,217:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.75s, LR: 0.00013, Train Loss: 0.0158, Train Acc: 1.0000,
                            Val Loss: 0.2923, Val Acc: 0.9190, Test Acc: 0.9141
2022-09-10 20:08:25,217:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 51/1000
2022-09-10 20:08:46,994:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.78s, LR: 0.00013, Train Loss: 0.0187, Train Acc: 0.9950,
                            Val Loss: 0.2717, Val Acc: 0.9260, Test Acc: 0.9218
2022-09-10 20:08:46,994:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 52/1000
2022-09-10 20:09:09,625:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.63s, LR: 0.00006, Train Loss: 0.0156, Train Acc: 1.0000,
                            Val Loss: 0.2570, Val Acc: 0.9360, Test Acc: 0.9354
2022-09-10 20:09:09,625:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 53/1000
2022-09-10 20:09:31,576:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.95s, LR: 0.00006, Train Loss: 0.0179, Train Acc: 0.9950,
                            Val Loss: 0.2648, Val Acc: 0.9410, Test Acc: 0.9332
2022-09-10 20:09:31,576:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 54/1000
2022-09-10 20:09:53,264:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.69s, LR: 0.00006, Train Loss: 0.0164, Train Acc: 1.0000,
                            Val Loss: 0.2748, Val Acc: 0.9360, Test Acc: 0.9296
2022-09-10 20:09:53,264:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 55/1000
2022-09-10 20:10:14,952:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.69s, LR: 0.00006, Train Loss: 0.0141, Train Acc: 1.0000,
                            Val Loss: 0.2648, Val Acc: 0.9360, Test Acc: 0.9324
2022-09-10 20:10:14,952:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 56/1000
2022-09-10 20:10:39,833:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 24.88s, LR: 0.00006, Train Loss: 0.0117, Train Acc: 0.9950,
                            Val Loss: 0.2625, Val Acc: 0.9410, Test Acc: 0.9357
2022-09-10 20:10:39,834:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 57/1000
2022-09-10 20:11:03,407:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.57s, LR: 0.00006, Train Loss: 0.0116, Train Acc: 1.0000,
                            Val Loss: 0.2615, Val Acc: 0.9430, Test Acc: 0.9389
2022-09-10 20:11:03,408:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 58/1000
2022-09-10 20:11:25,870:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.46s, LR: 0.00006, Train Loss: 0.0163, Train Acc: 0.9950,
                            Val Loss: 0.2627, Val Acc: 0.9430, Test Acc: 0.9386
2022-09-10 20:11:25,871:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 59/1000
2022-09-10 20:11:48,943:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.07s, LR: 0.00006, Train Loss: 0.0127, Train Acc: 1.0000,
                            Val Loss: 0.2628, Val Acc: 0.9460, Test Acc: 0.9412
2022-09-10 20:11:48,943:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 60/1000
2022-09-10 20:12:12,718:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 23.77s, LR: 0.00006, Train Loss: 0.0087, Train Acc: 1.0000,
                            Val Loss: 0.2611, Val Acc: 0.9440, Test Acc: 0.9411
2022-09-10 20:12:12,718:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 61/1000
2022-09-10 20:12:34,408:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.69s, LR: 0.00006, Train Loss: 0.0143, Train Acc: 1.0000,
                            Val Loss: 0.2649, Val Acc: 0.9440, Test Acc: 0.9380
2022-09-10 20:12:34,408:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 62/1000
2022-09-10 20:12:58,806:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 24.40s, LR: 0.00006, Train Loss: 0.0084, Train Acc: 1.0000,
                            Val Loss: 0.2637, Val Acc: 0.9450, Test Acc: 0.9381
2022-09-10 20:12:58,806:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 63/1000
2022-09-10 20:13:24,019:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 25.21s, LR: 0.00003, Train Loss: 0.0146, Train Acc: 1.0000,
                            Val Loss: 0.2657, Val Acc: 0.9440, Test Acc: 0.9372
2022-09-10 20:13:24,020:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 64/1000
2022-09-10 20:13:45,820:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.80s, LR: 0.00003, Train Loss: 0.0079, Train Acc: 1.0000,
                            Val Loss: 0.2649, Val Acc: 0.9430, Test Acc: 0.9369
2022-09-10 20:13:45,820:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 65/1000
2022-09-10 20:14:07,587:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.77s, LR: 0.00003, Train Loss: 0.0139, Train Acc: 1.0000,
                            Val Loss: 0.2670, Val Acc: 0.9460, Test Acc: 0.9402
2022-09-10 20:14:07,588:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 66/1000
2022-09-10 20:14:29,325:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.74s, LR: 0.00003, Train Loss: 0.0094, Train Acc: 1.0000,
                            Val Loss: 0.2708, Val Acc: 0.9470, Test Acc: 0.9446
2022-09-10 20:14:29,326:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 67/1000
2022-09-10 20:14:51,153:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.83s, LR: 0.00003, Train Loss: 0.0062, Train Acc: 1.0000,
                            Val Loss: 0.2677, Val Acc: 0.9480, Test Acc: 0.9423
2022-09-10 20:14:51,153:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 68/1000
2022-09-10 20:15:13,260:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.11s, LR: 0.00003, Train Loss: 0.0132, Train Acc: 0.9950,
                            Val Loss: 0.2749, Val Acc: 0.9490, Test Acc: 0.9417
2022-09-10 20:15:13,261:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 69/1000
2022-09-10 20:15:35,789:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.53s, LR: 0.00003, Train Loss: 0.0077, Train Acc: 1.0000,
                            Val Loss: 0.2703, Val Acc: 0.9450, Test Acc: 0.9367
2022-09-10 20:15:35,790:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 70/1000
2022-09-10 20:15:57,777:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.99s, LR: 0.00003, Train Loss: 0.0215, Train Acc: 0.9950,
                            Val Loss: 0.2661, Val Acc: 0.9380, Test Acc: 0.9332
2022-09-10 20:15:57,778:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 71/1000
2022-09-10 20:16:20,436:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.66s, LR: 0.00003, Train Loss: 0.0128, Train Acc: 1.0000,
                            Val Loss: 0.2706, Val Acc: 0.9320, Test Acc: 0.9285
2022-09-10 20:16:20,436:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 72/1000
2022-09-10 20:16:44,502:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 24.07s, LR: 0.00003, Train Loss: 0.0088, Train Acc: 1.0000,
                            Val Loss: 0.2636, Val Acc: 0.9380, Test Acc: 0.9330
2022-09-10 20:16:44,502:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 73/1000
2022-09-10 20:17:06,455:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.95s, LR: 0.00003, Train Loss: 0.0161, Train Acc: 0.9950,
                            Val Loss: 0.2617, Val Acc: 0.9430, Test Acc: 0.9380
2022-09-10 20:17:06,455:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 74/1000
2022-09-10 20:17:28,691:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.24s, LR: 0.00002, Train Loss: 0.0108, Train Acc: 1.0000,
                            Val Loss: 0.2650, Val Acc: 0.9440, Test Acc: 0.9385
2022-09-10 20:17:28,691:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 75/1000
2022-09-10 20:17:50,624:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.93s, LR: 0.00002, Train Loss: 0.0117, Train Acc: 0.9950,
                            Val Loss: 0.2644, Val Acc: 0.9440, Test Acc: 0.9389
2022-09-10 20:17:50,624:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 76/1000
2022-09-10 20:18:14,872:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 24.25s, LR: 0.00002, Train Loss: 0.0132, Train Acc: 1.0000,
                            Val Loss: 0.2664, Val Acc: 0.9450, Test Acc: 0.9376
2022-09-10 20:18:14,872:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 77/1000
2022-09-10 20:18:39,103:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 24.23s, LR: 0.00002, Train Loss: 0.0136, Train Acc: 1.0000,
                            Val Loss: 0.2662, Val Acc: 0.9420, Test Acc: 0.9367
2022-09-10 20:18:39,103:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 78/1000
2022-09-10 20:19:03,723:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 24.62s, LR: 0.00002, Train Loss: 0.0095, Train Acc: 1.0000,
                            Val Loss: 0.2644, Val Acc: 0.9420, Test Acc: 0.9374
2022-09-10 20:19:03,723:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 79/1000
2022-09-10 20:19:26,158:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.44s, LR: 0.00002, Train Loss: 0.0116, Train Acc: 1.0000,
                            Val Loss: 0.2637, Val Acc: 0.9420, Test Acc: 0.9378
2022-09-10 20:19:26,159:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 80/1000
2022-09-10 20:19:47,712:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.55s, LR: 0.00002, Train Loss: 0.0068, Train Acc: 1.0000,
                            Val Loss: 0.2662, Val Acc: 0.9410, Test Acc: 0.9372
2022-09-10 20:19:47,713:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 81/1000
2022-09-10 20:20:09,819:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.11s, LR: 0.00002, Train Loss: 0.0087, Train Acc: 1.0000,
                            Val Loss: 0.2670, Val Acc: 0.9380, Test Acc: 0.9362
2022-09-10 20:20:09,820:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 82/1000
2022-09-10 20:20:31,940:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.12s, LR: 0.00002, Train Loss: 0.0101, Train Acc: 1.0000,
                            Val Loss: 0.2661, Val Acc: 0.9410, Test Acc: 0.9369
2022-09-10 20:20:31,940:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 83/1000
2022-09-10 20:20:53,879:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.94s, LR: 0.00002, Train Loss: 0.0100, Train Acc: 1.0000,
                            Val Loss: 0.2655, Val Acc: 0.9400, Test Acc: 0.9382
2022-09-10 20:20:53,879:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 84/1000
2022-09-10 20:21:15,930:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.05s, LR: 0.00002, Train Loss: 0.0113, Train Acc: 1.0000,
                            Val Loss: 0.2658, Val Acc: 0.9390, Test Acc: 0.9389
2022-09-10 20:21:15,931:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 85/1000
2022-09-10 20:21:37,967:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.04s, LR: 0.00001, Train Loss: 0.0089, Train Acc: 1.0000,
                            Val Loss: 0.2677, Val Acc: 0.9400, Test Acc: 0.9378
2022-09-10 20:21:37,968:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 86/1000
2022-09-10 20:22:00,136:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.17s, LR: 0.00001, Train Loss: 0.0089, Train Acc: 1.0000,
                            Val Loss: 0.2665, Val Acc: 0.9410, Test Acc: 0.9385
2022-09-10 20:22:00,137:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 87/1000
2022-09-10 20:22:22,266:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00001, Train Loss: 0.0117, Train Acc: 1.0000,
                            Val Loss: 0.2677, Val Acc: 0.9400, Test Acc: 0.9405
2022-09-10 20:22:22,266:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 88/1000
2022-09-10 20:22:44,325:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.06s, LR: 0.00001, Train Loss: 0.0074, Train Acc: 1.0000,
                            Val Loss: 0.2715, Val Acc: 0.9410, Test Acc: 0.9395
2022-09-10 20:22:44,326:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 89/1000
2022-09-10 20:23:05,928:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.60s, LR: 0.00001, Train Loss: 0.0062, Train Acc: 1.0000,
                            Val Loss: 0.2709, Val Acc: 0.9410, Test Acc: 0.9388
2022-09-10 20:23:05,930:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 90/1000
2022-09-10 20:23:28,143:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.21s, LR: 0.00001, Train Loss: 0.0064, Train Acc: 1.0000,
                            Val Loss: 0.2686, Val Acc: 0.9410, Test Acc: 0.9392
2022-09-10 20:23:28,144:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 91/1000
2022-09-10 20:23:50,375:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.23s, LR: 0.00001, Train Loss: 0.0088, Train Acc: 1.0000,
                            Val Loss: 0.2716, Val Acc: 0.9430, Test Acc: 0.9397
2022-09-10 20:23:50,376:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 92/1000
2022-09-10 20:24:12,505:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.13s, LR: 0.00001, Train Loss: 0.0064, Train Acc: 1.0000,
                            Val Loss: 0.2716, Val Acc: 0.9410, Test Acc: 0.9399
2022-09-10 20:24:12,506:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 93/1000
2022-09-10 20:24:34,554:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.05s, LR: 0.00001, Train Loss: 0.0094, Train Acc: 1.0000,
                            Val Loss: 0.2710, Val Acc: 0.9430, Test Acc: 0.9403
2022-09-10 20:24:34,555:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 94/1000
2022-09-10 20:24:56,655:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.10s, LR: 0.00001, Train Loss: 0.0068, Train Acc: 1.0000,
                            Val Loss: 0.2702, Val Acc: 0.9410, Test Acc: 0.9404
2022-09-10 20:24:56,656:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 95/1000
2022-09-10 20:25:18,664:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.01s, LR: 0.00001, Train Loss: 0.0061, Train Acc: 1.0000,
                            Val Loss: 0.2687, Val Acc: 0.9420, Test Acc: 0.9399
2022-09-10 20:25:18,664:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 96/1000
2022-09-10 20:25:41,140:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.48s, LR: 0.00000, Train Loss: 0.0071, Train Acc: 1.0000,
                            Val Loss: 0.2700, Val Acc: 0.9410, Test Acc: 0.9390
2022-09-10 20:25:41,141:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 97/1000
2022-09-10 20:26:03,747:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.61s, LR: 0.00000, Train Loss: 0.0068, Train Acc: 1.0000,
                            Val Loss: 0.2677, Val Acc: 0.9430, Test Acc: 0.9393
2022-09-10 20:26:03,748:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 98/1000
2022-09-10 20:26:26,226:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.48s, LR: 0.00000, Train Loss: 0.0068, Train Acc: 1.0000,
                            Val Loss: 0.2684, Val Acc: 0.9420, Test Acc: 0.9391
2022-09-10 20:26:26,226:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 99/1000
2022-09-10 20:26:48,551:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.32s, LR: 0.00000, Train Loss: 0.0062, Train Acc: 1.0000,
                            Val Loss: 0.2674, Val Acc: 0.9450, Test Acc: 0.9390
2022-09-10 20:26:48,551:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 100/1000
2022-09-10 20:27:10,487:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.93s, LR: 0.00000, Train Loss: 0.0084, Train Acc: 1.0000,
                            Val Loss: 0.2672, Val Acc: 0.9440, Test Acc: 0.9402
2022-09-10 20:27:10,487:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 101/1000
2022-09-10 20:27:32,835:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.35s, LR: 0.00000, Train Loss: 0.0082, Train Acc: 1.0000,
                            Val Loss: 0.2685, Val Acc: 0.9450, Test Acc: 0.9389
2022-09-10 20:27:32,836:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 102/1000
2022-09-10 20:27:55,152:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.32s, LR: 0.00000, Train Loss: 0.0148, Train Acc: 0.9950,
                            Val Loss: 0.2684, Val Acc: 0.9450, Test Acc: 0.9396
2022-09-10 20:27:55,152:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 103/1000
2022-09-10 20:28:17,737:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.58s, LR: 0.00000, Train Loss: 0.0095, Train Acc: 1.0000,
                            Val Loss: 0.2707, Val Acc: 0.9420, Test Acc: 0.9386
2022-09-10 20:28:17,737:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 104/1000
2022-09-10 20:28:40,136:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.40s, LR: 0.00000, Train Loss: 0.0096, Train Acc: 1.0000,
                            Val Loss: 0.2689, Val Acc: 0.9430, Test Acc: 0.9384
2022-09-10 20:28:40,137:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 105/1000
2022-09-10 20:29:02,101:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.96s, LR: 0.00000, Train Loss: 0.0171, Train Acc: 1.0000,
                            Val Loss: 0.2702, Val Acc: 0.9450, Test Acc: 0.9403
2022-09-10 20:29:02,102:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 106/1000
2022-09-10 20:29:24,561:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.46s, LR: 0.00000, Train Loss: 0.0088, Train Acc: 1.0000,
                            Val Loss: 0.2702, Val Acc: 0.9450, Test Acc: 0.9392
2022-09-10 20:29:24,561:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 107/1000
2022-09-10 20:29:46,958:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.40s, LR: 0.00000, Train Loss: 0.0066, Train Acc: 1.0000,
                            Val Loss: 0.2691, Val Acc: 0.9430, Test Acc: 0.9389
2022-09-10 20:29:46,959:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 108/1000
2022-09-10 20:30:09,340:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.38s, LR: 0.00000, Train Loss: 0.0111, Train Acc: 1.0000,
                            Val Loss: 0.2745, Val Acc: 0.9420, Test Acc: 0.9369
2022-09-10 20:30:09,341:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 109/1000
2022-09-10 20:30:31,603:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.26s, LR: 0.00000, Train Loss: 0.0104, Train Acc: 1.0000,
                            Val Loss: 0.2710, Val Acc: 0.9420, Test Acc: 0.9382
2022-09-10 20:30:31,604:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 110/1000
2022-09-10 20:30:53,912:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.31s, LR: 0.00000, Train Loss: 0.0153, Train Acc: 0.9900,
                            Val Loss: 0.2704, Val Acc: 0.9430, Test Acc: 0.9384
2022-09-10 20:30:53,914:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 111/1000
2022-09-10 20:31:16,247:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.33s, LR: 0.00000, Train Loss: 0.0067, Train Acc: 1.0000,
                            Val Loss: 0.2712, Val Acc: 0.9420, Test Acc: 0.9379
2022-09-10 20:31:16,248:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 112/1000
2022-09-10 20:31:39,049:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.80s, LR: 0.00000, Train Loss: 0.0064, Train Acc: 1.0000,
                            Val Loss: 0.2694, Val Acc: 0.9440, Test Acc: 0.9394
2022-09-10 20:31:39,049:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 113/1000
2022-09-10 20:32:01,454:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.41s, LR: 0.00000, Train Loss: 0.0129, Train Acc: 1.0000,
                            Val Loss: 0.2707, Val Acc: 0.9430, Test Acc: 0.9388
2022-09-10 20:32:01,454:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 114/1000
2022-09-10 20:32:23,775:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.32s, LR: 0.00000, Train Loss: 0.0137, Train Acc: 1.0000,
                            Val Loss: 0.2692, Val Acc: 0.9430, Test Acc: 0.9386
2022-09-10 20:32:23,775:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 115/1000
2022-09-10 20:32:46,056:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.28s, LR: 0.00000, Train Loss: 0.0076, Train Acc: 1.0000,
                            Val Loss: 0.2698, Val Acc: 0.9430, Test Acc: 0.9382
2022-09-10 20:32:46,056:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 116/1000
2022-09-10 20:33:08,378:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 22.32s, LR: 0.00000, Train Loss: 0.0210, Train Acc: 0.9950,
                            Val Loss: 0.2720, Val Acc: 0.9420, Test Acc: 0.9378
2022-09-10 20:33:08,378:main_CYCLES_graph_classification.py:158 -   train_val_pipeline(): Epoch 117/1000
2022-09-10 20:33:30,136:main_CYCLES_graph_classification.py:196 -   train_val_pipeline(): 	Time: 21.76s, LR: 0.00000, Train Loss: 0.0066, Train Acc: 1.0000,
                            Val Loss: 0.2718, Val Acc: 0.9440, Test Acc: 0.9388
2022-09-10 20:33:30,137:main_CYCLES_graph_classification.py:217 -   train_val_pipeline(): 
!! LR EQUAL TO MIN LR SET.
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:236 -   train_val_pipeline(): Test Accuracy: 0.9388
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:237 -   train_val_pipeline(): Best Test Accuracy: 0.9575
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:238 -   train_val_pipeline(): Train Accuracy: 1.0000
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:239 -   train_val_pipeline(): Best Train Accuracy Corresponding to Best Test Accuracy: 0.9650
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:240 -   train_val_pipeline(): Convergence Time (Epochs): 116.0000
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:241 -   train_val_pipeline(): TOTAL TIME TAKEN: 2648.5778s
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:242 -   train_val_pipeline(): AVG TIME PER EPOCH: 22.1833s
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:246 -   train_val_pipeline(): {'seed': 41, 'epochs': 1000, 'batch_size': 25, 'init_lr': 0.0005, 'lr_reduce_factor': 0.5, 'lr_schedule_patience': 10, 'min_lr': 1e-06, 'weight_decay': 0.0, 'print_epoch_interval': 5, 'max_time': 24, 'seed_array': [41], 'job_num': 64}
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:247 -   train_val_pipeline(): train history: [1.0]
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:248 -   train_val_pipeline(): test history: [0.9388]
2022-09-10 20:33:49,564:main_CYCLES_graph_classification.py:249 -   train_val_pipeline(): val history: [0.944]
