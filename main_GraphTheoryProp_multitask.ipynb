{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Main Driver Notebook for Training Graph NNs on GraphTheoryProp datasets for Multitask  \n",
                "Source: https://github.com/lukecavabarrett/pna"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### MODELS\n",
                "- GIN  \n",
                "- GatedGCN \n",
                "\n",
                "### DATASET\n",
                "- GraphTheoryProp\n",
                "\n",
                "### TASK\n",
                "- Multitask, for more see https://github.com/lukecavabarrett/pna"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "    IMPORTING LIBS\n",
                "\"\"\"\n",
                "import dgl\n",
                "\n",
                "import numpy as np\n",
                "import os\n",
                "import socket\n",
                "import time\n",
                "import random\n",
                "import glob\n",
                "import argparse, json\n",
                "import pickle\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "from tensorboardX import SummaryWriter\n",
                "from tqdm import tqdm\n",
                "\n",
                "class DotDict(dict):\n",
                "    def __init__(self, **kwds):\n",
                "        self.update(kwds)\n",
                "        self.__dict__ = self"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "True\n"
                    ]
                }
            ],
            "source": [
                "# \"\"\"\n",
                "#     AUTORELOAD IPYTHON EXTENSION FOR RELOADING IMPORTED MODULES\n",
                "# \"\"\"\n",
                "\n",
                "def in_ipynb():\n",
                "    try:\n",
                "        cfg = get_ipython().config \n",
                "        return True\n",
                "    except NameError:\n",
                "        return False\n",
                "    \n",
                "notebook_mode = in_ipynb()\n",
                "print(notebook_mode)\n",
                "\n",
                "if notebook_mode == True:\n",
                "    %load_ext autoreload\n",
                "    %autoreload 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "    IMPORTING CUSTOM MODULES/METHODS\n",
                "\"\"\"\n",
                "from nets.GraphTheoryProp_multitask.load_net import gnn_model # import all GNNS\n",
                "from data.data import LoadData # import dataset\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "    GPU Setup\n",
                "\"\"\"\n",
                "def gpu_setup(use_gpu, gpu_id):\n",
                "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
                "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)  \n",
                "\n",
                "    if torch.cuda.is_available() and use_gpu:\n",
                "        print('cuda available with GPU:',torch.cuda.get_device_name(0))\n",
                "        device = torch.device(\"cuda\")\n",
                "    else:\n",
                "        print('cuda not available')\n",
                "        device = torch.device(\"cpu\")\n",
                "    return device\n",
                "\n",
                "\n",
                "use_gpu = True\n",
                "gpu_id = -1\n",
                "device = None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "[I] Loading data (notebook) ...\n",
                        "[I] Loading dataset GraphTheoryProp...\n",
                        "train, test, val sizes : 5120 1280 640\n",
                        "[I] Finished loading.\n",
                        "[I] Data load time: 5.8440s\n",
                        "[I] Finished loading.\n"
                    ]
                }
            ],
            "source": [
                "# \"\"\"\n",
                "#     USER CONTROLS\n",
                "# \"\"\"\n",
                "if notebook_mode == True:\n",
                "    \n",
                "    MODEL_NAME = 'GatedGCN'\n",
                "\n",
                "    DATASET_NAME = 'GraphTheoryProp'\n",
                "\n",
                "    out_dir = 'out/GraphTheoryProp_graph_classification/'\n",
                "    root_log_dir = out_dir + 'logs/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
                "    root_ckpt_dir = out_dir + 'checkpoints/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
                "\n",
                "    print(\"[I] Loading data (notebook) ...\")\n",
                "    dataset = LoadData(DATASET_NAME)\n",
                "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
                "    print(\"[I] Finished loading.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# \"\"\"\n",
                "#     PARAMETERS\n",
                "# \"\"\"\n",
                "if notebook_mode == True:\n",
                "\n",
                "    n_heads = -1\n",
                "    edge_feat = False\n",
                "    pseudo_dim_MoNet = -1\n",
                "    kernel = -1\n",
                "    gnn_per_block = -1\n",
                "    embedding_dim = -1\n",
                "    pool_ratio = -1\n",
                "    n_mlp_GIN = -1\n",
                "    gated = False\n",
                "    self_loop = False\n",
                "    #self_loop = True\n",
                "    max_time = 12\n",
                "    \n",
                "    \n",
                "\n",
                "    if MODEL_NAME == 'GatedGCN':\n",
                "        seed=41; epochs=1; batch_size=5; init_lr=5e-5; lr_reduce_factor=0.5; lr_schedule_patience=25; min_lr = 1e-6; weight_decay=0\n",
                "        L=8; hidden_dim=40; out_dim=hidden_dim; dropout=0.0; readout='sum'\n",
                "        init_lr=5e-4; lr_reduce_factor=0.5; lr_schedule_patience=10; pos_enc=True; pos_enc_dim=12; batch_size=25; # v2\n",
                "    \n",
                "    \n",
                "    # generic new_params\n",
                "    net_params = {}\n",
                "    net_params['device'] = device\n",
                "    net_params['gated'] = gated  # for mlpnet baseline\n",
                "    net_params['in_dim'] = trainset[0][0].ndata['feat'][0].size(0)\n",
                "    net_params['residual'] = True\n",
                "    net_params['hidden_dim'] = hidden_dim\n",
                "    net_params['out_dim'] = out_dim\n",
                "    # num_classes = len(np.unique(np.array(trainset[:][1])))\n",
                "    # net_params['n_classes'] = num_classes\n",
                "    net_params['n_heads'] = n_heads\n",
                "    net_params['L'] = L  # min L should be 2\n",
                "    net_params['readout'] = \"sum\"\n",
                "    net_params['layer_norm'] = True\n",
                "    net_params['batch_norm'] = True\n",
                "    net_params['in_feat_dropout'] = 0.0\n",
                "    net_params['dropout'] = 0.0\n",
                "    net_params['edge_feat'] = edge_feat\n",
                "    net_params['self_loop'] = self_loop\n",
                "    net_params['pos_enc'] = pos_enc\n",
                "    net_params['pos_enc_dim'] = pos_enc_dim\n",
                "    net_params['use_gru'] = True\n",
                "\n",
                "    net_params['batch_size'] = batch_size   "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "MODEL DETAILS:\n",
                        "\n",
                        "MODEL/Total parameters: GatedGCN 102146\n"
                    ]
                }
            ],
            "source": [
                "\"\"\"\n",
                "    VIEWING MODEL CONFIG AND PARAMS\n",
                "\"\"\"\n",
                "def view_model_param(MODEL_NAME, net_params):\n",
                "    model = gnn_model(MODEL_NAME, net_params)\n",
                "    total_param = 0\n",
                "    print(\"MODEL DETAILS:\\n\")\n",
                "    #print(model)\n",
                "    for param in model.parameters():\n",
                "        # print(param.data.size())\n",
                "        total_param += np.prod(list(param.data.size()))\n",
                "    print('MODEL/Total parameters:', MODEL_NAME, total_param)\n",
                "    return total_param\n",
                "\n",
                "\n",
                "if notebook_mode == True:\n",
                "    view_model_param(MODEL_NAME, net_params)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"\"\"\n",
                "    TRAINING CODE\n",
                "\"\"\"\n",
                "\n",
                "def train_val_pipeline(MODEL_NAME, dataset, params, net_params, dirs):\n",
                "    t0 = time.time()\n",
                "    per_epoch_time = []\n",
                "        \n",
                "    DATASET_NAME = dataset.name\n",
                "    \n",
                "    if net_params['pos_enc']:\n",
                "        print(\"[!] Adding graph positional encoding.\")\n",
                "        dataset._add_positional_encodings(net_params['pos_enc_dim'])\n",
                "    \n",
                "    trainset, valset, testset = dataset.train, dataset.val, dataset.test\n",
                "    \n",
                "    root_log_dir, root_ckpt_dir, write_file_name, write_config_file = dirs\n",
                "    device = net_params['device']\n",
                "    \n",
                "    # Write the network and optimization hyper-parameters in folder config/\n",
                "    with open(write_config_file + '.txt', 'w') as f:\n",
                "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n\\nTotal Parameters: {}\\n\\n\"\"\"\\\n",
                "                .format(DATASET_NAME, MODEL_NAME, params, net_params, net_params['total_param']))\n",
                "        \n",
                "    log_dir = os.path.join(root_log_dir, \"RUN_\" + str(0))\n",
                "    writer = SummaryWriter(log_dir=log_dir)\n",
                "\n",
                "    # setting seeds\n",
                "    random.seed(params['seed'])\n",
                "    np.random.seed(params['seed'])\n",
                "    torch.manual_seed(params['seed'])\n",
                "    if device.type == 'cuda':\n",
                "        torch.cuda.manual_seed(params['seed'])\n",
                "    \n",
                "    print(\"Training Graphs: \", len(trainset))\n",
                "    print(\"Validation Graphs: \", len(valset))\n",
                "    print(\"Test Graphs: \", len(testset))\n",
                "\n",
                "    model = gnn_model(MODEL_NAME, net_params)\n",
                "    model = model.to(device)\n",
                "\n",
                "    optimizer = optim.Adam(model.parameters(), lr=params['init_lr'], weight_decay=params['weight_decay'])\n",
                "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
                "                                                     factor=params['lr_reduce_factor'],\n",
                "                                                     patience=params['lr_schedule_patience'],\n",
                "                                                     verbose=True)\n",
                "    \n",
                "    epoch_train_losses, epoch_val_losses = [], []\n",
                "    epoch_train_mses, epoch_val_mses = [], [] \n",
                "    \n",
                "\n",
                "    # import train functions for all other GCNs\n",
                "    from train.train_GraphTheoryProp_multitask import train_epoch_sparse as train_epoch, evaluate_network_sparse as evaluate_network\n",
                "\n",
                "    train_loader = DataLoader(trainset, batch_size=params['batch_size'], shuffle=True, collate_fn=dataset.collate)\n",
                "    val_loader = DataLoader(valset, batch_size=params['batch_size'], shuffle=False, collate_fn=dataset.collate)\n",
                "    test_loader = DataLoader(testset, batch_size=params['batch_size'], shuffle=False, collate_fn=dataset.collate)\n",
                "\n",
                "    # At any point you can hit Ctrl + C to break out of training early.\n",
                "    try:\n",
                "        with tqdm(range(params['epochs'])) as t:\n",
                "            for epoch in t:\n",
                "\n",
                "                t.set_description('Epoch %d' % epoch)\n",
                "\n",
                "                start = time.time()\n",
                "\n",
                "                epoch_train_loss, epoch_train_log_mse, optimizer = train_epoch(model, optimizer, device, train_loader, epoch)\n",
                "\n",
                "                epoch_val_loss, epoch_val_log_mse, __ = evaluate_network(model, device, val_loader, epoch)\n",
                "                _, epoch_test_log_mse, __ = evaluate_network(model, device, test_loader, epoch)                \n",
                "                \n",
                "                epoch_train_losses.append(epoch_train_loss)\n",
                "                epoch_val_losses.append(epoch_val_loss)\n",
                "                epoch_train_mses.append(epoch_train_log_mse)\n",
                "                epoch_val_mses.append(epoch_val_log_mse)\n",
                "\n",
                "                writer.add_scalar('train/_loss', epoch_train_loss, epoch)\n",
                "                writer.add_scalar('val/_loss', epoch_val_loss, epoch)\n",
                "                writer.add_scalar('train/_log_mse', epoch_train_log_mse, epoch)\n",
                "                writer.add_scalar('val/_log_mse', epoch_val_log_mse, epoch)\n",
                "                writer.add_scalar('test/_log_mse', epoch_test_log_mse, epoch)\n",
                "                writer.add_scalar('learning_rate', optimizer.param_groups[0]['lr'], epoch)\n",
                "\n",
                "                \n",
                "                t.set_postfix(time=time.time()-start, lr=optimizer.param_groups[0]['lr'],\n",
                "                              train_loss=epoch_train_loss, val_loss=epoch_val_loss,\n",
                "                              train_log_mse=epoch_train_log_mse, val_log_mse=epoch_val_log_mse,\n",
                "                              test_log_mse=epoch_test_log_mse)    \n",
                "\n",
                "                per_epoch_time.append(time.time()-start)\n",
                "\n",
                "                # Saving checkpoint\n",
                "                ckpt_dir = os.path.join(root_ckpt_dir, \"RUN_\")\n",
                "                if not os.path.exists(ckpt_dir):\n",
                "                    os.makedirs(ckpt_dir)\n",
                "                torch.save(model.state_dict(), '{}.pkl'.format(ckpt_dir + \"/epoch_\" + str(epoch)))\n",
                "\n",
                "                files = glob.glob(ckpt_dir + '/*.pkl')\n",
                "                for file in files:\n",
                "                    epoch_nb = file.split('_')[-1]\n",
                "                    epoch_nb = int(epoch_nb.split('.')[0])\n",
                "                    if epoch_nb < epoch-1:\n",
                "                        os.remove(file)\n",
                "\n",
                "                scheduler.step(epoch_val_loss)\n",
                "\n",
                "                if optimizer.param_groups[0]['lr'] < params['min_lr']:\n",
                "                    print(\"\\n!! LR EQUAL TO MIN LR SET.\")\n",
                "                    break\n",
                "                    \n",
                "                # Stop training after params['max_time'] hours\n",
                "                if time.time()-t0 > params['max_time']*3600:\n",
                "                    print('-' * 89)\n",
                "                    print(\"Max_time for training elapsed {:.2f} hours, so stopping\".format(params['max_time']))\n",
                "                    break\n",
                "    \n",
                "    except KeyboardInterrupt:\n",
                "        print('-' * 89)\n",
                "        print('Exiting from training early because of KeyboardInterrupt')\n",
                "    \n",
                "    _, test_log_mse, specific_test_log_mse = evaluate_network(model, device, test_loader, epoch)\n",
                "    _, train_log_mse, specific_train_log_mse = evaluate_network(model, device, train_loader, epoch)\n",
                "    print(\"Test Log MSE: {:.4f}\".format(test_log_mse))\n",
                "    print(\"Specific Test Log MSE: {}\".format(specific_test_log_mse))\n",
                "    print(\"Train Log MSE: {:.4f}\".format(train_log_mse))\n",
                "    print(\"Specific Train Log MSE: {}\".format(specific_train_log_mse))\n",
                "    print(\"Convergence Time (Epochs): {:.4f}\".format(epoch))\n",
                "    print(\"TOTAL TIME TAKEN: {:.4f}s\".format(time.time()-t0))\n",
                "    print(\"AVG TIME PER EPOCH: {:.4f}s\".format(np.mean(per_epoch_time)))\n",
                "\n",
                "    writer.close()\n",
                "\n",
                "    \"\"\"\n",
                "        Write the results in out_dir/results folder\n",
                "    \"\"\"\n",
                "    with open(write_file_name + '.txt', 'w') as f:\n",
                "        f.write(\"\"\"Dataset: {},\\nModel: {}\\n\\nparams={}\\n\\nnet_params={}\\n\\n{}\\n\\nTotal Parameters: {}\\n\\n\n",
                "    FINAL RESULTS\\nTEST Log MSE: {:.4f}\\nSpecific TEST Log MSE: {}\\nTRAIN Log MSE: {:.4f}\\nSpecific TRAIN Log MSE: {}\\n\\n\n",
                "    Convergence Time (Epochs): {:.4f}\\nTotal Time Taken: {:.4f} hrs\\nAverage Time Per Epoch: {:.4f} s\\n\\n\\n\"\"\"\\\n",
                "          .format(DATASET_NAME, MODEL_NAME, params, net_params, model, net_params['total_param'],\n",
                "                  test_log_mse, specific_test_log_mse, train_log_mse, specific_train_log_mse, epoch, (time.time()-t0)/3600, np.mean(per_epoch_time)))\n",
                "               "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Convert main_GraphTheoryProp_multitask.ipynb to main_GraphTheoryProp_multitask.py\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[NbConvertApp] Converting notebook main_GraphTheoryProp_multitask.ipynb to script\n",
                        "[NbConvertApp] Writing 22615 bytes to main_GraphTheoryProp_multitask.py\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Clean main_GraphTheoryProp_multitask.py\n",
                        "Done. \n",
                        "[I] Loading dataset GraphTheoryProp...\n",
                        "train, test, val sizes : 5120 1280 640\n",
                        "[I] Finished loading.\n",
                        "[I] Data load time: 6.2053s\n",
                        "cuda not available\n",
                        "MODEL DETAILS:\n",
                        "\n",
                        "MODEL/Total parameters: GatedGCN 102146\n",
                        "[!] Adding graph positional encoding.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py:3719: DGLWarning: DGLGraph.adjacency_matrix_scipy is deprecated. Please replace it with:\n",
                        "\n",
                        "\tDGLGraph.adjacency_matrix(transpose, scipy_fmt=\"csr\").\n",
                        "\n",
                        "  dgl_warning('DGLGraph.adjacency_matrix_scipy is deprecated. '\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Graphs:  5120\n",
                        "Validation Graphs:  640\n",
                        "Test Graphs:  1280\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Epoch 0:   0%|          | 0/1000 [00:00<?, ?it/s]/home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
                        "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
                        "Epoch 63:   6%|â–‹         | 63/1000 [20:37<5:06:38, 19.64s/it, lr=0.0005, test_log_mse=-2.99, time=19.4, train_log_mse=-2.85, train_loss=0.00143, val_log_mse=-2.9, val_loss=0.00126] \n"
                    ]
                },
                {
                    "ename": "TypeError",
                    "evalue": "linear(): argument 'input' (position 1) must be Tensor, not NoneType",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "File \u001b[0;32m~/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py:32\u001b[0m, in \u001b[0;36mtrain_epoch_sparse\u001b[0;34m(model, optimizer, device, data_loader, epoch)\u001b[0m\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=30'>31</a>\u001b[0m     batch_pos_enc \u001b[39m=\u001b[39m batch_pos_enc \u001b[39m*\u001b[39m sign_flip\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m---> <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=31'>32</a>\u001b[0m     batch_scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(batch_graphs, batch_x, batch_e, batch_pos_enc)\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=32'>33</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n",
                        "File \u001b[0;32m~/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py:80\u001b[0m, in \u001b[0;36mGatedGCNNet.forward\u001b[0;34m(self, g, h, e, pos_enc)\u001b[0m\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=78'>79</a>\u001b[0m \u001b[39mfor\u001b[39;00m conv \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m---> <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=79'>80</a>\u001b[0m     h_t, e \u001b[39m=\u001b[39m conv(g, h, e)\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=81'>82</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_gru:\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=82'>83</a>\u001b[0m         \u001b[39m# Use GRU\u001b[39;00m\n",
                        "File \u001b[0;32m~/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n",
                        "File \u001b[0;32m~/Documents/projects/benchmarking-gnns/layers/gated_gcn_layer.py:67\u001b[0m, in \u001b[0;36mGatedGCNLayer.forward\u001b[0;34m(self, g, h, e)\u001b[0m\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/layers/gated_gcn_layer.py?line=65'>66</a>\u001b[0m g\u001b[39m.\u001b[39mupdate_all(fn\u001b[39m.\u001b[39mu_mul_e(\u001b[39m'\u001b[39m\u001b[39mBh\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msigma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m), fn\u001b[39m.\u001b[39msum(\u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msum_sigma_h\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m---> <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/layers/gated_gcn_layer.py?line=66'>67</a>\u001b[0m g\u001b[39m.\u001b[39;49mupdate_all(fn\u001b[39m.\u001b[39;49mcopy_e(\u001b[39m'\u001b[39;49m\u001b[39msigma\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m'\u001b[39;49m), fn\u001b[39m.\u001b[39;49msum(\u001b[39m'\u001b[39;49m\u001b[39mm\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39msum_sigma\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/layers/gated_gcn_layer.py?line=67'>68</a>\u001b[0m g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39mAh\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39msum_sigma_h\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m/\u001b[39m (g\u001b[39m.\u001b[39mndata[\u001b[39m'\u001b[39m\u001b[39msum_sigma\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m1e-6\u001b[39m)\n",
                        "File \u001b[0;32m~/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py:4894\u001b[0m, in \u001b[0;36mDGLHeteroGraph.update_all\u001b[0;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=4892'>4893</a>\u001b[0m _, dtid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mmetagraph\u001b[39m.\u001b[39mfind_edge(etid)\n\u001b[0;32m-> <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=4893'>4894</a>\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m etype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39;49m[etype]\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=4894'>4895</a>\u001b[0m ndata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mmessage_passing(g, message_func, reduce_func, apply_node_func)\n",
                        "File \u001b[0;32m~/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py:2259\u001b[0m, in \u001b[0;36mDGLHeteroGraph.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=2256'>2257</a>\u001b[0m     new_eframes \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_edge_frames[etid]]\n\u001b[0;32m-> <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=2258'>2259</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__class__\u001b[39;49m(new_g, new_ntypes, new_etypes, new_nframes, new_eframes)\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=2259'>2260</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py:85\u001b[0m, in \u001b[0;36mDGLHeteroGraph.__init__\u001b[0;34m(self, gidx, ntypes, etypes, node_frames, edge_frames, **deprecate_kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=82'>83</a>\u001b[0m     dgl_warning(\u001b[39m'\u001b[39m\u001b[39mKeyword arguments \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m are deprecated in v0.5, and can be safely\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=83'>84</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m removed in all cases.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlist\u001b[39m(deprecate_kwargs\u001b[39m.\u001b[39mkeys())))\n\u001b[0;32m---> <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=84'>85</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init(gidx, ntypes, etypes, node_frames, edge_frames)\n",
                        "File \u001b[0;32m~/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py:125\u001b[0m, in \u001b[0;36mDGLHeteroGraph._init\u001b[0;34m(self, gidx, ntypes, etypes, node_frames, edge_frames)\u001b[0m\n\u001b[1;32m    <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=123'>124</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_canonical_etypes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=124'>125</a>\u001b[0m     \u001b[39mif\u001b[39;00m (\u001b[39mlen\u001b[39;49m(etypes) \u001b[39m==\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(ntypes) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m    <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/dgl/heterograph.py?line=125'>126</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_canonical_etypes \u001b[39m=\u001b[39m [(ntypes[\u001b[39m0\u001b[39m], etypes[\u001b[39m0\u001b[39m], ntypes[\u001b[39m0\u001b[39m])]\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "\u001b[1;32m/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 197>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=225'>226</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcleaner_main\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=226'>227</a>\u001b[0m     cleaner_main(\u001b[39m'\u001b[39m\u001b[39mmain_GraphTheoryProp_multitask\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=228'>229</a>\u001b[0m     main(\u001b[39mTrue\u001b[39;49;00m,config)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=230'>231</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=232'>233</a>\u001b[0m     main()\n",
                        "\u001b[1;32m/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb Cell 13'\u001b[0m in \u001b[0;36mmain\u001b[0;34m(notebook_mode, config)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=189'>190</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(out_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mconfigs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=191'>192</a>\u001b[0m net_params[\u001b[39m'\u001b[39m\u001b[39mtotal_param\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m view_model_param(MODEL_NAME, net_params)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000012?line=192'>193</a>\u001b[0m train_val_pipeline(MODEL_NAME, dataset, params, net_params, dirs)\n",
                        "\u001b[1;32m/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb Cell 12'\u001b[0m in \u001b[0;36mtrain_val_pipeline\u001b[0;34m(MODEL_NAME, dataset, params, net_params, dirs)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000011?line=63'>64</a>\u001b[0m t\u001b[39m.\u001b[39mset_description(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000011?line=65'>66</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000011?line=67'>68</a>\u001b[0m epoch_train_loss, epoch_train_log_mse, optimizer \u001b[39m=\u001b[39m train_epoch(model, optimizer, device, train_loader, epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000011?line=69'>70</a>\u001b[0m epoch_val_loss, epoch_val_log_mse, __ \u001b[39m=\u001b[39m evaluate_network(model, device, val_loader, epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/psoga/Documents/projects/benchmarking-gnns/main_GraphTheoryProp_multitask.ipynb#ch0000011?line=70'>71</a>\u001b[0m _, epoch_test_log_mse, __ \u001b[39m=\u001b[39m evaluate_network(model, device, test_loader, epoch)                \n",
                        "File \u001b[0;32m~/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py:34\u001b[0m, in \u001b[0;36mtrain_epoch_sparse\u001b[0;34m(model, optimizer, device, data_loader, epoch)\u001b[0m\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=31'>32</a>\u001b[0m     batch_scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(batch_graphs, batch_x, batch_e, batch_pos_enc)\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=32'>33</a>\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=33'>34</a>\u001b[0m     batch_scores \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(batch_graphs, batch_x, batch_e)\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=34'>35</a>\u001b[0m loss, specific_loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mloss(batch_scores, batch_labels) \n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/train/train_GraphTheoryProp_multitask.py?line=35'>36</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
                        "File \u001b[0;32m~/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py:68\u001b[0m, in \u001b[0;36mGatedGCNNet.forward\u001b[0;34m(self, g, h, e, pos_enc)\u001b[0m\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=65'>66</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_h(h)\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=66'>67</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_enc:\n\u001b[0;32m---> <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=67'>68</a>\u001b[0m     h_pos_enc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding_pos_enc(pos_enc) \n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=68'>69</a>\u001b[0m     h \u001b[39m=\u001b[39m h \u001b[39m+\u001b[39m h_pos_enc\n\u001b[1;32m     <a href='file:///home/psoga/Documents/projects/benchmarking-gnns/nets/GraphTheoryProp_multitask/gated_gcn_net.py?line=70'>71</a>\u001b[0m h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_feat_dropout(h)\n",
                        "File \u001b[0;32m~/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
                        "File \u001b[0;32m~/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/linear.py:103\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=101'>102</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/psoga/.virtualenvs/gnn/lib/python3.8/site-packages/torch/nn/modules/linear.py?line=102'>103</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
                        "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not NoneType"
                    ]
                }
            ],
            "source": [
                "def main(notebook_mode=False,config=None):\n",
                "    \n",
                "    \"\"\"\n",
                "        USER CONTROLS\n",
                "    \"\"\"\n",
                "    \n",
                "    # terminal mode\n",
                "    if notebook_mode==False:\n",
                "        \n",
                "        parser = argparse.ArgumentParser()\n",
                "        parser.add_argument('--config', help=\"Please give a config.json file with training/model/data/param details\")\n",
                "        parser.add_argument('--gpu_id', help=\"Please give a value for gpu id\")\n",
                "        parser.add_argument('--model', help=\"Please give a value for model name\")\n",
                "        parser.add_argument('--dataset', help=\"Please give a value for dataset name\")\n",
                "        parser.add_argument('--out_dir', help=\"Please give a value for out_dir\")\n",
                "        parser.add_argument('--seed', help=\"Please give a value for seed\")\n",
                "        parser.add_argument('--epochs', help=\"Please give a value for epochs\")\n",
                "        parser.add_argument('--batch_size', help=\"Please give a value for batch_size\")\n",
                "        parser.add_argument('--init_lr', help=\"Please give a value for init_lr\")\n",
                "        parser.add_argument('--lr_reduce_factor', help=\"Please give a value for lr_reduce_factor\")\n",
                "        parser.add_argument('--lr_schedule_patience', help=\"Please give a value for lr_schedule_patience\")\n",
                "        parser.add_argument('--min_lr', help=\"Please give a value for min_lr\")\n",
                "        parser.add_argument('--weight_decay', help=\"Please give a value for weight_decay\")\n",
                "        parser.add_argument('--print_epoch_interval', help=\"Please give a value for print_epoch_interval\")    \n",
                "        parser.add_argument('--L', help=\"Please give a value for L\")\n",
                "        parser.add_argument('--hidden_dim', help=\"Please give a value for hidden_dim\")\n",
                "        parser.add_argument('--out_dim', help=\"Please give a value for out_dim\")\n",
                "        parser.add_argument('--residual', help=\"Please give a value for residual\")\n",
                "        parser.add_argument('--edge_feat', help=\"Please give a value for edge_feat\")\n",
                "        parser.add_argument('--readout', help=\"Please give a value for readout\")\n",
                "        parser.add_argument('--kernel', help=\"Please give a value for kernel\")\n",
                "        parser.add_argument('--n_heads', help=\"Please give a value for n_heads\")\n",
                "        parser.add_argument('--gated', help=\"Please give a value for gated\")\n",
                "        parser.add_argument('--in_feat_dropout', help=\"Please give a value for in_feat_dropout\")\n",
                "        parser.add_argument('--dropout', help=\"Please give a value for dropout\")\n",
                "        parser.add_argument('--layer_norm', help=\"Please give a value for layer_norm\")\n",
                "        parser.add_argument('--batch_norm', help=\"Please give a value for batch_norm\")\n",
                "        parser.add_argument('--sage_aggregator', help=\"Please give a value for sage_aggregator\")\n",
                "        parser.add_argument('--data_mode', help=\"Please give a value for data_mode\")\n",
                "        parser.add_argument('--num_pool', help=\"Please give a value for num_pool\")\n",
                "        parser.add_argument('--gnn_per_block', help=\"Please give a value for gnn_per_block\")\n",
                "        parser.add_argument('--embedding_dim', help=\"Please give a value for embedding_dim\")\n",
                "        parser.add_argument('--pool_ratio', help=\"Please give a value for pool_ratio\")\n",
                "        parser.add_argument('--linkpred', help=\"Please give a value for linkpred\")\n",
                "        parser.add_argument('--cat', help=\"Please give a value for cat\")\n",
                "        parser.add_argument('--self_loop', help=\"Please give a value for self_loop\")\n",
                "        parser.add_argument('--max_time', help=\"Please give a value for max_time\")\n",
                "        parser.add_argument('--num_train_data', help=\"Please give a value for num_train_data\")\n",
                "        args = parser.parse_args()\n",
                "        with open(args.config) as f:\n",
                "            config = json.load(f)\n",
                "            \n",
                "\n",
                "        # device\n",
                "        if args.gpu_id is not None:\n",
                "            config['gpu']['id'] = int(args.gpu_id)\n",
                "            config['gpu']['use'] = True\n",
                "        device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
                "\n",
                "        # model, dataset, out_dir\n",
                "        if args.model is not None:\n",
                "            MODEL_NAME = args.model\n",
                "        else:\n",
                "            MODEL_NAME = config['model']\n",
                "        if args.dataset is not None:\n",
                "            DATASET_NAME = args.dataset\n",
                "        else:\n",
                "            DATASET_NAME = config['dataset']\n",
                "        dataset = LoadData(DATASET_NAME)\n",
                "        if args.out_dir is not None:\n",
                "            out_dir = args.out_dir\n",
                "        else:\n",
                "            out_dir = config['out_dir']\n",
                "\n",
                "        # parameters\n",
                "        params = config['params']\n",
                "        if args.seed is not None:\n",
                "            params['seed'] = int(args.seed)\n",
                "        if args.epochs is not None:\n",
                "            params['epochs'] = int(args.epochs)\n",
                "        if args.batch_size is not None:\n",
                "            params['batch_size'] = int(args.batch_size)\n",
                "        if args.init_lr is not None:\n",
                "            params['init_lr'] = float(args.init_lr)\n",
                "        if args.lr_reduce_factor is not None:\n",
                "            params['lr_reduce_factor'] = float(args.lr_reduce_factor)\n",
                "        if args.lr_schedule_patience is not None:\n",
                "            params['lr_schedule_patience'] = int(args.lr_schedule_patience)\n",
                "        if args.min_lr is not None:\n",
                "            params['min_lr'] = float(args.min_lr)\n",
                "        if args.weight_decay is not None:\n",
                "            params['weight_decay'] = float(args.weight_decay)\n",
                "        if args.print_epoch_interval is not None:\n",
                "            params['print_epoch_interval'] = int(args.print_epoch_interval)\n",
                "        if args.max_time is not None:\n",
                "            params['max_time'] = float(args.max_time)\n",
                "\n",
                "        # network parameters\n",
                "        net_params = config['net_params']\n",
                "        net_params['device'] = device\n",
                "        net_params['gpu_id'] = config['gpu']['id']\n",
                "        net_params['batch_size'] = params['batch_size']\n",
                "        if args.L is not None:\n",
                "            net_params['L'] = int(args.L)\n",
                "        if args.hidden_dim is not None:\n",
                "            net_params['hidden_dim'] = int(args.hidden_dim)\n",
                "        if args.out_dim is not None:\n",
                "            net_params['out_dim'] = int(args.out_dim)   \n",
                "        if args.residual is not None:\n",
                "            net_params['residual'] = True if args.residual=='True' else False\n",
                "        if args.edge_feat is not None:\n",
                "            net_params['edge_feat'] = True if args.edge_feat=='True' else False\n",
                "        if args.readout is not None:\n",
                "            net_params['readout'] = args.readout\n",
                "        if args.kernel is not None:\n",
                "            net_params['kernel'] = int(args.kernel)\n",
                "        if args.n_heads is not None:\n",
                "            net_params['n_heads'] = int(args.n_heads)\n",
                "        if args.gated is not None:\n",
                "            net_params['gated'] = True if args.gated=='True' else False\n",
                "        if args.in_feat_dropout is not None:\n",
                "            net_params['in_feat_dropout'] = float(args.in_feat_dropout)\n",
                "        if args.dropout is not None:\n",
                "            net_params['dropout'] = float(args.dropout)\n",
                "        if args.layer_norm is not None:\n",
                "            net_params['layer_norm'] = True if args.layer_norm=='True' else False\n",
                "        if args.batch_norm is not None:\n",
                "            net_params['batch_norm'] = True if args.batch_norm=='True' else False\n",
                "        if args.sage_aggregator is not None:\n",
                "            net_params['sage_aggregator'] = args.sage_aggregator\n",
                "        if args.data_mode is not None:\n",
                "            net_params['data_mode'] = args.data_mode\n",
                "        if args.num_pool is not None:\n",
                "            net_params['num_pool'] = int(args.num_pool)\n",
                "        if args.gnn_per_block is not None:\n",
                "            net_params['gnn_per_block'] = int(args.gnn_per_block)\n",
                "        if args.embedding_dim is not None:\n",
                "            net_params['embedding_dim'] = int(args.embedding_dim)\n",
                "        if args.pool_ratio is not None:\n",
                "            net_params['pool_ratio'] = float(args.pool_ratio)\n",
                "        if args.linkpred is not None:\n",
                "            net_params['linkpred'] = True if args.linkpred=='True' else False\n",
                "        if args.cat is not None:\n",
                "            net_params['cat'] = True if args.cat=='True' else False\n",
                "        if args.self_loop is not None:\n",
                "            net_params['self_loop'] = True if args.self_loop=='True' else False\n",
                "        if args.num_train_data is not None:\n",
                "            net_params['num_train_data'] = int(args.num_train_data)\n",
                "\n",
                "            \n",
                "    # notebook mode\n",
                "    if notebook_mode:\n",
                "        \n",
                "        # parameters\n",
                "        params = config['params']\n",
                "        \n",
                "        # dataset\n",
                "        DATASET_NAME = config['dataset']\n",
                "        dataset = LoadData(DATASET_NAME)\n",
                "        \n",
                "        # device\n",
                "        device = gpu_setup(config['gpu']['use'], config['gpu']['id'])\n",
                "        out_dir = config['out_dir']\n",
                "        \n",
                "        # GNN model\n",
                "        MODEL_NAME = config['model']\n",
                "        \n",
                "        # network parameters\n",
                "        net_params = config['net_params']\n",
                "        net_params['device'] = device\n",
                "        net_params['gpu_id'] = config['gpu']['id']\n",
                "        net_params['batch_size'] = params['batch_size']\n",
                "              \n",
                "    D = torch.cat([torch.sparse.sum(g.adjacency_matrix(transpose=True), dim=-1).to_dense() for g in\n",
                "                   dataset.train.graph_lists])\n",
                "    net_params['avg_d'] = dict(lin=torch.mean(D),\n",
                "                               exp=torch.mean(torch.exp(torch.div(1, D)) - 1),\n",
                "                               log=torch.mean(torch.log(D + 1)))\n",
                "        \n",
                "    root_log_dir = out_dir + 'logs/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
                "    root_ckpt_dir = out_dir + 'checkpoints/' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
                "    write_file_name = out_dir + 'results/result_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
                "    write_config_file = out_dir + 'configs/config_' + MODEL_NAME + \"_\" + DATASET_NAME + \"_GPU\" + str(config['gpu']['id']) + \"_\" + time.strftime('%Hh%Mm%Ss_on_%b_%d_%Y')\n",
                "    dirs = root_log_dir, root_ckpt_dir, write_file_name, write_config_file\n",
                "\n",
                "    if not os.path.exists(out_dir + 'results'):\n",
                "        os.makedirs(out_dir + 'results')\n",
                "        \n",
                "    if not os.path.exists(out_dir + 'configs'):\n",
                "        os.makedirs(out_dir + 'configs')\n",
                "\n",
                "    net_params['total_param'] = view_model_param(MODEL_NAME, net_params)\n",
                "    train_val_pipeline(MODEL_NAME, dataset, params, net_params, dirs)\n",
                "\n",
                "    \n",
                "    \n",
                "if notebook_mode==True:\n",
                "    \n",
                "    config = {}\n",
                "    # gpu config\n",
                "    gpu = {}\n",
                "    gpu['use'] = use_gpu\n",
                "    gpu['id'] = gpu_id\n",
                "    config['gpu'] = gpu\n",
                "    # GNN model, dataset, out_dir\n",
                "    config['model'] = MODEL_NAME\n",
                "    config['dataset'] = DATASET_NAME\n",
                "    config['out_dir'] = out_dir\n",
                "    # parameters\n",
                "    params = {}\n",
                "    params['seed'] = seed\n",
                "    params['epochs'] = epochs\n",
                "    params['batch_size'] = batch_size\n",
                "    params['init_lr'] = init_lr\n",
                "    params['lr_reduce_factor'] = lr_reduce_factor \n",
                "    params['lr_schedule_patience'] = lr_schedule_patience\n",
                "    params['min_lr'] = min_lr\n",
                "    params['weight_decay'] = weight_decay\n",
                "    params['print_epoch_interval'] = 5\n",
                "    params['max_time'] = max_time\n",
                "    config['params'] = params\n",
                "    # network parameters\n",
                "    config['net_params'] = net_params\n",
                "    \n",
                "    # convert to .py format\n",
                "    from utils.cleaner_main import *\n",
                "    cleaner_main('main_GraphTheoryProp_multitask')\n",
                "    \n",
                "    main(True,config)\n",
                "    \n",
                "else:\n",
                "    \n",
                "    main()\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "f7fe216062a07faf7ec3b52e917e13a4b7ba3074eea43b649aa296dc1fb0b724"
        },
        "kernelspec": {
            "display_name": "Python 3.8.10 ('gnn')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}